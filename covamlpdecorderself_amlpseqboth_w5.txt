2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:11167
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:11167
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:11167
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:11167
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for 4 nodes.
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for 4 nodes.
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-0-249 as rank 0
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-0-249 as rank 3
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for 4 nodes.
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-0-249 as rank 2
2023-01-12 15:47:18 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for 4 nodes.
2023-01-12 15:47:18 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-0-249 as rank 1
2023-01-12 15:47:23 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amlp_activation='softmax', apply_bert_init=True, arch='cmlm_transformer_wmt_en_de', attention_dropout=0.0, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, concatPE=True, cpu=False, criterion='nat_loss', cross_self_attention=False, curriculum=0, data='/mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=8, decoder_cross_attention_type='amlpseq', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=512, decoder_self_attention_type='covamlp2', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:11167', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dont_use_layernorm=False, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, encoder_self_attention_type='amlpseq', eval_bleu=True, eval_bleu_args='{"iter_decode_max_iter": 0, "iter_decode_with_beam": 1}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, insertCausalSelfAttn=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=20, label_smoothing=0.1, landmarks=16, left_pad_source='True', left_pad_target='False', length_loss_factor=0.1, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', maskdistshiftpower=1.0, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=16384, max_tokens_valid=16384, max_update=300000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, ngram_predictor=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=True, no_token_positional_embeddings=False, noise='random_mask', nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, pred_length_offset=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, replacefactor=0.3, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, selfcorrection=0, sentence_avg=False, sg_length_pred=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='de', src_embedding_copy=False, stop_time_hours=0, target_lang='en', task='translation_lev', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=40000, weight_decay=0.01, zero_sharding='none')
2023-01-12 15:47:24 | INFO | fairseq.tasks.translation | [de] dictionary: 39960 types
2023-01-12 15:47:24 | INFO | fairseq.tasks.translation | [en] dictionary: 39960 types
2023-01-12 15:47:24 | INFO | fairseq.data.data_utils | loaded 3000 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/valid.de-en.de
2023-01-12 15:47:24 | INFO | fairseq.data.data_utils | loaded 3000 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/valid.de-en.en
2023-01-12 15:47:24 | INFO | fairseq.tasks.translation | /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict valid de-en 3000 examples
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSCovAMLP2
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSCovAMLP2
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSCovAMLP2
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSCovAMLP2
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSCovAMLP2
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSCovAMLP2
2023-01-12 15:47:24 | INFO | root | Using efficient attention FSAMLPSeq
2023-01-12 15:47:25 | INFO | fairseq_cli.train | CMLMNATransformerModel(
  (encoder): FairseqNATEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39960, 512, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (PEfc): Linear(in_features=1024, out_features=512, bias=True)
  )
  (decoder): NATransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39960, 512, padding_idx=1)
    (PEfc): Linear(in_features=1024, out_features=512, bias=True)
    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (d_proj): Linear(in_features=512, out_features=512, bias=True)
          (d_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (c_proj): Linear(in_features=512, out_features=128, bias=True)
          (c_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (s_proj): Linear(in_features=64, out_features=64, bias=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (inner_proj): Linear(in_features=16, out_features=16, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (d_proj): Linear(in_features=512, out_features=512, bias=True)
          (d_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (c_proj): Linear(in_features=512, out_features=128, bias=True)
          (c_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (s_proj): Linear(in_features=64, out_features=64, bias=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (inner_proj): Linear(in_features=16, out_features=16, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (d_proj): Linear(in_features=512, out_features=512, bias=True)
          (d_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (c_proj): Linear(in_features=512, out_features=128, bias=True)
          (c_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (s_proj): Linear(in_features=64, out_features=64, bias=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (inner_proj): Linear(in_features=16, out_features=16, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (d_proj): Linear(in_features=512, out_features=512, bias=True)
          (d_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (c_proj): Linear(in_features=512, out_features=128, bias=True)
          (c_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (s_proj): Linear(in_features=64, out_features=64, bias=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (inner_proj): Linear(in_features=16, out_features=16, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (d_proj): Linear(in_features=512, out_features=512, bias=True)
          (d_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (c_proj): Linear(in_features=512, out_features=128, bias=True)
          (c_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (s_proj): Linear(in_features=64, out_features=64, bias=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (inner_proj): Linear(in_features=16, out_features=16, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (d_proj): Linear(in_features=512, out_features=512, bias=True)
          (d_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (c_proj): Linear(in_features=512, out_features=128, bias=True)
          (c_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)
          (s_proj): Linear(in_features=64, out_features=64, bias=True)
          (in_proj): Linear(in_features=512, out_features=512, bias=True)
          (inner_proj): Linear(in_features=16, out_features=16, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39960, bias=False)
    (embed_length): Embedding(256, 512)
  )
)
2023-01-12 15:47:25 | INFO | fairseq_cli.train | task: translation_lev (TranslationLevenshteinTask)
2023-01-12 15:47:25 | INFO | fairseq_cli.train | model: cmlm_transformer_wmt_en_de (CMLMNATransformerModel)
2023-01-12 15:47:25 | INFO | fairseq_cli.train | criterion: nat_loss (LabelSmoothedDualImitationCriterion)
2023-01-12 15:47:25 | INFO | fairseq_cli.train | num. model params: 69132256 (num. trained: 69132256)
2023-01-12 15:47:26 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-12 15:47:26 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-12 15:47:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-01-12 15:47:26 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-01-12 15:47:26 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-01-12 15:47:26 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-01-12 15:47:26 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-01-12 15:47:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-01-12 15:47:26 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-01-12 15:47:26 | INFO | fairseq_cli.train | max tokens per GPU = 16384 and max sentences per GPU = None
2023-01-12 15:47:26 | INFO | fairseq.trainer | no existing checkpoint found s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint_last.pt
2023-01-12 15:47:26 | INFO | fairseq.trainer | loading train data for epoch 1
2023-01-12 15:47:27 | INFO | fairseq.data.data_utils | loaded 3961179 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/train.de-en.de
2023-01-12 15:47:27 | INFO | fairseq.data.data_utils | loaded 3961179 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/train.de-en.en
2023-01-12 15:47:27 | INFO | fairseq.tasks.translation | /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict train de-en 3961179 examples
2023-01-12 15:47:30 | INFO | fairseq.trainer | begin training epoch 1
2023-01-12 15:49:52 | INFO | train_inner | epoch 001:    100 / 1978 loss=16.023, nll_loss=15.19, word_ins=15.214, length=8.093, ppl=66604.2, wps=45762, ups=0.77, wpb=59108.8, bsz=1998.2, num_updates=100, lr=1.34975e-06, gnorm=19.916, loss_scale=128, train_wall=129, wall=146
2023-01-12 15:52:00 | INFO | train_inner | epoch 001:    200 / 1978 loss=15.263, nll_loss=14.369, word_ins=14.477, length=7.864, ppl=39322.4, wps=46487.8, ups=0.78, wpb=59361.4, bsz=1947.1, num_updates=200, lr=2.5995e-06, gnorm=10.551, loss_scale=128, train_wall=127, wall=274
2023-01-12 15:54:07 | INFO | train_inner | epoch 001:    300 / 1978 loss=14.796, nll_loss=13.893, word_ins=14.048, length=7.484, ppl=28453.2, wps=46347.5, ups=0.78, wpb=59179.3, bsz=2037.1, num_updates=300, lr=3.84925e-06, gnorm=3.885, loss_scale=128, train_wall=127, wall=402
2023-01-12 15:56:14 | INFO | train_inner | epoch 001:    400 / 1978 loss=14.348, nll_loss=13.443, word_ins=13.643, length=7.044, ppl=20852.2, wps=46637.3, ups=0.79, wpb=59153.9, bsz=1975.5, num_updates=400, lr=5.099e-06, gnorm=3.109, loss_scale=128, train_wall=127, wall=528
2023-01-12 15:58:22 | INFO | train_inner | epoch 001:    500 / 1978 loss=13.801, nll_loss=12.871, word_ins=13.129, length=6.715, ppl=14271.4, wps=46577.8, ups=0.78, wpb=59393.1, bsz=2009.6, num_updates=500, lr=6.34875e-06, gnorm=2.999, loss_scale=128, train_wall=127, wall=656
2023-01-12 16:00:29 | INFO | train_inner | epoch 001:    600 / 1978 loss=13.314, nll_loss=12.348, word_ins=12.666, length=6.479, ppl=10185.6, wps=46570.5, ups=0.79, wpb=59278.4, bsz=2105.2, num_updates=600, lr=7.5985e-06, gnorm=2.797, loss_scale=128, train_wall=127, wall=783
2023-01-12 16:02:37 | INFO | train_inner | epoch 001:    700 / 1978 loss=12.828, nll_loss=11.799, word_ins=12.184, length=6.44, ppl=7270.37, wps=46141.1, ups=0.78, wpb=59036.3, bsz=1984.5, num_updates=700, lr=8.84825e-06, gnorm=2.482, loss_scale=128, train_wall=128, wall=911
2023-01-12 16:04:44 | INFO | train_inner | epoch 001:    800 / 1978 loss=12.319, nll_loss=11.262, word_ins=11.72, length=5.994, ppl=5110.5, wps=46686.9, ups=0.79, wpb=59113.1, bsz=1993.6, num_updates=800, lr=1.0098e-05, gnorm=2.914, loss_scale=128, train_wall=126, wall=1038
2023-01-12 16:06:52 | INFO | train_inner | epoch 001:    900 / 1978 loss=11.929, nll_loss=10.819, word_ins=11.347, length=5.818, ppl=3899.8, wps=46319.2, ups=0.78, wpb=59307.5, bsz=2063.4, num_updates=900, lr=1.13478e-05, gnorm=3.507, loss_scale=128, train_wall=128, wall=1166
2023-01-12 16:09:00 | INFO | train_inner | epoch 001:   1000 / 1978 loss=11.61, nll_loss=10.451, word_ins=11.051, length=5.591, ppl=3125.6, wps=46428.1, ups=0.78, wpb=59482.4, bsz=2068, num_updates=1000, lr=1.25975e-05, gnorm=3.273, loss_scale=128, train_wall=128, wall=1294
2023-01-12 16:11:07 | INFO | train_inner | epoch 001:   1100 / 1978 loss=11.406, nll_loss=10.206, word_ins=10.867, length=5.388, ppl=2713.11, wps=46599.1, ups=0.78, wpb=59397.7, bsz=2036.3, num_updates=1100, lr=1.38473e-05, gnorm=3.717, loss_scale=128, train_wall=127, wall=1421
2023-01-12 16:13:15 | INFO | train_inner | epoch 001:   1200 / 1978 loss=11.3, nll_loss=10.073, word_ins=10.779, length=5.212, ppl=2521.82, wps=46700.4, ups=0.78, wpb=59571.2, bsz=1983.2, num_updates=1200, lr=1.5097e-05, gnorm=3.602, loss_scale=128, train_wall=127, wall=1549
2023-01-12 16:15:22 | INFO | train_inner | epoch 001:   1300 / 1978 loss=11.263, nll_loss=10.015, word_ins=10.745, length=5.185, ppl=2458.06, wps=46857.6, ups=0.78, wpb=59703.8, bsz=1988.8, num_updates=1300, lr=1.63468e-05, gnorm=4.095, loss_scale=128, train_wall=127, wall=1676
2023-01-12 16:17:30 | INFO | train_inner | epoch 001:   1400 / 1978 loss=11.235, nll_loss=9.996, word_ins=10.735, length=4.999, ppl=2410.87, wps=46229, ups=0.78, wpb=59091.6, bsz=1959.8, num_updates=1400, lr=1.75965e-05, gnorm=4.368, loss_scale=128, train_wall=128, wall=1804
2023-01-12 16:19:38 | INFO | train_inner | epoch 001:   1500 / 1978 loss=11.168, nll_loss=9.927, word_ins=10.678, length=4.906, ppl=2301.48, wps=46313.3, ups=0.78, wpb=59020.2, bsz=1966.2, num_updates=1500, lr=1.88463e-05, gnorm=4.713, loss_scale=128, train_wall=127, wall=1932
2023-01-12 16:21:45 | INFO | train_inner | epoch 001:   1600 / 1978 loss=11.098, nll_loss=9.846, word_ins=10.609, length=4.888, ppl=2191.72, wps=46649.2, ups=0.78, wpb=59535.7, bsz=1973, num_updates=1600, lr=2.0096e-05, gnorm=5.191, loss_scale=128, train_wall=127, wall=2059
2023-01-12 16:23:53 | INFO | train_inner | epoch 001:   1700 / 1978 loss=11.069, nll_loss=9.817, word_ins=10.583, length=4.856, ppl=2148.19, wps=46432, ups=0.78, wpb=59202.2, bsz=2037.6, num_updates=1700, lr=2.13458e-05, gnorm=5.306, loss_scale=128, train_wall=127, wall=2187
2023-01-12 16:26:00 | INFO | train_inner | epoch 001:   1800 / 1978 loss=11.005, nll_loss=9.743, word_ins=10.521, length=4.834, ppl=2054.67, wps=46347, ups=0.79, wpb=59000.9, bsz=1959.2, num_updates=1800, lr=2.25955e-05, gnorm=5.632, loss_scale=128, train_wall=127, wall=2314
2023-01-12 16:28:08 | INFO | train_inner | epoch 001:   1900 / 1978 loss=10.871, nll_loss=9.616, word_ins=10.41, length=4.609, ppl=1872.5, wps=46669.7, ups=0.78, wpb=59757.9, bsz=2060.6, num_updates=1900, lr=2.38453e-05, gnorm=5.42, loss_scale=128, train_wall=128, wall=2442
2023-01-12 16:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 16:30:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.306 | nll_loss 10.114 | word_ins 10.86 | length 4.476 | ppl 2532.38 | wps 133651 | wpb 40242.5 | bsz 1500 | num_updates 1978
2023-01-12 16:30:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 16:30:40 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint1.pt (epoch 1 @ 1978 updates, score 11.306) (writing took 40.16496227495372 seconds)
2023-01-12 16:30:40 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-01-12 16:30:40 | INFO | train | epoch 001 | loss 12.392 | nll_loss 11.282 | word_ins 11.805 | length 5.87 | ppl 5374.75 | wps 45496.9 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 1978 | lr 2.48201e-05 | gnorm 5.152 | loss_scale 128 | train_wall 2520 | wall 2594
2023-01-12 16:30:40 | INFO | fairseq.trainer | begin training epoch 2
2023-01-12 16:31:21 | INFO | train_inner | epoch 002:     22 / 1978 loss=10.836, nll_loss=9.56, word_ins=10.361, length=4.743, ppl=1827.67, wps=30672.6, ups=0.52, wpb=59161.8, bsz=1891.4, num_updates=2000, lr=2.5095e-05, gnorm=5.507, loss_scale=128, train_wall=127, wall=2635
2023-01-12 16:33:28 | INFO | train_inner | epoch 002:    122 / 1978 loss=10.708, nll_loss=9.439, word_ins=10.255, length=4.525, ppl=1672.36, wps=46480.2, ups=0.79, wpb=59207.7, bsz=2051.7, num_updates=2100, lr=2.63448e-05, gnorm=5.44, loss_scale=128, train_wall=127, wall=2762
2023-01-12 16:35:36 | INFO | train_inner | epoch 002:    222 / 1978 loss=10.682, nll_loss=9.394, word_ins=10.216, length=4.652, ppl=1642.52, wps=46213.2, ups=0.79, wpb=58751.6, bsz=1963.6, num_updates=2200, lr=2.75945e-05, gnorm=5.44, loss_scale=128, train_wall=127, wall=2890
2023-01-12 16:37:44 | INFO | train_inner | epoch 002:    322 / 1978 loss=10.558, nll_loss=9.262, word_ins=10.101, length=4.567, ppl=1507.88, wps=46420.7, ups=0.78, wpb=59490.1, bsz=2073.3, num_updates=2300, lr=2.88443e-05, gnorm=5.773, loss_scale=128, train_wall=128, wall=3018
2023-01-12 16:39:51 | INFO | train_inner | epoch 002:    422 / 1978 loss=10.439, nll_loss=9.139, word_ins=9.995, length=4.433, ppl=1387.83, wps=46645, ups=0.79, wpb=59330.3, bsz=2091.3, num_updates=2400, lr=3.0094e-05, gnorm=5.392, loss_scale=128, train_wall=127, wall=3145
2023-01-12 16:41:58 | INFO | train_inner | epoch 002:    522 / 1978 loss=10.396, nll_loss=9.066, word_ins=9.933, length=4.635, ppl=1347.6, wps=46608.5, ups=0.79, wpb=59228.1, bsz=1929.4, num_updates=2500, lr=3.13438e-05, gnorm=5.765, loss_scale=128, train_wall=127, wall=3272
2023-01-12 16:44:05 | INFO | train_inner | epoch 002:    622 / 1978 loss=10.311, nll_loss=8.978, word_ins=9.857, length=4.538, ppl=1270.63, wps=46873.9, ups=0.79, wpb=59640.4, bsz=1988, num_updates=2600, lr=3.25935e-05, gnorm=5.976, loss_scale=128, train_wall=127, wall=3399
2023-01-12 16:46:13 | INFO | train_inner | epoch 002:    722 / 1978 loss=10.253, nll_loss=8.918, word_ins=9.807, length=4.462, ppl=1220.27, wps=46550.9, ups=0.78, wpb=59687.2, bsz=2007.6, num_updates=2700, lr=3.38433e-05, gnorm=4.85, loss_scale=128, train_wall=128, wall=3528
2023-01-12 16:48:20 | INFO | train_inner | epoch 002:    822 / 1978 loss=10.201, nll_loss=8.849, word_ins=9.748, length=4.529, ppl=1176.88, wps=46897.3, ups=0.79, wpb=59356.3, bsz=1925.6, num_updates=2800, lr=3.5093e-05, gnorm=5.304, loss_scale=128, train_wall=126, wall=3654
2023-01-12 16:50:27 | INFO | train_inner | epoch 002:    922 / 1978 loss=10.046, nll_loss=8.685, word_ins=9.606, length=4.396, ppl=1056.88, wps=46957.8, ups=0.78, wpb=59826.5, bsz=2119.2, num_updates=2900, lr=3.63428e-05, gnorm=4.875, loss_scale=128, train_wall=127, wall=3781
2023-01-12 16:52:34 | INFO | train_inner | epoch 002:   1022 / 1978 loss=10.053, nll_loss=8.673, word_ins=9.598, length=4.55, ppl=1062.22, wps=46791.2, ups=0.79, wpb=59314.3, bsz=1933.7, num_updates=3000, lr=3.75925e-05, gnorm=5.57, loss_scale=128, train_wall=127, wall=3908
2023-01-12 16:54:42 | INFO | train_inner | epoch 002:   1122 / 1978 loss=9.993, nll_loss=8.615, word_ins=9.548, length=4.455, ppl=1019.37, wps=46153.8, ups=0.78, wpb=59152.7, bsz=1970, num_updates=3100, lr=3.88423e-05, gnorm=5.009, loss_scale=128, train_wall=128, wall=4036
2023-01-12 16:56:50 | INFO | train_inner | epoch 002:   1222 / 1978 loss=9.93, nll_loss=8.533, word_ins=9.478, length=4.517, ppl=975.27, wps=46412.7, ups=0.78, wpb=59201, bsz=1948.8, num_updates=3200, lr=4.0092e-05, gnorm=5.115, loss_scale=128, train_wall=127, wall=4164
2023-01-12 16:58:58 | INFO | train_inner | epoch 002:   1322 / 1978 loss=9.859, nll_loss=8.463, word_ins=9.417, length=4.421, ppl=928.48, wps=46388.9, ups=0.78, wpb=59222.7, bsz=2044.7, num_updates=3300, lr=4.13418e-05, gnorm=5.157, loss_scale=128, train_wall=127, wall=4292
2023-01-12 17:01:05 | INFO | train_inner | epoch 002:   1422 / 1978 loss=9.804, nll_loss=8.395, word_ins=9.36, length=4.44, ppl=893.93, wps=46413.1, ups=0.78, wpb=59259.2, bsz=1991.5, num_updates=3400, lr=4.25915e-05, gnorm=5.286, loss_scale=128, train_wall=127, wall=4419
2023-01-12 17:03:12 | INFO | train_inner | epoch 002:   1522 / 1978 loss=9.742, nll_loss=8.321, word_ins=9.297, length=4.449, ppl=856.09, wps=46470.2, ups=0.79, wpb=58972, bsz=2027.1, num_updates=3500, lr=4.38413e-05, gnorm=5.014, loss_scale=128, train_wall=127, wall=4546
2023-01-12 17:05:20 | INFO | train_inner | epoch 002:   1622 / 1978 loss=9.688, nll_loss=8.263, word_ins=9.245, length=4.425, ppl=824.6, wps=46026.3, ups=0.78, wpb=58808.2, bsz=2101.6, num_updates=3600, lr=4.5091e-05, gnorm=5.374, loss_scale=128, train_wall=128, wall=4674
2023-01-12 17:07:28 | INFO | train_inner | epoch 002:   1722 / 1978 loss=9.636, nll_loss=8.209, word_ins=9.201, length=4.35, ppl=795.64, wps=46163.8, ups=0.78, wpb=58938.4, bsz=2081.3, num_updates=3700, lr=4.63408e-05, gnorm=4.952, loss_scale=128, train_wall=127, wall=4802
2023-01-12 17:09:35 | INFO | train_inner | epoch 002:   1822 / 1978 loss=9.594, nll_loss=8.149, word_ins=9.151, length=4.434, ppl=772.9, wps=46943.8, ups=0.79, wpb=59710.6, bsz=1938.2, num_updates=3800, lr=4.75905e-05, gnorm=4.885, loss_scale=128, train_wall=127, wall=4929
2023-01-12 17:11:42 | INFO | train_inner | epoch 002:   1922 / 1978 loss=9.569, nll_loss=8.126, word_ins=9.132, length=4.373, ppl=759.54, wps=46562.4, ups=0.79, wpb=59098, bsz=1890.4, num_updates=3900, lr=4.88403e-05, gnorm=5.325, loss_scale=128, train_wall=127, wall=5056
2023-01-12 17:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 17:13:06 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.162 | nll_loss 8.822 | word_ins 9.756 | length 4.061 | ppl 1145.9 | wps 127193 | wpb 40242.5 | bsz 1500 | num_updates 3956 | best_loss 10.162
2023-01-12 17:13:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 17:13:47 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint2.pt (epoch 2 @ 3956 updates, score 10.162) (writing took 40.13813304109499 seconds)
2023-01-12 17:13:47 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-01-12 17:13:47 | INFO | train | epoch 002 | loss 10.069 | nll_loss 8.7 | word_ins 9.621 | length 4.481 | ppl 1073.87 | wps 45342.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 3956 | lr 4.95401e-05 | gnorm 5.286 | loss_scale 128 | train_wall 2516 | wall 5181
2023-01-12 17:13:47 | INFO | fairseq.trainer | begin training epoch 3
2023-01-12 17:14:55 | INFO | train_inner | epoch 003:     44 / 1978 loss=9.486, nll_loss=8.026, word_ins=9.047, length=4.39, ppl=716.91, wps=31014.5, ups=0.52, wpb=59814.4, bsz=1944.2, num_updates=4000, lr=5.009e-05, gnorm=4.907, loss_scale=128, train_wall=127, wall=5249
2023-01-12 17:17:02 | INFO | train_inner | epoch 003:    144 / 1978 loss=9.439, nll_loss=7.97, word_ins=8.998, length=4.41, ppl=694.17, wps=46476, ups=0.78, wpb=59425.8, bsz=2013.8, num_updates=4100, lr=5.13398e-05, gnorm=5.168, loss_scale=256, train_wall=128, wall=5377
2023-01-12 17:19:11 | INFO | train_inner | epoch 003:    244 / 1978 loss=9.36, nll_loss=7.942, word_ins=8.934, length=4.253, ppl=656.94, wps=46311.9, ups=0.78, wpb=59523.1, bsz=2085.2, num_updates=4200, lr=5.25895e-05, gnorm=4.905, loss_scale=256, train_wall=128, wall=5505
2023-01-12 17:21:19 | INFO | train_inner | epoch 003:    344 / 1978 loss=9.345, nll_loss=7.912, word_ins=8.903, length=4.421, ppl=650.43, wps=46527.9, ups=0.78, wpb=59392, bsz=1977.4, num_updates=4300, lr=5.38393e-05, gnorm=4.864, loss_scale=256, train_wall=127, wall=5633
2023-01-12 17:23:27 | INFO | train_inner | epoch 003:    444 / 1978 loss=9.286, nll_loss=7.862, word_ins=8.858, length=4.283, ppl=624.32, wps=46489.1, ups=0.78, wpb=59522.3, bsz=1968.6, num_updates=4400, lr=5.5089e-05, gnorm=4.323, loss_scale=256, train_wall=128, wall=5761
2023-01-12 17:25:34 | INFO | train_inner | epoch 003:    544 / 1978 loss=9.29, nll_loss=7.865, word_ins=8.86, length=4.304, ppl=626.06, wps=46466.5, ups=0.79, wpb=58958.2, bsz=1963.6, num_updates=4500, lr=5.63388e-05, gnorm=4.733, loss_scale=256, train_wall=127, wall=5888
2023-01-12 17:27:41 | INFO | train_inner | epoch 003:    644 / 1978 loss=9.184, nll_loss=7.747, word_ins=8.755, length=4.284, ppl=581.53, wps=46854, ups=0.79, wpb=59629.8, bsz=2014.2, num_updates=4600, lr=5.75885e-05, gnorm=4.736, loss_scale=256, train_wall=127, wall=6015
2023-01-12 17:29:48 | INFO | train_inner | epoch 003:    744 / 1978 loss=9.177, nll_loss=7.722, word_ins=8.733, length=4.435, ppl=578.79, wps=46374.5, ups=0.79, wpb=58984, bsz=1950.5, num_updates=4700, lr=5.88383e-05, gnorm=4.918, loss_scale=256, train_wall=127, wall=6142
2023-01-12 17:31:56 | INFO | train_inner | epoch 003:    844 / 1978 loss=9.12, nll_loss=7.675, word_ins=8.692, length=4.282, ppl=556.37, wps=45960.6, ups=0.78, wpb=58908.9, bsz=2029.8, num_updates=4800, lr=6.0088e-05, gnorm=4.876, loss_scale=256, train_wall=128, wall=6270
2023-01-12 17:34:03 | INFO | train_inner | epoch 003:    944 / 1978 loss=9.127, nll_loss=7.672, word_ins=8.69, length=4.376, ppl=559.18, wps=46497.5, ups=0.79, wpb=59083.8, bsz=1907.9, num_updates=4900, lr=6.13378e-05, gnorm=4.582, loss_scale=256, train_wall=127, wall=6398
2023-01-12 17:36:11 | INFO | train_inner | epoch 003:   1044 / 1978 loss=9.089, nll_loss=7.616, word_ins=8.641, length=4.482, ppl=544.61, wps=46457.6, ups=0.79, wpb=59086.6, bsz=1924.2, num_updates=5000, lr=6.25875e-05, gnorm=4.924, loss_scale=256, train_wall=127, wall=6525
2023-01-12 17:38:18 | INFO | train_inner | epoch 003:   1144 / 1978 loss=8.973, nll_loss=7.5, word_ins=8.54, length=4.337, ppl=502.61, wps=46763.2, ups=0.78, wpb=59645.6, bsz=2011.6, num_updates=5100, lr=6.38373e-05, gnorm=4.666, loss_scale=256, train_wall=127, wall=6652
2023-01-12 17:40:26 | INFO | train_inner | epoch 003:   1244 / 1978 loss=8.892, nll_loss=7.412, word_ins=8.462, length=4.302, ppl=475.04, wps=46491.4, ups=0.78, wpb=59635.9, bsz=2093.8, num_updates=5200, lr=6.5087e-05, gnorm=4.404, loss_scale=256, train_wall=128, wall=6781
2023-01-12 17:42:35 | INFO | train_inner | epoch 003:   1344 / 1978 loss=8.873, nll_loss=7.398, word_ins=8.449, length=4.241, ppl=468.97, wps=46179.8, ups=0.78, wpb=59426.4, bsz=2104.5, num_updates=5300, lr=6.63368e-05, gnorm=4.802, loss_scale=256, train_wall=128, wall=6909
2023-01-12 17:44:42 | INFO | train_inner | epoch 003:   1444 / 1978 loss=8.93, nll_loss=7.444, word_ins=8.491, length=4.392, ppl=487.78, wps=46564.4, ups=0.79, wpb=59166.6, bsz=1883.5, num_updates=5400, lr=6.75865e-05, gnorm=4.462, loss_scale=256, train_wall=127, wall=7036
2023-01-12 17:46:50 | INFO | train_inner | epoch 003:   1544 / 1978 loss=8.846, nll_loss=7.351, word_ins=8.41, length=4.357, ppl=460.15, wps=45749.7, ups=0.78, wpb=58658.5, bsz=2086.9, num_updates=5500, lr=6.88363e-05, gnorm=4.653, loss_scale=256, train_wall=128, wall=7165
2023-01-12 17:48:57 | INFO | train_inner | epoch 003:   1644 / 1978 loss=8.813, nll_loss=7.326, word_ins=8.389, length=4.237, ppl=449.62, wps=47001.4, ups=0.79, wpb=59525.6, bsz=1977.2, num_updates=5600, lr=7.0086e-05, gnorm=4.253, loss_scale=256, train_wall=126, wall=7291
2023-01-12 17:51:04 | INFO | train_inner | epoch 003:   1744 / 1978 loss=8.7, nll_loss=7.198, word_ins=8.276, length=4.238, ppl=415.86, wps=47023.6, ups=0.79, wpb=59700.5, bsz=2020.8, num_updates=5700, lr=7.13358e-05, gnorm=4.276, loss_scale=256, train_wall=127, wall=7418
2023-01-12 17:53:11 | INFO | train_inner | epoch 003:   1844 / 1978 loss=8.692, nll_loss=7.184, word_ins=8.265, length=4.27, ppl=413.57, wps=46124.5, ups=0.78, wpb=58777.1, bsz=2095.5, num_updates=5800, lr=7.25855e-05, gnorm=4.59, loss_scale=256, train_wall=127, wall=7546
2023-01-12 17:55:18 | INFO | train_inner | epoch 003:   1944 / 1978 loss=8.697, nll_loss=7.178, word_ins=8.26, length=4.364, ppl=414.89, wps=46734.6, ups=0.79, wpb=59082.4, bsz=1975.5, num_updates=5900, lr=7.38353e-05, gnorm=4.515, loss_scale=256, train_wall=126, wall=7672
2023-01-12 17:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 17:56:14 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.469 | nll_loss 8.043 | word_ins 9.044 | length 4.243 | ppl 708.73 | wps 127566 | wpb 40242.5 | bsz 1500 | num_updates 5934 | best_loss 9.469
2023-01-12 17:56:14 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 17:56:54 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint3.pt (epoch 3 @ 5934 updates, score 9.469) (writing took 40.373024637810886 seconds)
2023-01-12 17:56:54 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-01-12 17:56:54 | INFO | train | epoch 003 | loss 9.046 | nll_loss 7.578 | word_ins 8.612 | length 4.334 | ppl 528.56 | wps 45321.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 5934 | lr 7.42602e-05 | gnorm 4.658 | loss_scale 256 | train_wall 2519 | wall 7768
2023-01-12 17:56:54 | INFO | fairseq.trainer | begin training epoch 4
2023-01-12 17:58:30 | INFO | train_inner | epoch 004:     66 / 1978 loss=8.608, nll_loss=7.083, word_ins=8.176, length=4.312, ppl=390.07, wps=30724.5, ups=0.52, wpb=59028, bsz=2043.6, num_updates=6000, lr=7.5085e-05, gnorm=4.606, loss_scale=256, train_wall=127, wall=7864
2023-01-12 18:00:38 | INFO | train_inner | epoch 004:    166 / 1978 loss=8.606, nll_loss=7.072, word_ins=8.169, length=4.377, ppl=389.71, wps=46014, ups=0.78, wpb=58694.1, bsz=1951, num_updates=6100, lr=7.63348e-05, gnorm=4.653, loss_scale=256, train_wall=127, wall=7992
2023-01-12 18:02:45 | INFO | train_inner | epoch 004:    266 / 1978 loss=8.58, nll_loss=7.055, word_ins=8.153, length=4.275, ppl=382.73, wps=46150.3, ups=0.79, wpb=58776.4, bsz=2002.6, num_updates=6200, lr=7.75845e-05, gnorm=4.582, loss_scale=256, train_wall=127, wall=8119
2023-01-12 18:04:52 | INFO | train_inner | epoch 004:    366 / 1978 loss=8.555, nll_loss=7.013, word_ins=8.117, length=4.378, ppl=375.99, wps=46809.1, ups=0.79, wpb=59407.8, bsz=2035.8, num_updates=6300, lr=7.88343e-05, gnorm=5.01, loss_scale=256, train_wall=127, wall=8246
2023-01-12 18:06:59 | INFO | train_inner | epoch 004:    466 / 1978 loss=8.511, nll_loss=6.974, word_ins=8.083, length=4.28, ppl=364.93, wps=46969.3, ups=0.79, wpb=59494.9, bsz=1908.6, num_updates=6400, lr=8.0084e-05, gnorm=4.489, loss_scale=256, train_wall=126, wall=8373
2023-01-12 18:09:06 | INFO | train_inner | epoch 004:    566 / 1978 loss=8.437, nll_loss=6.886, word_ins=8.006, length=4.304, ppl=346.49, wps=46513.5, ups=0.79, wpb=59122.8, bsz=1969.3, num_updates=6500, lr=8.13338e-05, gnorm=4.632, loss_scale=256, train_wall=127, wall=8500
2023-01-12 18:11:12 | INFO | train_inner | epoch 004:    666 / 1978 loss=8.35, nll_loss=6.793, word_ins=7.925, length=4.259, ppl=326.38, wps=46918.1, ups=0.79, wpb=59331.5, bsz=1970.7, num_updates=6600, lr=8.25835e-05, gnorm=4.679, loss_scale=256, train_wall=126, wall=8626
2023-01-12 18:13:20 | INFO | train_inner | epoch 004:    766 / 1978 loss=8.249, nll_loss=6.671, word_ins=7.817, length=4.322, ppl=304.28, wps=46593.8, ups=0.78, wpb=59496.1, bsz=2072.1, num_updates=6700, lr=8.38333e-05, gnorm=4.689, loss_scale=256, train_wall=127, wall=8754
2023-01-12 18:15:27 | INFO | train_inner | epoch 004:    866 / 1978 loss=8.217, nll_loss=6.642, word_ins=7.793, length=4.241, ppl=297.5, wps=46685.2, ups=0.79, wpb=59266.5, bsz=1942.1, num_updates=6800, lr=8.5083e-05, gnorm=4.732, loss_scale=256, train_wall=127, wall=8881
2023-01-12 18:17:35 | INFO | train_inner | epoch 004:    966 / 1978 loss=8.079, nll_loss=6.492, word_ins=7.661, length=4.177, ppl=270.43, wps=46254.5, ups=0.78, wpb=59392.1, bsz=2086.3, num_updates=6900, lr=8.63328e-05, gnorm=4.821, loss_scale=256, train_wall=128, wall=9009
2023-01-12 18:19:43 | INFO | train_inner | epoch 004:   1066 / 1978 loss=7.971, nll_loss=6.366, word_ins=7.551, length=4.201, ppl=250.89, wps=46613, ups=0.78, wpb=59663.1, bsz=2033.3, num_updates=7000, lr=8.75825e-05, gnorm=4.901, loss_scale=256, train_wall=128, wall=9137
2023-01-12 18:21:52 | INFO | train_inner | epoch 004:   1166 / 1978 loss=7.9, nll_loss=6.274, word_ins=7.471, length=4.296, ppl=238.9, wps=46146.2, ups=0.78, wpb=59243, bsz=2080.7, num_updates=7100, lr=8.88323e-05, gnorm=4.521, loss_scale=256, train_wall=128, wall=9266
2023-01-12 18:23:59 | INFO | train_inner | epoch 004:   1266 / 1978 loss=7.881, nll_loss=6.245, word_ins=7.445, length=4.356, ppl=235.74, wps=46291.9, ups=0.78, wpb=59096.1, bsz=1976.4, num_updates=7200, lr=9.0082e-05, gnorm=4.977, loss_scale=256, train_wall=127, wall=9393
2023-01-12 18:26:08 | INFO | train_inner | epoch 004:   1366 / 1978 loss=7.725, nll_loss=6.092, word_ins=7.311, length=4.137, ppl=211.53, wps=46262.5, ups=0.78, wpb=59492.5, bsz=2066, num_updates=7300, lr=9.13318e-05, gnorm=4.805, loss_scale=256, train_wall=128, wall=9522
2023-01-12 18:29:24 | INFO | train_inner | epoch 004:   1466 / 1978 loss=7.751, nll_loss=6.092, word_ins=7.313, length=4.377, ppl=215.36, wps=29887.5, ups=0.51, wpb=58684.2, bsz=1936.7, num_updates=7400, lr=9.25815e-05, gnorm=4.836, loss_scale=256, train_wall=196, wall=9718
2023-01-12 18:31:31 | INFO | train_inner | epoch 004:   1566 / 1978 loss=7.624, nll_loss=5.957, word_ins=7.194, length=4.305, ppl=197.3, wps=47124, ups=0.79, wpb=59775.9, bsz=1941, num_updates=7500, lr=9.38313e-05, gnorm=4.387, loss_scale=256, train_wall=127, wall=9845
2023-01-12 18:33:38 | INFO | train_inner | epoch 004:   1666 / 1978 loss=7.518, nll_loss=5.845, word_ins=7.095, length=4.223, ppl=183.28, wps=46986, ups=0.79, wpb=59709.6, bsz=2041.6, num_updates=7600, lr=9.5081e-05, gnorm=4.574, loss_scale=256, train_wall=127, wall=9972
2023-01-12 18:35:45 | INFO | train_inner | epoch 004:   1766 / 1978 loss=7.458, nll_loss=5.777, word_ins=7.038, length=4.202, ppl=175.79, wps=46431.4, ups=0.79, wpb=59022.9, bsz=1996.7, num_updates=7700, lr=9.63308e-05, gnorm=4.406, loss_scale=256, train_wall=127, wall=10099
2023-01-12 18:37:53 | INFO | train_inner | epoch 004:   1866 / 1978 loss=7.355, nll_loss=5.648, word_ins=6.925, length=4.298, ppl=163.7, wps=46871.4, ups=0.78, wpb=59862.3, bsz=1979, num_updates=7800, lr=9.75805e-05, gnorm=4.5, loss_scale=256, train_wall=128, wall=10227
2023-01-12 18:40:01 | INFO | train_inner | epoch 004:   1966 / 1978 loss=7.313, nll_loss=5.596, word_ins=6.88, length=4.327, ppl=158.98, wps=46164.3, ups=0.78, wpb=59174.3, bsz=2023.4, num_updates=7900, lr=9.88303e-05, gnorm=4.617, loss_scale=256, train_wall=128, wall=10355
2023-01-12 18:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 18:40:30 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.061 | nll_loss 6.423 | word_ins 7.648 | length 4.127 | ppl 267.04 | wps 95704 | wpb 40242.5 | bsz 1500 | num_updates 7912 | best_loss 8.061
2023-01-12 18:40:30 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 18:41:10 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint4.pt (epoch 4 @ 7912 updates, score 8.061) (writing took 39.9700276684016 seconds)
2023-01-12 18:41:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-01-12 18:41:10 | INFO | train | epoch 004 | loss 8.02 | nll_loss 6.413 | word_ins 7.593 | length 4.28 | ppl 259.66 | wps 44149.9 | ups 0.74 | wpb 59284.3 | bsz 2002.6 | num_updates 7912 | lr 9.89802e-05 | gnorm 4.679 | loss_scale 256 | train_wall 2587 | wall 10424
2023-01-12 18:41:10 | INFO | fairseq.trainer | begin training epoch 5
2023-01-12 18:43:14 | INFO | train_inner | epoch 005:     88 / 1978 loss=7.21, nll_loss=5.501, word_ins=6.798, length=4.124, ppl=148.07, wps=30577.6, ups=0.52, wpb=58952.2, bsz=2080.6, num_updates=8000, lr=0.00010008, gnorm=4.649, loss_scale=256, train_wall=127, wall=10548
2023-01-12 18:45:22 | INFO | train_inner | epoch 005:    188 / 1978 loss=7.154, nll_loss=5.425, word_ins=6.732, length=4.224, ppl=142.41, wps=46386, ups=0.78, wpb=59430.1, bsz=2076.2, num_updates=8100, lr=0.00010133, gnorm=4.246, loss_scale=256, train_wall=128, wall=10676
2023-01-12 18:47:29 | INFO | train_inner | epoch 005:    288 / 1978 loss=7.155, nll_loss=5.414, word_ins=6.724, length=4.309, ppl=142.54, wps=46082.2, ups=0.78, wpb=58721.3, bsz=2013.8, num_updates=8200, lr=0.00010258, gnorm=4.561, loss_scale=512, train_wall=127, wall=10804
2023-01-12 18:49:37 | INFO | train_inner | epoch 005:    388 / 1978 loss=7.098, nll_loss=5.337, word_ins=6.674, length=4.238, ppl=137.01, wps=46628.9, ups=0.78, wpb=59506.9, bsz=1980.2, num_updates=8300, lr=0.000103829, gnorm=4.639, loss_scale=512, train_wall=127, wall=10931
2023-01-12 18:51:44 | INFO | train_inner | epoch 005:    488 / 1978 loss=7.075, nll_loss=5.303, word_ins=6.649, length=4.266, ppl=134.87, wps=46455, ups=0.79, wpb=59100.9, bsz=1928.6, num_updates=8400, lr=0.000105079, gnorm=4.405, loss_scale=512, train_wall=127, wall=11058
2023-01-12 18:53:53 | INFO | train_inner | epoch 005:    588 / 1978 loss=6.934, nll_loss=5.145, word_ins=6.513, length=4.218, ppl=122.3, wps=46491, ups=0.78, wpb=59861.8, bsz=2076.6, num_updates=8500, lr=0.000106329, gnorm=4.592, loss_scale=512, train_wall=129, wall=11187
2023-01-12 18:56:02 | INFO | train_inner | epoch 005:    688 / 1978 loss=6.835, nll_loss=5.034, word_ins=6.416, length=4.185, ppl=114.16, wps=46034, ups=0.77, wpb=59402.3, bsz=2071.5, num_updates=8600, lr=0.000107579, gnorm=4.307, loss_scale=512, train_wall=129, wall=11316
2023-01-12 18:58:10 | INFO | train_inner | epoch 005:    788 / 1978 loss=6.866, nll_loss=5.057, word_ins=6.439, length=4.275, ppl=116.68, wps=46510.5, ups=0.78, wpb=59260.3, bsz=1912.6, num_updates=8700, lr=0.000108828, gnorm=4.426, loss_scale=512, train_wall=127, wall=11444
2023-01-12 19:00:17 | INFO | train_inner | epoch 005:    888 / 1978 loss=6.837, nll_loss=5.027, word_ins=6.414, length=4.229, ppl=114.34, wps=46817.4, ups=0.79, wpb=59590.8, bsz=1944.4, num_updates=8800, lr=0.000110078, gnorm=4.387, loss_scale=512, train_wall=127, wall=11571
2023-01-12 19:02:25 | INFO | train_inner | epoch 005:    988 / 1978 loss=6.719, nll_loss=4.896, word_ins=6.3, length=4.186, ppl=105.34, wps=45988.4, ups=0.78, wpb=59009.5, bsz=2035.6, num_updates=8900, lr=0.000111328, gnorm=4.632, loss_scale=512, train_wall=128, wall=11699
2023-01-12 19:04:33 | INFO | train_inner | epoch 005:   1088 / 1978 loss=6.674, nll_loss=4.846, word_ins=6.258, length=4.162, ppl=102.1, wps=46143.1, ups=0.78, wpb=59020.6, bsz=2068.9, num_updates=9000, lr=0.000112578, gnorm=4.321, loss_scale=512, train_wall=128, wall=11827
2023-01-12 19:06:39 | INFO | train_inner | epoch 005:   1188 / 1978 loss=6.655, nll_loss=4.814, word_ins=6.231, length=4.238, ppl=100.77, wps=47021.8, ups=0.79, wpb=59428.2, bsz=2011.1, num_updates=9100, lr=0.000113827, gnorm=4.637, loss_scale=512, train_wall=126, wall=11954
2023-01-12 19:08:47 | INFO | train_inner | epoch 005:   1288 / 1978 loss=6.614, nll_loss=4.765, word_ins=6.191, length=4.226, ppl=97.93, wps=46274.3, ups=0.78, wpb=59240.8, bsz=1976.9, num_updates=9200, lr=0.000115077, gnorm=4.181, loss_scale=512, train_wall=128, wall=12082
2023-01-12 19:10:55 | INFO | train_inner | epoch 005:   1388 / 1978 loss=6.533, nll_loss=4.668, word_ins=6.108, length=4.245, ppl=92.58, wps=46363.7, ups=0.78, wpb=59125, bsz=1974.9, num_updates=9300, lr=0.000116327, gnorm=4.506, loss_scale=512, train_wall=127, wall=12209
2023-01-12 19:13:01 | INFO | train_inner | epoch 005:   1488 / 1978 loss=6.578, nll_loss=4.712, word_ins=6.147, length=4.316, ppl=95.55, wps=46851.9, ups=0.8, wpb=58820.5, bsz=1914.3, num_updates=9400, lr=0.000117577, gnorm=4.317, loss_scale=512, train_wall=125, wall=12335
2023-01-12 19:15:08 | INFO | train_inner | epoch 005:   1588 / 1978 loss=6.469, nll_loss=4.588, word_ins=6.041, length=4.278, ppl=88.58, wps=46656, ups=0.78, wpb=59480.2, bsz=1966.4, num_updates=9500, lr=0.000118826, gnorm=4.089, loss_scale=512, train_wall=127, wall=12462
2023-01-12 19:17:15 | INFO | train_inner | epoch 005:   1688 / 1978 loss=6.381, nll_loss=4.502, word_ins=5.964, length=4.165, ppl=83.34, wps=46436.4, ups=0.79, wpb=59010, bsz=2031.7, num_updates=9600, lr=0.000120076, gnorm=4.529, loss_scale=512, train_wall=127, wall=12589
2023-01-12 19:19:22 | INFO | train_inner | epoch 005:   1788 / 1978 loss=6.336, nll_loss=4.449, word_ins=5.921, length=4.155, ppl=80.79, wps=46794.4, ups=0.79, wpb=59583.8, bsz=1969.4, num_updates=9700, lr=0.000121326, gnorm=4.094, loss_scale=512, train_wall=127, wall=12717
2023-01-12 19:21:30 | INFO | train_inner | epoch 005:   1888 / 1978 loss=6.313, nll_loss=4.418, word_ins=5.895, length=4.182, ppl=79.53, wps=46482.8, ups=0.79, wpb=59202.4, bsz=1988.4, num_updates=9800, lr=0.000122576, gnorm=4.348, loss_scale=512, train_wall=127, wall=12844
2023-01-12 19:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 19:23:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.032 | nll_loss 5.207 | word_ins 6.637 | length 3.964 | ppl 130.91 | wps 198095 | wpb 40242.5 | bsz 1500 | num_updates 9890 | best_loss 7.032
2023-01-12 19:23:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 19:24:19 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint5.pt (epoch 5 @ 9890 updates, score 7.032) (writing took 40.15012288093567 seconds)
2023-01-12 19:24:19 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-01-12 19:24:19 | INFO | train | epoch 005 | loss 6.73 | nll_loss 4.908 | word_ins 6.309 | length 4.215 | ppl 106.19 | wps 45300.6 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 9890 | lr 0.0001237 | gnorm 4.402 | loss_scale 512 | train_wall 2519 | wall 13013
2023-01-12 19:24:19 | INFO | fairseq.trainer | begin training epoch 6
2023-01-12 19:24:43 | INFO | train_inner | epoch 006:     10 / 1978 loss=6.218, nll_loss=4.318, word_ins=5.808, length=4.092, ppl=74.42, wps=30853.4, ups=0.52, wpb=59582.6, bsz=2027.3, num_updates=9900, lr=0.000123825, gnorm=4.316, loss_scale=512, train_wall=127, wall=13037
2023-01-12 19:26:51 | INFO | train_inner | epoch 006:    110 / 1978 loss=6.163, nll_loss=4.248, word_ins=5.748, length=4.152, ppl=71.67, wps=46753.2, ups=0.78, wpb=59831.8, bsz=2013.8, num_updates=10000, lr=0.000125075, gnorm=4.026, loss_scale=512, train_wall=128, wall=13165
2023-01-12 19:29:00 | INFO | train_inner | epoch 006:    210 / 1978 loss=6.129, nll_loss=4.2, word_ins=5.707, length=4.21, ppl=69.97, wps=46039.2, ups=0.78, wpb=59245.1, bsz=2056.2, num_updates=10100, lr=0.000126325, gnorm=4.151, loss_scale=512, train_wall=128, wall=13294
2023-01-12 19:31:08 | INFO | train_inner | epoch 006:    310 / 1978 loss=6.079, nll_loss=4.144, word_ins=5.66, length=4.19, ppl=67.6, wps=46495.7, ups=0.78, wpb=59609.3, bsz=2096.2, num_updates=10200, lr=0.000127575, gnorm=4.081, loss_scale=512, train_wall=128, wall=13422
2023-01-12 19:33:14 | INFO | train_inner | epoch 006:    410 / 1978 loss=6.065, nll_loss=4.14, word_ins=5.658, length=4.066, ppl=66.94, wps=47251.9, ups=0.79, wpb=59829.8, bsz=1952.1, num_updates=10300, lr=0.000128824, gnorm=3.922, loss_scale=512, train_wall=126, wall=13549
2023-01-12 19:35:21 | INFO | train_inner | epoch 006:    510 / 1978 loss=6.09, nll_loss=4.151, word_ins=5.668, length=4.21, ppl=68.1, wps=46394.9, ups=0.79, wpb=58717.7, bsz=1926, num_updates=10400, lr=0.000130074, gnorm=3.7, loss_scale=512, train_wall=126, wall=13675
2023-01-12 19:37:29 | INFO | train_inner | epoch 006:    610 / 1978 loss=5.983, nll_loss=4.03, word_ins=5.562, length=4.206, ppl=63.25, wps=45837.1, ups=0.78, wpb=58636, bsz=2045.8, num_updates=10500, lr=0.000131324, gnorm=3.812, loss_scale=512, train_wall=128, wall=13803
2023-01-12 19:39:36 | INFO | train_inner | epoch 006:    710 / 1978 loss=5.97, nll_loss=4.015, word_ins=5.552, length=4.183, ppl=62.69, wps=46743.4, ups=0.79, wpb=59467.1, bsz=1960.7, num_updates=10600, lr=0.000132574, gnorm=3.812, loss_scale=512, train_wall=127, wall=13930
2023-01-12 19:41:43 | INFO | train_inner | epoch 006:    810 / 1978 loss=6.022, nll_loss=4.071, word_ins=5.601, length=4.216, ppl=65, wps=46261.1, ups=0.79, wpb=58611.9, bsz=1970.3, num_updates=10700, lr=0.000133823, gnorm=4.293, loss_scale=512, train_wall=126, wall=14057
2023-01-12 19:43:50 | INFO | train_inner | epoch 006:    910 / 1978 loss=5.918, nll_loss=3.957, word_ins=5.503, length=4.157, ppl=60.48, wps=46746.6, ups=0.78, wpb=59634.7, bsz=2019.8, num_updates=10800, lr=0.000135073, gnorm=3.67, loss_scale=512, train_wall=127, wall=14184
2023-01-12 19:45:59 | INFO | train_inner | epoch 006:   1010 / 1978 loss=5.847, nll_loss=3.878, word_ins=5.435, length=4.121, ppl=57.56, wps=46368.9, ups=0.78, wpb=59504.4, bsz=2025, num_updates=10900, lr=0.000136323, gnorm=3.881, loss_scale=512, train_wall=128, wall=14313
2023-01-12 19:48:07 | INFO | train_inner | epoch 006:   1110 / 1978 loss=5.858, nll_loss=3.88, word_ins=5.437, length=4.21, ppl=58.02, wps=46265.3, ups=0.78, wpb=59115.9, bsz=2037.3, num_updates=11000, lr=0.000137573, gnorm=3.839, loss_scale=512, train_wall=128, wall=14441
2023-01-12 19:50:15 | INFO | train_inner | epoch 006:   1210 / 1978 loss=5.78, nll_loss=3.797, word_ins=5.365, length=4.147, ppl=54.94, wps=46180.5, ups=0.78, wpb=59284.8, bsz=2064.3, num_updates=11100, lr=0.000138822, gnorm=3.812, loss_scale=512, train_wall=128, wall=14569
2023-01-12 19:52:21 | INFO | train_inner | epoch 006:   1310 / 1978 loss=5.813, nll_loss=3.833, word_ins=5.397, length=4.161, ppl=56.24, wps=46961.1, ups=0.79, wpb=59332.6, bsz=1909.4, num_updates=11200, lr=0.000140072, gnorm=3.769, loss_scale=512, train_wall=126, wall=14695
2023-01-12 19:54:29 | INFO | train_inner | epoch 006:   1410 / 1978 loss=5.763, nll_loss=3.77, word_ins=5.342, length=4.201, ppl=54.29, wps=45904.4, ups=0.78, wpb=58826, bsz=2004, num_updates=11300, lr=0.000141322, gnorm=3.58, loss_scale=512, train_wall=128, wall=14823
2023-01-12 19:56:37 | INFO | train_inner | epoch 006:   1510 / 1978 loss=5.699, nll_loss=3.71, word_ins=5.291, length=4.086, ppl=51.96, wps=46483.7, ups=0.79, wpb=59101.2, bsz=2005.2, num_updates=11400, lr=0.000142572, gnorm=3.489, loss_scale=512, train_wall=127, wall=14951
2023-01-12 19:58:44 | INFO | train_inner | epoch 006:   1610 / 1978 loss=5.722, nll_loss=3.725, word_ins=5.306, length=4.166, ppl=52.79, wps=46164, ups=0.78, wpb=58987, bsz=1973.4, num_updates=11500, lr=0.000143821, gnorm=3.534, loss_scale=512, train_wall=128, wall=15078
2023-01-12 20:00:53 | INFO | train_inner | epoch 006:   1710 / 1978 loss=5.584, nll_loss=3.576, word_ins=5.176, length=4.088, ppl=47.98, wps=46573.6, ups=0.78, wpb=59715.6, bsz=2082.8, num_updates=11600, lr=0.000145071, gnorm=3.551, loss_scale=512, train_wall=128, wall=15207
2023-01-12 20:02:59 | INFO | train_inner | epoch 006:   1810 / 1978 loss=5.756, nll_loss=3.755, word_ins=5.332, length=4.237, ppl=54.03, wps=46410.9, ups=0.79, wpb=58820.2, bsz=1915.4, num_updates=11700, lr=0.000146321, gnorm=3.629, loss_scale=512, train_wall=127, wall=15333
2023-01-12 20:05:07 | INFO | train_inner | epoch 006:   1910 / 1978 loss=5.56, nll_loss=3.546, word_ins=5.15, length=4.092, ppl=47.16, wps=47219.9, ups=0.79, wpb=60078, bsz=2033, num_updates=11800, lr=0.000147571, gnorm=3.421, loss_scale=512, train_wall=127, wall=15461
2023-01-12 20:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 20:06:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.251 | nll_loss 4.256 | word_ins 5.856 | length 3.947 | ppl 76.17 | wps 156627 | wpb 40242.5 | bsz 1500 | num_updates 11868 | best_loss 6.251
2023-01-12 20:06:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 20:07:29 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint6.pt (epoch 6 @ 11868 updates, score 6.251) (writing took 40.14877424389124 seconds)
2023-01-12 20:07:29 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-01-12 20:07:29 | INFO | train | epoch 006 | loss 5.876 | nll_loss 3.908 | word_ins 5.46 | length 4.161 | ppl 58.73 | wps 45265.1 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 11868 | lr 0.00014842 | gnorm 3.778 | loss_scale 512 | train_wall 2519 | wall 15603
2023-01-12 20:07:29 | INFO | fairseq.trainer | begin training epoch 7
2023-01-12 20:08:22 | INFO | train_inner | epoch 007:     32 / 1978 loss=5.569, nll_loss=3.559, word_ins=5.16, length=4.089, ppl=47.48, wps=30334, ups=0.51, wpb=59301.9, bsz=1939.4, num_updates=11900, lr=0.00014882, gnorm=3.409, loss_scale=512, train_wall=127, wall=15656
2023-01-12 20:10:30 | INFO | train_inner | epoch 007:    132 / 1978 loss=5.517, nll_loss=3.497, word_ins=5.108, length=4.095, ppl=45.81, wps=46432.5, ups=0.78, wpb=59480.4, bsz=2024.6, num_updates=12000, lr=0.00015007, gnorm=3.402, loss_scale=512, train_wall=128, wall=15784
2023-01-12 20:12:37 | INFO | train_inner | epoch 007:    232 / 1978 loss=5.519, nll_loss=3.503, word_ins=5.112, length=4.067, ppl=45.84, wps=46831.1, ups=0.79, wpb=59555.8, bsz=2030.3, num_updates=12100, lr=0.00015132, gnorm=3.502, loss_scale=512, train_wall=127, wall=15911
2023-01-12 20:14:45 | INFO | train_inner | epoch 007:    332 / 1978 loss=5.453, nll_loss=3.421, word_ins=5.041, length=4.122, ppl=43.8, wps=46269.2, ups=0.78, wpb=59138, bsz=2046.8, num_updates=12200, lr=0.00015257, gnorm=3.142, loss_scale=512, train_wall=128, wall=16039
2023-01-12 20:16:54 | INFO | train_inner | epoch 007:    432 / 1978 loss=5.501, nll_loss=3.475, word_ins=5.089, length=4.116, ppl=45.28, wps=46112.5, ups=0.78, wpb=59419.5, bsz=2047, num_updates=12300, lr=0.000153819, gnorm=3.34, loss_scale=1024, train_wall=129, wall=16168
2023-01-12 20:19:02 | INFO | train_inner | epoch 007:    532 / 1978 loss=5.445, nll_loss=3.422, word_ins=5.035, length=4.097, ppl=43.55, wps=46267.6, ups=0.78, wpb=59394.7, bsz=2092.7, num_updates=12400, lr=0.000155069, gnorm=3.478, loss_scale=1024, train_wall=128, wall=16296
2023-01-12 20:21:09 | INFO | train_inner | epoch 007:    632 / 1978 loss=5.484, nll_loss=3.457, word_ins=5.065, length=4.183, ppl=44.75, wps=46363.9, ups=0.79, wpb=58932.1, bsz=1939.3, num_updates=12500, lr=0.000156319, gnorm=3.2, loss_scale=1024, train_wall=127, wall=16424
2023-01-12 20:23:17 | INFO | train_inner | epoch 007:    732 / 1978 loss=5.387, nll_loss=3.363, word_ins=4.983, length=4.042, ppl=41.85, wps=47017, ups=0.79, wpb=59812.7, bsz=1994.6, num_updates=12600, lr=0.000157569, gnorm=3.154, loss_scale=1024, train_wall=127, wall=16551
2023-01-12 20:25:24 | INFO | train_inner | epoch 007:    832 / 1978 loss=5.426, nll_loss=3.403, word_ins=5.019, length=4.073, ppl=42.99, wps=46722, ups=0.78, wpb=59567.1, bsz=1953.4, num_updates=12700, lr=0.000158818, gnorm=3.338, loss_scale=1024, train_wall=127, wall=16678
2023-01-12 20:27:32 | INFO | train_inner | epoch 007:    932 / 1978 loss=5.357, nll_loss=3.327, word_ins=4.952, length=4.057, ppl=40.99, wps=46624.6, ups=0.78, wpb=59629.5, bsz=2022.2, num_updates=12800, lr=0.000160068, gnorm=3.205, loss_scale=1024, train_wall=128, wall=16806
2023-01-12 20:29:40 | INFO | train_inner | epoch 007:   1032 / 1978 loss=5.314, nll_loss=3.276, word_ins=4.907, length=4.078, ppl=39.79, wps=46428.8, ups=0.78, wpb=59203.8, bsz=2063.9, num_updates=12900, lr=0.000161318, gnorm=3.168, loss_scale=1024, train_wall=127, wall=16934
2023-01-12 20:31:47 | INFO | train_inner | epoch 007:   1132 / 1978 loss=5.327, nll_loss=3.292, word_ins=4.921, length=4.062, ppl=40.15, wps=46203.3, ups=0.78, wpb=59026.6, bsz=2023.2, num_updates=13000, lr=0.000162568, gnorm=3.042, loss_scale=1024, train_wall=128, wall=17061
2023-01-12 20:33:55 | INFO | train_inner | epoch 007:   1232 / 1978 loss=5.374, nll_loss=3.335, word_ins=4.959, length=4.154, ppl=41.47, wps=46242.8, ups=0.78, wpb=58920.5, bsz=1980.5, num_updates=13100, lr=0.000163817, gnorm=3.017, loss_scale=1024, train_wall=127, wall=17189
2023-01-12 20:36:02 | INFO | train_inner | epoch 007:   1332 / 1978 loss=5.368, nll_loss=3.325, word_ins=4.95, length=4.171, ppl=41.29, wps=46809.6, ups=0.79, wpb=59382.7, bsz=1877.6, num_updates=13200, lr=0.000165067, gnorm=3.06, loss_scale=1024, train_wall=127, wall=17316
2023-01-12 20:38:09 | INFO | train_inner | epoch 007:   1432 / 1978 loss=5.255, nll_loss=3.208, word_ins=4.847, length=4.086, ppl=38.19, wps=46487.1, ups=0.78, wpb=59379.1, bsz=2074, num_updates=13300, lr=0.000166317, gnorm=3.155, loss_scale=1024, train_wall=128, wall=17443
2023-01-12 20:40:18 | INFO | train_inner | epoch 007:   1532 / 1978 loss=5.269, nll_loss=3.226, word_ins=4.862, length=4.067, ppl=38.56, wps=45837.5, ups=0.78, wpb=59122.2, bsz=2061.7, num_updates=13400, lr=0.000167567, gnorm=3.033, loss_scale=1024, train_wall=129, wall=17572
2023-01-12 20:42:26 | INFO | train_inner | epoch 007:   1632 / 1978 loss=5.319, nll_loss=3.273, word_ins=4.904, length=4.149, ppl=39.91, wps=46596.5, ups=0.78, wpb=59426.5, bsz=1955, num_updates=13500, lr=0.000168816, gnorm=2.944, loss_scale=1024, train_wall=127, wall=17700
2023-01-12 20:44:33 | INFO | train_inner | epoch 007:   1732 / 1978 loss=5.307, nll_loss=3.25, word_ins=4.882, length=4.251, ppl=39.6, wps=46188, ups=0.79, wpb=58500.3, bsz=1962, num_updates=13600, lr=0.000170066, gnorm=3.077, loss_scale=1024, train_wall=126, wall=17827
2023-01-12 20:46:41 | INFO | train_inner | epoch 007:   1832 / 1978 loss=5.267, nll_loss=3.221, word_ins=4.857, length=4.099, ppl=38.51, wps=46443.7, ups=0.78, wpb=59496.7, bsz=1975, num_updates=13700, lr=0.000171316, gnorm=3.286, loss_scale=1024, train_wall=128, wall=17955
2023-01-12 20:48:48 | INFO | train_inner | epoch 007:   1932 / 1978 loss=5.188, nll_loss=3.135, word_ins=4.781, length=4.067, ppl=36.44, wps=46756.2, ups=0.79, wpb=59453.4, bsz=2003.8, num_updates=13800, lr=0.000172566, gnorm=2.817, loss_scale=1024, train_wall=127, wall=18082
2023-01-12 20:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 20:49:59 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 5.82 | nll_loss 3.769 | word_ins 5.422 | length 3.977 | ppl 56.48 | wps 102848 | wpb 40242.5 | bsz 1500 | num_updates 13846 | best_loss 5.82
2023-01-12 20:49:59 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 20:50:39 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint7.pt (epoch 7 @ 13846 updates, score 5.82) (writing took 39.968197650741786 seconds)
2023-01-12 20:50:39 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-01-12 20:50:39 | INFO | train | epoch 007 | loss 5.371 | nll_loss 3.336 | word_ins 4.961 | length 4.108 | ppl 41.4 | wps 45271.3 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 13846 | lr 0.00017314 | gnorm 3.168 | loss_scale 1024 | train_wall 2520 | wall 18193
2023-01-12 20:50:39 | INFO | fairseq.trainer | begin training epoch 8
2023-01-12 20:52:01 | INFO | train_inner | epoch 008:     54 / 1978 loss=5.238, nll_loss=3.188, word_ins=4.829, length=4.099, ppl=37.75, wps=30737.7, ups=0.52, wpb=59250.2, bsz=1894.4, num_updates=13900, lr=0.000173815, gnorm=2.884, loss_scale=1024, train_wall=127, wall=18275
2023-01-12 20:54:08 | INFO | train_inner | epoch 008:    154 / 1978 loss=5.203, nll_loss=3.149, word_ins=4.795, length=4.085, ppl=36.84, wps=46542, ups=0.79, wpb=59175.2, bsz=1913.5, num_updates=14000, lr=0.000175065, gnorm=2.834, loss_scale=1024, train_wall=127, wall=18402
2023-01-12 20:56:16 | INFO | train_inner | epoch 008:    254 / 1978 loss=5.086, nll_loss=3.028, word_ins=4.688, length=3.982, ppl=33.97, wps=46268.3, ups=0.78, wpb=59200.2, bsz=2051.1, num_updates=14100, lr=0.000176315, gnorm=2.768, loss_scale=1024, train_wall=128, wall=18530
2023-01-12 20:58:24 | INFO | train_inner | epoch 008:    354 / 1978 loss=5.098, nll_loss=3.032, word_ins=4.691, length=4.069, ppl=34.25, wps=46487.5, ups=0.78, wpb=59669.9, bsz=2016.9, num_updates=14200, lr=0.000177565, gnorm=2.775, loss_scale=1024, train_wall=128, wall=18658
2023-01-12 21:00:30 | INFO | train_inner | epoch 008:    454 / 1978 loss=5.2, nll_loss=3.14, word_ins=4.787, length=4.133, ppl=36.76, wps=46805.3, ups=0.79, wpb=58978.4, bsz=1891.3, num_updates=14300, lr=0.000178814, gnorm=2.782, loss_scale=1024, train_wall=126, wall=18784
2023-01-12 21:02:38 | INFO | train_inner | epoch 008:    554 / 1978 loss=5.104, nll_loss=3.042, word_ins=4.699, length=4.051, ppl=34.4, wps=46481.9, ups=0.78, wpb=59267.8, bsz=1988.7, num_updates=14400, lr=0.000180064, gnorm=2.738, loss_scale=1024, train_wall=127, wall=18912
2023-01-12 21:04:45 | INFO | train_inner | epoch 008:    654 / 1978 loss=5.046, nll_loss=2.982, word_ins=4.646, length=3.996, ppl=33.04, wps=46388.2, ups=0.78, wpb=59328.6, bsz=2054.3, num_updates=14500, lr=0.000181314, gnorm=2.677, loss_scale=1024, train_wall=128, wall=19040
2023-01-12 21:06:53 | INFO | train_inner | epoch 008:    754 / 1978 loss=5.075, nll_loss=3.007, word_ins=4.668, length=4.076, ppl=33.71, wps=46451.3, ups=0.78, wpb=59389.8, bsz=2055.7, num_updates=14600, lr=0.000182564, gnorm=2.573, loss_scale=1024, train_wall=128, wall=19167
2023-01-12 21:09:00 | INFO | train_inner | epoch 008:    854 / 1978 loss=5.129, nll_loss=3.064, word_ins=4.717, length=4.118, ppl=35, wps=46282.9, ups=0.79, wpb=58790.3, bsz=1951, num_updates=14700, lr=0.000183813, gnorm=2.715, loss_scale=1024, train_wall=127, wall=19294
2023-01-12 21:11:09 | INFO | train_inner | epoch 008:    954 / 1978 loss=4.988, nll_loss=2.915, word_ins=4.588, length=4.003, ppl=31.73, wps=45930, ups=0.78, wpb=58888.8, bsz=2096.6, num_updates=14800, lr=0.000185063, gnorm=2.656, loss_scale=1024, train_wall=128, wall=19423
2023-01-12 21:13:17 | INFO | train_inner | epoch 008:   1054 / 1978 loss=5.044, nll_loss=2.976, word_ins=4.64, length=4.044, ppl=32.99, wps=45831.9, ups=0.78, wpb=58739.2, bsz=2037.9, num_updates=14900, lr=0.000186313, gnorm=2.601, loss_scale=1024, train_wall=128, wall=19551
2023-01-12 21:15:24 | INFO | train_inner | epoch 008:   1154 / 1978 loss=5.013, nll_loss=2.938, word_ins=4.607, length=4.064, ppl=32.29, wps=46388.4, ups=0.79, wpb=59087.4, bsz=2014.2, num_updates=15000, lr=0.000187563, gnorm=2.792, loss_scale=1024, train_wall=127, wall=19678
2023-01-12 21:17:33 | INFO | train_inner | epoch 008:   1254 / 1978 loss=4.944, nll_loss=2.868, word_ins=4.544, length=3.998, ppl=30.77, wps=46427.9, ups=0.78, wpb=59717.5, bsz=2102.7, num_updates=15100, lr=0.000188812, gnorm=2.618, loss_scale=1024, train_wall=128, wall=19807
2023-01-12 21:19:41 | INFO | train_inner | epoch 008:   1354 / 1978 loss=4.972, nll_loss=2.903, word_ins=4.575, length=3.962, ppl=31.38, wps=46239.2, ups=0.78, wpb=59286.2, bsz=2017.7, num_updates=15200, lr=0.000190062, gnorm=2.535, loss_scale=1024, train_wall=128, wall=19935
2023-01-12 21:21:48 | INFO | train_inner | epoch 008:   1454 / 1978 loss=4.975, nll_loss=2.899, word_ins=4.571, length=4.043, ppl=31.45, wps=46804, ups=0.79, wpb=59433.8, bsz=2008.6, num_updates=15300, lr=0.000191312, gnorm=2.6, loss_scale=1024, train_wall=127, wall=20062
2023-01-12 21:23:54 | INFO | train_inner | epoch 008:   1554 / 1978 loss=5.038, nll_loss=2.965, word_ins=4.629, length=4.082, ppl=32.85, wps=47001.7, ups=0.79, wpb=59327.1, bsz=1888.1, num_updates=15400, lr=0.000192562, gnorm=2.731, loss_scale=1024, train_wall=126, wall=20188
2023-01-12 21:26:02 | INFO | train_inner | epoch 008:   1654 / 1978 loss=4.929, nll_loss=2.854, word_ins=4.531, length=3.978, ppl=30.46, wps=46613.8, ups=0.78, wpb=59742.7, bsz=2026.9, num_updates=15500, lr=0.000193811, gnorm=2.586, loss_scale=1024, train_wall=128, wall=20316
2023-01-12 21:28:09 | INFO | train_inner | epoch 008:   1754 / 1978 loss=4.989, nll_loss=2.903, word_ins=4.574, length=4.152, ppl=31.75, wps=46691.7, ups=0.79, wpb=59295.2, bsz=1990.7, num_updates=15600, lr=0.000195061, gnorm=2.623, loss_scale=1024, train_wall=127, wall=20443
2023-01-12 21:30:17 | INFO | train_inner | epoch 008:   1854 / 1978 loss=4.962, nll_loss=2.874, word_ins=4.548, length=4.139, ppl=31.18, wps=46347.2, ups=0.78, wpb=59235.5, bsz=2045.3, num_updates=15700, lr=0.000196311, gnorm=2.467, loss_scale=1024, train_wall=128, wall=20571
2023-01-12 21:32:24 | INFO | train_inner | epoch 008:   1954 / 1978 loss=4.936, nll_loss=2.854, word_ins=4.53, length=4.066, ppl=30.62, wps=47120.4, ups=0.79, wpb=59822.2, bsz=1981.8, num_updates=15800, lr=0.000197561, gnorm=2.47, loss_scale=1024, train_wall=127, wall=20698
2023-01-12 21:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 21:33:07 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.562 | nll_loss 3.5 | word_ins 5.166 | length 3.95 | ppl 47.23 | wps 148043 | wpb 40242.5 | bsz 1500 | num_updates 15824 | best_loss 5.562
2023-01-12 21:33:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 21:33:47 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint8.pt (epoch 8 @ 15824 updates, score 5.562) (writing took 39.96219717385247 seconds)
2023-01-12 21:33:47 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-01-12 21:33:47 | INFO | train | epoch 008 | loss 5.044 | nll_loss 2.974 | word_ins 4.638 | length 4.054 | ppl 32.98 | wps 45319.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 15824 | lr 0.00019786 | gnorm 2.669 | loss_scale 1024 | train_wall 2519 | wall 20781
2023-01-12 21:33:47 | INFO | fairseq.trainer | begin training epoch 9
2023-01-12 21:35:36 | INFO | train_inner | epoch 009:     76 / 1978 loss=4.881, nll_loss=2.798, word_ins=4.482, length=3.989, ppl=29.46, wps=30855.6, ups=0.52, wpb=59311.3, bsz=1997, num_updates=15900, lr=0.00019881, gnorm=2.377, loss_scale=1024, train_wall=127, wall=20890
2023-01-12 21:37:44 | INFO | train_inner | epoch 009:    176 / 1978 loss=4.885, nll_loss=2.806, word_ins=4.488, length=3.976, ppl=29.55, wps=46236.3, ups=0.78, wpb=59147.6, bsz=2070.6, num_updates=16000, lr=0.00020006, gnorm=2.495, loss_scale=1024, train_wall=128, wall=21018
2023-01-12 21:39:51 | INFO | train_inner | epoch 009:    276 / 1978 loss=4.923, nll_loss=2.838, word_ins=4.516, length=4.073, ppl=30.33, wps=46358.5, ups=0.79, wpb=58629.6, bsz=1939.7, num_updates=16100, lr=0.00020131, gnorm=2.414, loss_scale=1024, train_wall=126, wall=21145
2023-01-12 21:41:59 | INFO | train_inner | epoch 009:    376 / 1978 loss=4.889, nll_loss=2.802, word_ins=4.484, length=4.046, ppl=29.63, wps=45915, ups=0.78, wpb=59098, bsz=2023, num_updates=16200, lr=0.00020256, gnorm=2.361, loss_scale=1024, train_wall=128, wall=21274
2023-01-12 21:44:08 | INFO | train_inner | epoch 009:    476 / 1978 loss=4.826, nll_loss=2.728, word_ins=4.418, length=4.088, ppl=28.37, wps=46074.8, ups=0.78, wpb=58999.5, bsz=2058.3, num_updates=16300, lr=0.000203809, gnorm=2.263, loss_scale=1024, train_wall=128, wall=21402
2023-01-12 21:46:15 | INFO | train_inner | epoch 009:    576 / 1978 loss=4.825, nll_loss=2.74, word_ins=4.43, length=3.955, ppl=28.35, wps=46732.4, ups=0.78, wpb=59655.8, bsz=2032.9, num_updates=16400, lr=0.000205059, gnorm=2.34, loss_scale=2048, train_wall=127, wall=21529
2023-01-12 21:48:22 | INFO | train_inner | epoch 009:    676 / 1978 loss=4.782, nll_loss=2.687, word_ins=4.383, length=3.992, ppl=27.52, wps=46639.2, ups=0.79, wpb=59270.5, bsz=2048.7, num_updates=16500, lr=0.000206309, gnorm=2.18, loss_scale=2048, train_wall=127, wall=21656
2023-01-12 21:50:30 | INFO | train_inner | epoch 009:    776 / 1978 loss=4.814, nll_loss=2.731, word_ins=4.423, length=3.906, ppl=28.13, wps=46441.8, ups=0.78, wpb=59505.8, bsz=2071.8, num_updates=16600, lr=0.000207559, gnorm=2.514, loss_scale=2048, train_wall=128, wall=21784
2023-01-12 21:52:37 | INFO | train_inner | epoch 009:    876 / 1978 loss=4.795, nll_loss=2.708, word_ins=4.401, length=3.942, ppl=27.77, wps=47208.1, ups=0.79, wpb=59652.2, bsz=1946.2, num_updates=16700, lr=0.000208808, gnorm=2.437, loss_scale=2048, train_wall=126, wall=21911
2023-01-12 21:54:44 | INFO | train_inner | epoch 009:    976 / 1978 loss=4.765, nll_loss=2.667, word_ins=4.365, length=4.003, ppl=27.19, wps=46810, ups=0.78, wpb=59687.2, bsz=2026.2, num_updates=16800, lr=0.000210058, gnorm=2.276, loss_scale=2048, train_wall=127, wall=22038
2023-01-12 21:56:52 | INFO | train_inner | epoch 009:   1076 / 1978 loss=4.806, nll_loss=2.703, word_ins=4.397, length=4.093, ppl=27.98, wps=46851.8, ups=0.79, wpb=59649, bsz=1961, num_updates=16900, lr=0.000211308, gnorm=2.295, loss_scale=2048, train_wall=127, wall=22166
2023-01-12 21:59:00 | INFO | train_inner | epoch 009:   1176 / 1978 loss=4.824, nll_loss=2.723, word_ins=4.414, length=4.099, ppl=28.33, wps=45829.6, ups=0.78, wpb=58805.4, bsz=2024.4, num_updates=17000, lr=0.000212558, gnorm=3.111, loss_scale=2048, train_wall=128, wall=22294
2023-01-12 22:01:07 | INFO | train_inner | epoch 009:   1276 / 1978 loss=4.762, nll_loss=2.662, word_ins=4.359, length=4.025, ppl=27.13, wps=46696.2, ups=0.79, wpb=59423.7, bsz=2011.1, num_updates=17100, lr=0.000213807, gnorm=2.11, loss_scale=2048, train_wall=127, wall=22421
2023-01-12 22:03:15 | INFO | train_inner | epoch 009:   1376 / 1978 loss=4.774, nll_loss=2.676, word_ins=4.372, length=4.018, ppl=27.36, wps=46457.8, ups=0.78, wpb=59448.6, bsz=2023.8, num_updates=17200, lr=0.000215057, gnorm=2.244, loss_scale=2048, train_wall=128, wall=22549
2023-01-12 22:05:23 | INFO | train_inner | epoch 009:   1476 / 1978 loss=4.778, nll_loss=2.679, word_ins=4.375, length=4.032, ppl=27.43, wps=46073, ups=0.78, wpb=58898.6, bsz=1990.2, num_updates=17300, lr=0.000216307, gnorm=2.196, loss_scale=2048, train_wall=128, wall=22677
2023-01-12 22:07:29 | INFO | train_inner | epoch 009:   1576 / 1978 loss=4.881, nll_loss=2.78, word_ins=4.464, length=4.169, ppl=29.47, wps=46791.7, ups=0.79, wpb=59074.8, bsz=1912, num_updates=17400, lr=0.000217557, gnorm=2.276, loss_scale=2048, train_wall=126, wall=22803
2023-01-12 22:09:36 | INFO | train_inner | epoch 009:   1676 / 1978 loss=4.786, nll_loss=2.686, word_ins=4.381, length=4.051, ppl=27.59, wps=46028.3, ups=0.79, wpb=58420.8, bsz=1989.4, num_updates=17500, lr=0.000218806, gnorm=2.193, loss_scale=2048, train_wall=127, wall=22930
2023-01-12 22:11:44 | INFO | train_inner | epoch 009:   1776 / 1978 loss=4.784, nll_loss=2.678, word_ins=4.374, length=4.1, ppl=27.55, wps=46427.1, ups=0.79, wpb=59118.4, bsz=1901.9, num_updates=17600, lr=0.000220056, gnorm=2.281, loss_scale=2048, train_wall=127, wall=23058
2023-01-12 22:13:52 | INFO | train_inner | epoch 009:   1876 / 1978 loss=4.669, nll_loss=2.567, word_ins=4.274, length=3.95, ppl=25.45, wps=46636.4, ups=0.78, wpb=59865.7, bsz=2077.9, num_updates=17700, lr=0.000221306, gnorm=2.034, loss_scale=2048, train_wall=128, wall=23186
2023-01-12 22:15:59 | INFO | train_inner | epoch 009:   1976 / 1978 loss=4.754, nll_loss=2.655, word_ins=4.352, length=4.023, ppl=26.99, wps=47015.7, ups=0.79, wpb=59851.2, bsz=1928.6, num_updates=17800, lr=0.000222556, gnorm=2.152, loss_scale=2048, train_wall=127, wall=23313
2023-01-12 22:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 22:16:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.36 | nll_loss 3.227 | word_ins 4.956 | length 4.051 | ppl 41.08 | wps 106048 | wpb 40242.5 | bsz 1500 | num_updates 17802 | best_loss 5.36
2023-01-12 22:16:16 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 22:16:56 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint9.pt (epoch 9 @ 17802 updates, score 5.36) (writing took 39.80413002194837 seconds)
2023-01-12 22:16:56 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-01-12 22:16:56 | INFO | train | epoch 009 | loss 4.809 | nll_loss 2.714 | word_ins 4.406 | length 4.028 | ppl 28.03 | wps 45296.2 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 17802 | lr 0.00022258 | gnorm 2.326 | loss_scale 2048 | train_wall 2518 | wall 23370
2023-01-12 22:16:56 | INFO | fairseq.trainer | begin training epoch 10
2023-01-12 22:19:13 | INFO | train_inner | epoch 010:     98 / 1978 loss=4.761, nll_loss=2.656, word_ins=4.352, length=4.089, ppl=27.12, wps=30316.3, ups=0.52, wpb=58712.5, bsz=1925, num_updates=17900, lr=0.000223805, gnorm=2.143, loss_scale=2048, train_wall=127, wall=23507
2023-01-12 22:21:21 | INFO | train_inner | epoch 010:    198 / 1978 loss=4.665, nll_loss=2.559, word_ins=4.268, length=3.976, ppl=25.37, wps=46185.8, ups=0.78, wpb=59113.8, bsz=2045.4, num_updates=18000, lr=0.000225055, gnorm=2.107, loss_scale=2048, train_wall=128, wall=23635
2023-01-12 22:23:28 | INFO | train_inner | epoch 010:    298 / 1978 loss=4.687, nll_loss=2.572, word_ins=4.278, length=4.091, ppl=25.76, wps=46106, ups=0.79, wpb=58714.6, bsz=2020.7, num_updates=18100, lr=0.000226305, gnorm=2.106, loss_scale=2048, train_wall=127, wall=23762
2023-01-12 22:25:36 | INFO | train_inner | epoch 010:    398 / 1978 loss=4.666, nll_loss=2.555, word_ins=4.263, length=4.025, ppl=25.38, wps=46378.6, ups=0.78, wpb=59267.2, bsz=1997.8, num_updates=18200, lr=0.000227555, gnorm=2.156, loss_scale=2048, train_wall=128, wall=23890
2023-01-12 22:27:45 | INFO | train_inner | epoch 010:    498 / 1978 loss=4.563, nll_loss=2.453, word_ins=4.172, length=3.912, ppl=23.64, wps=46831.5, ups=0.78, wpb=60321.6, bsz=2150.6, num_updates=18300, lr=0.000228804, gnorm=2.002, loss_scale=2048, train_wall=129, wall=24019
2023-01-12 22:29:52 | INFO | train_inner | epoch 010:    598 / 1978 loss=4.651, nll_loss=2.536, word_ins=4.246, length=4.047, ppl=25.12, wps=46487.8, ups=0.79, wpb=59165, bsz=1986.2, num_updates=18400, lr=0.000230054, gnorm=2.129, loss_scale=2048, train_wall=127, wall=24146
2023-01-12 22:32:00 | INFO | train_inner | epoch 010:    698 / 1978 loss=4.632, nll_loss=2.529, word_ins=4.239, length=3.936, ppl=24.8, wps=46090.6, ups=0.78, wpb=59156.7, bsz=1993.8, num_updates=18500, lr=0.000231304, gnorm=1.977, loss_scale=2048, train_wall=128, wall=24275
2023-01-12 22:34:08 | INFO | train_inner | epoch 010:    798 / 1978 loss=4.709, nll_loss=2.611, word_ins=4.311, length=3.978, ppl=26.15, wps=46449.8, ups=0.78, wpb=59349.2, bsz=1981.8, num_updates=18600, lr=0.000232554, gnorm=2.191, loss_scale=2048, train_wall=128, wall=24402
2023-01-12 22:36:15 | INFO | train_inner | epoch 010:    898 / 1978 loss=4.661, nll_loss=2.556, word_ins=4.263, length=3.984, ppl=25.3, wps=46444.6, ups=0.79, wpb=59100.6, bsz=2024.5, num_updates=18700, lr=0.000233803, gnorm=2.011, loss_scale=2048, train_wall=127, wall=24530
2023-01-12 22:38:23 | INFO | train_inner | epoch 010:    998 / 1978 loss=4.621, nll_loss=2.515, word_ins=4.226, length=3.952, ppl=24.61, wps=46796.8, ups=0.79, wpb=59612.4, bsz=1976.2, num_updates=18800, lr=0.000235053, gnorm=1.983, loss_scale=2048, train_wall=127, wall=24657
2023-01-12 22:40:29 | INFO | train_inner | epoch 010:   1098 / 1978 loss=4.649, nll_loss=2.542, word_ins=4.25, length=3.992, ppl=25.09, wps=46791, ups=0.79, wpb=58970.8, bsz=1943, num_updates=18900, lr=0.000236303, gnorm=1.976, loss_scale=2048, train_wall=126, wall=24783
2023-01-12 22:42:36 | INFO | train_inner | epoch 010:   1198 / 1978 loss=4.617, nll_loss=2.506, word_ins=4.218, length=3.986, ppl=24.54, wps=46773, ups=0.79, wpb=59436.5, bsz=1972.7, num_updates=19000, lr=0.000237553, gnorm=2.021, loss_scale=2048, train_wall=127, wall=24910
2023-01-12 22:44:43 | INFO | train_inner | epoch 010:   1298 / 1978 loss=4.608, nll_loss=2.498, word_ins=4.21, length=3.974, ppl=24.38, wps=46661.6, ups=0.79, wpb=59410.8, bsz=1975.4, num_updates=19100, lr=0.000238802, gnorm=1.957, loss_scale=2048, train_wall=127, wall=25037
2023-01-12 22:46:51 | INFO | train_inner | epoch 010:   1398 / 1978 loss=4.613, nll_loss=2.507, word_ins=4.218, length=3.949, ppl=24.47, wps=46562.4, ups=0.79, wpb=59254.4, bsz=1968.6, num_updates=19200, lr=0.000240052, gnorm=1.89, loss_scale=2048, train_wall=127, wall=25165
2023-01-12 22:49:00 | INFO | train_inner | epoch 010:   1498 / 1978 loss=4.557, nll_loss=2.447, word_ins=4.165, length=3.915, ppl=23.54, wps=46051.8, ups=0.78, wpb=59414.3, bsz=2051.8, num_updates=19300, lr=0.000241302, gnorm=1.898, loss_scale=2048, train_wall=129, wall=25294
2023-01-12 22:51:08 | INFO | train_inner | epoch 010:   1598 / 1978 loss=4.522, nll_loss=2.41, word_ins=4.131, length=3.906, ppl=22.97, wps=46862.6, ups=0.78, wpb=59972.5, bsz=2003.7, num_updates=19400, lr=0.000242552, gnorm=1.858, loss_scale=2048, train_wall=128, wall=25422
2023-01-12 22:53:15 | INFO | train_inner | epoch 010:   1698 / 1978 loss=4.582, nll_loss=2.471, word_ins=4.186, length=3.964, ppl=23.95, wps=46287.4, ups=0.78, wpb=59104.4, bsz=2014.7, num_updates=19500, lr=0.000243801, gnorm=1.96, loss_scale=2048, train_wall=127, wall=25549
2023-01-12 22:55:23 | INFO | train_inner | epoch 010:   1798 / 1978 loss=4.57, nll_loss=2.459, word_ins=4.174, length=3.954, ppl=23.75, wps=46377.8, ups=0.78, wpb=59168.9, bsz=2004.1, num_updates=19600, lr=0.000245051, gnorm=1.938, loss_scale=2048, train_wall=127, wall=25677
2023-01-12 22:57:30 | INFO | train_inner | epoch 010:   1898 / 1978 loss=4.575, nll_loss=2.464, word_ins=4.179, length=3.963, ppl=23.84, wps=46822.1, ups=0.78, wpb=59702.9, bsz=1996.4, num_updates=19700, lr=0.000246301, gnorm=1.821, loss_scale=2048, train_wall=127, wall=25804
2023-01-12 22:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 22:59:25 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.2 | nll_loss 3.079 | word_ins 4.807 | length 3.922 | ppl 36.75 | wps 145094 | wpb 40242.5 | bsz 1500 | num_updates 19780 | best_loss 5.2
2023-01-12 22:59:25 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 23:00:04 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint10.pt (epoch 10 @ 19780 updates, score 5.2) (writing took 39.812047904822975 seconds)
2023-01-12 23:00:04 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-01-12 23:00:04 | INFO | train | epoch 010 | loss 4.623 | nll_loss 2.514 | word_ins 4.226 | length 3.978 | ppl 24.65 | wps 45300.4 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 19780 | lr 0.000247301 | gnorm 2 | loss_scale 2048 | train_wall 2520 | wall 25958
2023-01-12 23:00:04 | INFO | fairseq.trainer | begin training epoch 11
2023-01-12 23:00:41 | INFO | train_inner | epoch 011:     20 / 1978 loss=4.578, nll_loss=2.463, word_ins=4.178, length=3.997, ppl=23.89, wps=30773.8, ups=0.53, wpb=58580.7, bsz=1963.5, num_updates=19800, lr=0.000247551, gnorm=1.847, loss_scale=2048, train_wall=126, wall=25995
2023-01-12 23:02:48 | INFO | train_inner | epoch 011:    120 / 1978 loss=4.51, nll_loss=2.405, word_ins=4.127, length=3.833, ppl=22.78, wps=46661.1, ups=0.79, wpb=59292.8, bsz=1982.3, num_updates=19900, lr=0.0002488, gnorm=1.841, loss_scale=2048, train_wall=127, wall=26122
2023-01-12 23:04:56 | INFO | train_inner | epoch 011:    220 / 1978 loss=4.525, nll_loss=2.408, word_ins=4.129, length=3.962, ppl=23.02, wps=46248.8, ups=0.78, wpb=59392.8, bsz=2055.5, num_updates=20000, lr=0.00025005, gnorm=1.894, loss_scale=2048, train_wall=128, wall=26250
2023-01-12 23:07:04 | INFO | train_inner | epoch 011:    320 / 1978 loss=4.511, nll_loss=2.393, word_ins=4.116, length=3.956, ppl=22.8, wps=46233, ups=0.78, wpb=59014.6, bsz=2045.7, num_updates=20100, lr=0.0002513, gnorm=1.836, loss_scale=2048, train_wall=127, wall=26378
2023-01-12 23:09:10 | INFO | train_inner | epoch 011:    420 / 1978 loss=4.545, nll_loss=2.431, word_ins=4.148, length=3.968, ppl=23.34, wps=46812.5, ups=0.79, wpb=59253.7, bsz=1947.8, num_updates=20200, lr=0.00025255, gnorm=1.827, loss_scale=2048, train_wall=126, wall=26505
2023-01-12 23:11:17 | INFO | train_inner | epoch 011:    520 / 1978 loss=4.586, nll_loss=2.471, word_ins=4.183, length=4.025, ppl=24.02, wps=46691.7, ups=0.79, wpb=59053.5, bsz=1875.6, num_updates=20300, lr=0.000253799, gnorm=1.833, loss_scale=2048, train_wall=126, wall=26631
2023-01-12 23:13:24 | INFO | train_inner | epoch 011:    620 / 1978 loss=4.515, nll_loss=2.387, word_ins=4.109, length=4.055, ppl=22.86, wps=46763.9, ups=0.79, wpb=59390.5, bsz=1936.4, num_updates=20400, lr=0.000255049, gnorm=1.88, loss_scale=2048, train_wall=127, wall=26758
2023-01-12 23:15:31 | INFO | train_inner | epoch 011:    720 / 1978 loss=4.506, nll_loss=2.391, word_ins=4.112, length=3.94, ppl=22.72, wps=46725.6, ups=0.79, wpb=59280.9, bsz=1983.8, num_updates=20500, lr=0.000256299, gnorm=1.813, loss_scale=4096, train_wall=127, wall=26885
2023-01-12 23:17:37 | INFO | train_inner | epoch 011:    820 / 1978 loss=4.516, nll_loss=2.395, word_ins=4.117, length=3.988, ppl=22.88, wps=46926.5, ups=0.79, wpb=59267.7, bsz=1911.8, num_updates=20600, lr=0.000257549, gnorm=1.812, loss_scale=4096, train_wall=126, wall=27011
2023-01-12 23:19:45 | INFO | train_inner | epoch 011:    920 / 1978 loss=4.43, nll_loss=2.315, word_ins=4.045, length=3.845, ppl=21.55, wps=46402.6, ups=0.78, wpb=59470.9, bsz=2106.2, num_updates=20700, lr=0.000258798, gnorm=1.788, loss_scale=4096, train_wall=128, wall=27139
2023-01-12 23:21:51 | INFO | train_inner | epoch 011:   1020 / 1978 loss=4.484, nll_loss=2.361, word_ins=4.086, length=3.982, ppl=22.38, wps=47247.7, ups=0.8, wpb=59173.8, bsz=1884.6, num_updates=20800, lr=0.000260048, gnorm=1.715, loss_scale=4096, train_wall=125, wall=27265
2023-01-12 23:23:58 | INFO | train_inner | epoch 011:   1120 / 1978 loss=4.432, nll_loss=2.311, word_ins=4.04, length=3.92, ppl=21.59, wps=46616.9, ups=0.78, wpb=59558.1, bsz=2016.4, num_updates=20900, lr=0.000261298, gnorm=1.743, loss_scale=4096, train_wall=128, wall=27392
2023-01-12 23:26:06 | INFO | train_inner | epoch 011:   1220 / 1978 loss=4.456, nll_loss=2.338, word_ins=4.065, length=3.919, ppl=21.95, wps=46690.9, ups=0.78, wpb=59513.4, bsz=2004.4, num_updates=21000, lr=0.000262548, gnorm=1.704, loss_scale=4096, train_wall=127, wall=27520
2023-01-12 23:28:14 | INFO | train_inner | epoch 011:   1320 / 1978 loss=4.389, nll_loss=2.27, word_ins=4.003, length=3.86, ppl=20.95, wps=46563.7, ups=0.78, wpb=59492.3, bsz=2090.1, num_updates=21100, lr=0.000263797, gnorm=1.727, loss_scale=4096, train_wall=128, wall=27648
2023-01-12 23:30:23 | INFO | train_inner | epoch 011:   1420 / 1978 loss=4.447, nll_loss=2.322, word_ins=4.05, length=3.971, ppl=21.82, wps=45961.7, ups=0.78, wpb=59296.7, bsz=2069.3, num_updates=21200, lr=0.000265047, gnorm=1.693, loss_scale=4096, train_wall=129, wall=27777
2023-01-12 23:32:31 | INFO | train_inner | epoch 011:   1520 / 1978 loss=4.399, nll_loss=2.271, word_ins=4.005, length=3.942, ppl=21.1, wps=46004.9, ups=0.78, wpb=59096.8, bsz=2081.3, num_updates=21300, lr=0.000266297, gnorm=1.748, loss_scale=4096, train_wall=128, wall=27905
2023-01-12 23:34:39 | INFO | train_inner | epoch 011:   1620 / 1978 loss=4.467, nll_loss=2.349, word_ins=4.073, length=3.939, ppl=22.12, wps=46276.4, ups=0.78, wpb=59059, bsz=1991, num_updates=21400, lr=0.000267547, gnorm=1.651, loss_scale=4096, train_wall=127, wall=28033
2023-01-12 23:36:46 | INFO | train_inner | epoch 011:   1720 / 1978 loss=4.462, nll_loss=2.332, word_ins=4.059, length=4.035, ppl=22.05, wps=46826.3, ups=0.79, wpb=59538, bsz=1946.8, num_updates=21500, lr=0.000268796, gnorm=1.691, loss_scale=4096, train_wall=127, wall=28160
2023-01-12 23:38:53 | INFO | train_inner | epoch 011:   1820 / 1978 loss=4.398, nll_loss=2.276, word_ins=4.007, length=3.911, ppl=21.09, wps=46316.6, ups=0.78, wpb=59043, bsz=2049, num_updates=21600, lr=0.000270046, gnorm=1.662, loss_scale=4096, train_wall=127, wall=28287
2023-01-12 23:41:01 | INFO | train_inner | epoch 011:   1920 / 1978 loss=4.38, nll_loss=2.254, word_ins=3.988, length=3.919, ppl=20.82, wps=46442.3, ups=0.78, wpb=59434.9, bsz=2072.7, num_updates=21700, lr=0.000271296, gnorm=1.634, loss_scale=4096, train_wall=128, wall=28415
2023-01-12 23:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-12 23:42:28 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.105 | nll_loss 2.96 | word_ins 4.689 | length 4.158 | ppl 34.41 | wps 170849 | wpb 40242.5 | bsz 1500 | num_updates 21758 | best_loss 5.105
2023-01-12 23:42:28 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-12 23:43:08 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint11.pt (epoch 11 @ 21758 updates, score 5.105) (writing took 40.051263289991766 seconds)
2023-01-12 23:43:08 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-01-12 23:43:08 | INFO | train | epoch 011 | loss 4.471 | nll_loss 2.351 | word_ins 4.076 | length 3.945 | ppl 22.17 | wps 45388.7 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 21758 | lr 0.000272021 | gnorm 1.759 | loss_scale 4096 | train_wall 2516 | wall 28542
2023-01-12 23:43:08 | INFO | fairseq.trainer | begin training epoch 12
2023-01-12 23:44:13 | INFO | train_inner | epoch 012:     42 / 1978 loss=4.386, nll_loss=2.264, word_ins=3.996, length=3.903, ppl=20.91, wps=30810.7, ups=0.52, wpb=59094, bsz=2050.6, num_updates=21800, lr=0.000272546, gnorm=1.608, loss_scale=4096, train_wall=128, wall=28607
2023-01-12 23:46:21 | INFO | train_inner | epoch 012:    142 / 1978 loss=4.352, nll_loss=2.229, word_ins=3.965, length=3.876, ppl=20.42, wps=46675.8, ups=0.78, wpb=59612.3, bsz=2050.6, num_updates=21900, lr=0.000273795, gnorm=1.751, loss_scale=4096, train_wall=128, wall=28735
2023-01-12 23:48:28 | INFO | train_inner | epoch 012:    242 / 1978 loss=4.381, nll_loss=2.253, word_ins=3.986, length=3.946, ppl=20.83, wps=46655.5, ups=0.79, wpb=59250.8, bsz=1981.8, num_updates=22000, lr=0.000275045, gnorm=1.605, loss_scale=4096, train_wall=127, wall=28862
2023-01-12 23:50:35 | INFO | train_inner | epoch 012:    342 / 1978 loss=4.35, nll_loss=2.222, word_ins=3.959, length=3.912, ppl=20.4, wps=46257.2, ups=0.78, wpb=58940, bsz=2011.6, num_updates=22100, lr=0.000276295, gnorm=1.574, loss_scale=4096, train_wall=127, wall=28989
2023-01-12 23:52:43 | INFO | train_inner | epoch 012:    442 / 1978 loss=4.379, nll_loss=2.253, word_ins=3.986, length=3.935, ppl=20.81, wps=46733.3, ups=0.79, wpb=59500.6, bsz=1965.9, num_updates=22200, lr=0.000277545, gnorm=1.608, loss_scale=4096, train_wall=127, wall=29117
2023-01-12 23:54:50 | INFO | train_inner | epoch 012:    542 / 1978 loss=4.442, nll_loss=2.317, word_ins=4.042, length=4.001, ppl=21.73, wps=46684.1, ups=0.78, wpb=59530.2, bsz=2019.8, num_updates=22300, lr=0.000278794, gnorm=1.713, loss_scale=4096, train_wall=127, wall=29244
2023-01-12 23:56:58 | INFO | train_inner | epoch 012:    642 / 1978 loss=4.336, nll_loss=2.218, word_ins=3.954, length=3.815, ppl=20.19, wps=46334.7, ups=0.78, wpb=59417.5, bsz=2044, num_updates=22400, lr=0.000280044, gnorm=1.58, loss_scale=4096, train_wall=128, wall=29372
2023-01-12 23:59:06 | INFO | train_inner | epoch 012:    742 / 1978 loss=4.35, nll_loss=2.219, word_ins=3.956, length=3.934, ppl=20.39, wps=46501, ups=0.78, wpb=59240.8, bsz=2036.6, num_updates=22500, lr=0.000281294, gnorm=1.635, loss_scale=4096, train_wall=127, wall=29500
2023-01-13 00:01:15 | INFO | train_inner | epoch 012:    842 / 1978 loss=4.326, nll_loss=2.209, word_ins=3.946, length=3.795, ppl=20.05, wps=45830.3, ups=0.77, wpb=59191.7, bsz=2131.9, num_updates=22600, lr=0.000282544, gnorm=1.551, loss_scale=4096, train_wall=129, wall=29629
2023-01-13 00:03:23 | INFO | train_inner | epoch 012:    942 / 1978 loss=4.296, nll_loss=2.167, word_ins=3.909, length=3.87, ppl=19.64, wps=46634.2, ups=0.78, wpb=59570.7, bsz=1992.5, num_updates=22700, lr=0.000283793, gnorm=1.501, loss_scale=4096, train_wall=128, wall=29757
2023-01-13 00:05:30 | INFO | train_inner | epoch 012:   1042 / 1978 loss=4.337, nll_loss=2.213, word_ins=3.95, length=3.873, ppl=20.21, wps=46542.1, ups=0.79, wpb=59170.6, bsz=1961.7, num_updates=22800, lr=0.000285043, gnorm=1.55, loss_scale=4096, train_wall=127, wall=29884
2023-01-13 00:07:38 | INFO | train_inner | epoch 012:   1142 / 1978 loss=4.35, nll_loss=2.222, word_ins=3.957, length=3.927, ppl=20.39, wps=46307, ups=0.78, wpb=59345.4, bsz=2002.6, num_updates=22900, lr=0.000286293, gnorm=1.605, loss_scale=4096, train_wall=128, wall=30012
2023-01-13 00:09:44 | INFO | train_inner | epoch 012:   1242 / 1978 loss=4.356, nll_loss=2.226, word_ins=3.961, length=3.953, ppl=20.48, wps=46443.4, ups=0.79, wpb=58783, bsz=1899.1, num_updates=23000, lr=0.000287543, gnorm=1.532, loss_scale=4096, train_wall=126, wall=30139
2023-01-13 00:11:51 | INFO | train_inner | epoch 012:   1342 / 1978 loss=4.332, nll_loss=2.203, word_ins=3.94, length=3.922, ppl=20.14, wps=46092.9, ups=0.79, wpb=58545.2, bsz=2021.6, num_updates=23100, lr=0.000288792, gnorm=1.63, loss_scale=4096, train_wall=127, wall=30266
2023-01-13 00:13:59 | INFO | train_inner | epoch 012:   1442 / 1978 loss=4.346, nll_loss=2.22, word_ins=3.954, length=3.917, ppl=20.34, wps=46734.9, ups=0.79, wpb=59501.6, bsz=1951.6, num_updates=23200, lr=0.000290042, gnorm=1.576, loss_scale=4096, train_wall=127, wall=30393
2023-01-13 00:16:07 | INFO | train_inner | epoch 012:   1542 / 1978 loss=4.35, nll_loss=2.218, word_ins=3.954, length=3.966, ppl=20.4, wps=46170.9, ups=0.78, wpb=59091.7, bsz=1995.9, num_updates=23300, lr=0.000291292, gnorm=1.551, loss_scale=4096, train_wall=128, wall=30521
2023-01-13 00:18:15 | INFO | train_inner | epoch 012:   1642 / 1978 loss=4.296, nll_loss=2.162, word_ins=3.903, length=3.928, ppl=19.65, wps=46600.5, ups=0.78, wpb=59682.4, bsz=2003.6, num_updates=23400, lr=0.000292542, gnorm=1.554, loss_scale=4096, train_wall=128, wall=30649
2023-01-13 00:20:23 | INFO | train_inner | epoch 012:   1742 / 1978 loss=4.28, nll_loss=2.145, word_ins=3.888, length=3.923, ppl=19.43, wps=46300.1, ups=0.78, wpb=59207.6, bsz=2072.9, num_updates=23500, lr=0.000293791, gnorm=1.535, loss_scale=4096, train_wall=128, wall=30777
2023-01-13 00:22:30 | INFO | train_inner | epoch 012:   1842 / 1978 loss=4.301, nll_loss=2.174, word_ins=3.913, length=3.884, ppl=19.71, wps=46767.4, ups=0.79, wpb=59478.9, bsz=1949.8, num_updates=23600, lr=0.000295041, gnorm=1.511, loss_scale=4096, train_wall=127, wall=30904
2023-01-13 00:24:36 | INFO | train_inner | epoch 012:   1942 / 1978 loss=4.27, nll_loss=2.142, word_ins=3.884, length=3.861, ppl=19.29, wps=47141.1, ups=0.79, wpb=59366.9, bsz=1924, num_updates=23700, lr=0.000296291, gnorm=1.531, loss_scale=4096, train_wall=126, wall=31030
2023-01-13 00:25:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 00:25:36 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.927 | nll_loss 2.768 | word_ins 4.527 | length 4 | ppl 30.41 | wps 114544 | wpb 40242.5 | bsz 1500 | num_updates 23736 | best_loss 4.927
2023-01-13 00:25:36 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 00:26:17 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint12.pt (epoch 12 @ 23736 updates, score 4.927) (writing took 40.763384385965765 seconds)
2023-01-13 00:26:17 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-01-13 00:26:17 | INFO | train | epoch 012 | loss 4.338 | nll_loss 2.211 | word_ins 3.947 | length 3.909 | ppl 20.23 | wps 45296 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 23736 | lr 0.000296741 | gnorm 1.584 | loss_scale 4096 | train_wall 2519 | wall 31131
2023-01-13 00:26:17 | INFO | fairseq.trainer | begin training epoch 13
2023-01-13 00:27:50 | INFO | train_inner | epoch 013:     64 / 1978 loss=4.267, nll_loss=2.126, word_ins=3.87, length=3.971, ppl=19.25, wps=30325, ups=0.52, wpb=58846.6, bsz=2037.3, num_updates=23800, lr=0.000297541, gnorm=1.492, loss_scale=4096, train_wall=127, wall=31224
2023-01-13 00:29:58 | INFO | train_inner | epoch 013:    164 / 1978 loss=4.249, nll_loss=2.113, word_ins=3.859, length=3.894, ppl=19.01, wps=46334.1, ups=0.78, wpb=59341.5, bsz=2040.7, num_updates=23900, lr=0.00029879, gnorm=1.631, loss_scale=4096, train_wall=128, wall=31352
2023-01-13 00:32:06 | INFO | train_inner | epoch 013:    264 / 1978 loss=4.24, nll_loss=2.104, word_ins=3.85, length=3.9, ppl=18.9, wps=46417.4, ups=0.78, wpb=59408.4, bsz=2020.1, num_updates=24000, lr=0.00030004, gnorm=1.502, loss_scale=4096, train_wall=128, wall=31480
2023-01-13 00:34:15 | INFO | train_inner | epoch 013:    364 / 1978 loss=4.201, nll_loss=2.071, word_ins=3.82, length=3.81, ppl=18.39, wps=46340.4, ups=0.78, wpb=59581.4, bsz=2035.6, num_updates=24100, lr=0.00030129, gnorm=1.474, loss_scale=4096, train_wall=128, wall=31609
2023-01-13 00:36:23 | INFO | train_inner | epoch 013:    464 / 1978 loss=4.211, nll_loss=2.08, word_ins=3.828, length=3.829, ppl=18.52, wps=46046.5, ups=0.78, wpb=59290.9, bsz=2086.6, num_updates=24200, lr=0.00030254, gnorm=1.492, loss_scale=4096, train_wall=129, wall=31737
2023-01-13 00:38:32 | INFO | train_inner | epoch 013:    564 / 1978 loss=4.26, nll_loss=2.129, word_ins=3.871, length=3.886, ppl=19.16, wps=46071.4, ups=0.78, wpb=59197.7, bsz=1965.4, num_updates=24300, lr=0.000303789, gnorm=1.483, loss_scale=4096, train_wall=128, wall=31866
2023-01-13 00:40:39 | INFO | train_inner | epoch 013:    664 / 1978 loss=4.192, nll_loss=2.06, word_ins=3.81, length=3.822, ppl=18.28, wps=46619.6, ups=0.78, wpb=59404.7, bsz=2052.9, num_updates=24400, lr=0.000305039, gnorm=1.484, loss_scale=4096, train_wall=127, wall=31993
2023-01-13 00:42:47 | INFO | train_inner | epoch 013:    764 / 1978 loss=4.235, nll_loss=2.1, word_ins=3.846, length=3.891, ppl=18.83, wps=46639.6, ups=0.79, wpb=59335.7, bsz=1925.5, num_updates=24500, lr=0.000306289, gnorm=1.472, loss_scale=4096, train_wall=127, wall=32121
2023-01-13 00:44:55 | INFO | train_inner | epoch 013:    864 / 1978 loss=4.259, nll_loss=2.119, word_ins=3.861, length=3.974, ppl=19.14, wps=45655.5, ups=0.78, wpb=58682.1, bsz=2011, num_updates=24600, lr=0.000307539, gnorm=1.473, loss_scale=8192, train_wall=128, wall=32249
2023-01-13 00:47:02 | INFO | train_inner | epoch 013:    964 / 1978 loss=4.216, nll_loss=2.083, word_ins=3.83, length=3.853, ppl=18.58, wps=46913.6, ups=0.79, wpb=59748.7, bsz=1949.4, num_updates=24700, lr=0.000308788, gnorm=1.483, loss_scale=8192, train_wall=127, wall=32377
2023-01-13 00:49:10 | INFO | train_inner | epoch 013:   1064 / 1978 loss=4.194, nll_loss=2.062, word_ins=3.811, length=3.838, ppl=18.31, wps=46196.1, ups=0.78, wpb=59051.3, bsz=2059.4, num_updates=24800, lr=0.000310038, gnorm=1.534, loss_scale=8192, train_wall=128, wall=32504
2023-01-13 00:51:18 | INFO | train_inner | epoch 013:   1164 / 1978 loss=4.206, nll_loss=2.068, word_ins=3.816, length=3.909, ppl=18.46, wps=46542.7, ups=0.78, wpb=59612, bsz=1980.5, num_updates=24900, lr=0.000311288, gnorm=1.464, loss_scale=8192, train_wall=128, wall=32632
2023-01-13 00:53:32 | INFO | train_inner | epoch 013:   1264 / 1978 loss=4.237, nll_loss=2.101, word_ins=3.845, length=3.923, ppl=18.86, wps=44066.1, ups=0.75, wpb=58935.5, bsz=1938.4, num_updates=25000, lr=0.000312538, gnorm=1.525, loss_scale=8192, train_wall=127, wall=32766
2023-01-13 00:55:39 | INFO | train_inner | epoch 013:   1364 / 1978 loss=4.243, nll_loss=2.115, word_ins=3.857, length=3.86, ppl=18.94, wps=46395.5, ups=0.79, wpb=58958.3, bsz=1964.8, num_updates=25100, lr=0.000313787, gnorm=1.512, loss_scale=8192, train_wall=127, wall=32893
2023-01-13 00:57:47 | INFO | train_inner | epoch 013:   1464 / 1978 loss=4.164, nll_loss=2.034, word_ins=3.784, length=3.798, ppl=17.93, wps=46686.8, ups=0.78, wpb=59635.9, bsz=2062.7, num_updates=25200, lr=0.000315037, gnorm=1.488, loss_scale=8192, train_wall=128, wall=33021
2023-01-13 00:59:54 | INFO | train_inner | epoch 013:   1564 / 1978 loss=4.187, nll_loss=2.045, word_ins=3.794, length=3.929, ppl=18.21, wps=46918.4, ups=0.79, wpb=59630.8, bsz=1996.8, num_updates=25300, lr=0.000316287, gnorm=1.469, loss_scale=8192, train_wall=127, wall=33148
2023-01-13 01:02:01 | INFO | train_inner | epoch 013:   1664 / 1978 loss=4.161, nll_loss=2.027, word_ins=3.778, length=3.834, ppl=17.89, wps=46895.2, ups=0.79, wpb=59541.7, bsz=1946.2, num_updates=25400, lr=0.000317537, gnorm=1.442, loss_scale=8192, train_wall=127, wall=33275
2023-01-13 01:04:10 | INFO | train_inner | epoch 013:   1764 / 1978 loss=4.183, nll_loss=2.034, word_ins=3.784, length=3.994, ppl=18.17, wps=45836.4, ups=0.78, wpb=58985.6, bsz=2025, num_updates=25500, lr=0.000318786, gnorm=1.473, loss_scale=8192, train_wall=128, wall=33404
2023-01-13 01:06:17 | INFO | train_inner | epoch 013:   1864 / 1978 loss=4.107, nll_loss=1.962, word_ins=3.72, length=3.878, ppl=17.24, wps=46616.3, ups=0.78, wpb=59571.1, bsz=2055.6, num_updates=25600, lr=0.000320036, gnorm=1.366, loss_scale=8192, train_wall=128, wall=33532
2023-01-13 01:08:25 | INFO | train_inner | epoch 013:   1964 / 1978 loss=4.154, nll_loss=2.017, word_ins=3.769, length=3.856, ppl=17.81, wps=46323.1, ups=0.78, wpb=59093.1, bsz=1950.7, num_updates=25700, lr=0.000321286, gnorm=1.485, loss_scale=8192, train_wall=127, wall=33659
2023-01-13 01:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 01:08:57 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.799 | nll_loss 2.636 | word_ins 4.396 | length 4.033 | ppl 27.84 | wps 112664 | wpb 40242.5 | bsz 1500 | num_updates 25714 | best_loss 4.799
2023-01-13 01:08:57 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 01:09:37 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint13.pt (epoch 13 @ 25714 updates, score 4.799) (writing took 40.11121764080599 seconds)
2023-01-13 01:09:37 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-01-13 01:09:37 | INFO | train | epoch 013 | loss 4.208 | nll_loss 2.072 | word_ins 3.82 | length 3.883 | ppl 18.48 | wps 45092 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 25714 | lr 0.000321461 | gnorm 1.487 | loss_scale 8192 | train_wall 2523 | wall 33731
2023-01-13 01:09:37 | INFO | fairseq.trainer | begin training epoch 14
2023-01-13 01:11:41 | INFO | train_inner | epoch 014:     86 / 1978 loss=4.169, nll_loss=2.032, word_ins=3.781, length=3.876, ppl=17.99, wps=30026.1, ups=0.51, wpb=58720.2, bsz=2045.1, num_updates=25800, lr=0.000322536, gnorm=1.442, loss_scale=8192, train_wall=128, wall=33855
2023-01-13 01:13:49 | INFO | train_inner | epoch 014:    186 / 1978 loss=4.154, nll_loss=2.01, word_ins=3.762, length=3.923, ppl=17.81, wps=46422.1, ups=0.78, wpb=59378.5, bsz=1943.5, num_updates=25900, lr=0.000323785, gnorm=1.424, loss_scale=8192, train_wall=128, wall=33983
2023-01-13 01:15:57 | INFO | train_inner | epoch 014:    286 / 1978 loss=4.121, nll_loss=1.983, word_ins=3.738, length=3.831, ppl=17.4, wps=46045, ups=0.78, wpb=58989.8, bsz=2034.2, num_updates=26000, lr=0.000325035, gnorm=1.417, loss_scale=8192, train_wall=128, wall=34111
2023-01-13 01:18:03 | INFO | train_inner | epoch 014:    386 / 1978 loss=4.155, nll_loss=2.012, word_ins=3.763, length=3.922, ppl=17.82, wps=46344.6, ups=0.79, wpb=58735, bsz=1936.6, num_updates=26100, lr=0.000326285, gnorm=1.456, loss_scale=8192, train_wall=126, wall=34237
2023-01-13 01:20:12 | INFO | train_inner | epoch 014:    486 / 1978 loss=4.098, nll_loss=1.957, word_ins=3.714, length=3.843, ppl=17.12, wps=46173.3, ups=0.78, wpb=59230.8, bsz=2040.5, num_updates=26200, lr=0.000327535, gnorm=1.352, loss_scale=8192, train_wall=128, wall=34366
2023-01-13 01:22:19 | INFO | train_inner | epoch 014:    586 / 1978 loss=4.072, nll_loss=1.934, word_ins=3.693, length=3.794, ppl=16.82, wps=46462.5, ups=0.78, wpb=59317, bsz=2013, num_updates=26300, lr=0.000328784, gnorm=1.365, loss_scale=8192, train_wall=127, wall=34493
2023-01-13 01:24:33 | INFO | train_inner | epoch 014:    686 / 1978 loss=4.102, nll_loss=1.966, word_ins=3.721, length=3.811, ppl=17.17, wps=44347.3, ups=0.75, wpb=59484.6, bsz=2018, num_updates=26400, lr=0.000330034, gnorm=1.388, loss_scale=8192, train_wall=134, wall=34628
2023-01-13 01:26:41 | INFO | train_inner | epoch 014:    786 / 1978 loss=4.129, nll_loss=1.991, word_ins=3.744, length=3.845, ppl=17.49, wps=46485.2, ups=0.78, wpb=59233.8, bsz=1968.4, num_updates=26500, lr=0.000331284, gnorm=1.368, loss_scale=8192, train_wall=127, wall=34755
2023-01-13 01:28:50 | INFO | train_inner | epoch 014:    886 / 1978 loss=4.038, nll_loss=1.89, word_ins=3.653, length=3.846, ppl=16.42, wps=46447.7, ups=0.78, wpb=59825.5, bsz=2084.4, num_updates=26600, lr=0.000332534, gnorm=1.332, loss_scale=8192, train_wall=129, wall=34884
2023-01-13 01:31:07 | INFO | train_inner | epoch 014:    986 / 1978 loss=4.109, nll_loss=1.966, word_ins=3.72, length=3.885, ppl=17.25, wps=43210.9, ups=0.73, wpb=59483.8, bsz=1984.2, num_updates=26700, lr=0.000333783, gnorm=1.446, loss_scale=8192, train_wall=137, wall=35021
2023-01-13 01:33:15 | INFO | train_inner | epoch 014:   1086 / 1978 loss=4.161, nll_loss=2.02, word_ins=3.768, length=3.929, ppl=17.89, wps=46112.6, ups=0.79, wpb=58633, bsz=1954.6, num_updates=26800, lr=0.000335033, gnorm=1.373, loss_scale=8192, train_wall=127, wall=35149
2023-01-13 01:35:40 | INFO | train_inner | epoch 014:   1186 / 1978 loss=4.02, nll_loss=1.876, word_ins=3.64, length=3.798, ppl=16.23, wps=41161.1, ups=0.69, wpb=59726.7, bsz=2093, num_updates=26900, lr=0.000336283, gnorm=1.327, loss_scale=8192, train_wall=145, wall=35294
2023-01-13 01:37:47 | INFO | train_inner | epoch 014:   1286 / 1978 loss=4.103, nll_loss=1.959, word_ins=3.714, length=3.896, ppl=17.19, wps=46538.5, ups=0.78, wpb=59289.8, bsz=2002.5, num_updates=27000, lr=0.000337533, gnorm=1.324, loss_scale=8192, train_wall=127, wall=35421
2023-01-13 01:40:00 | INFO | train_inner | epoch 014:   1386 / 1978 loss=4.106, nll_loss=1.966, word_ins=3.72, length=3.864, ppl=17.22, wps=44559.2, ups=0.75, wpb=59342.8, bsz=1992.6, num_updates=27100, lr=0.000338782, gnorm=1.371, loss_scale=8192, train_wall=133, wall=35554
2023-01-13 01:42:11 | INFO | train_inner | epoch 014:   1486 / 1978 loss=4.093, nll_loss=1.953, word_ins=3.708, length=3.844, ppl=17.06, wps=45351.5, ups=0.77, wpb=59243.7, bsz=1912.4, num_updates=27200, lr=0.000340032, gnorm=1.303, loss_scale=8192, train_wall=126, wall=35685
2023-01-13 01:44:18 | INFO | train_inner | epoch 014:   1586 / 1978 loss=4.057, nll_loss=1.912, word_ins=3.672, length=3.846, ppl=16.64, wps=47040.7, ups=0.78, wpb=59992.3, bsz=1958.6, num_updates=27300, lr=0.000341282, gnorm=1.318, loss_scale=8192, train_wall=127, wall=35813
2023-01-13 01:46:25 | INFO | train_inner | epoch 014:   1686 / 1978 loss=4.063, nll_loss=1.921, word_ins=3.679, length=3.846, ppl=16.72, wps=46809.7, ups=0.79, wpb=59403.3, bsz=1954.8, num_updates=27400, lr=0.000342532, gnorm=1.277, loss_scale=8192, train_wall=127, wall=35939
2023-01-13 01:48:33 | INFO | train_inner | epoch 014:   1786 / 1978 loss=4.064, nll_loss=1.922, word_ins=3.68, length=3.845, ppl=16.73, wps=46349.7, ups=0.78, wpb=59269.5, bsz=2038, num_updates=27500, lr=0.000343781, gnorm=1.286, loss_scale=8192, train_wall=128, wall=36067
2023-01-13 01:50:49 | INFO | train_inner | epoch 014:   1886 / 1978 loss=4.013, nll_loss=1.873, word_ins=3.636, length=3.77, ppl=16.14, wps=43604.5, ups=0.74, wpb=59244.7, bsz=2044.2, num_updates=27600, lr=0.000345031, gnorm=1.241, loss_scale=8192, train_wall=136, wall=36203
2023-01-13 01:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 01:52:59 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.754 | nll_loss 2.611 | word_ins 4.364 | length 3.899 | ppl 26.98 | wps 152615 | wpb 40242.5 | bsz 1500 | num_updates 27692 | best_loss 4.754
2023-01-13 01:52:59 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 01:53:40 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint14.pt (epoch 14 @ 27692 updates, score 4.754) (writing took 41.283967413939536 seconds)
2023-01-13 01:53:40 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-01-13 01:53:40 | INFO | train | epoch 014 | loss 4.092 | nll_loss 1.951 | word_ins 3.707 | length 3.85 | ppl 17.05 | wps 44369.8 | ups 0.75 | wpb 59284.3 | bsz 2002.6 | num_updates 27692 | lr 0.000346181 | gnorm 1.353 | loss_scale 8192 | train_wall 2568 | wall 36374
2023-01-13 01:53:40 | INFO | fairseq.trainer | begin training epoch 15
2023-01-13 01:54:21 | INFO | train_inner | epoch 015:      8 / 1978 loss=4.011, nll_loss=1.87, word_ins=3.632, length=3.792, ppl=16.13, wps=27900.9, ups=0.47, wpb=59191.2, bsz=2042.5, num_updates=27700, lr=0.000346281, gnorm=1.258, loss_scale=8192, train_wall=127, wall=36415
2023-01-13 01:56:31 | INFO | train_inner | epoch 015:    108 / 1978 loss=3.994, nll_loss=1.856, word_ins=3.62, length=3.734, ppl=15.93, wps=46137.4, ups=0.77, wpb=59656.6, bsz=2053, num_updates=27800, lr=0.000347531, gnorm=1.236, loss_scale=8192, train_wall=129, wall=36545
2023-01-13 01:58:38 | INFO | train_inner | epoch 015:    208 / 1978 loss=4.014, nll_loss=1.872, word_ins=3.635, length=3.79, ppl=16.16, wps=46843.8, ups=0.78, wpb=59682.3, bsz=1953.9, num_updates=27900, lr=0.00034878, gnorm=1.248, loss_scale=8192, train_wall=127, wall=36672
2023-01-13 02:00:46 | INFO | train_inner | epoch 015:    308 / 1978 loss=3.994, nll_loss=1.853, word_ins=3.617, length=3.764, ppl=15.93, wps=46186.4, ups=0.78, wpb=58926.8, bsz=2047.9, num_updates=28000, lr=0.00035003, gnorm=1.213, loss_scale=8192, train_wall=127, wall=36800
2023-01-13 02:02:54 | INFO | train_inner | epoch 015:    408 / 1978 loss=4.022, nll_loss=1.876, word_ins=3.638, length=3.845, ppl=16.25, wps=46475.3, ups=0.78, wpb=59501.6, bsz=2021.5, num_updates=28100, lr=0.00035128, gnorm=1.292, loss_scale=8192, train_wall=128, wall=36928
2023-01-13 02:05:02 | INFO | train_inner | epoch 015:    508 / 1978 loss=4.065, nll_loss=1.919, word_ins=3.677, length=3.887, ppl=16.74, wps=45894.6, ups=0.78, wpb=58863.1, bsz=2039.4, num_updates=28200, lr=0.00035253, gnorm=1.307, loss_scale=8192, train_wall=128, wall=37056
2023-01-13 02:07:11 | INFO | train_inner | epoch 015:    608 / 1978 loss=3.967, nll_loss=1.827, word_ins=3.594, length=3.73, ppl=15.64, wps=46281.5, ups=0.77, wpb=59869.6, bsz=2078.5, num_updates=28300, lr=0.000353779, gnorm=1.199, loss_scale=8192, train_wall=129, wall=37185
2023-01-13 02:09:17 | INFO | train_inner | epoch 015:    708 / 1978 loss=4.049, nll_loss=1.903, word_ins=3.663, length=3.861, ppl=16.55, wps=46880.3, ups=0.79, wpb=59126.1, bsz=1862.8, num_updates=28400, lr=0.000355029, gnorm=1.233, loss_scale=8192, train_wall=126, wall=37311
2023-01-13 02:11:25 | INFO | train_inner | epoch 015:    808 / 1978 loss=3.994, nll_loss=1.852, word_ins=3.616, length=3.783, ppl=15.93, wps=46550.2, ups=0.78, wpb=59439, bsz=1967.9, num_updates=28500, lr=0.000356279, gnorm=1.224, loss_scale=8192, train_wall=127, wall=37439
2023-01-13 02:12:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2023-01-13 02:13:55 | INFO | train_inner | epoch 015:    909 / 1978 loss=3.982, nll_loss=1.836, word_ins=3.601, length=3.811, ppl=15.81, wps=39624.4, ups=0.67, wpb=59507.9, bsz=2044.2, num_updates=28600, lr=0.000357529, gnorm=1.193, loss_scale=4096, train_wall=150, wall=37589
2023-01-13 02:16:03 | INFO | train_inner | epoch 015:   1009 / 1978 loss=3.983, nll_loss=1.833, word_ins=3.599, length=3.837, ppl=15.81, wps=46542.8, ups=0.78, wpb=59381.8, bsz=1991.2, num_updates=28700, lr=0.000358778, gnorm=1.207, loss_scale=4096, train_wall=127, wall=37717
2023-01-13 02:18:11 | INFO | train_inner | epoch 015:   1109 / 1978 loss=4.026, nll_loss=1.883, word_ins=3.643, length=3.834, ppl=16.29, wps=46505.4, ups=0.78, wpb=59445.3, bsz=1975.4, num_updates=28800, lr=0.000360028, gnorm=1.247, loss_scale=4096, train_wall=128, wall=37845
2023-01-13 02:20:19 | INFO | train_inner | epoch 015:   1209 / 1978 loss=3.966, nll_loss=1.824, word_ins=3.59, length=3.754, ppl=15.62, wps=46182.7, ups=0.78, wpb=59479.7, bsz=2031.6, num_updates=28900, lr=0.000361278, gnorm=1.216, loss_scale=4096, train_wall=129, wall=37974
2023-01-13 02:22:27 | INFO | train_inner | epoch 015:   1309 / 1978 loss=4.023, nll_loss=1.88, word_ins=3.641, length=3.825, ppl=16.26, wps=46199, ups=0.78, wpb=59036.3, bsz=2087.8, num_updates=29000, lr=0.000362528, gnorm=1.23, loss_scale=4096, train_wall=128, wall=38101
2023-01-13 02:24:35 | INFO | train_inner | epoch 015:   1409 / 1978 loss=4.01, nll_loss=1.863, word_ins=3.625, length=3.853, ppl=16.11, wps=46119, ups=0.78, wpb=58871.3, bsz=1995.7, num_updates=29100, lr=0.000363777, gnorm=1.232, loss_scale=4096, train_wall=127, wall=38229
2023-01-13 02:26:42 | INFO | train_inner | epoch 015:   1509 / 1978 loss=4.04, nll_loss=1.894, word_ins=3.652, length=3.875, ppl=16.45, wps=46287.7, ups=0.79, wpb=58934.1, bsz=1952.1, num_updates=29200, lr=0.000365027, gnorm=1.214, loss_scale=4096, train_wall=127, wall=38356
2023-01-13 02:28:50 | INFO | train_inner | epoch 015:   1609 / 1978 loss=3.985, nll_loss=1.842, word_ins=3.606, length=3.791, ppl=15.83, wps=46386.5, ups=0.78, wpb=59215.5, bsz=1995.5, num_updates=29300, lr=0.000366277, gnorm=1.156, loss_scale=4096, train_wall=127, wall=38484
2023-01-13 02:30:57 | INFO | train_inner | epoch 015:   1709 / 1978 loss=4.027, nll_loss=1.887, word_ins=3.646, length=3.812, ppl=16.3, wps=46754.1, ups=0.79, wpb=59257.7, bsz=1892, num_updates=29400, lr=0.000367527, gnorm=1.212, loss_scale=4096, train_wall=127, wall=38611
2023-01-13 02:33:04 | INFO | train_inner | epoch 015:   1809 / 1978 loss=3.964, nll_loss=1.813, word_ins=3.579, length=3.846, ppl=15.61, wps=46138.7, ups=0.79, wpb=58611.8, bsz=2021.7, num_updates=29500, lr=0.000368776, gnorm=1.149, loss_scale=4096, train_wall=127, wall=38738
2023-01-13 02:35:12 | INFO | train_inner | epoch 015:   1909 / 1978 loss=3.939, nll_loss=1.795, word_ins=3.563, length=3.769, ppl=15.34, wps=46329, ups=0.78, wpb=59451.8, bsz=2029.8, num_updates=29600, lr=0.000370026, gnorm=1.131, loss_scale=4096, train_wall=128, wall=38866
2023-01-13 02:36:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 02:36:51 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.679 | nll_loss 2.535 | word_ins 4.297 | length 3.813 | ppl 25.61 | wps 105645 | wpb 40242.5 | bsz 1500 | num_updates 29669 | best_loss 4.679
2023-01-13 02:36:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 02:37:32 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint15.pt (epoch 15 @ 29669 updates, score 4.679) (writing took 40.2110757320188 seconds)
2023-01-13 02:37:32 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-01-13 02:37:32 | INFO | train | epoch 015 | loss 4.002 | nll_loss 1.858 | word_ins 3.621 | length 3.811 | ppl 16.02 | wps 44542.2 | ups 0.75 | wpb 59285.5 | bsz 2001.8 | num_updates 29669 | lr 0.000370888 | gnorm 1.217 | loss_scale 4096 | train_wall 2544 | wall 39006
2023-01-13 02:37:32 | INFO | fairseq.trainer | begin training epoch 16
2023-01-13 02:38:23 | INFO | train_inner | epoch 016:     31 / 1978 loss=3.988, nll_loss=1.843, word_ins=3.606, length=3.818, ppl=15.86, wps=31037.2, ups=0.52, wpb=59246.6, bsz=1967, num_updates=29700, lr=0.000371276, gnorm=1.179, loss_scale=4096, train_wall=127, wall=39057
2023-01-13 02:40:31 | INFO | train_inner | epoch 016:    131 / 1978 loss=3.944, nll_loss=1.8, word_ins=3.568, length=3.759, ppl=15.39, wps=46842.7, ups=0.78, wpb=60055.8, bsz=2001.7, num_updates=29800, lr=0.000372526, gnorm=1.152, loss_scale=4096, train_wall=128, wall=39185
2023-01-13 02:42:38 | INFO | train_inner | epoch 016:    231 / 1978 loss=3.974, nll_loss=1.828, word_ins=3.592, length=3.818, ppl=15.72, wps=46455.5, ups=0.79, wpb=59058, bsz=1914.8, num_updates=29900, lr=0.000373775, gnorm=1.153, loss_scale=4096, train_wall=127, wall=39312
2023-01-13 02:44:47 | INFO | train_inner | epoch 016:    331 / 1978 loss=3.954, nll_loss=1.809, word_ins=3.576, length=3.777, ppl=15.5, wps=46056.5, ups=0.78, wpb=59211.5, bsz=2010.6, num_updates=30000, lr=0.000375025, gnorm=1.119, loss_scale=4096, train_wall=128, wall=39441
2023-01-13 02:46:55 | INFO | train_inner | epoch 016:    431 / 1978 loss=3.896, nll_loss=1.748, word_ins=3.52, length=3.759, ppl=14.89, wps=46360.3, ups=0.78, wpb=59592, bsz=2063.8, num_updates=30100, lr=0.000376275, gnorm=1.088, loss_scale=4096, train_wall=128, wall=39569
2023-01-13 02:49:03 | INFO | train_inner | epoch 016:    531 / 1978 loss=3.932, nll_loss=1.787, word_ins=3.555, length=3.77, ppl=15.26, wps=46357.2, ups=0.78, wpb=59245, bsz=2050.2, num_updates=30200, lr=0.000377525, gnorm=1.168, loss_scale=4096, train_wall=128, wall=39697
2023-01-13 02:51:14 | INFO | train_inner | epoch 016:    631 / 1978 loss=3.928, nll_loss=1.78, word_ins=3.549, length=3.794, ppl=15.22, wps=45291.9, ups=0.76, wpb=59236.3, bsz=1991.1, num_updates=30300, lr=0.000378774, gnorm=1.112, loss_scale=4096, train_wall=127, wall=39828
2023-01-13 02:53:28 | INFO | train_inner | epoch 016:    731 / 1978 loss=3.962, nll_loss=1.815, word_ins=3.581, length=3.811, ppl=15.58, wps=44242.5, ups=0.75, wpb=59148.5, bsz=1973, num_updates=30400, lr=0.000380024, gnorm=1.107, loss_scale=4096, train_wall=133, wall=39962
2023-01-13 02:55:36 | INFO | train_inner | epoch 016:    831 / 1978 loss=3.879, nll_loss=1.741, word_ins=3.513, length=3.663, ppl=14.71, wps=46272.7, ups=0.78, wpb=59508.2, bsz=2092.1, num_updates=30500, lr=0.000381274, gnorm=1.116, loss_scale=4096, train_wall=128, wall=40090
2023-01-13 02:57:44 | INFO | train_inner | epoch 016:    931 / 1978 loss=3.896, nll_loss=1.75, word_ins=3.522, length=3.744, ppl=14.89, wps=46444.1, ups=0.78, wpb=59353.4, bsz=2078, num_updates=30600, lr=0.000382524, gnorm=1.1, loss_scale=4096, train_wall=128, wall=40218
2023-01-13 02:59:51 | INFO | train_inner | epoch 016:   1031 / 1978 loss=3.944, nll_loss=1.798, word_ins=3.564, length=3.806, ppl=15.4, wps=46774.2, ups=0.79, wpb=59576.6, bsz=1933.5, num_updates=30700, lr=0.000383773, gnorm=1.108, loss_scale=4096, train_wall=127, wall=40345
2023-01-13 03:01:58 | INFO | train_inner | epoch 016:   1131 / 1978 loss=3.995, nll_loss=1.847, word_ins=3.608, length=3.864, ppl=15.94, wps=46817.9, ups=0.79, wpb=59047.7, bsz=1866.2, num_updates=30800, lr=0.000385023, gnorm=1.134, loss_scale=4096, train_wall=126, wall=40472
2023-01-13 03:04:06 | INFO | train_inner | epoch 016:   1231 / 1978 loss=3.901, nll_loss=1.751, word_ins=3.522, length=3.794, ppl=14.94, wps=46212.6, ups=0.78, wpb=59459.7, bsz=2024.5, num_updates=30900, lr=0.000386273, gnorm=1.067, loss_scale=4096, train_wall=128, wall=40600
2023-01-13 03:06:21 | INFO | train_inner | epoch 016:   1331 / 1978 loss=3.915, nll_loss=1.77, word_ins=3.539, length=3.767, ppl=15.09, wps=43790.4, ups=0.74, wpb=58898.5, bsz=2056.4, num_updates=31000, lr=0.000387523, gnorm=1.076, loss_scale=4096, train_wall=128, wall=40735
2023-01-13 03:08:29 | INFO | train_inner | epoch 016:   1431 / 1978 loss=3.912, nll_loss=1.767, word_ins=3.536, length=3.762, ppl=15.05, wps=46348.2, ups=0.78, wpb=59422.3, bsz=2039, num_updates=31100, lr=0.000388772, gnorm=1.079, loss_scale=4096, train_wall=128, wall=40863
2023-01-13 03:10:36 | INFO | train_inner | epoch 016:   1531 / 1978 loss=3.964, nll_loss=1.817, word_ins=3.582, length=3.822, ppl=15.6, wps=46467.3, ups=0.78, wpb=59229.2, bsz=1965.4, num_updates=31200, lr=0.000390022, gnorm=1.124, loss_scale=4096, train_wall=127, wall=40990
2023-01-13 03:12:45 | INFO | train_inner | epoch 016:   1631 / 1978 loss=3.91, nll_loss=1.757, word_ins=3.527, length=3.827, ppl=15.03, wps=46151.7, ups=0.78, wpb=59357.3, bsz=2017.6, num_updates=31300, lr=0.000391272, gnorm=1.092, loss_scale=4096, train_wall=128, wall=41119
2023-01-13 03:14:54 | INFO | train_inner | epoch 016:   1731 / 1978 loss=3.934, nll_loss=1.78, word_ins=3.548, length=3.863, ppl=15.29, wps=46241.3, ups=0.78, wpb=59481.1, bsz=1987.8, num_updates=31400, lr=0.000392522, gnorm=1.105, loss_scale=4096, train_wall=128, wall=41248
2023-01-13 03:17:02 | INFO | train_inner | epoch 016:   1831 / 1978 loss=3.904, nll_loss=1.759, word_ins=3.528, length=3.759, ppl=14.97, wps=46214.9, ups=0.78, wpb=59145, bsz=2020.2, num_updates=31500, lr=0.000393771, gnorm=1.071, loss_scale=4096, train_wall=128, wall=41376
2023-01-13 03:19:09 | INFO | train_inner | epoch 016:   1931 / 1978 loss=3.926, nll_loss=1.767, word_ins=3.537, length=3.89, ppl=15.2, wps=46159, ups=0.79, wpb=58568.6, bsz=1964.5, num_updates=31600, lr=0.000395021, gnorm=1.045, loss_scale=4096, train_wall=127, wall=41503
2023-01-13 03:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 03:20:20 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.59 | nll_loss 2.434 | word_ins 4.196 | length 3.933 | ppl 24.08 | wps 177840 | wpb 40242.5 | bsz 1500 | num_updates 31647 | best_loss 4.59
2023-01-13 03:20:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 03:21:02 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint16.pt (epoch 16 @ 31647 updates, score 4.59) (writing took 41.86838539643213 seconds)
2023-01-13 03:21:02 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-01-13 03:21:02 | INFO | train | epoch 016 | loss 3.93 | nll_loss 1.782 | word_ins 3.55 | length 3.791 | ppl 15.24 | wps 44921.1 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 31647 | lr 0.000395608 | gnorm 1.106 | loss_scale 4096 | train_wall 2531 | wall 41616
2023-01-13 03:21:02 | INFO | fairseq.trainer | begin training epoch 17
2023-01-13 03:22:21 | INFO | train_inner | epoch 017:     53 / 1978 loss=3.909, nll_loss=1.757, word_ins=3.526, length=3.825, ppl=15.02, wps=30592.7, ups=0.52, wpb=58871.7, bsz=1983, num_updates=31700, lr=0.000396271, gnorm=1.033, loss_scale=4096, train_wall=127, wall=41695
2023-01-13 03:24:30 | INFO | train_inner | epoch 017:    153 / 1978 loss=3.825, nll_loss=1.684, word_ins=3.461, length=3.633, ppl=14.17, wps=46362.4, ups=0.77, wpb=59909.7, bsz=2116.8, num_updates=31800, lr=0.000397521, gnorm=1.041, loss_scale=4096, train_wall=129, wall=41824
2023-01-13 03:26:38 | INFO | train_inner | epoch 017:    253 / 1978 loss=3.875, nll_loss=1.731, word_ins=3.503, length=3.721, ppl=14.67, wps=46703.3, ups=0.78, wpb=59518.4, bsz=1973.2, num_updates=31900, lr=0.00039877, gnorm=1.037, loss_scale=4096, train_wall=127, wall=41952
2023-01-13 03:28:46 | INFO | train_inner | epoch 017:    353 / 1978 loss=3.896, nll_loss=1.748, word_ins=3.519, length=3.769, ppl=14.88, wps=46220, ups=0.78, wpb=59342.1, bsz=2014.5, num_updates=32000, lr=0.00040002, gnorm=1.076, loss_scale=4096, train_wall=128, wall=42080
2023-01-13 03:30:59 | INFO | train_inner | epoch 017:    453 / 1978 loss=3.885, nll_loss=1.738, word_ins=3.509, length=3.763, ppl=14.78, wps=44589.4, ups=0.75, wpb=59111.4, bsz=2006.8, num_updates=32100, lr=0.00040127, gnorm=1.066, loss_scale=4096, train_wall=132, wall=42213
2023-01-13 03:33:07 | INFO | train_inner | epoch 017:    553 / 1978 loss=3.87, nll_loss=1.732, word_ins=3.504, length=3.667, ppl=14.62, wps=46497.7, ups=0.78, wpb=59796.6, bsz=2043.8, num_updates=32200, lr=0.00040252, gnorm=1.048, loss_scale=4096, train_wall=128, wall=42341
2023-01-13 03:35:14 | INFO | train_inner | epoch 017:    653 / 1978 loss=3.908, nll_loss=1.756, word_ins=3.525, length=3.829, ppl=15.01, wps=46755.7, ups=0.79, wpb=59248.2, bsz=1905.5, num_updates=32300, lr=0.000403769, gnorm=1.06, loss_scale=4096, train_wall=127, wall=42468
2023-01-13 03:37:22 | INFO | train_inner | epoch 017:    753 / 1978 loss=3.906, nll_loss=1.746, word_ins=3.516, length=3.895, ppl=14.99, wps=46118.6, ups=0.78, wpb=58925.5, bsz=2006.6, num_updates=32400, lr=0.000405019, gnorm=1.07, loss_scale=4096, train_wall=128, wall=42596
2023-01-13 03:39:30 | INFO | train_inner | epoch 017:    853 / 1978 loss=3.883, nll_loss=1.737, word_ins=3.508, length=3.749, ppl=14.76, wps=46037.2, ups=0.78, wpb=58837.8, bsz=2036.7, num_updates=32500, lr=0.000406269, gnorm=1.024, loss_scale=4096, train_wall=128, wall=42724
2023-01-13 03:41:37 | INFO | train_inner | epoch 017:    953 / 1978 loss=3.914, nll_loss=1.766, word_ins=3.534, length=3.804, ppl=15.08, wps=46716.4, ups=0.79, wpb=59328.5, bsz=1945.2, num_updates=32600, lr=0.000407519, gnorm=1.064, loss_scale=4096, train_wall=127, wall=42851
2023-01-13 03:43:48 | INFO | train_inner | epoch 017:   1053 / 1978 loss=3.835, nll_loss=1.688, word_ins=3.464, length=3.716, ppl=14.27, wps=45504.2, ups=0.76, wpb=59619.5, bsz=1987.6, num_updates=32700, lr=0.000408768, gnorm=0.977, loss_scale=8192, train_wall=131, wall=42982
2023-01-13 03:45:55 | INFO | train_inner | epoch 017:   1153 / 1978 loss=3.892, nll_loss=1.74, word_ins=3.511, length=3.811, ppl=14.85, wps=45969.8, ups=0.78, wpb=58738.6, bsz=1959.4, num_updates=32800, lr=0.000410018, gnorm=1.007, loss_scale=8192, train_wall=128, wall=43109
2023-01-13 03:48:32 | INFO | train_inner | epoch 017:   1253 / 1978 loss=3.843, nll_loss=1.688, word_ins=3.464, length=3.786, ppl=14.35, wps=37852.3, ups=0.64, wpb=59186.2, bsz=2081.8, num_updates=32900, lr=0.000411268, gnorm=1.008, loss_scale=8192, train_wall=129, wall=43266
2023-01-13 03:50:40 | INFO | train_inner | epoch 017:   1353 / 1978 loss=3.847, nll_loss=1.698, word_ins=3.473, length=3.733, ppl=14.39, wps=46187.9, ups=0.78, wpb=59122.3, bsz=2070.6, num_updates=33000, lr=0.000412518, gnorm=1.036, loss_scale=8192, train_wall=128, wall=43394
2023-01-13 03:52:51 | INFO | train_inner | epoch 017:   1453 / 1978 loss=3.865, nll_loss=1.714, word_ins=3.486, length=3.792, ppl=14.57, wps=45084.9, ups=0.76, wpb=59311.2, bsz=1993.8, num_updates=33100, lr=0.000413767, gnorm=1.008, loss_scale=8192, train_wall=128, wall=43525
2023-01-13 03:58:27 | INFO | train_inner | epoch 017:   1553 / 1978 loss=3.874, nll_loss=1.726, word_ins=3.497, length=3.765, ppl=14.66, wps=17603.5, ups=0.3, wpb=59066.5, bsz=1971, num_updates=33200, lr=0.000415017, gnorm=1.01, loss_scale=8192, train_wall=335, wall=43861
2023-01-13 04:00:34 | INFO | train_inner | epoch 017:   1653 / 1978 loss=3.887, nll_loss=1.733, word_ins=3.504, length=3.835, ppl=14.8, wps=46221.4, ups=0.79, wpb=58718.3, bsz=1964.7, num_updates=33300, lr=0.000416267, gnorm=1.018, loss_scale=8192, train_wall=127, wall=43988
2023-01-13 04:02:52 | INFO | train_inner | epoch 017:   1753 / 1978 loss=3.841, nll_loss=1.692, word_ins=3.466, length=3.746, ppl=14.33, wps=43157.3, ups=0.72, wpb=59766.7, bsz=2020.2, num_updates=33400, lr=0.000417517, gnorm=0.994, loss_scale=8192, train_wall=138, wall=44126
2023-01-13 04:05:00 | INFO | train_inner | epoch 017:   1853 / 1978 loss=3.852, nll_loss=1.705, word_ins=3.478, length=3.736, ppl=14.44, wps=46725.5, ups=0.79, wpb=59479.4, bsz=1969, num_updates=33500, lr=0.000418766, gnorm=0.965, loss_scale=8192, train_wall=127, wall=44254
2023-01-13 04:07:08 | INFO | train_inner | epoch 017:   1953 / 1978 loss=3.852, nll_loss=1.701, word_ins=3.475, length=3.777, ppl=14.44, wps=46385.3, ups=0.78, wpb=59675.9, bsz=1992.4, num_updates=33600, lr=0.000420016, gnorm=0.995, loss_scale=8192, train_wall=128, wall=44382
2023-01-13 04:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 04:07:54 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.558 | nll_loss 2.401 | word_ins 4.163 | length 3.956 | ppl 23.56 | wps 96382.7 | wpb 40242.5 | bsz 1500 | num_updates 33625 | best_loss 4.558
2023-01-13 04:07:54 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 04:08:34 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint17.pt (epoch 17 @ 33625 updates, score 4.558) (writing took 40.2546516363509 seconds)
2023-01-13 04:08:34 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-01-13 04:08:34 | INFO | train | epoch 017 | loss 3.871 | nll_loss 1.722 | word_ins 3.495 | length 3.763 | ppl 14.63 | wps 41118 | ups 0.69 | wpb 59284.3 | bsz 2002.6 | num_updates 33625 | lr 0.000420328 | gnorm 1.025 | loss_scale 8192 | train_wall 2751 | wall 44468
2023-01-13 04:08:34 | INFO | fairseq.trainer | begin training epoch 18
2023-01-13 04:10:42 | INFO | train_inner | epoch 018:     75 / 1978 loss=3.855, nll_loss=1.702, word_ins=3.476, length=3.788, ppl=14.47, wps=27718.6, ups=0.47, wpb=59120.1, bsz=1974.2, num_updates=33700, lr=0.000421266, gnorm=1.017, loss_scale=8192, train_wall=145, wall=44596
2023-01-13 04:12:51 | INFO | train_inner | epoch 018:    175 / 1978 loss=3.842, nll_loss=1.693, word_ins=3.468, length=3.744, ppl=14.34, wps=45633.7, ups=0.77, wpb=59136.9, bsz=1934, num_updates=33800, lr=0.000422516, gnorm=0.987, loss_scale=8192, train_wall=129, wall=44725
2023-01-13 04:14:59 | INFO | train_inner | epoch 018:    275 / 1978 loss=3.785, nll_loss=1.638, word_ins=3.419, length=3.661, ppl=13.78, wps=46650.9, ups=0.78, wpb=59472.2, bsz=2007.4, num_updates=33900, lr=0.000423765, gnorm=0.954, loss_scale=8192, train_wall=127, wall=44853
2023-01-13 04:17:06 | INFO | train_inner | epoch 018:    375 / 1978 loss=3.826, nll_loss=1.676, word_ins=3.451, length=3.748, ppl=14.19, wps=46208.8, ups=0.79, wpb=58828.3, bsz=1993.1, num_updates=34000, lr=0.000425015, gnorm=0.97, loss_scale=8192, train_wall=127, wall=44980
2023-01-13 04:19:15 | INFO | train_inner | epoch 018:    475 / 1978 loss=3.815, nll_loss=1.666, word_ins=3.442, length=3.73, ppl=14.07, wps=46408.9, ups=0.78, wpb=59782.2, bsz=2077.4, num_updates=34100, lr=0.000426265, gnorm=0.996, loss_scale=8192, train_wall=129, wall=45109
2023-01-13 04:21:22 | INFO | train_inner | epoch 018:    575 / 1978 loss=3.85, nll_loss=1.704, word_ins=3.477, length=3.733, ppl=14.42, wps=46198.1, ups=0.78, wpb=58957, bsz=2008.6, num_updates=34200, lr=0.000427515, gnorm=0.974, loss_scale=8192, train_wall=127, wall=45237
2023-01-13 04:23:30 | INFO | train_inner | epoch 018:    675 / 1978 loss=3.835, nll_loss=1.694, word_ins=3.468, length=3.675, ppl=14.27, wps=46439.9, ups=0.78, wpb=59314.5, bsz=1981.8, num_updates=34300, lr=0.000428764, gnorm=1.031, loss_scale=8192, train_wall=128, wall=45364
2023-01-13 04:25:38 | INFO | train_inner | epoch 018:    775 / 1978 loss=3.823, nll_loss=1.67, word_ins=3.447, length=3.764, ppl=14.15, wps=46697.7, ups=0.78, wpb=59594.4, bsz=1956.2, num_updates=34400, lr=0.000430014, gnorm=0.973, loss_scale=8192, train_wall=127, wall=45492
2023-01-13 04:27:46 | INFO | train_inner | epoch 018:    875 / 1978 loss=3.813, nll_loss=1.663, word_ins=3.44, length=3.731, ppl=14.06, wps=46152, ups=0.78, wpb=59003.7, bsz=2012.7, num_updates=34500, lr=0.000431264, gnorm=0.95, loss_scale=8192, train_wall=128, wall=45620
2023-01-13 04:29:53 | INFO | train_inner | epoch 018:    975 / 1978 loss=3.815, nll_loss=1.669, word_ins=3.445, length=3.699, ppl=14.07, wps=47221.5, ups=0.78, wpb=60166.3, bsz=1990.2, num_updates=34600, lr=0.000432514, gnorm=0.975, loss_scale=8192, train_wall=127, wall=45747
2023-01-13 04:32:10 | INFO | train_inner | epoch 018:   1075 / 1978 loss=3.885, nll_loss=1.733, word_ins=3.502, length=3.832, ppl=14.77, wps=42930.8, ups=0.73, wpb=58827.5, bsz=1976.5, num_updates=34700, lr=0.000433763, gnorm=1.007, loss_scale=8192, train_wall=137, wall=45884
2023-01-13 04:34:17 | INFO | train_inner | epoch 018:   1175 / 1978 loss=3.829, nll_loss=1.676, word_ins=3.452, length=3.778, ppl=14.22, wps=46299.8, ups=0.79, wpb=58910.7, bsz=2021, num_updates=34800, lr=0.000435013, gnorm=0.958, loss_scale=8192, train_wall=127, wall=46011
2023-01-13 04:36:25 | INFO | train_inner | epoch 018:   1275 / 1978 loss=3.814, nll_loss=1.665, word_ins=3.441, length=3.726, ppl=14.06, wps=46040.8, ups=0.78, wpb=58979.6, bsz=2024.6, num_updates=34900, lr=0.000436263, gnorm=0.945, loss_scale=8192, train_wall=128, wall=46140
2023-01-13 04:38:34 | INFO | train_inner | epoch 018:   1375 / 1978 loss=3.764, nll_loss=1.619, word_ins=3.399, length=3.649, ppl=13.59, wps=46298.1, ups=0.78, wpb=59363, bsz=2149.9, num_updates=35000, lr=0.000437513, gnorm=0.966, loss_scale=8192, train_wall=128, wall=46268
2023-01-13 04:40:41 | INFO | train_inner | epoch 018:   1475 / 1978 loss=3.81, nll_loss=1.66, word_ins=3.436, length=3.732, ppl=14.02, wps=46817.7, ups=0.79, wpb=59477.1, bsz=1966.7, num_updates=35100, lr=0.000438762, gnorm=0.951, loss_scale=8192, train_wall=127, wall=46395
2023-01-13 04:42:48 | INFO | train_inner | epoch 018:   1575 / 1978 loss=3.809, nll_loss=1.652, word_ins=3.43, length=3.79, ppl=14.02, wps=46649.1, ups=0.79, wpb=59245.9, bsz=1934.1, num_updates=35200, lr=0.000440012, gnorm=0.973, loss_scale=8192, train_wall=127, wall=46522
2023-01-13 04:44:55 | INFO | train_inner | epoch 018:   1675 / 1978 loss=3.805, nll_loss=1.651, word_ins=3.428, length=3.77, ppl=13.98, wps=46240.2, ups=0.78, wpb=58924.7, bsz=2023.7, num_updates=35300, lr=0.000441262, gnorm=0.961, loss_scale=8192, train_wall=127, wall=46649
2023-01-13 04:47:04 | INFO | train_inner | epoch 018:   1775 / 1978 loss=3.785, nll_loss=1.636, word_ins=3.415, length=3.702, ppl=13.78, wps=46626.6, ups=0.78, wpb=59918, bsz=2084, num_updates=35400, lr=0.000442512, gnorm=0.955, loss_scale=8192, train_wall=128, wall=46778
2023-01-13 04:49:12 | INFO | train_inner | epoch 018:   1875 / 1978 loss=3.767, nll_loss=1.617, word_ins=3.397, length=3.704, ppl=13.62, wps=46773.5, ups=0.78, wpb=59884.5, bsz=2013.8, num_updates=35500, lr=0.000443761, gnorm=0.927, loss_scale=8192, train_wall=128, wall=46906
2023-01-13 04:51:18 | INFO | train_inner | epoch 018:   1975 / 1978 loss=3.824, nll_loss=1.677, word_ins=3.451, length=3.725, ppl=14.16, wps=46383, ups=0.79, wpb=58766.2, bsz=1929, num_updates=35600, lr=0.000445011, gnorm=0.955, loss_scale=8192, train_wall=127, wall=47032
2023-01-13 04:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 04:51:36 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.587 | nll_loss 2.44 | word_ins 4.196 | length 3.91 | ppl 24.03 | wps 127905 | wpb 40242.5 | bsz 1500 | num_updates 35603 | best_loss 4.558
2023-01-13 04:51:36 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 04:52:03 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint18.pt (epoch 18 @ 35603 updates, score 4.587) (writing took 27.394586133770645 seconds)
2023-01-13 04:52:03 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-01-13 04:52:03 | INFO | train | epoch 018 | loss 3.818 | nll_loss 1.668 | word_ins 3.444 | length 3.737 | ppl 14.1 | wps 44937.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 35603 | lr 0.000445048 | gnorm 0.972 | loss_scale 8192 | train_wall 2550 | wall 47077
2023-01-13 04:52:03 | INFO | fairseq.trainer | begin training epoch 19
2023-01-13 04:54:19 | INFO | train_inner | epoch 019:     97 / 1978 loss=3.795, nll_loss=1.649, word_ins=3.426, length=3.687, ppl=13.88, wps=32837.1, ups=0.55, wpb=59258.1, bsz=1986.1, num_updates=35700, lr=0.000446261, gnorm=0.992, loss_scale=8192, train_wall=128, wall=47213
2023-01-13 04:56:27 | INFO | train_inner | epoch 019:    197 / 1978 loss=3.732, nll_loss=1.592, word_ins=3.375, length=3.57, ppl=13.29, wps=46512.1, ups=0.78, wpb=59571.8, bsz=2042, num_updates=35800, lr=0.000447511, gnorm=0.919, loss_scale=8192, train_wall=128, wall=47341
2023-01-13 04:58:34 | INFO | train_inner | epoch 019:    297 / 1978 loss=3.752, nll_loss=1.605, word_ins=3.387, length=3.647, ppl=13.47, wps=46719.3, ups=0.78, wpb=59586.7, bsz=2035.7, num_updates=35900, lr=0.00044876, gnorm=0.946, loss_scale=8192, train_wall=127, wall=47469
2023-01-13 05:00:46 | INFO | train_inner | epoch 019:    397 / 1978 loss=3.767, nll_loss=1.619, word_ins=3.399, length=3.687, ppl=13.62, wps=45127.2, ups=0.76, wpb=59287.8, bsz=2041, num_updates=36000, lr=0.00045001, gnorm=0.966, loss_scale=8192, train_wall=131, wall=47600
2023-01-13 05:02:53 | INFO | train_inner | epoch 019:    497 / 1978 loss=3.816, nll_loss=1.67, word_ins=3.444, length=3.723, ppl=14.09, wps=46570.2, ups=0.79, wpb=59237.4, bsz=1882.9, num_updates=36100, lr=0.00045126, gnorm=0.962, loss_scale=8192, train_wall=127, wall=47727
2023-01-13 05:05:02 | INFO | train_inner | epoch 019:    597 / 1978 loss=3.704, nll_loss=1.567, word_ins=3.351, length=3.531, ppl=13.03, wps=46588.7, ups=0.77, wpb=60185, bsz=2127.8, num_updates=36200, lr=0.00045251, gnorm=0.916, loss_scale=8192, train_wall=129, wall=47856
2023-01-13 05:07:09 | INFO | train_inner | epoch 019:    697 / 1978 loss=3.809, nll_loss=1.66, word_ins=3.436, length=3.73, ppl=14.01, wps=46612.4, ups=0.79, wpb=59138.7, bsz=1947.7, num_updates=36300, lr=0.000453759, gnorm=0.974, loss_scale=8192, train_wall=127, wall=47983
2023-01-13 05:09:17 | INFO | train_inner | epoch 019:    797 / 1978 loss=3.797, nll_loss=1.644, word_ins=3.421, length=3.756, ppl=13.9, wps=45992.2, ups=0.78, wpb=58883.1, bsz=1965.7, num_updates=36400, lr=0.000455009, gnorm=0.931, loss_scale=8192, train_wall=128, wall=48111
2023-01-13 05:11:25 | INFO | train_inner | epoch 019:    897 / 1978 loss=3.755, nll_loss=1.595, word_ins=3.378, length=3.773, ppl=13.5, wps=46372.8, ups=0.78, wpb=59102.6, bsz=2062.6, num_updates=36500, lr=0.000456259, gnorm=0.965, loss_scale=8192, train_wall=127, wall=48239
2023-01-13 05:13:32 | INFO | train_inner | epoch 019:    997 / 1978 loss=3.799, nll_loss=1.65, word_ins=3.427, length=3.72, ppl=13.92, wps=46558, ups=0.79, wpb=59304.8, bsz=1934.3, num_updates=36600, lr=0.000457509, gnorm=0.928, loss_scale=8192, train_wall=127, wall=48366
2023-01-13 05:15:41 | INFO | train_inner | epoch 019:   1097 / 1978 loss=3.795, nll_loss=1.637, word_ins=3.415, length=3.8, ppl=13.88, wps=46065.1, ups=0.78, wpb=59205.7, bsz=2009, num_updates=36700, lr=0.000458758, gnorm=0.959, loss_scale=8192, train_wall=128, wall=48495
2023-01-13 05:18:07 | INFO | train_inner | epoch 019:   1197 / 1978 loss=3.817, nll_loss=1.662, word_ins=3.436, length=3.81, ppl=14.09, wps=40187.1, ups=0.68, wpb=59060, bsz=1971.7, num_updates=36800, lr=0.000460008, gnorm=0.945, loss_scale=16384, train_wall=147, wall=48642
2023-01-13 05:20:35 | INFO | train_inner | epoch 019:   1297 / 1978 loss=3.823, nll_loss=1.664, word_ins=3.439, length=3.839, ppl=14.15, wps=40268.4, ups=0.68, wpb=59361.2, bsz=1920.5, num_updates=36900, lr=0.000461258, gnorm=0.94, loss_scale=16384, train_wall=147, wall=48789
2023-01-13 05:22:43 | INFO | train_inner | epoch 019:   1397 / 1978 loss=3.794, nll_loss=1.639, word_ins=3.417, length=3.775, ppl=13.87, wps=46127.6, ups=0.78, wpb=58981.7, bsz=1958.2, num_updates=37000, lr=0.000462508, gnorm=0.969, loss_scale=16384, train_wall=128, wall=48917
2023-01-13 05:24:51 | INFO | train_inner | epoch 019:   1497 / 1978 loss=3.717, nll_loss=1.568, word_ins=3.353, length=3.647, ppl=13.15, wps=46663.1, ups=0.78, wpb=59865.2, bsz=2076.4, num_updates=37100, lr=0.000463757, gnorm=0.888, loss_scale=16384, train_wall=128, wall=49045
2023-01-13 05:27:05 | INFO | train_inner | epoch 019:   1597 / 1978 loss=3.789, nll_loss=1.64, word_ins=3.417, length=3.721, ppl=13.82, wps=43961.8, ups=0.75, wpb=58736.8, bsz=2002.3, num_updates=37200, lr=0.000465007, gnorm=0.928, loss_scale=16384, train_wall=133, wall=49179
2023-01-13 05:29:13 | INFO | train_inner | epoch 019:   1697 / 1978 loss=3.773, nll_loss=1.619, word_ins=3.398, length=3.745, ppl=13.67, wps=46222.3, ups=0.78, wpb=59313, bsz=2005, num_updates=37300, lr=0.000466257, gnorm=0.936, loss_scale=16384, train_wall=128, wall=49307
2023-01-13 05:31:24 | INFO | train_inner | epoch 019:   1797 / 1978 loss=3.739, nll_loss=1.588, word_ins=3.371, length=3.688, ppl=13.36, wps=45262.8, ups=0.76, wpb=59257.1, bsz=2098.3, num_updates=37400, lr=0.000467507, gnorm=0.923, loss_scale=16384, train_wall=131, wall=49438
2023-01-13 05:33:31 | INFO | train_inner | epoch 019:   1897 / 1978 loss=3.782, nll_loss=1.63, word_ins=3.407, length=3.744, ppl=13.75, wps=46786.8, ups=0.79, wpb=59225.2, bsz=1967, num_updates=37500, lr=0.000468756, gnorm=0.929, loss_scale=16384, train_wall=126, wall=49565
2023-01-13 05:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 05:35:27 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.524 | nll_loss 2.343 | word_ins 4.12 | length 4.038 | ppl 23 | wps 129724 | wpb 40242.5 | bsz 1500 | num_updates 37581 | best_loss 4.524
2023-01-13 05:35:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 05:36:08 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint19.pt (epoch 19 @ 37581 updates, score 4.524) (writing took 41.70383042562753 seconds)
2023-01-13 05:36:08 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-01-13 05:36:08 | INFO | train | epoch 019 | loss 3.777 | nll_loss 1.627 | word_ins 3.405 | length 3.717 | ppl 13.71 | wps 44335.9 | ups 0.75 | wpb 59284.3 | bsz 2002.6 | num_updates 37581 | lr 0.000469769 | gnorm 0.943 | loss_scale 16384 | train_wall 2574 | wall 49722
2023-01-13 05:36:08 | INFO | fairseq.trainer | begin training epoch 20
2023-01-13 05:36:44 | INFO | train_inner | epoch 020:     19 / 1978 loss=3.756, nll_loss=1.606, word_ins=3.386, length=3.699, ppl=13.51, wps=30485, ups=0.52, wpb=59090.2, bsz=2039.2, num_updates=37600, lr=0.000470006, gnorm=0.92, loss_scale=16384, train_wall=127, wall=49758
2023-01-13 05:38:54 | INFO | train_inner | epoch 020:    119 / 1978 loss=3.709, nll_loss=1.561, word_ins=3.346, length=3.625, ppl=13.08, wps=46244.7, ups=0.77, wpb=59909.5, bsz=2105.1, num_updates=37700, lr=0.000471256, gnorm=0.926, loss_scale=16384, train_wall=129, wall=49888
2023-01-13 05:41:02 | INFO | train_inner | epoch 020:    219 / 1978 loss=3.796, nll_loss=1.639, word_ins=3.416, length=3.795, ppl=13.89, wps=46264.6, ups=0.78, wpb=59159.6, bsz=1948.9, num_updates=37800, lr=0.000472506, gnorm=0.953, loss_scale=16384, train_wall=128, wall=50016
2023-01-13 05:43:10 | INFO | train_inner | epoch 020:    319 / 1978 loss=3.721, nll_loss=1.575, word_ins=3.358, length=3.629, ppl=13.19, wps=46473.3, ups=0.78, wpb=59367.8, bsz=2054.6, num_updates=37900, lr=0.000473755, gnorm=0.888, loss_scale=16384, train_wall=128, wall=50144
2023-01-13 05:45:17 | INFO | train_inner | epoch 020:    419 / 1978 loss=3.745, nll_loss=1.582, word_ins=3.364, length=3.808, ppl=13.41, wps=46551.7, ups=0.78, wpb=59434.6, bsz=2047, num_updates=38000, lr=0.000475005, gnorm=0.908, loss_scale=16384, train_wall=127, wall=50271
2023-01-13 05:47:25 | INFO | train_inner | epoch 020:    519 / 1978 loss=3.716, nll_loss=1.567, word_ins=3.351, length=3.644, ppl=13.14, wps=46266.2, ups=0.78, wpb=59131.5, bsz=2032.9, num_updates=38100, lr=0.000476255, gnorm=0.881, loss_scale=16384, train_wall=128, wall=50399
2023-01-13 05:49:33 | INFO | train_inner | epoch 020:    619 / 1978 loss=3.758, nll_loss=1.61, word_ins=3.39, length=3.676, ppl=13.52, wps=46732.8, ups=0.78, wpb=59598.4, bsz=2009.8, num_updates=38200, lr=0.000477505, gnorm=0.934, loss_scale=16384, train_wall=127, wall=50527
2023-01-13 05:51:41 | INFO | train_inner | epoch 020:    719 / 1978 loss=3.715, nll_loss=1.567, word_ins=3.352, length=3.638, ppl=13.14, wps=46624.2, ups=0.78, wpb=59665, bsz=2009.5, num_updates=38300, lr=0.000478754, gnorm=0.955, loss_scale=16384, train_wall=128, wall=50655
2023-01-13 05:53:48 | INFO | train_inner | epoch 020:    819 / 1978 loss=3.778, nll_loss=1.625, word_ins=3.403, length=3.753, ppl=13.72, wps=46434.3, ups=0.79, wpb=58980.2, bsz=1987.3, num_updates=38400, lr=0.000480004, gnorm=0.912, loss_scale=16384, train_wall=127, wall=50782
2023-01-13 05:55:59 | INFO | train_inner | epoch 020:    919 / 1978 loss=3.691, nll_loss=1.539, word_ins=3.325, length=3.663, ppl=12.92, wps=45315.8, ups=0.76, wpb=59642.3, bsz=2063.4, num_updates=38500, lr=0.000481254, gnorm=0.902, loss_scale=16384, train_wall=131, wall=50913
2023-01-13 05:58:08 | INFO | train_inner | epoch 020:   1019 / 1978 loss=3.72, nll_loss=1.574, word_ins=3.356, length=3.64, ppl=13.18, wps=46314.9, ups=0.78, wpb=59738.8, bsz=1983, num_updates=38600, lr=0.000482504, gnorm=0.9, loss_scale=16384, train_wall=129, wall=51042
2023-01-13 06:00:21 | INFO | train_inner | epoch 020:   1119 / 1978 loss=3.731, nll_loss=1.583, word_ins=3.365, length=3.665, ppl=13.28, wps=44739.6, ups=0.76, wpb=59227.7, bsz=1999, num_updates=38700, lr=0.000483753, gnorm=0.89, loss_scale=16384, train_wall=132, wall=51175
2023-01-13 06:02:28 | INFO | train_inner | epoch 020:   1219 / 1978 loss=3.77, nll_loss=1.625, word_ins=3.402, length=3.675, ppl=13.64, wps=46236.5, ups=0.78, wpb=59111.6, bsz=1995.1, num_updates=38800, lr=0.000485003, gnorm=0.938, loss_scale=16384, train_wall=128, wall=51303
2023-01-13 06:04:35 | INFO | train_inner | epoch 020:   1319 / 1978 loss=3.758, nll_loss=1.61, word_ins=3.389, length=3.686, ppl=13.53, wps=46992.9, ups=0.79, wpb=59369.7, bsz=1914.5, num_updates=38900, lr=0.000486253, gnorm=0.929, loss_scale=16384, train_wall=126, wall=51429
2023-01-13 06:06:42 | INFO | train_inner | epoch 020:   1419 / 1978 loss=3.782, nll_loss=1.626, word_ins=3.403, length=3.792, ppl=13.76, wps=46337.7, ups=0.79, wpb=58842.2, bsz=1928.2, num_updates=39000, lr=0.000487503, gnorm=0.928, loss_scale=16384, train_wall=127, wall=51556
2023-01-13 06:08:49 | INFO | train_inner | epoch 020:   1519 / 1978 loss=3.738, nll_loss=1.579, word_ins=3.362, length=3.761, ppl=13.34, wps=46176.2, ups=0.78, wpb=58917.1, bsz=1943.8, num_updates=39100, lr=0.000488752, gnorm=0.904, loss_scale=16384, train_wall=127, wall=51683
2023-01-13 06:10:57 | INFO | train_inner | epoch 020:   1619 / 1978 loss=3.737, nll_loss=1.584, word_ins=3.366, length=3.706, ppl=13.33, wps=46311.6, ups=0.78, wpb=59111.6, bsz=2034.7, num_updates=39200, lr=0.000490002, gnorm=0.88, loss_scale=16384, train_wall=127, wall=51811
2023-01-13 06:13:03 | INFO | train_inner | epoch 020:   1719 / 1978 loss=3.775, nll_loss=1.62, word_ins=3.398, length=3.775, ppl=13.69, wps=46724.6, ups=0.79, wpb=58953.4, bsz=1928.6, num_updates=39300, lr=0.000491252, gnorm=0.912, loss_scale=16384, train_wall=126, wall=51937
2023-01-13 06:15:10 | INFO | train_inner | epoch 020:   1819 / 1978 loss=3.718, nll_loss=1.563, word_ins=3.347, length=3.711, ppl=13.16, wps=46717.1, ups=0.79, wpb=59450, bsz=1998.2, num_updates=39400, lr=0.000492501, gnorm=0.893, loss_scale=16384, train_wall=127, wall=52065
2023-01-13 06:17:19 | INFO | train_inner | epoch 020:   1919 / 1978 loss=3.722, nll_loss=1.571, word_ins=3.354, length=3.683, ppl=13.19, wps=45997.7, ups=0.78, wpb=59153.8, bsz=2043.6, num_updates=39500, lr=0.000493751, gnorm=0.899, loss_scale=16384, train_wall=128, wall=52193
2023-01-13 06:18:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 06:18:49 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.468 | nll_loss 2.296 | word_ins 4.064 | length 4.044 | ppl 22.13 | wps 92016.8 | wpb 40242.5 | bsz 1500 | num_updates 39559 | best_loss 4.468
2023-01-13 06:18:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 06:19:29 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint20.pt (epoch 20 @ 39559 updates, score 4.468) (writing took 40.47984866797924 seconds)
2023-01-13 06:19:29 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-01-13 06:19:29 | INFO | train | epoch 020 | loss 3.741 | nll_loss 1.59 | word_ins 3.371 | length 3.7 | ppl 13.37 | wps 45089.5 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 39559 | lr 0.000494489 | gnorm 0.912 | loss_scale 16384 | train_wall 2530 | wall 52323
2023-01-13 06:19:29 | INFO | fairseq.trainer | begin training epoch 21
2023-01-13 06:20:33 | INFO | train_inner | epoch 021:     41 / 1978 loss=3.759, nll_loss=1.61, word_ins=3.389, length=3.703, ppl=13.54, wps=30278.5, ups=0.52, wpb=58781.8, bsz=1992.1, num_updates=39600, lr=0.000495001, gnorm=0.917, loss_scale=16384, train_wall=128, wall=52387
2023-01-13 06:22:42 | INFO | train_inner | epoch 021:    141 / 1978 loss=3.691, nll_loss=1.538, word_ins=3.325, length=3.66, ppl=12.91, wps=46160.4, ups=0.78, wpb=59541.3, bsz=2102.2, num_updates=39700, lr=0.000496251, gnorm=0.909, loss_scale=16384, train_wall=129, wall=52516
2023-01-13 06:24:50 | INFO | train_inner | epoch 021:    241 / 1978 loss=3.673, nll_loss=1.524, word_ins=3.311, length=3.615, ppl=12.75, wps=46663.9, ups=0.78, wpb=59620.4, bsz=2040.5, num_updates=39800, lr=0.0004975, gnorm=0.887, loss_scale=16384, train_wall=128, wall=52644
2023-01-13 06:27:03 | INFO | train_inner | epoch 021:    341 / 1978 loss=3.692, nll_loss=1.54, word_ins=3.326, length=3.654, ppl=12.92, wps=44723.1, ups=0.75, wpb=59713.5, bsz=2009.1, num_updates=39900, lr=0.00049875, gnorm=0.892, loss_scale=16384, train_wall=133, wall=52778
2023-01-13 06:29:11 | INFO | train_inner | epoch 021:    441 / 1978 loss=3.688, nll_loss=1.533, word_ins=3.319, length=3.693, ppl=12.89, wps=46658.6, ups=0.79, wpb=59286.1, bsz=1972.5, num_updates=40000, lr=0.0005, gnorm=0.903, loss_scale=16384, train_wall=127, wall=52905
2023-01-13 06:31:18 | INFO | train_inner | epoch 021:    541 / 1978 loss=3.705, nll_loss=1.546, word_ins=3.331, length=3.74, ppl=13.04, wps=46762.7, ups=0.78, wpb=59792.2, bsz=1988.6, num_updates=40100, lr=0.000499376, gnorm=0.891, loss_scale=16384, train_wall=128, wall=53033
2023-01-13 06:33:26 | INFO | train_inner | epoch 021:    641 / 1978 loss=3.698, nll_loss=1.548, word_ins=3.333, length=3.65, ppl=12.98, wps=46253.9, ups=0.78, wpb=59022.2, bsz=1966, num_updates=40200, lr=0.000498755, gnorm=0.888, loss_scale=16384, train_wall=127, wall=53160
2023-01-13 06:35:33 | INFO | train_inner | epoch 021:    741 / 1978 loss=3.753, nll_loss=1.599, word_ins=3.378, length=3.747, ppl=13.48, wps=46543.9, ups=0.79, wpb=59205.3, bsz=1940.6, num_updates=40300, lr=0.000498135, gnorm=0.912, loss_scale=16384, train_wall=127, wall=53287
2023-01-13 06:37:41 | INFO | train_inner | epoch 021:    841 / 1978 loss=3.715, nll_loss=1.561, word_ins=3.344, length=3.708, ppl=13.13, wps=46497.5, ups=0.78, wpb=59273.4, bsz=1947, num_updates=40400, lr=0.000497519, gnorm=0.878, loss_scale=16384, train_wall=127, wall=53415
2023-01-13 06:39:49 | INFO | train_inner | epoch 021:    941 / 1978 loss=3.73, nll_loss=1.573, word_ins=3.355, length=3.752, ppl=13.27, wps=46284.9, ups=0.78, wpb=59244.7, bsz=1991.7, num_updates=40500, lr=0.000496904, gnorm=0.903, loss_scale=16384, train_wall=128, wall=53543
2023-01-13 06:41:57 | INFO | train_inner | epoch 021:   1041 / 1978 loss=3.705, nll_loss=1.545, word_ins=3.33, length=3.75, ppl=13.04, wps=46140.5, ups=0.78, wpb=59232.4, bsz=1995.1, num_updates=40600, lr=0.000496292, gnorm=0.906, loss_scale=16384, train_wall=128, wall=53671
2023-01-13 06:44:04 | INFO | train_inner | epoch 021:   1141 / 1978 loss=3.699, nll_loss=1.554, word_ins=3.338, length=3.615, ppl=12.99, wps=46351.7, ups=0.79, wpb=58984.4, bsz=1998.2, num_updates=40700, lr=0.000495682, gnorm=0.878, loss_scale=16384, train_wall=127, wall=53798
2023-01-13 06:46:15 | INFO | train_inner | epoch 021:   1241 / 1978 loss=3.716, nll_loss=1.561, word_ins=3.344, length=3.722, ppl=13.14, wps=44900.7, ups=0.77, wpb=58544, bsz=1998.3, num_updates=40800, lr=0.000495074, gnorm=0.897, loss_scale=16384, train_wall=130, wall=53929
2023-01-13 06:48:22 | INFO | train_inner | epoch 021:   1341 / 1978 loss=3.693, nll_loss=1.537, word_ins=3.322, length=3.711, ppl=12.94, wps=46781.1, ups=0.79, wpb=59512.9, bsz=2018.8, num_updates=40900, lr=0.000494468, gnorm=0.86, loss_scale=32768, train_wall=127, wall=54056
2023-01-13 06:50:30 | INFO | train_inner | epoch 021:   1441 / 1978 loss=3.678, nll_loss=1.529, word_ins=3.315, length=3.626, ppl=12.8, wps=46365.1, ups=0.78, wpb=59335.5, bsz=2020.4, num_updates=41000, lr=0.000493865, gnorm=0.865, loss_scale=32768, train_wall=128, wall=54184
2023-01-13 06:52:38 | INFO | train_inner | epoch 021:   1541 / 1978 loss=3.666, nll_loss=1.512, word_ins=3.299, length=3.67, ppl=12.69, wps=46518, ups=0.78, wpb=59502.9, bsz=2027.8, num_updates=41100, lr=0.000493264, gnorm=0.881, loss_scale=32768, train_wall=128, wall=54312
2023-01-13 06:54:45 | INFO | train_inner | epoch 021:   1641 / 1978 loss=3.699, nll_loss=1.543, word_ins=3.328, length=3.709, ppl=12.98, wps=46644.8, ups=0.78, wpb=59425.9, bsz=2005.9, num_updates=41200, lr=0.000492665, gnorm=0.884, loss_scale=32768, train_wall=127, wall=54439
2023-01-13 06:56:54 | INFO | train_inner | epoch 021:   1741 / 1978 loss=3.689, nll_loss=1.532, word_ins=3.318, length=3.719, ppl=12.9, wps=45580.1, ups=0.78, wpb=58649, bsz=1998.6, num_updates=41300, lr=0.000492068, gnorm=0.869, loss_scale=32768, train_wall=128, wall=54568
2023-01-13 06:59:01 | INFO | train_inner | epoch 021:   1841 / 1978 loss=3.669, nll_loss=1.522, word_ins=3.308, length=3.608, ppl=12.72, wps=46592.4, ups=0.79, wpb=59204.2, bsz=2016.9, num_updates=41400, lr=0.000491473, gnorm=0.852, loss_scale=32768, train_wall=127, wall=54695
2023-01-13 07:01:10 | INFO | train_inner | epoch 021:   1941 / 1978 loss=3.664, nll_loss=1.518, word_ins=3.303, length=3.606, ppl=12.67, wps=46094.3, ups=0.78, wpb=59472.1, bsz=2070.7, num_updates=41500, lr=0.000490881, gnorm=0.865, loss_scale=32768, train_wall=129, wall=54824
2023-01-13 07:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 07:02:09 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.481 | nll_loss 2.264 | word_ins 4.041 | length 4.392 | ppl 22.33 | wps 179693 | wpb 40242.5 | bsz 1500 | num_updates 41537 | best_loss 4.468
2023-01-13 07:02:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 07:02:36 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint21.pt (epoch 21 @ 41537 updates, score 4.481) (writing took 26.90685729077086 seconds)
2023-01-13 07:02:36 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-01-13 07:02:36 | INFO | train | epoch 021 | loss 3.698 | nll_loss 1.545 | word_ins 3.329 | length 3.683 | ppl 12.98 | wps 45322.8 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 41537 | lr 0.000490662 | gnorm 0.887 | loss_scale 32768 | train_wall 2531 | wall 54910
2023-01-13 07:02:36 | INFO | fairseq.trainer | begin training epoch 22
2023-01-13 07:04:09 | INFO | train_inner | epoch 022:     63 / 1978 loss=3.686, nll_loss=1.537, word_ins=3.322, length=3.637, ppl=12.87, wps=32703.4, ups=0.56, wpb=58525.5, bsz=1974.2, num_updates=41600, lr=0.00049029, gnorm=0.903, loss_scale=32768, train_wall=128, wall=55003
2023-01-13 07:06:18 | INFO | train_inner | epoch 022:    163 / 1978 loss=3.637, nll_loss=1.488, word_ins=3.278, length=3.594, ppl=12.44, wps=46177.7, ups=0.78, wpb=59440.4, bsz=2053.8, num_updates=41700, lr=0.000489702, gnorm=0.866, loss_scale=32768, train_wall=128, wall=55132
2023-01-13 07:08:26 | INFO | train_inner | epoch 022:    263 / 1978 loss=3.626, nll_loss=1.473, word_ins=3.264, length=3.615, ppl=12.34, wps=46579.5, ups=0.78, wpb=59603.8, bsz=2024.4, num_updates=41800, lr=0.000489116, gnorm=0.875, loss_scale=32768, train_wall=128, wall=55260
2023-01-13 07:10:33 | INFO | train_inner | epoch 022:    363 / 1978 loss=3.652, nll_loss=1.492, word_ins=3.281, length=3.711, ppl=12.57, wps=46693.3, ups=0.78, wpb=59589.8, bsz=1993.9, num_updates=41900, lr=0.000488532, gnorm=0.871, loss_scale=32768, train_wall=127, wall=55387
2023-01-13 07:12:42 | INFO | train_inner | epoch 022:    463 / 1978 loss=3.641, nll_loss=1.489, word_ins=3.278, length=3.632, ppl=12.48, wps=46556.5, ups=0.78, wpb=59675.2, bsz=2037.1, num_updates=42000, lr=0.00048795, gnorm=0.866, loss_scale=32768, train_wall=128, wall=55516
2023-01-13 07:14:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 07:14:50 | INFO | train_inner | epoch 022:    564 / 1978 loss=3.667, nll_loss=1.514, word_ins=3.301, length=3.662, ppl=12.7, wps=45803.7, ups=0.78, wpb=59071.8, bsz=2002.1, num_updates=42100, lr=0.00048737, gnorm=0.869, loss_scale=16384, train_wall=129, wall=55645
2023-01-13 07:16:58 | INFO | train_inner | epoch 022:    664 / 1978 loss=3.638, nll_loss=1.483, word_ins=3.273, length=3.654, ppl=12.45, wps=46675, ups=0.79, wpb=59325.8, bsz=1992.2, num_updates=42200, lr=0.000486792, gnorm=0.844, loss_scale=16384, train_wall=127, wall=55772
2023-01-13 07:19:05 | INFO | train_inner | epoch 022:    764 / 1978 loss=3.649, nll_loss=1.491, word_ins=3.281, length=3.687, ppl=12.55, wps=46299.7, ups=0.78, wpb=59014.9, bsz=2013, num_updates=42300, lr=0.000486217, gnorm=0.884, loss_scale=16384, train_wall=127, wall=55899
2023-01-13 07:21:14 | INFO | train_inner | epoch 022:    864 / 1978 loss=3.612, nll_loss=1.471, word_ins=3.261, length=3.512, ppl=12.23, wps=46073.9, ups=0.78, wpb=59372.6, bsz=2120.6, num_updates=42400, lr=0.000485643, gnorm=0.857, loss_scale=16384, train_wall=129, wall=56028
2023-01-13 07:23:21 | INFO | train_inner | epoch 022:    964 / 1978 loss=3.621, nll_loss=1.467, word_ins=3.258, length=3.626, ppl=12.3, wps=46329.7, ups=0.78, wpb=59090.1, bsz=2043.3, num_updates=42500, lr=0.000485071, gnorm=0.871, loss_scale=16384, train_wall=127, wall=56156
2023-01-13 07:25:29 | INFO | train_inner | epoch 022:   1064 / 1978 loss=3.638, nll_loss=1.493, word_ins=3.281, length=3.564, ppl=12.45, wps=46684.7, ups=0.78, wpb=59724.7, bsz=2023.2, num_updates=42600, lr=0.000484502, gnorm=0.861, loss_scale=16384, train_wall=128, wall=56283
2023-01-13 07:27:36 | INFO | train_inner | epoch 022:   1164 / 1978 loss=3.658, nll_loss=1.499, word_ins=3.287, length=3.714, ppl=12.62, wps=46147.2, ups=0.79, wpb=58538, bsz=1909.8, num_updates=42700, lr=0.000483934, gnorm=0.871, loss_scale=16384, train_wall=127, wall=56410
2023-01-13 07:29:44 | INFO | train_inner | epoch 022:   1264 / 1978 loss=3.683, nll_loss=1.53, word_ins=3.314, length=3.685, ppl=12.84, wps=45963.8, ups=0.78, wpb=58621.8, bsz=2005.9, num_updates=42800, lr=0.000483368, gnorm=0.869, loss_scale=16384, train_wall=127, wall=56538
2023-01-13 07:31:51 | INFO | train_inner | epoch 022:   1364 / 1978 loss=3.668, nll_loss=1.523, word_ins=3.308, length=3.599, ppl=12.71, wps=46761.6, ups=0.78, wpb=59709, bsz=1961.4, num_updates=42900, lr=0.000482805, gnorm=0.878, loss_scale=16384, train_wall=127, wall=56666
2023-01-13 07:33:59 | INFO | train_inner | epoch 022:   1464 / 1978 loss=3.621, nll_loss=1.463, word_ins=3.253, length=3.674, ppl=12.3, wps=46666, ups=0.78, wpb=59655.8, bsz=2058.7, num_updates=43000, lr=0.000482243, gnorm=0.842, loss_scale=16384, train_wall=128, wall=56793
2023-01-13 07:36:07 | INFO | train_inner | epoch 022:   1564 / 1978 loss=3.653, nll_loss=1.499, word_ins=3.286, length=3.666, ppl=12.58, wps=46250.4, ups=0.78, wpb=59221, bsz=1996.6, num_updates=43100, lr=0.000481683, gnorm=0.884, loss_scale=16384, train_wall=128, wall=56921
2023-01-13 07:38:15 | INFO | train_inner | epoch 022:   1664 / 1978 loss=3.649, nll_loss=1.502, word_ins=3.288, length=3.614, ppl=12.55, wps=46994.3, ups=0.78, wpb=59976.6, bsz=1956.7, num_updates=43200, lr=0.000481125, gnorm=0.899, loss_scale=16384, train_wall=127, wall=57049
2023-01-13 07:40:23 | INFO | train_inner | epoch 022:   1764 / 1978 loss=3.679, nll_loss=1.525, word_ins=3.309, length=3.692, ppl=12.81, wps=46105.4, ups=0.78, wpb=58888.2, bsz=1963.4, num_updates=43300, lr=0.000480569, gnorm=0.863, loss_scale=16384, train_wall=128, wall=57177
2023-01-13 07:42:30 | INFO | train_inner | epoch 022:   1864 / 1978 loss=3.636, nll_loss=1.484, word_ins=3.273, length=3.636, ppl=12.43, wps=46753.7, ups=0.79, wpb=59533.9, bsz=1962, num_updates=43400, lr=0.000480015, gnorm=0.867, loss_scale=16384, train_wall=127, wall=57304
2023-01-13 07:44:37 | INFO | train_inner | epoch 022:   1964 / 1978 loss=3.64, nll_loss=1.488, word_ins=3.276, length=3.642, ppl=12.47, wps=46995, ups=0.79, wpb=59500.9, bsz=1893.6, num_updates=43500, lr=0.000479463, gnorm=0.872, loss_scale=16384, train_wall=126, wall=57431
2023-01-13 07:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 07:45:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.526 | nll_loss 2.261 | word_ins 4.029 | length 4.973 | ppl 23.04 | wps 123832 | wpb 40242.5 | bsz 1500 | num_updates 43514 | best_loss 4.468
2023-01-13 07:45:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 07:45:35 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint22.pt (epoch 22 @ 43514 updates, score 4.526) (writing took 26.81223118957132 seconds)
2023-01-13 07:45:35 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-01-13 07:45:35 | INFO | train | epoch 022 | loss 3.645 | nll_loss 1.493 | word_ins 3.282 | length 3.638 | ppl 12.51 | wps 45450.7 | ups 0.77 | wpb 59291.2 | bsz 2003 | num_updates 43514 | lr 0.000479386 | gnorm 0.869 | loss_scale 16384 | train_wall 2523 | wall 57489
2023-01-13 07:45:35 | INFO | fairseq.trainer | begin training epoch 23
2023-01-13 07:47:37 | INFO | train_inner | epoch 023:     86 / 1978 loss=3.608, nll_loss=1.457, word_ins=3.249, length=3.592, ppl=12.2, wps=32578.4, ups=0.55, wpb=58794.5, bsz=2087.2, num_updates=43600, lr=0.000478913, gnorm=0.874, loss_scale=16384, train_wall=128, wall=57611
2023-01-13 07:49:45 | INFO | train_inner | epoch 023:    186 / 1978 loss=3.604, nll_loss=1.45, word_ins=3.243, length=3.607, ppl=12.16, wps=46528.3, ups=0.79, wpb=59271.7, bsz=1995, num_updates=43700, lr=0.000478365, gnorm=0.881, loss_scale=16384, train_wall=127, wall=57739
2023-01-13 07:51:53 | INFO | train_inner | epoch 023:    286 / 1978 loss=3.591, nll_loss=1.442, word_ins=3.235, length=3.555, ppl=12.05, wps=46194.9, ups=0.78, wpb=59449.1, bsz=2038.3, num_updates=43800, lr=0.000477818, gnorm=0.843, loss_scale=16384, train_wall=128, wall=57867
2023-01-13 07:54:01 | INFO | train_inner | epoch 023:    386 / 1978 loss=3.623, nll_loss=1.466, word_ins=3.256, length=3.669, ppl=12.32, wps=46468.3, ups=0.78, wpb=59420.7, bsz=1966.5, num_updates=43900, lr=0.000477274, gnorm=0.853, loss_scale=16384, train_wall=128, wall=57995
2023-01-13 07:56:08 | INFO | train_inner | epoch 023:    486 / 1978 loss=3.652, nll_loss=1.498, word_ins=3.286, length=3.66, ppl=12.57, wps=46469.2, ups=0.79, wpb=59122.7, bsz=1910.2, num_updates=44000, lr=0.000476731, gnorm=0.881, loss_scale=16384, train_wall=127, wall=58122
2023-01-13 07:58:17 | INFO | train_inner | epoch 023:    586 / 1978 loss=3.562, nll_loss=1.415, word_ins=3.21, length=3.519, ppl=11.81, wps=46241.6, ups=0.78, wpb=59499.7, bsz=2103.6, num_updates=44100, lr=0.00047619, gnorm=0.835, loss_scale=16384, train_wall=128, wall=58251
2023-01-13 08:00:25 | INFO | train_inner | epoch 023:    686 / 1978 loss=3.612, nll_loss=1.456, word_ins=3.247, length=3.649, ppl=12.23, wps=46428.6, ups=0.78, wpb=59525.3, bsz=2001.7, num_updates=44200, lr=0.000475651, gnorm=0.867, loss_scale=16384, train_wall=128, wall=58379
2023-01-13 08:02:33 | INFO | train_inner | epoch 023:    786 / 1978 loss=3.645, nll_loss=1.486, word_ins=3.274, length=3.707, ppl=12.51, wps=46519.8, ups=0.78, wpb=59301.2, bsz=1904.6, num_updates=44300, lr=0.000475114, gnorm=0.881, loss_scale=16384, train_wall=127, wall=58507
2023-01-13 08:04:41 | INFO | train_inner | epoch 023:    886 / 1978 loss=3.605, nll_loss=1.456, word_ins=3.248, length=3.57, ppl=12.16, wps=46513.1, ups=0.78, wpb=59422.9, bsz=1999.7, num_updates=44400, lr=0.000474579, gnorm=0.878, loss_scale=16384, train_wall=127, wall=58635
2023-01-13 08:06:49 | INFO | train_inner | epoch 023:    986 / 1978 loss=3.594, nll_loss=1.443, word_ins=3.235, length=3.591, ppl=12.07, wps=46316.9, ups=0.78, wpb=59443, bsz=1995, num_updates=44500, lr=0.000474045, gnorm=0.838, loss_scale=16384, train_wall=128, wall=58763
2023-01-13 08:08:57 | INFO | train_inner | epoch 023:   1086 / 1978 loss=3.607, nll_loss=1.452, word_ins=3.243, length=3.643, ppl=12.19, wps=46191.8, ups=0.78, wpb=58963.9, bsz=1962.4, num_updates=44600, lr=0.000473514, gnorm=0.854, loss_scale=16384, train_wall=127, wall=58891
2023-01-13 08:11:05 | INFO | train_inner | epoch 023:   1186 / 1978 loss=3.575, nll_loss=1.424, word_ins=3.218, length=3.571, ppl=11.91, wps=46081.3, ups=0.78, wpb=59379.4, bsz=2104.2, num_updates=44700, lr=0.000472984, gnorm=0.866, loss_scale=16384, train_wall=129, wall=59019
2023-01-13 08:13:14 | INFO | train_inner | epoch 023:   1286 / 1978 loss=3.567, nll_loss=1.421, word_ins=3.214, length=3.53, ppl=11.86, wps=46132.6, ups=0.78, wpb=59515.9, bsz=2017.8, num_updates=44800, lr=0.000472456, gnorm=0.871, loss_scale=16384, train_wall=129, wall=59148
2023-01-13 08:15:23 | INFO | train_inner | epoch 023:   1386 / 1978 loss=3.586, nll_loss=1.435, word_ins=3.227, length=3.585, ppl=12.01, wps=46410.3, ups=0.78, wpb=59578.9, bsz=2061.1, num_updates=44900, lr=0.000471929, gnorm=0.859, loss_scale=16384, train_wall=128, wall=59277
2023-01-13 08:17:31 | INFO | train_inner | epoch 023:   1486 / 1978 loss=3.606, nll_loss=1.449, word_ins=3.24, length=3.667, ppl=12.18, wps=45809.5, ups=0.78, wpb=58587.2, bsz=1984.2, num_updates=45000, lr=0.000471405, gnorm=0.854, loss_scale=16384, train_wall=128, wall=59405
2023-01-13 08:19:38 | INFO | train_inner | epoch 023:   1586 / 1978 loss=3.618, nll_loss=1.463, word_ins=3.253, length=3.657, ppl=12.28, wps=46467, ups=0.79, wpb=59047.2, bsz=1953.9, num_updates=45100, lr=0.000470882, gnorm=0.867, loss_scale=16384, train_wall=127, wall=59532
2023-01-13 08:21:47 | INFO | train_inner | epoch 023:   1686 / 1978 loss=3.571, nll_loss=1.421, word_ins=3.214, length=3.57, ppl=11.89, wps=45948.9, ups=0.77, wpb=59583.9, bsz=2006.7, num_updates=45200, lr=0.00047036, gnorm=0.84, loss_scale=16384, train_wall=129, wall=59662
2023-01-13 08:23:55 | INFO | train_inner | epoch 023:   1786 / 1978 loss=3.643, nll_loss=1.495, word_ins=3.281, length=3.624, ppl=12.49, wps=46357.9, ups=0.78, wpb=59325.2, bsz=1983.5, num_updates=45300, lr=0.000469841, gnorm=0.877, loss_scale=16384, train_wall=128, wall=59789
2023-01-13 08:26:03 | INFO | train_inner | epoch 023:   1886 / 1978 loss=3.568, nll_loss=1.415, word_ins=3.209, length=3.589, ppl=11.86, wps=46195.3, ups=0.78, wpb=59115.9, bsz=2011.1, num_updates=45400, lr=0.000469323, gnorm=0.852, loss_scale=16384, train_wall=128, wall=59917
2023-01-13 08:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 08:28:13 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.561 | nll_loss 2.193 | word_ins 3.965 | length 5.955 | ppl 23.6 | wps 100044 | wpb 40242.5 | bsz 1500 | num_updates 45492 | best_loss 4.468
2023-01-13 08:28:13 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 08:28:41 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint23.pt (epoch 23 @ 45492 updates, score 4.561) (writing took 27.365234261844307 seconds)
2023-01-13 08:28:41 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-01-13 08:28:41 | INFO | train | epoch 023 | loss 3.602 | nll_loss 1.45 | word_ins 3.241 | length 3.61 | ppl 12.14 | wps 45359.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 45492 | lr 0.000468848 | gnorm 0.861 | loss_scale 16384 | train_wall 2530 | wall 60075
2023-01-13 08:28:41 | INFO | fairseq.trainer | begin training epoch 24
2023-01-13 08:29:03 | INFO | train_inner | epoch 024:      8 / 1978 loss=3.591, nll_loss=1.439, word_ins=3.23, length=3.609, ppl=12.05, wps=32860.9, ups=0.56, wpb=58927.4, bsz=2001.5, num_updates=45500, lr=0.000468807, gnorm=0.842, loss_scale=16384, train_wall=128, wall=60097
2023-01-13 08:31:10 | INFO | train_inner | epoch 024:    108 / 1978 loss=3.585, nll_loss=1.433, word_ins=3.226, length=3.592, ppl=12, wps=46625.4, ups=0.79, wpb=59239.3, bsz=1971, num_updates=45600, lr=0.000468293, gnorm=0.866, loss_scale=16384, train_wall=127, wall=60224
2023-01-13 08:33:17 | INFO | train_inner | epoch 024:    208 / 1978 loss=3.562, nll_loss=1.414, word_ins=3.208, length=3.54, ppl=11.81, wps=46567.8, ups=0.79, wpb=59106.1, bsz=1998.7, num_updates=45700, lr=0.00046778, gnorm=0.857, loss_scale=16384, train_wall=127, wall=60351
2023-01-13 08:35:25 | INFO | train_inner | epoch 024:    308 / 1978 loss=3.606, nll_loss=1.447, word_ins=3.238, length=3.68, ppl=12.18, wps=45862.2, ups=0.78, wpb=58652, bsz=1995.2, num_updates=45800, lr=0.000467269, gnorm=0.884, loss_scale=16384, train_wall=128, wall=60479
2023-01-13 08:37:33 | INFO | train_inner | epoch 024:    408 / 1978 loss=3.541, nll_loss=1.388, word_ins=3.185, length=3.565, ppl=11.64, wps=46391.5, ups=0.78, wpb=59523.3, bsz=2126.4, num_updates=45900, lr=0.00046676, gnorm=0.848, loss_scale=16384, train_wall=128, wall=60607
2023-01-13 08:39:41 | INFO | train_inner | epoch 024:    508 / 1978 loss=3.555, nll_loss=1.404, word_ins=3.199, length=3.56, ppl=11.75, wps=46464.7, ups=0.78, wpb=59645.9, bsz=2018.6, num_updates=46000, lr=0.000466252, gnorm=0.866, loss_scale=16384, train_wall=128, wall=60735
2023-01-13 08:41:58 | INFO | train_inner | epoch 024:    608 / 1978 loss=3.545, nll_loss=1.392, word_ins=3.188, length=3.567, ppl=11.67, wps=43379.1, ups=0.73, wpb=59191.8, bsz=2087.7, num_updates=46100, lr=0.000465746, gnorm=0.864, loss_scale=16384, train_wall=136, wall=60872
2023-01-13 08:42:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-13 08:44:05 | INFO | train_inner | epoch 024:    709 / 1978 loss=3.592, nll_loss=1.426, word_ins=3.219, length=3.731, ppl=12.06, wps=46480.7, ups=0.78, wpb=59228.5, bsz=1913.4, num_updates=46200, lr=0.000465242, gnorm=0.841, loss_scale=8192, train_wall=127, wall=60999
2023-01-13 08:46:14 | INFO | train_inner | epoch 024:    809 / 1978 loss=3.553, nll_loss=1.408, word_ins=3.202, length=3.512, ppl=11.74, wps=46303, ups=0.78, wpb=59539.3, bsz=2040.1, num_updates=46300, lr=0.000464739, gnorm=0.927, loss_scale=8192, train_wall=128, wall=61128
2023-01-13 08:48:22 | INFO | train_inner | epoch 024:    909 / 1978 loss=3.533, nll_loss=1.385, word_ins=3.182, length=3.512, ppl=11.58, wps=46549.8, ups=0.78, wpb=59828.6, bsz=2072.9, num_updates=46400, lr=0.000464238, gnorm=0.855, loss_scale=8192, train_wall=128, wall=61256
2023-01-13 08:50:31 | INFO | train_inner | epoch 024:   1009 / 1978 loss=3.548, nll_loss=1.401, word_ins=3.196, length=3.519, ppl=11.69, wps=46210.2, ups=0.78, wpb=59513.1, bsz=2009.5, num_updates=46500, lr=0.000463739, gnorm=0.858, loss_scale=8192, train_wall=129, wall=61385
2023-01-13 08:52:39 | INFO | train_inner | epoch 024:   1109 / 1978 loss=3.562, nll_loss=1.408, word_ins=3.202, length=3.595, ppl=11.81, wps=46132.2, ups=0.78, wpb=59081.6, bsz=2004.8, num_updates=46600, lr=0.000463241, gnorm=0.862, loss_scale=8192, train_wall=128, wall=61513
2023-01-13 08:54:47 | INFO | train_inner | epoch 024:   1209 / 1978 loss=3.553, nll_loss=1.397, word_ins=3.192, length=3.606, ppl=11.74, wps=46301.2, ups=0.78, wpb=59143.6, bsz=1970, num_updates=46700, lr=0.000462745, gnorm=0.842, loss_scale=8192, train_wall=128, wall=61641
2023-01-13 08:56:55 | INFO | train_inner | epoch 024:   1309 / 1978 loss=3.548, nll_loss=1.402, word_ins=3.197, length=3.51, ppl=11.69, wps=46218.2, ups=0.78, wpb=59142.9, bsz=2043.9, num_updates=46800, lr=0.00046225, gnorm=0.844, loss_scale=8192, train_wall=128, wall=61769
2023-01-13 08:59:03 | INFO | train_inner | epoch 024:   1409 / 1978 loss=3.609, nll_loss=1.458, word_ins=3.247, length=3.62, ppl=12.2, wps=46217.3, ups=0.78, wpb=59429.2, bsz=1933.5, num_updates=46900, lr=0.000461757, gnorm=0.872, loss_scale=8192, train_wall=128, wall=61898
2023-01-13 09:01:12 | INFO | train_inner | epoch 024:   1509 / 1978 loss=3.53, nll_loss=1.381, word_ins=3.177, length=3.524, ppl=11.55, wps=46304, ups=0.78, wpb=59313.5, bsz=2039.9, num_updates=47000, lr=0.000461266, gnorm=0.887, loss_scale=8192, train_wall=127, wall=62026
2023-01-13 09:03:18 | INFO | train_inner | epoch 024:   1609 / 1978 loss=3.608, nll_loss=1.452, word_ins=3.241, length=3.666, ppl=12.19, wps=46517.7, ups=0.79, wpb=58906.7, bsz=1906.6, num_updates=47100, lr=0.000460776, gnorm=0.856, loss_scale=8192, train_wall=126, wall=62152
2023-01-13 09:05:25 | INFO | train_inner | epoch 024:   1709 / 1978 loss=3.578, nll_loss=1.421, word_ins=3.214, length=3.639, ppl=11.94, wps=46905.6, ups=0.79, wpb=59677.1, bsz=1898, num_updates=47200, lr=0.000460287, gnorm=0.873, loss_scale=8192, train_wall=127, wall=62280
2023-01-13 09:07:40 | INFO | train_inner | epoch 024:   1809 / 1978 loss=3.561, nll_loss=1.411, word_ins=3.204, length=3.567, ppl=11.8, wps=43794.4, ups=0.74, wpb=59109.8, bsz=1992.3, num_updates=47300, lr=0.0004598, gnorm=0.841, loss_scale=8192, train_wall=135, wall=62414
2023-01-13 09:09:58 | INFO | train_inner | epoch 024:   1909 / 1978 loss=3.565, nll_loss=1.415, word_ins=3.207, length=3.573, ppl=11.83, wps=43073.2, ups=0.73, wpb=59226.9, bsz=2011.8, num_updates=47400, lr=0.000459315, gnorm=0.851, loss_scale=8192, train_wall=137, wall=62552
2023-01-13 09:11:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 09:11:39 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.437 | nll_loss 2.188 | word_ins 3.965 | length 4.714 | ppl 21.65 | wps 165278 | wpb 40242.5 | bsz 1500 | num_updates 47469 | best_loss 4.437
2023-01-13 09:11:39 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 09:12:22 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint24.pt (epoch 24 @ 47469 updates, score 4.437) (writing took 42.2974865520373 seconds)
2023-01-13 09:12:22 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-01-13 09:12:22 | INFO | train | epoch 024 | loss 3.564 | nll_loss 1.412 | word_ins 3.206 | length 3.584 | ppl 11.83 | wps 44722.8 | ups 0.75 | wpb 59290.4 | bsz 2002.9 | num_updates 47469 | lr 0.000458981 | gnorm 0.864 | loss_scale 8192 | train_wall 2549 | wall 62696
2023-01-13 09:12:22 | INFO | fairseq.trainer | begin training epoch 25
2023-01-13 09:13:27 | INFO | train_inner | epoch 025:     31 / 1978 loss=3.558, nll_loss=1.407, word_ins=3.201, length=3.574, ppl=11.78, wps=28426.2, ups=0.48, wpb=59542.9, bsz=1996.2, num_updates=47500, lr=0.000458831, gnorm=0.892, loss_scale=8192, train_wall=128, wall=62761
2023-01-13 09:15:35 | INFO | train_inner | epoch 025:    131 / 1978 loss=3.551, nll_loss=1.393, word_ins=3.189, length=3.624, ppl=11.72, wps=46323.5, ups=0.78, wpb=59065.3, bsz=1958.7, num_updates=47600, lr=0.000458349, gnorm=0.859, loss_scale=8192, train_wall=127, wall=62889
2023-01-13 09:17:43 | INFO | train_inner | epoch 025:    231 / 1978 loss=3.556, nll_loss=1.407, word_ins=3.201, length=3.554, ppl=11.76, wps=46168.6, ups=0.78, wpb=59042.5, bsz=2023.2, num_updates=47700, lr=0.000457869, gnorm=0.873, loss_scale=8192, train_wall=128, wall=63017
2023-01-13 09:19:50 | INFO | train_inner | epoch 025:    331 / 1978 loss=3.521, nll_loss=1.367, word_ins=3.165, length=3.561, ppl=11.48, wps=46326, ups=0.79, wpb=58869, bsz=1939.4, num_updates=47800, lr=0.000457389, gnorm=0.831, loss_scale=8192, train_wall=127, wall=63144
2023-01-13 09:21:57 | INFO | train_inner | epoch 025:    431 / 1978 loss=3.536, nll_loss=1.379, word_ins=3.176, length=3.596, ppl=11.6, wps=46657.4, ups=0.79, wpb=59212.4, bsz=1953.4, num_updates=47900, lr=0.000456912, gnorm=0.853, loss_scale=8192, train_wall=127, wall=63271
2023-01-13 09:24:05 | INFO | train_inner | epoch 025:    531 / 1978 loss=3.58, nll_loss=1.421, word_ins=3.213, length=3.667, ppl=11.96, wps=46278.5, ups=0.78, wpb=59286.1, bsz=1955.6, num_updates=48000, lr=0.000456435, gnorm=0.869, loss_scale=8192, train_wall=128, wall=63399
2023-01-13 09:26:13 | INFO | train_inner | epoch 025:    631 / 1978 loss=3.528, nll_loss=1.374, word_ins=3.17, length=3.577, ppl=11.54, wps=46639.4, ups=0.78, wpb=59595.1, bsz=1986.6, num_updates=48100, lr=0.000455961, gnorm=0.851, loss_scale=8192, train_wall=128, wall=63527
2023-01-13 09:28:20 | INFO | train_inner | epoch 025:    731 / 1978 loss=3.521, nll_loss=1.374, word_ins=3.17, length=3.511, ppl=11.48, wps=46269.9, ups=0.78, wpb=59010.1, bsz=2066.6, num_updates=48200, lr=0.000455488, gnorm=0.845, loss_scale=8192, train_wall=127, wall=63654
2023-01-13 09:30:28 | INFO | train_inner | epoch 025:    831 / 1978 loss=3.513, nll_loss=1.361, word_ins=3.158, length=3.548, ppl=11.42, wps=46504.3, ups=0.78, wpb=59486.3, bsz=2046.6, num_updates=48300, lr=0.000455016, gnorm=0.846, loss_scale=8192, train_wall=128, wall=63782
2023-01-13 09:32:51 | INFO | train_inner | epoch 025:    931 / 1978 loss=3.537, nll_loss=1.388, word_ins=3.183, length=3.537, ppl=11.61, wps=41980.4, ups=0.7, wpb=59873.3, bsz=1997.2, num_updates=48400, lr=0.000454545, gnorm=0.854, loss_scale=8192, train_wall=129, wall=63925
2023-01-13 09:34:58 | INFO | train_inner | epoch 025:   1031 / 1978 loss=3.555, nll_loss=1.4, word_ins=3.194, length=3.603, ppl=11.75, wps=46284, ups=0.79, wpb=58824.3, bsz=1967.8, num_updates=48500, lr=0.000454077, gnorm=0.861, loss_scale=8192, train_wall=127, wall=64052
2023-01-13 09:37:07 | INFO | train_inner | epoch 025:   1131 / 1978 loss=3.486, nll_loss=1.339, word_ins=3.138, length=3.475, ppl=11.2, wps=46371.2, ups=0.77, wpb=59878.3, bsz=2103, num_updates=48600, lr=0.000453609, gnorm=0.846, loss_scale=8192, train_wall=129, wall=64181
2023-01-13 09:40:02 | INFO | train_inner | epoch 025:   1231 / 1978 loss=3.532, nll_loss=1.386, word_ins=3.18, length=3.521, ppl=11.57, wps=34176.3, ups=0.57, wpb=59658.1, bsz=2005.4, num_updates=48700, lr=0.000453143, gnorm=0.859, loss_scale=8192, train_wall=174, wall=64356
2023-01-13 09:42:10 | INFO | train_inner | epoch 025:   1331 / 1978 loss=3.497, nll_loss=1.35, word_ins=3.148, length=3.485, ppl=11.29, wps=46686.8, ups=0.78, wpb=59845, bsz=2052.9, num_updates=48800, lr=0.000452679, gnorm=0.868, loss_scale=8192, train_wall=128, wall=64484
2023-01-13 09:44:17 | INFO | train_inner | epoch 025:   1431 / 1978 loss=3.533, nll_loss=1.382, word_ins=3.177, length=3.555, ppl=11.57, wps=46531.7, ups=0.78, wpb=59360.3, bsz=1979.6, num_updates=48900, lr=0.000452216, gnorm=0.873, loss_scale=8192, train_wall=127, wall=64611
2023-01-13 09:46:25 | INFO | train_inner | epoch 025:   1531 / 1978 loss=3.531, nll_loss=1.377, word_ins=3.173, length=3.581, ppl=11.56, wps=46241.4, ups=0.78, wpb=59027.1, bsz=2019, num_updates=49000, lr=0.000451754, gnorm=0.861, loss_scale=8192, train_wall=127, wall=64739
2023-01-13 09:48:32 | INFO | train_inner | epoch 025:   1631 / 1978 loss=3.513, nll_loss=1.358, word_ins=3.155, length=3.586, ppl=11.42, wps=46770.3, ups=0.79, wpb=59359.3, bsz=2022.2, num_updates=49100, lr=0.000451294, gnorm=0.835, loss_scale=8192, train_wall=127, wall=64866
2023-01-13 09:50:39 | INFO | train_inner | epoch 025:   1731 / 1978 loss=3.559, nll_loss=1.403, word_ins=3.197, length=3.621, ppl=11.79, wps=46252.7, ups=0.79, wpb=58859, bsz=1957.2, num_updates=49200, lr=0.000450835, gnorm=0.875, loss_scale=8192, train_wall=127, wall=64993
2023-01-13 09:52:47 | INFO | train_inner | epoch 025:   1831 / 1978 loss=3.554, nll_loss=1.396, word_ins=3.19, length=3.646, ppl=11.75, wps=46129.5, ups=0.78, wpb=59074.5, bsz=1960.8, num_updates=49300, lr=0.000450377, gnorm=0.868, loss_scale=8192, train_wall=128, wall=65121
2023-01-13 09:54:57 | INFO | train_inner | epoch 025:   1931 / 1978 loss=3.488, nll_loss=1.338, word_ins=3.137, length=3.509, ppl=11.22, wps=46051.3, ups=0.77, wpb=59566.5, bsz=2158.1, num_updates=49400, lr=0.000449921, gnorm=0.853, loss_scale=8192, train_wall=129, wall=65251
2023-01-13 09:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 09:56:09 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.542 | nll_loss 2.144 | word_ins 3.919 | length 6.23 | ppl 23.29 | wps 185909 | wpb 40242.5 | bsz 1500 | num_updates 49447 | best_loss 4.437
2023-01-13 09:56:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 09:56:36 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint25.pt (epoch 25 @ 49447 updates, score 4.542) (writing took 26.717706845141947 seconds)
2023-01-13 09:56:36 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-01-13 09:56:36 | INFO | train | epoch 025 | loss 3.533 | nll_loss 1.381 | word_ins 3.176 | length 3.568 | ppl 11.58 | wps 44181.4 | ups 0.75 | wpb 59284.3 | bsz 2002.6 | num_updates 49447 | lr 0.000449707 | gnorm 0.858 | loss_scale 8192 | train_wall 2569 | wall 65350
2023-01-13 09:56:36 | INFO | fairseq.trainer | begin training epoch 26
2023-01-13 09:57:55 | INFO | train_inner | epoch 026:     53 / 1978 loss=3.544, nll_loss=1.395, word_ins=3.19, length=3.541, ppl=11.66, wps=32489.1, ups=0.56, wpb=58123.7, bsz=1958.8, num_updates=49500, lr=0.000449467, gnorm=0.867, loss_scale=8192, train_wall=127, wall=65430
2023-01-13 10:00:04 | INFO | train_inner | epoch 026:    153 / 1978 loss=3.558, nll_loss=1.407, word_ins=3.2, length=3.585, ppl=11.78, wps=45464.9, ups=0.78, wpb=58488.9, bsz=1947.9, num_updates=49600, lr=0.000449013, gnorm=0.861, loss_scale=8192, train_wall=128, wall=65558
2023-01-13 10:02:13 | INFO | train_inner | epoch 026:    253 / 1978 loss=3.438, nll_loss=1.292, word_ins=3.097, length=3.414, ppl=10.84, wps=46104.6, ups=0.77, wpb=59509, bsz=2141, num_updates=49700, lr=0.000448561, gnorm=0.816, loss_scale=8192, train_wall=129, wall=65687
2023-01-13 10:04:21 | INFO | train_inner | epoch 026:    353 / 1978 loss=3.497, nll_loss=1.346, word_ins=3.145, length=3.525, ppl=11.29, wps=46286.6, ups=0.78, wpb=59345, bsz=1990.7, num_updates=49800, lr=0.000448111, gnorm=0.838, loss_scale=8192, train_wall=128, wall=65815
2023-01-13 10:06:29 | INFO | train_inner | epoch 026:    453 / 1978 loss=3.53, nll_loss=1.374, word_ins=3.169, length=3.612, ppl=11.55, wps=46436, ups=0.78, wpb=59284.5, bsz=1988, num_updates=49900, lr=0.000447661, gnorm=0.853, loss_scale=8192, train_wall=127, wall=65943
2023-01-13 10:08:36 | INFO | train_inner | epoch 026:    553 / 1978 loss=3.537, nll_loss=1.385, word_ins=3.179, length=3.58, ppl=11.61, wps=46487.4, ups=0.79, wpb=59017.8, bsz=1948.5, num_updates=50000, lr=0.000447214, gnorm=0.862, loss_scale=8192, train_wall=127, wall=66070
2023-01-13 10:10:44 | INFO | train_inner | epoch 026:    653 / 1978 loss=3.515, nll_loss=1.362, word_ins=3.158, length=3.562, ppl=11.43, wps=46323.2, ups=0.78, wpb=59330.7, bsz=1975.8, num_updates=50100, lr=0.000446767, gnorm=0.89, loss_scale=8192, train_wall=128, wall=66198
2023-01-13 10:12:51 | INFO | train_inner | epoch 026:    753 / 1978 loss=3.495, nll_loss=1.343, word_ins=3.142, length=3.536, ppl=11.28, wps=46566.3, ups=0.79, wpb=59157, bsz=2030.6, num_updates=50200, lr=0.000446322, gnorm=0.854, loss_scale=8192, train_wall=127, wall=66325
2023-01-13 10:14:58 | INFO | train_inner | epoch 026:    853 / 1978 loss=3.527, nll_loss=1.37, word_ins=3.167, length=3.6, ppl=11.52, wps=46757.2, ups=0.79, wpb=59395.7, bsz=1938.2, num_updates=50300, lr=0.000445878, gnorm=0.869, loss_scale=16384, train_wall=127, wall=66452
2023-01-13 10:17:07 | INFO | train_inner | epoch 026:    953 / 1978 loss=3.488, nll_loss=1.338, word_ins=3.137, length=3.51, ppl=11.22, wps=46563.1, ups=0.78, wpb=59864.5, bsz=2035.3, num_updates=50400, lr=0.000445435, gnorm=0.859, loss_scale=16384, train_wall=128, wall=66581
2023-01-13 10:19:14 | INFO | train_inner | epoch 026:   1053 / 1978 loss=3.489, nll_loss=1.338, word_ins=3.137, length=3.519, ppl=11.23, wps=46496.8, ups=0.78, wpb=59327.1, bsz=2014, num_updates=50500, lr=0.000444994, gnorm=0.83, loss_scale=16384, train_wall=127, wall=66708
2023-01-13 10:21:22 | INFO | train_inner | epoch 026:   1153 / 1978 loss=3.531, nll_loss=1.376, word_ins=3.172, length=3.595, ppl=11.56, wps=46220.4, ups=0.79, wpb=58786.1, bsz=1903.4, num_updates=50600, lr=0.000444554, gnorm=0.852, loss_scale=16384, train_wall=127, wall=66836
2023-01-13 10:23:30 | INFO | train_inner | epoch 026:   1253 / 1978 loss=3.495, nll_loss=1.342, word_ins=3.14, length=3.547, ppl=11.27, wps=45923.2, ups=0.78, wpb=58924.4, bsz=2064.8, num_updates=50700, lr=0.000444116, gnorm=0.872, loss_scale=16384, train_wall=128, wall=66964
2023-01-13 10:25:38 | INFO | train_inner | epoch 026:   1353 / 1978 loss=3.513, nll_loss=1.364, word_ins=3.159, length=3.539, ppl=11.42, wps=46436.6, ups=0.78, wpb=59517.9, bsz=2035.2, num_updates=50800, lr=0.000443678, gnorm=0.866, loss_scale=16384, train_wall=128, wall=67092
2023-01-13 10:27:45 | INFO | train_inner | epoch 026:   1453 / 1978 loss=3.5, nll_loss=1.345, word_ins=3.143, length=3.564, ppl=11.31, wps=46414.2, ups=0.79, wpb=59087.8, bsz=1947.4, num_updates=50900, lr=0.000443242, gnorm=0.863, loss_scale=16384, train_wall=127, wall=67219
2023-01-13 10:29:53 | INFO | train_inner | epoch 026:   1553 / 1978 loss=3.506, nll_loss=1.358, word_ins=3.154, length=3.527, ppl=11.36, wps=46647.8, ups=0.78, wpb=59515.7, bsz=2007, num_updates=51000, lr=0.000442807, gnorm=0.854, loss_scale=16384, train_wall=127, wall=67347
2023-01-13 10:32:01 | INFO | train_inner | epoch 026:   1653 / 1978 loss=3.511, nll_loss=1.357, word_ins=3.153, length=3.577, ppl=11.4, wps=46362.2, ups=0.78, wpb=59500, bsz=2005.4, num_updates=51100, lr=0.000442374, gnorm=0.881, loss_scale=16384, train_wall=128, wall=67475
2023-01-13 10:34:08 | INFO | train_inner | epoch 026:   1753 / 1978 loss=3.511, nll_loss=1.358, word_ins=3.154, length=3.565, ppl=11.4, wps=46978, ups=0.79, wpb=59736, bsz=1926.6, num_updates=51200, lr=0.000441942, gnorm=0.874, loss_scale=16384, train_wall=127, wall=67603
2023-01-13 10:36:16 | INFO | train_inner | epoch 026:   1853 / 1978 loss=3.489, nll_loss=1.339, word_ins=3.137, length=3.518, ppl=11.23, wps=46478.8, ups=0.78, wpb=59361.8, bsz=2005.6, num_updates=51300, lr=0.000441511, gnorm=0.852, loss_scale=16384, train_wall=127, wall=67730
2023-01-13 10:38:25 | INFO | train_inner | epoch 026:   1953 / 1978 loss=3.438, nll_loss=1.291, word_ins=3.093, length=3.447, ppl=10.84, wps=46520.2, ups=0.78, wpb=59833.7, bsz=2139.6, num_updates=51400, lr=0.000441081, gnorm=0.852, loss_scale=16384, train_wall=128, wall=67859
2023-01-13 10:38:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 10:39:11 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.5 | nll_loss 2.138 | word_ins 3.911 | length 5.89 | ppl 22.63 | wps 124144 | wpb 40242.5 | bsz 1500 | num_updates 51425 | best_loss 4.437
2023-01-13 10:39:11 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 10:39:38 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint26.pt (epoch 26 @ 51425 updates, score 4.5) (writing took 26.845519565977156 seconds)
2023-01-13 10:39:38 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-01-13 10:39:38 | INFO | train | epoch 026 | loss 3.503 | nll_loss 1.352 | word_ins 3.149 | length 3.54 | ppl 11.34 | wps 45407.9 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 51425 | lr 0.000440974 | gnorm 0.858 | loss_scale 16384 | train_wall 2524 | wall 67932
2023-01-13 10:39:38 | INFO | fairseq.trainer | begin training epoch 27
2023-01-13 10:41:27 | INFO | train_inner | epoch 027:     75 / 1978 loss=3.446, nll_loss=1.295, word_ins=3.098, length=3.478, ppl=10.9, wps=32524.6, ups=0.55, wpb=59298.4, bsz=2021.2, num_updates=51500, lr=0.000440653, gnorm=0.844, loss_scale=16384, train_wall=128, wall=68041
2023-01-13 10:43:35 | INFO | train_inner | epoch 027:    175 / 1978 loss=3.48, nll_loss=1.329, word_ins=3.129, length=3.515, ppl=11.16, wps=46354.8, ups=0.78, wpb=59195.9, bsz=2023.4, num_updates=51600, lr=0.000440225, gnorm=0.881, loss_scale=16384, train_wall=127, wall=68169
2023-01-13 10:45:43 | INFO | train_inner | epoch 027:    275 / 1978 loss=3.441, nll_loss=1.292, word_ins=3.095, length=3.459, ppl=10.86, wps=46331, ups=0.78, wpb=59440.3, bsz=2073.4, num_updates=51700, lr=0.000439799, gnorm=0.857, loss_scale=16384, train_wall=128, wall=68297
2023-01-13 10:47:50 | INFO | train_inner | epoch 027:    375 / 1978 loss=3.486, nll_loss=1.328, word_ins=3.127, length=3.587, ppl=11.21, wps=45964.4, ups=0.79, wpb=58480.9, bsz=1998.8, num_updates=51800, lr=0.000439375, gnorm=0.84, loss_scale=16384, train_wall=127, wall=68425
2023-01-13 10:49:57 | INFO | train_inner | epoch 027:    475 / 1978 loss=3.465, nll_loss=1.31, word_ins=3.112, length=3.535, ppl=11.04, wps=47068.2, ups=0.79, wpb=59458.9, bsz=1941.1, num_updates=51900, lr=0.000438951, gnorm=0.864, loss_scale=16384, train_wall=126, wall=68551
2023-01-13 10:52:05 | INFO | train_inner | epoch 027:    575 / 1978 loss=3.512, nll_loss=1.358, word_ins=3.155, length=3.575, ppl=11.41, wps=46187.8, ups=0.78, wpb=59237.2, bsz=1992.9, num_updates=52000, lr=0.000438529, gnorm=0.866, loss_scale=16384, train_wall=128, wall=68679
2023-01-13 10:54:13 | INFO | train_inner | epoch 027:    675 / 1978 loss=3.479, nll_loss=1.323, word_ins=3.123, length=3.56, ppl=11.15, wps=46382.5, ups=0.78, wpb=59420.9, bsz=2000.5, num_updates=52100, lr=0.000438108, gnorm=0.858, loss_scale=16384, train_wall=128, wall=68807
2023-01-13 10:56:21 | INFO | train_inner | epoch 027:    775 / 1978 loss=3.478, nll_loss=1.327, word_ins=3.126, length=3.518, ppl=11.14, wps=46665.2, ups=0.78, wpb=59511.9, bsz=1979.3, num_updates=52200, lr=0.000437688, gnorm=0.857, loss_scale=16384, train_wall=127, wall=68935
2023-01-13 10:58:30 | INFO | train_inner | epoch 027:    875 / 1978 loss=3.475, nll_loss=1.332, word_ins=3.131, length=3.44, ppl=11.12, wps=45784.4, ups=0.77, wpb=59085.6, bsz=2077.5, num_updates=52300, lr=0.000437269, gnorm=0.862, loss_scale=16384, train_wall=129, wall=69064
2023-01-13 11:00:38 | INFO | train_inner | epoch 027:    975 / 1978 loss=3.524, nll_loss=1.371, word_ins=3.166, length=3.576, ppl=11.5, wps=45704.4, ups=0.78, wpb=58631, bsz=2003.8, num_updates=52400, lr=0.000436852, gnorm=0.866, loss_scale=16384, train_wall=128, wall=69192
2023-01-13 11:02:46 | INFO | train_inner | epoch 027:   1075 / 1978 loss=3.469, nll_loss=1.319, word_ins=3.12, length=3.489, ppl=11.07, wps=46621.8, ups=0.78, wpb=59717.9, bsz=2001.8, num_updates=52500, lr=0.000436436, gnorm=0.853, loss_scale=16384, train_wall=128, wall=69320
2023-01-13 11:04:53 | INFO | train_inner | epoch 027:   1175 / 1978 loss=3.5, nll_loss=1.347, word_ins=3.143, length=3.566, ppl=11.31, wps=46715.8, ups=0.79, wpb=59278.5, bsz=1937.4, num_updates=52600, lr=0.000436021, gnorm=0.882, loss_scale=16384, train_wall=127, wall=69447
2023-01-13 11:07:00 | INFO | train_inner | epoch 027:   1275 / 1978 loss=3.479, nll_loss=1.332, word_ins=3.13, length=3.49, ppl=11.15, wps=46627.3, ups=0.78, wpb=59443.2, bsz=2000.1, num_updates=52700, lr=0.000435607, gnorm=0.851, loss_scale=16384, train_wall=127, wall=69575
2023-01-13 11:09:08 | INFO | train_inner | epoch 027:   1375 / 1978 loss=3.461, nll_loss=1.314, word_ins=3.114, length=3.467, ppl=11.01, wps=46615.9, ups=0.78, wpb=59495.5, bsz=1993.5, num_updates=52800, lr=0.000435194, gnorm=0.859, loss_scale=16384, train_wall=127, wall=69702
2023-01-13 11:11:16 | INFO | train_inner | epoch 027:   1475 / 1978 loss=3.464, nll_loss=1.31, word_ins=3.11, length=3.536, ppl=11.03, wps=46284.4, ups=0.78, wpb=59352.1, bsz=2054.4, num_updates=52900, lr=0.000434783, gnorm=0.864, loss_scale=16384, train_wall=128, wall=69830
2023-01-13 11:13:23 | INFO | train_inner | epoch 027:   1575 / 1978 loss=3.492, nll_loss=1.336, word_ins=3.133, length=3.583, ppl=11.25, wps=47102, ups=0.79, wpb=59604.8, bsz=1983.1, num_updates=53000, lr=0.000434372, gnorm=0.86, loss_scale=16384, train_wall=126, wall=69957
2023-01-13 11:15:31 | INFO | train_inner | epoch 027:   1675 / 1978 loss=3.478, nll_loss=1.33, word_ins=3.127, length=3.51, ppl=11.15, wps=46550.7, ups=0.78, wpb=59525.6, bsz=1991, num_updates=53100, lr=0.000433963, gnorm=0.858, loss_scale=16384, train_wall=128, wall=70085
2023-01-13 11:17:38 | INFO | train_inner | epoch 027:   1775 / 1978 loss=3.472, nll_loss=1.322, word_ins=3.121, length=3.511, ppl=11.1, wps=46561.6, ups=0.78, wpb=59401, bsz=1985.1, num_updates=53200, lr=0.000433555, gnorm=0.882, loss_scale=16384, train_wall=127, wall=70212
2023-01-13 11:19:45 | INFO | train_inner | epoch 027:   1875 / 1978 loss=3.521, nll_loss=1.365, word_ins=3.16, length=3.616, ppl=11.48, wps=46580, ups=0.79, wpb=58858.1, bsz=1897.7, num_updates=53300, lr=0.000433148, gnorm=0.9, loss_scale=16384, train_wall=126, wall=70339
2023-01-13 11:21:53 | INFO | train_inner | epoch 027:   1975 / 1978 loss=3.454, nll_loss=1.305, word_ins=3.105, length=3.491, ppl=10.96, wps=46227.8, ups=0.78, wpb=59404.8, bsz=2065.6, num_updates=53400, lr=0.000432742, gnorm=0.855, loss_scale=16384, train_wall=128, wall=70467
2023-01-13 11:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 11:22:11 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.442 | nll_loss 2.121 | word_ins 3.897 | length 5.454 | ppl 21.74 | wps 104615 | wpb 40242.5 | bsz 1500 | num_updates 53403 | best_loss 4.437
2023-01-13 11:22:11 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 11:22:38 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint27.pt (epoch 27 @ 53403 updates, score 4.442) (writing took 27.204930047038943 seconds)
2023-01-13 11:22:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-01-13 11:22:38 | INFO | train | epoch 027 | loss 3.479 | nll_loss 1.327 | word_ins 3.126 | length 3.525 | ppl 11.15 | wps 45453.2 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 53403 | lr 0.00043273 | gnorm 0.863 | loss_scale 16384 | train_wall 2522 | wall 70512
2023-01-13 11:22:38 | INFO | fairseq.trainer | begin training epoch 28
2023-01-13 11:24:54 | INFO | train_inner | epoch 028:     97 / 1978 loss=3.469, nll_loss=1.308, word_ins=3.109, length=3.598, ppl=11.07, wps=32717.4, ups=0.55, wpb=58991.3, bsz=1967.9, num_updates=53500, lr=0.000432338, gnorm=0.872, loss_scale=16384, train_wall=127, wall=70648
2023-01-13 11:27:01 | INFO | train_inner | epoch 028:    197 / 1978 loss=3.509, nll_loss=1.352, word_ins=3.149, length=3.599, ppl=11.39, wps=46651.4, ups=0.79, wpb=59313.6, bsz=1916.2, num_updates=53600, lr=0.000431934, gnorm=0.888, loss_scale=16384, train_wall=127, wall=70775
2023-01-13 11:29:09 | INFO | train_inner | epoch 028:    297 / 1978 loss=3.46, nll_loss=1.305, word_ins=3.106, length=3.544, ppl=11.01, wps=46138.9, ups=0.78, wpb=59026.7, bsz=1969, num_updates=53700, lr=0.000431532, gnorm=0.865, loss_scale=16384, train_wall=128, wall=70903
2023-01-13 11:31:16 | INFO | train_inner | epoch 028:    397 / 1978 loss=3.417, nll_loss=1.272, word_ins=3.075, length=3.42, ppl=10.68, wps=46518.4, ups=0.78, wpb=59425.8, bsz=2110.8, num_updates=53800, lr=0.000431131, gnorm=0.855, loss_scale=16384, train_wall=128, wall=71030
2023-01-13 11:33:24 | INFO | train_inner | epoch 028:    497 / 1978 loss=3.474, nll_loss=1.319, word_ins=3.119, length=3.553, ppl=11.11, wps=45922.5, ups=0.78, wpb=58827.5, bsz=1980.2, num_updates=53900, lr=0.00043073, gnorm=0.853, loss_scale=16384, train_wall=128, wall=71159
2023-01-13 11:35:32 | INFO | train_inner | epoch 028:    597 / 1978 loss=3.458, nll_loss=1.307, word_ins=3.107, length=3.506, ppl=10.99, wps=47042.9, ups=0.79, wpb=59909.3, bsz=1970.2, num_updates=54000, lr=0.000430331, gnorm=0.872, loss_scale=16384, train_wall=127, wall=71286
2023-01-13 11:37:39 | INFO | train_inner | epoch 028:    697 / 1978 loss=3.444, nll_loss=1.293, word_ins=3.096, length=3.485, ppl=10.88, wps=46736.1, ups=0.79, wpb=59503.3, bsz=2007.8, num_updates=54100, lr=0.000429934, gnorm=0.861, loss_scale=16384, train_wall=127, wall=71413
2023-01-13 11:39:47 | INFO | train_inner | epoch 028:    797 / 1978 loss=3.459, nll_loss=1.305, word_ins=3.105, length=3.539, ppl=11, wps=46588.3, ups=0.79, wpb=59340.3, bsz=2042.1, num_updates=54200, lr=0.000429537, gnorm=0.865, loss_scale=16384, train_wall=127, wall=71541
2023-01-13 11:41:55 | INFO | train_inner | epoch 028:    897 / 1978 loss=3.434, nll_loss=1.289, word_ins=3.091, length=3.428, ppl=10.81, wps=46580.5, ups=0.78, wpb=59743.8, bsz=2068.6, num_updates=54300, lr=0.000429141, gnorm=0.852, loss_scale=16384, train_wall=128, wall=71669
2023-01-13 11:44:03 | INFO | train_inner | epoch 028:    997 / 1978 loss=3.443, nll_loss=1.296, word_ins=3.098, length=3.45, ppl=10.87, wps=46111.9, ups=0.78, wpb=59237.4, bsz=2018.9, num_updates=54400, lr=0.000428746, gnorm=0.846, loss_scale=32768, train_wall=128, wall=71797
2023-01-13 11:46:11 | INFO | train_inner | epoch 028:   1097 / 1978 loss=3.46, nll_loss=1.308, word_ins=3.108, length=3.527, ppl=11.01, wps=46412.3, ups=0.78, wpb=59274.7, bsz=1980.7, num_updates=54500, lr=0.000428353, gnorm=0.881, loss_scale=32768, train_wall=128, wall=71925
2023-01-13 11:48:19 | INFO | train_inner | epoch 028:   1197 / 1978 loss=3.439, nll_loss=1.282, word_ins=3.085, length=3.545, ppl=10.85, wps=46354.1, ups=0.78, wpb=59303.3, bsz=2019.9, num_updates=54600, lr=0.00042796, gnorm=0.854, loss_scale=32768, train_wall=128, wall=72053
2023-01-13 11:50:29 | INFO | train_inner | epoch 028:   1297 / 1978 loss=3.475, nll_loss=1.317, word_ins=3.117, length=3.584, ppl=11.12, wps=45310.1, ups=0.77, wpb=58919.2, bsz=1961.8, num_updates=54700, lr=0.000427569, gnorm=0.87, loss_scale=32768, train_wall=130, wall=72183
2023-01-13 11:52:37 | INFO | train_inner | epoch 028:   1397 / 1978 loss=3.454, nll_loss=1.302, word_ins=3.102, length=3.515, ppl=10.96, wps=46205.1, ups=0.78, wpb=59161.8, bsz=2003.1, num_updates=54800, lr=0.000427179, gnorm=0.871, loss_scale=32768, train_wall=128, wall=72311
2023-01-13 11:54:45 | INFO | train_inner | epoch 028:   1497 / 1978 loss=3.436, nll_loss=1.283, word_ins=3.086, length=3.496, ppl=10.82, wps=46614.2, ups=0.78, wpb=59441.7, bsz=2049.2, num_updates=54900, lr=0.00042679, gnorm=0.859, loss_scale=32768, train_wall=127, wall=72439
2023-01-13 11:56:53 | INFO | train_inner | epoch 028:   1597 / 1978 loss=3.461, nll_loss=1.307, word_ins=3.106, length=3.545, ppl=11.01, wps=46734.1, ups=0.78, wpb=59838.6, bsz=1985, num_updates=55000, lr=0.000426401, gnorm=0.909, loss_scale=32768, train_wall=128, wall=72567
2023-01-13 11:59:00 | INFO | train_inner | epoch 028:   1697 / 1978 loss=3.447, nll_loss=1.296, word_ins=3.097, length=3.504, ppl=10.91, wps=46743.8, ups=0.79, wpb=59383.7, bsz=1962.5, num_updates=55100, lr=0.000426014, gnorm=0.869, loss_scale=32768, train_wall=127, wall=72694
2023-01-13 12:01:08 | INFO | train_inner | epoch 028:   1797 / 1978 loss=3.458, nll_loss=1.306, word_ins=3.106, length=3.513, ppl=10.99, wps=45898.4, ups=0.78, wpb=58874.1, bsz=2026.8, num_updates=55200, lr=0.000425628, gnorm=0.868, loss_scale=32768, train_wall=128, wall=72822
2023-01-13 12:03:16 | INFO | train_inner | epoch 028:   1897 / 1978 loss=3.475, nll_loss=1.324, word_ins=3.122, length=3.528, ppl=11.12, wps=46027.9, ups=0.78, wpb=58733.6, bsz=1989.4, num_updates=55300, lr=0.000425243, gnorm=0.879, loss_scale=32768, train_wall=127, wall=72950
2023-01-13 12:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 12:05:12 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.506 | nll_loss 2.101 | word_ins 3.873 | length 6.321 | ppl 22.72 | wps 122001 | wpb 40242.5 | bsz 1500 | num_updates 55381 | best_loss 4.437
2023-01-13 12:05:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 12:05:39 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint28.pt (epoch 28 @ 55381 updates, score 4.506) (writing took 26.62128497287631 seconds)
2023-01-13 12:05:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-01-13 12:05:39 | INFO | train | epoch 028 | loss 3.456 | nll_loss 1.303 | word_ins 3.104 | length 3.52 | ppl 10.97 | wps 45443.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 55381 | lr 0.000424932 | gnorm 0.868 | loss_scale 32768 | train_wall 2525 | wall 73093
2023-01-13 12:05:39 | INFO | fairseq.trainer | begin training epoch 29
2023-01-13 12:06:15 | INFO | train_inner | epoch 029:     19 / 1978 loss=3.44, nll_loss=1.288, word_ins=3.09, length=3.498, ppl=10.85, wps=33086.7, ups=0.56, wpb=59139, bsz=2016.5, num_updates=55400, lr=0.000424859, gnorm=0.858, loss_scale=32768, train_wall=127, wall=73129
2023-01-13 12:08:23 | INFO | train_inner | epoch 029:    119 / 1978 loss=3.431, nll_loss=1.282, word_ins=3.084, length=3.464, ppl=10.78, wps=46125.8, ups=0.78, wpb=59083.3, bsz=2027.6, num_updates=55500, lr=0.000424476, gnorm=0.873, loss_scale=32768, train_wall=128, wall=73257
2023-01-13 12:10:31 | INFO | train_inner | epoch 029:    219 / 1978 loss=3.428, nll_loss=1.278, word_ins=3.081, length=3.467, ppl=10.76, wps=46493.6, ups=0.78, wpb=59465.2, bsz=2013.8, num_updates=55600, lr=0.000424094, gnorm=0.858, loss_scale=32768, train_wall=128, wall=73385
2023-01-13 12:12:39 | INFO | train_inner | epoch 029:    319 / 1978 loss=3.458, nll_loss=1.303, word_ins=3.104, length=3.537, ppl=10.99, wps=45993.8, ups=0.78, wpb=59049, bsz=1989.9, num_updates=55700, lr=0.000423714, gnorm=0.882, loss_scale=32768, train_wall=128, wall=73513
2023-01-13 12:14:46 | INFO | train_inner | epoch 029:    419 / 1978 loss=3.424, nll_loss=1.273, word_ins=3.076, length=3.481, ppl=10.73, wps=46733.1, ups=0.79, wpb=59273.3, bsz=1987.5, num_updates=55800, lr=0.000423334, gnorm=0.859, loss_scale=32768, train_wall=127, wall=73640
2023-01-13 12:16:53 | INFO | train_inner | epoch 029:    519 / 1978 loss=3.436, nll_loss=1.289, word_ins=3.091, length=3.448, ppl=10.82, wps=46469, ups=0.78, wpb=59265.6, bsz=1990.3, num_updates=55900, lr=0.000422955, gnorm=0.869, loss_scale=32768, train_wall=127, wall=73767
2023-01-13 12:19:01 | INFO | train_inner | epoch 029:    619 / 1978 loss=3.475, nll_loss=1.321, word_ins=3.12, length=3.557, ppl=11.12, wps=45908.1, ups=0.79, wpb=58459.6, bsz=1979.5, num_updates=56000, lr=0.000422577, gnorm=0.872, loss_scale=32768, train_wall=127, wall=73895
2023-01-13 12:21:08 | INFO | train_inner | epoch 029:    719 / 1978 loss=3.445, nll_loss=1.294, word_ins=3.095, length=3.498, ppl=10.89, wps=46593.7, ups=0.79, wpb=59215.6, bsz=1989, num_updates=56100, lr=0.0004222, gnorm=0.882, loss_scale=32768, train_wall=127, wall=74022
2023-01-13 12:23:14 | INFO | train_inner | epoch 029:    819 / 1978 loss=3.442, nll_loss=1.291, word_ins=3.092, length=3.498, ppl=10.87, wps=46930.3, ups=0.79, wpb=59254.6, bsz=1962.8, num_updates=56200, lr=0.000421825, gnorm=0.871, loss_scale=32768, train_wall=126, wall=74148
2023-01-13 12:25:22 | INFO | train_inner | epoch 029:    919 / 1978 loss=3.455, nll_loss=1.298, word_ins=3.098, length=3.567, ppl=10.97, wps=46391.2, ups=0.78, wpb=59279.5, bsz=1963.5, num_updates=56300, lr=0.00042145, gnorm=0.878, loss_scale=32768, train_wall=128, wall=74276
2023-01-13 12:27:43 | INFO | train_inner | epoch 029:   1019 / 1978 loss=3.435, nll_loss=1.291, word_ins=3.092, length=3.431, ppl=10.82, wps=41897.6, ups=0.71, wpb=59225.3, bsz=2049.2, num_updates=56400, lr=0.000421076, gnorm=0.904, loss_scale=32768, train_wall=140, wall=74417
2023-01-13 12:30:15 | INFO | train_inner | epoch 029:   1119 / 1978 loss=3.405, nll_loss=1.256, word_ins=3.06, length=3.448, ppl=10.59, wps=38728.2, ups=0.66, wpb=58920.4, bsz=1970.3, num_updates=56500, lr=0.000420703, gnorm=0.861, loss_scale=32768, train_wall=151, wall=74570
2023-01-13 12:32:48 | INFO | train_inner | epoch 029:   1219 / 1978 loss=3.418, nll_loss=1.27, word_ins=3.072, length=3.458, ppl=10.69, wps=39201.5, ups=0.66, wpb=59657.7, bsz=1945.1, num_updates=56600, lr=0.000420331, gnorm=0.889, loss_scale=32768, train_wall=151, wall=74722
2023-01-13 12:35:24 | INFO | train_inner | epoch 029:   1319 / 1978 loss=3.449, nll_loss=1.295, word_ins=3.095, length=3.532, ppl=10.92, wps=38105.8, ups=0.64, wpb=59454.8, bsz=1967.2, num_updates=56700, lr=0.000419961, gnorm=0.875, loss_scale=32768, train_wall=155, wall=74878
2023-01-13 12:37:59 | INFO | train_inner | epoch 029:   1419 / 1978 loss=3.433, nll_loss=1.276, word_ins=3.078, length=3.549, ppl=10.8, wps=38418.1, ups=0.65, wpb=59519.7, bsz=2038.7, num_updates=56800, lr=0.000419591, gnorm=0.858, loss_scale=32768, train_wall=153, wall=75033
2023-01-13 12:40:36 | INFO | train_inner | epoch 029:   1519 / 1978 loss=3.429, nll_loss=1.283, word_ins=3.085, length=3.439, ppl=10.77, wps=37723.4, ups=0.64, wpb=59364.1, bsz=2029, num_updates=56900, lr=0.000419222, gnorm=0.875, loss_scale=32768, train_wall=156, wall=75190
2023-01-13 12:43:14 | INFO | train_inner | epoch 029:   1619 / 1978 loss=3.474, nll_loss=1.322, word_ins=3.12, length=3.542, ppl=11.11, wps=37428.8, ups=0.63, wpb=59020.8, bsz=1933.6, num_updates=57000, lr=0.000418854, gnorm=0.897, loss_scale=32768, train_wall=156, wall=75348
2023-01-13 12:45:49 | INFO | train_inner | epoch 029:   1719 / 1978 loss=3.429, nll_loss=1.275, word_ins=3.077, length=3.522, ppl=10.77, wps=38495.4, ups=0.64, wpb=59912.3, bsz=1979.2, num_updates=57100, lr=0.000418487, gnorm=0.852, loss_scale=32768, train_wall=154, wall=75503
2023-01-13 12:48:27 | INFO | train_inner | epoch 029:   1819 / 1978 loss=3.382, nll_loss=1.236, word_ins=3.042, length=3.397, ppl=10.42, wps=37901.5, ups=0.63, wpb=59801.5, bsz=2130.9, num_updates=57200, lr=0.000418121, gnorm=0.851, loss_scale=32768, train_wall=156, wall=75661
2023-01-13 12:51:04 | INFO | train_inner | epoch 029:   1919 / 1978 loss=3.413, nll_loss=1.261, word_ins=3.064, length=3.485, ppl=10.65, wps=37858.9, ups=0.64, wpb=59417.7, bsz=2074.5, num_updates=57300, lr=0.000417756, gnorm=0.856, loss_scale=32768, train_wall=155, wall=75818
2023-01-13 12:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 12:52:55 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.555 | nll_loss 2.126 | word_ins 3.895 | length 6.604 | ppl 23.5 | wps 33957.2 | wpb 40242.5 | bsz 1500 | num_updates 57359 | best_loss 4.437
2023-01-13 12:52:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 12:53:38 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint29.pt (epoch 29 @ 57359 updates, score 4.555) (writing took 42.77349181007594 seconds)
2023-01-13 12:53:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-01-13 12:53:38 | INFO | train | epoch 029 | loss 3.434 | nll_loss 1.283 | word_ins 3.085 | length 3.491 | ppl 10.81 | wps 40723 | ups 0.69 | wpb 59284.3 | bsz 2002.6 | num_updates 57359 | lr 0.000417541 | gnorm 0.871 | loss_scale 32768 | train_wall 2786 | wall 75972
2023-01-13 12:53:38 | INFO | fairseq.trainer | begin training epoch 30
2023-01-13 12:55:01 | INFO | train_inner | epoch 030:     41 / 1978 loss=3.413, nll_loss=1.264, word_ins=3.067, length=3.461, ppl=10.65, wps=25049.9, ups=0.42, wpb=59300.2, bsz=2029.6, num_updates=57400, lr=0.000417392, gnorm=0.866, loss_scale=32768, train_wall=153, wall=76055
2023-01-13 12:57:35 | INFO | train_inner | epoch 030:    141 / 1978 loss=3.433, nll_loss=1.281, word_ins=3.083, length=3.5, ppl=10.8, wps=38125.6, ups=0.65, wpb=58680.5, bsz=2024.8, num_updates=57500, lr=0.000417029, gnorm=0.892, loss_scale=32768, train_wall=153, wall=76209
2023-01-13 13:00:08 | INFO | train_inner | epoch 030:    241 / 1978 loss=3.42, nll_loss=1.265, word_ins=3.069, length=3.508, ppl=10.7, wps=38540, ups=0.65, wpb=59161, bsz=1945.5, num_updates=57600, lr=0.000416667, gnorm=0.878, loss_scale=32768, train_wall=152, wall=76362
2023-01-13 13:02:45 | INFO | train_inner | epoch 030:    341 / 1978 loss=3.364, nll_loss=1.218, word_ins=3.025, length=3.385, ppl=10.29, wps=38433.8, ups=0.64, wpb=60133.1, bsz=2165.7, num_updates=57700, lr=0.000416305, gnorm=0.852, loss_scale=32768, train_wall=155, wall=76519
2023-01-13 13:05:18 | INFO | train_inner | epoch 030:    441 / 1978 loss=3.421, nll_loss=1.277, word_ins=3.079, length=3.426, ppl=10.71, wps=39043.6, ups=0.65, wpb=59710.1, bsz=2022.5, num_updates=57800, lr=0.000415945, gnorm=0.896, loss_scale=32768, train_wall=152, wall=76672
2023-01-13 13:07:52 | INFO | train_inner | epoch 030:    541 / 1978 loss=3.432, nll_loss=1.279, word_ins=3.081, length=3.506, ppl=10.79, wps=38508.7, ups=0.65, wpb=59420.1, bsz=1918.6, num_updates=57900, lr=0.000415586, gnorm=0.868, loss_scale=32768, train_wall=153, wall=76826
2023-01-13 13:10:25 | INFO | train_inner | epoch 030:    641 / 1978 loss=3.44, nll_loss=1.289, word_ins=3.09, length=3.496, ppl=10.85, wps=38535.6, ups=0.65, wpb=58974.7, bsz=1952, num_updates=58000, lr=0.000415227, gnorm=0.878, loss_scale=32768, train_wall=151, wall=76979
2023-01-13 13:13:02 | INFO | train_inner | epoch 030:    741 / 1978 loss=3.398, nll_loss=1.251, word_ins=3.055, length=3.427, ppl=10.54, wps=38061.6, ups=0.64, wpb=59590.8, bsz=2036.4, num_updates=58100, lr=0.00041487, gnorm=0.884, loss_scale=32768, train_wall=155, wall=77136
2023-01-13 13:15:24 | INFO | train_inner | epoch 030:    841 / 1978 loss=3.435, nll_loss=1.277, word_ins=3.079, length=3.561, ppl=10.81, wps=41526.1, ups=0.7, wpb=59190.5, bsz=1966.2, num_updates=58200, lr=0.000414513, gnorm=0.883, loss_scale=32768, train_wall=142, wall=77278
2023-01-13 13:17:31 | INFO | train_inner | epoch 030:    941 / 1978 loss=3.434, nll_loss=1.279, word_ins=3.081, length=3.527, ppl=10.81, wps=46324.9, ups=0.79, wpb=58760.8, bsz=1915.7, num_updates=58300, lr=0.000414158, gnorm=0.874, loss_scale=32768, train_wall=127, wall=77405
2023-01-13 13:19:38 | INFO | train_inner | epoch 030:   1041 / 1978 loss=3.422, nll_loss=1.268, word_ins=3.07, length=3.521, ppl=10.72, wps=46119, ups=0.79, wpb=58526.1, bsz=2014, num_updates=58400, lr=0.000413803, gnorm=0.836, loss_scale=32768, train_wall=127, wall=77532
2023-01-13 13:20:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32768.0
2023-01-13 13:21:47 | INFO | train_inner | epoch 030:   1142 / 1978 loss=3.426, nll_loss=1.274, word_ins=3.076, length=3.5, ppl=10.75, wps=45715.5, ups=0.78, wpb=58827.2, bsz=1991.6, num_updates=58500, lr=0.000413449, gnorm=0.871, loss_scale=32768, train_wall=128, wall=77661
2023-01-13 13:23:55 | INFO | train_inner | epoch 030:   1242 / 1978 loss=3.386, nll_loss=1.243, word_ins=3.047, length=3.391, ppl=10.46, wps=46191.1, ups=0.78, wpb=59437.4, bsz=2084.2, num_updates=58600, lr=0.000413096, gnorm=0.858, loss_scale=32768, train_wall=128, wall=77789
2023-01-13 13:26:03 | INFO | train_inner | epoch 030:   1342 / 1978 loss=3.4, nll_loss=1.252, word_ins=3.057, length=3.429, ppl=10.55, wps=46894, ups=0.78, wpb=59999.3, bsz=2024.1, num_updates=58700, lr=0.000412744, gnorm=0.891, loss_scale=32768, train_wall=128, wall=77917
2023-01-13 13:28:11 | INFO | train_inner | epoch 030:   1442 / 1978 loss=3.425, nll_loss=1.273, word_ins=3.075, length=3.503, ppl=10.74, wps=46188.7, ups=0.78, wpb=58956.2, bsz=1971.7, num_updates=58800, lr=0.000412393, gnorm=0.881, loss_scale=32768, train_wall=127, wall=78045
2023-01-13 13:30:19 | INFO | train_inner | epoch 030:   1542 / 1978 loss=3.408, nll_loss=1.258, word_ins=3.061, length=3.467, ppl=10.61, wps=46177.7, ups=0.78, wpb=59029, bsz=2076.2, num_updates=58900, lr=0.000412043, gnorm=0.853, loss_scale=32768, train_wall=128, wall=78173
2023-01-13 13:32:27 | INFO | train_inner | epoch 030:   1642 / 1978 loss=3.428, nll_loss=1.282, word_ins=3.082, length=3.453, ppl=10.76, wps=46679.2, ups=0.78, wpb=59633.6, bsz=2010.4, num_updates=59000, lr=0.000411693, gnorm=0.892, loss_scale=32768, train_wall=128, wall=78301
2023-01-13 13:34:35 | INFO | train_inner | epoch 030:   1742 / 1978 loss=3.424, nll_loss=1.272, word_ins=3.074, length=3.498, ppl=10.73, wps=46520.5, ups=0.78, wpb=59677.7, bsz=1959.8, num_updates=59100, lr=0.000411345, gnorm=0.903, loss_scale=32768, train_wall=128, wall=78429
2023-01-13 13:34:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 13:36:45 | INFO | train_inner | epoch 030:   1843 / 1978 loss=3.403, nll_loss=1.251, word_ins=3.056, length=3.474, ppl=10.58, wps=45796.5, ups=0.77, wpb=59426.7, bsz=1990.6, num_updates=59200, lr=0.000410997, gnorm=0.858, loss_scale=16384, train_wall=130, wall=78559
2023-01-13 13:38:52 | INFO | train_inner | epoch 030:   1943 / 1978 loss=3.408, nll_loss=1.249, word_ins=3.053, length=3.546, ppl=10.61, wps=46503.2, ups=0.78, wpb=59447.6, bsz=1949.2, num_updates=59300, lr=0.000410651, gnorm=0.863, loss_scale=16384, train_wall=128, wall=78687
2023-01-13 13:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 13:39:50 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.499 | nll_loss 2.095 | word_ins 3.869 | length 6.297 | ppl 22.6 | wps 138605 | wpb 40242.5 | bsz 1500 | num_updates 59335 | best_loss 4.437
2023-01-13 13:39:50 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 13:40:18 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint30.pt (epoch 30 @ 59335 updates, score 4.499) (writing took 27.258599936030805 seconds)
2023-01-13 13:40:18 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-01-13 13:40:18 | INFO | train | epoch 030 | loss 3.415 | nll_loss 1.264 | word_ins 3.067 | length 3.478 | ppl 10.67 | wps 41847.3 | ups 0.71 | wpb 59286.2 | bsz 2001.4 | num_updates 59335 | lr 0.00041053 | gnorm 0.874 | loss_scale 16384 | train_wall 2726 | wall 78772
2023-01-13 13:40:18 | INFO | fairseq.trainer | begin training epoch 31
2023-01-13 13:41:52 | INFO | train_inner | epoch 031:     65 / 1978 loss=3.407, nll_loss=1.256, word_ins=3.059, length=3.474, ppl=10.61, wps=32625.4, ups=0.56, wpb=58673.2, bsz=1933.3, num_updates=59400, lr=0.000410305, gnorm=0.881, loss_scale=16384, train_wall=127, wall=78866
2023-01-13 13:44:01 | INFO | train_inner | epoch 031:    165 / 1978 loss=3.389, nll_loss=1.235, word_ins=3.041, length=3.475, ppl=10.48, wps=46061.4, ups=0.78, wpb=59355.8, bsz=2022.2, num_updates=59500, lr=0.00040996, gnorm=0.861, loss_scale=16384, train_wall=129, wall=78995
2023-01-13 13:46:08 | INFO | train_inner | epoch 031:    265 / 1978 loss=3.376, nll_loss=1.227, word_ins=3.034, length=3.424, ppl=10.38, wps=46399.2, ups=0.79, wpb=59044.3, bsz=1984.7, num_updates=59600, lr=0.000409616, gnorm=0.878, loss_scale=16384, train_wall=127, wall=79123
2023-01-13 13:48:18 | INFO | train_inner | epoch 031:    365 / 1978 loss=3.362, nll_loss=1.211, word_ins=3.02, length=3.425, ppl=10.28, wps=46131.3, ups=0.77, wpb=59599.7, bsz=2050.4, num_updates=59700, lr=0.000409273, gnorm=0.882, loss_scale=16384, train_wall=129, wall=79252
2023-01-13 13:50:25 | INFO | train_inner | epoch 031:    465 / 1978 loss=3.384, nll_loss=1.232, word_ins=3.038, length=3.458, ppl=10.44, wps=46201.6, ups=0.78, wpb=59049.5, bsz=1977.4, num_updates=59800, lr=0.00040893, gnorm=0.86, loss_scale=16384, train_wall=128, wall=79380
2023-01-13 13:52:34 | INFO | train_inner | epoch 031:    565 / 1978 loss=3.387, nll_loss=1.236, word_ins=3.042, length=3.458, ppl=10.46, wps=45977.6, ups=0.78, wpb=59175.9, bsz=2011.9, num_updates=59900, lr=0.000408589, gnorm=0.874, loss_scale=16384, train_wall=128, wall=79508
2023-01-13 13:54:42 | INFO | train_inner | epoch 031:    665 / 1978 loss=3.427, nll_loss=1.281, word_ins=3.082, length=3.452, ppl=10.76, wps=46358.9, ups=0.78, wpb=59311, bsz=1937, num_updates=60000, lr=0.000408248, gnorm=0.883, loss_scale=16384, train_wall=128, wall=79636
2023-01-13 13:56:50 | INFO | train_inner | epoch 031:    765 / 1978 loss=3.393, nll_loss=1.245, word_ins=3.049, length=3.445, ppl=10.51, wps=46360.5, ups=0.78, wpb=59422.2, bsz=1987.2, num_updates=60100, lr=0.000407909, gnorm=0.862, loss_scale=16384, train_wall=128, wall=79764
2023-01-13 13:58:59 | INFO | train_inner | epoch 031:    865 / 1978 loss=3.394, nll_loss=1.243, word_ins=3.047, length=3.466, ppl=10.51, wps=46275.5, ups=0.78, wpb=59595.4, bsz=2056.8, num_updates=60200, lr=0.00040757, gnorm=0.867, loss_scale=16384, train_wall=129, wall=79893
2023-01-13 14:01:08 | INFO | train_inner | epoch 031:    965 / 1978 loss=3.421, nll_loss=1.273, word_ins=3.075, length=3.462, ppl=10.71, wps=45712, ups=0.77, wpb=59003.1, bsz=1998.2, num_updates=60300, lr=0.000407231, gnorm=0.909, loss_scale=16384, train_wall=129, wall=80022
2023-01-13 14:03:17 | INFO | train_inner | epoch 031:   1065 / 1978 loss=3.41, nll_loss=1.265, word_ins=3.068, length=3.424, ppl=10.63, wps=45737.5, ups=0.77, wpb=59045.4, bsz=2052, num_updates=60400, lr=0.000406894, gnorm=0.889, loss_scale=16384, train_wall=129, wall=80151
2023-01-13 14:05:26 | INFO | train_inner | epoch 031:   1165 / 1978 loss=3.358, nll_loss=1.214, word_ins=3.021, length=3.365, ppl=10.25, wps=46540.5, ups=0.78, wpb=59941.5, bsz=2032.7, num_updates=60500, lr=0.000406558, gnorm=0.89, loss_scale=16384, train_wall=129, wall=80280
2023-01-13 14:07:33 | INFO | train_inner | epoch 031:   1265 / 1978 loss=3.406, nll_loss=1.255, word_ins=3.059, length=3.473, ppl=10.6, wps=46427.1, ups=0.78, wpb=59168.7, bsz=1992.3, num_updates=60600, lr=0.000406222, gnorm=0.879, loss_scale=16384, train_wall=127, wall=80408
2023-01-13 14:09:43 | INFO | train_inner | epoch 031:   1365 / 1978 loss=3.392, nll_loss=1.237, word_ins=3.041, length=3.509, ppl=10.5, wps=45659.1, ups=0.77, wpb=59254, bsz=2022.5, num_updates=60700, lr=0.000405887, gnorm=0.871, loss_scale=16384, train_wall=130, wall=80537
2023-01-13 14:11:51 | INFO | train_inner | epoch 031:   1465 / 1978 loss=3.378, nll_loss=1.221, word_ins=3.027, length=3.51, ppl=10.39, wps=46482.1, ups=0.78, wpb=59537.2, bsz=2010.2, num_updates=60800, lr=0.000405554, gnorm=0.877, loss_scale=16384, train_wall=128, wall=80665
2023-01-13 14:14:00 | INFO | train_inner | epoch 031:   1565 / 1978 loss=3.399, nll_loss=1.248, word_ins=3.052, length=3.474, ppl=10.55, wps=45889.5, ups=0.78, wpb=59079.2, bsz=2007, num_updates=60900, lr=0.00040522, gnorm=0.878, loss_scale=16384, train_wall=128, wall=80794
2023-01-13 14:16:08 | INFO | train_inner | epoch 031:   1665 / 1978 loss=3.409, nll_loss=1.256, word_ins=3.059, length=3.495, ppl=10.62, wps=46241.2, ups=0.78, wpb=59285, bsz=2026.2, num_updates=61000, lr=0.000404888, gnorm=0.894, loss_scale=16384, train_wall=128, wall=80922
2023-01-13 14:18:15 | INFO | train_inner | epoch 031:   1765 / 1978 loss=3.423, nll_loss=1.269, word_ins=3.07, length=3.529, ppl=10.72, wps=46766.6, ups=0.79, wpb=59409.6, bsz=1915.1, num_updates=61100, lr=0.000404557, gnorm=0.882, loss_scale=16384, train_wall=127, wall=81049
2023-01-13 14:20:24 | INFO | train_inner | epoch 031:   1865 / 1978 loss=3.41, nll_loss=1.258, word_ins=3.061, length=3.493, ppl=10.63, wps=45906, ups=0.78, wpb=59010.5, bsz=1999.5, num_updates=61200, lr=0.000404226, gnorm=0.874, loss_scale=16384, train_wall=128, wall=81178
2023-01-13 14:22:33 | INFO | train_inner | epoch 031:   1965 / 1978 loss=3.401, nll_loss=1.251, word_ins=3.055, length=3.462, ppl=10.56, wps=46135, ups=0.77, wpb=59696.6, bsz=2011.3, num_updates=61300, lr=0.000403896, gnorm=0.877, loss_scale=16384, train_wall=129, wall=81307
2023-01-13 14:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 14:23:03 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.492 | nll_loss 2.093 | word_ins 3.862 | length 6.304 | ppl 22.5 | wps 154182 | wpb 40242.5 | bsz 1500 | num_updates 61313 | best_loss 4.437
2023-01-13 14:23:03 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 14:23:29 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint31.pt (epoch 31 @ 61313 updates, score 4.492) (writing took 26.33939008973539 seconds)
2023-01-13 14:23:29 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-01-13 14:23:29 | INFO | train | epoch 031 | loss 3.396 | nll_loss 1.246 | word_ins 3.05 | length 3.464 | ppl 10.53 | wps 45245.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 61313 | lr 0.000403853 | gnorm 0.878 | loss_scale 16384 | train_wall 2535 | wall 81363
2023-01-13 14:23:29 | INFO | fairseq.trainer | begin training epoch 32
2023-01-13 14:25:33 | INFO | train_inner | epoch 032:     87 / 1978 loss=3.394, nll_loss=1.239, word_ins=3.045, length=3.495, ppl=10.51, wps=32603.1, ups=0.56, wpb=58526.6, bsz=2027.7, num_updates=61400, lr=0.000403567, gnorm=0.879, loss_scale=16384, train_wall=129, wall=81487
2023-01-13 14:27:41 | INFO | train_inner | epoch 032:    187 / 1978 loss=3.372, nll_loss=1.216, word_ins=3.023, length=3.493, ppl=10.36, wps=46004.3, ups=0.78, wpb=59115.1, bsz=2022.2, num_updates=61500, lr=0.000403239, gnorm=0.86, loss_scale=16384, train_wall=128, wall=81615
2023-01-13 14:29:50 | INFO | train_inner | epoch 032:    287 / 1978 loss=3.411, nll_loss=1.263, word_ins=3.066, length=3.453, ppl=10.64, wps=46387, ups=0.78, wpb=59462.6, bsz=1943.1, num_updates=61600, lr=0.000402911, gnorm=0.879, loss_scale=16384, train_wall=128, wall=81744
2023-01-13 14:31:58 | INFO | train_inner | epoch 032:    387 / 1978 loss=3.376, nll_loss=1.223, word_ins=3.029, length=3.464, ppl=10.38, wps=46178.5, ups=0.78, wpb=59336.9, bsz=1963.4, num_updates=61700, lr=0.000402585, gnorm=0.874, loss_scale=16384, train_wall=128, wall=81872
2023-01-13 14:34:07 | INFO | train_inner | epoch 032:    487 / 1978 loss=3.379, nll_loss=1.23, word_ins=3.036, length=3.435, ppl=10.41, wps=45709.6, ups=0.78, wpb=58768.4, bsz=2051.4, num_updates=61800, lr=0.000402259, gnorm=0.866, loss_scale=16384, train_wall=128, wall=82001
2023-01-13 14:36:15 | INFO | train_inner | epoch 032:    587 / 1978 loss=3.374, nll_loss=1.221, word_ins=3.027, length=3.469, ppl=10.37, wps=46464.3, ups=0.78, wpb=59440.3, bsz=1994.1, num_updates=61900, lr=0.000401934, gnorm=0.898, loss_scale=16384, train_wall=128, wall=82129
2023-01-13 14:38:22 | INFO | train_inner | epoch 032:    687 / 1978 loss=3.404, nll_loss=1.254, word_ins=3.057, length=3.477, ppl=10.59, wps=46212.4, ups=0.78, wpb=59116.3, bsz=1950.3, num_updates=62000, lr=0.00040161, gnorm=0.896, loss_scale=16384, train_wall=128, wall=82257
2023-01-13 14:40:31 | INFO | train_inner | epoch 032:    787 / 1978 loss=3.394, nll_loss=1.241, word_ins=3.045, length=3.487, ppl=10.51, wps=46222.1, ups=0.78, wpb=59354.7, bsz=1960.2, num_updates=62100, lr=0.000401286, gnorm=0.881, loss_scale=16384, train_wall=128, wall=82385
2023-01-13 14:42:40 | INFO | train_inner | epoch 032:    887 / 1978 loss=3.407, nll_loss=1.256, word_ins=3.059, length=3.486, ppl=10.61, wps=46012.5, ups=0.78, wpb=59234.3, bsz=1975.5, num_updates=62200, lr=0.000400963, gnorm=0.895, loss_scale=16384, train_wall=128, wall=82514
2023-01-13 14:44:48 | INFO | train_inner | epoch 032:    987 / 1978 loss=3.384, nll_loss=1.232, word_ins=3.037, length=3.471, ppl=10.44, wps=46365.8, ups=0.78, wpb=59583.8, bsz=1948.5, num_updates=62300, lr=0.000400642, gnorm=0.887, loss_scale=16384, train_wall=128, wall=82642
2023-01-13 14:46:58 | INFO | train_inner | epoch 032:   1087 / 1978 loss=3.339, nll_loss=1.19, word_ins=2.999, length=3.398, ppl=10.12, wps=45756.3, ups=0.77, wpb=59369.6, bsz=2147, num_updates=62400, lr=0.00040032, gnorm=0.881, loss_scale=16384, train_wall=129, wall=82772
2023-01-13 14:49:05 | INFO | train_inner | epoch 032:   1187 / 1978 loss=3.404, nll_loss=1.25, word_ins=3.053, length=3.508, ppl=10.59, wps=46668.4, ups=0.79, wpb=59430.7, bsz=1874, num_updates=62500, lr=0.0004, gnorm=0.879, loss_scale=16384, train_wall=127, wall=82899
2023-01-13 14:51:15 | INFO | train_inner | epoch 032:   1287 / 1978 loss=3.387, nll_loss=1.243, word_ins=3.046, length=3.411, ppl=10.46, wps=45928.7, ups=0.77, wpb=59568.9, bsz=2073, num_updates=62600, lr=0.00039968, gnorm=0.893, loss_scale=16384, train_wall=129, wall=83029
2023-01-13 14:53:23 | INFO | train_inner | epoch 032:   1387 / 1978 loss=3.396, nll_loss=1.243, word_ins=3.047, length=3.498, ppl=10.53, wps=45704.3, ups=0.78, wpb=58509.1, bsz=1963.8, num_updates=62700, lr=0.000399362, gnorm=0.885, loss_scale=16384, train_wall=128, wall=83157
2023-01-13 14:55:32 | INFO | train_inner | epoch 032:   1487 / 1978 loss=3.359, nll_loss=1.211, word_ins=3.017, length=3.424, ppl=10.26, wps=46011.2, ups=0.77, wpb=59557, bsz=2077.1, num_updates=62800, lr=0.000399043, gnorm=0.89, loss_scale=16384, train_wall=129, wall=83286
2023-01-13 14:57:40 | INFO | train_inner | epoch 032:   1587 / 1978 loss=3.383, nll_loss=1.234, word_ins=3.038, length=3.447, ppl=10.43, wps=46484.3, ups=0.78, wpb=59439.8, bsz=1989.3, num_updates=62900, lr=0.000398726, gnorm=0.875, loss_scale=16384, train_wall=128, wall=83414
2023-01-13 14:59:49 | INFO | train_inner | epoch 032:   1687 / 1978 loss=3.378, nll_loss=1.231, word_ins=3.035, length=3.424, ppl=10.39, wps=46523.9, ups=0.78, wpb=59655, bsz=1957.8, num_updates=63000, lr=0.00039841, gnorm=0.892, loss_scale=16384, train_wall=128, wall=83543
2023-01-13 15:01:57 | INFO | train_inner | epoch 032:   1787 / 1978 loss=3.349, nll_loss=1.203, word_ins=3.01, length=3.393, ppl=10.19, wps=46041.2, ups=0.78, wpb=59305.2, bsz=2106.4, num_updates=63100, lr=0.000398094, gnorm=0.868, loss_scale=16384, train_wall=129, wall=83671
2023-01-13 15:04:05 | INFO | train_inner | epoch 032:   1887 / 1978 loss=3.386, nll_loss=1.234, word_ins=3.039, length=3.471, ppl=10.45, wps=46452, ups=0.79, wpb=59138.3, bsz=2014.3, num_updates=63200, lr=0.000397779, gnorm=0.88, loss_scale=32768, train_wall=127, wall=83799
2023-01-13 15:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 15:06:15 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.493 | nll_loss 2.102 | word_ins 3.865 | length 6.279 | ppl 22.52 | wps 129460 | wpb 40242.5 | bsz 1500 | num_updates 63291 | best_loss 4.437
2023-01-13 15:06:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 15:06:43 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint32.pt (epoch 32 @ 63291 updates, score 4.493) (writing took 27.100128152873367 seconds)
2023-01-13 15:06:43 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-01-13 15:06:43 | INFO | train | epoch 032 | loss 3.382 | nll_loss 1.231 | word_ins 3.036 | length 3.458 | ppl 10.43 | wps 45218.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 63291 | lr 0.000397493 | gnorm 0.882 | loss_scale 32768 | train_wall 2536 | wall 83957
2023-01-13 15:06:43 | INFO | fairseq.trainer | begin training epoch 33
2023-01-13 15:07:06 | INFO | train_inner | epoch 033:      9 / 1978 loss=3.361, nll_loss=1.21, word_ins=3.016, length=3.445, ppl=10.27, wps=32755.8, ups=0.55, wpb=59547, bsz=2054.2, num_updates=63300, lr=0.000397464, gnorm=0.881, loss_scale=32768, train_wall=130, wall=83981
2023-01-13 15:09:14 | INFO | train_inner | epoch 033:    109 / 1978 loss=3.363, nll_loss=1.21, word_ins=3.018, length=3.459, ppl=10.29, wps=46066.5, ups=0.78, wpb=58852.6, bsz=1992.8, num_updates=63400, lr=0.000397151, gnorm=0.884, loss_scale=32768, train_wall=127, wall=84108
2023-01-13 15:11:22 | INFO | train_inner | epoch 033:    209 / 1978 loss=3.378, nll_loss=1.229, word_ins=3.034, length=3.435, ppl=10.39, wps=46323.5, ups=0.78, wpb=59366.5, bsz=1961.7, num_updates=63500, lr=0.000396838, gnorm=0.895, loss_scale=32768, train_wall=128, wall=84236
2023-01-13 15:13:30 | INFO | train_inner | epoch 033:    309 / 1978 loss=3.366, nll_loss=1.216, word_ins=3.023, length=3.427, ppl=10.31, wps=46284, ups=0.78, wpb=59260.6, bsz=2043.9, num_updates=63600, lr=0.000396526, gnorm=0.888, loss_scale=32768, train_wall=128, wall=84364
2023-01-13 15:15:39 | INFO | train_inner | epoch 033:    409 / 1978 loss=3.37, nll_loss=1.214, word_ins=3.021, length=3.498, ppl=10.34, wps=46093.3, ups=0.78, wpb=59058.4, bsz=2015.9, num_updates=63700, lr=0.000396214, gnorm=0.878, loss_scale=32768, train_wall=128, wall=84493
2023-01-13 15:17:47 | INFO | train_inner | epoch 033:    509 / 1978 loss=3.363, nll_loss=1.216, word_ins=3.022, length=3.409, ppl=10.29, wps=46295.2, ups=0.78, wpb=59585.2, bsz=1977.2, num_updates=63800, lr=0.000395904, gnorm=0.894, loss_scale=32768, train_wall=128, wall=84621
2023-01-13 15:19:54 | INFO | train_inner | epoch 033:    609 / 1978 loss=3.403, nll_loss=1.251, word_ins=3.054, length=3.486, ppl=10.58, wps=46556.2, ups=0.79, wpb=59162.8, bsz=1937.4, num_updates=63900, lr=0.000395594, gnorm=0.887, loss_scale=32768, train_wall=127, wall=84748
2023-01-13 15:21:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 15:22:03 | INFO | train_inner | epoch 033:    710 / 1978 loss=3.352, nll_loss=1.203, word_ins=3.01, length=3.424, ppl=10.21, wps=46281.8, ups=0.77, wpb=59747.3, bsz=2015.3, num_updates=64000, lr=0.000395285, gnorm=0.898, loss_scale=16384, train_wall=129, wall=84878
2023-01-13 15:24:12 | INFO | train_inner | epoch 033:    810 / 1978 loss=3.369, nll_loss=1.218, word_ins=3.025, length=3.437, ppl=10.33, wps=46262.1, ups=0.78, wpb=59474.9, bsz=2080.2, num_updates=64100, lr=0.000394976, gnorm=0.886, loss_scale=16384, train_wall=128, wall=85006
2023-01-13 15:26:20 | INFO | train_inner | epoch 033:    910 / 1978 loss=3.355, nll_loss=1.21, word_ins=3.016, length=3.387, ppl=10.23, wps=46434.2, ups=0.78, wpb=59553, bsz=1970.8, num_updates=64200, lr=0.000394669, gnorm=0.873, loss_scale=16384, train_wall=128, wall=85134
2023-01-13 15:28:27 | INFO | train_inner | epoch 033:   1010 / 1978 loss=3.402, nll_loss=1.255, word_ins=3.057, length=3.449, ppl=10.57, wps=46680.4, ups=0.79, wpb=59185.8, bsz=1892.2, num_updates=64300, lr=0.000394362, gnorm=0.883, loss_scale=16384, train_wall=127, wall=85261
2023-01-13 15:30:35 | INFO | train_inner | epoch 033:   1110 / 1978 loss=3.356, nll_loss=1.208, word_ins=3.015, length=3.411, ppl=10.24, wps=46230.6, ups=0.78, wpb=59083.7, bsz=2098.2, num_updates=64400, lr=0.000394055, gnorm=0.907, loss_scale=16384, train_wall=128, wall=85389
2023-01-13 15:32:43 | INFO | train_inner | epoch 033:   1210 / 1978 loss=3.351, nll_loss=1.2, word_ins=3.007, length=3.443, ppl=10.21, wps=46538.2, ups=0.78, wpb=59624.5, bsz=2055.4, num_updates=64500, lr=0.00039375, gnorm=0.878, loss_scale=16384, train_wall=128, wall=85517
2023-01-13 15:34:51 | INFO | train_inner | epoch 033:   1310 / 1978 loss=3.369, nll_loss=1.217, word_ins=3.023, length=3.465, ppl=10.33, wps=45723.9, ups=0.78, wpb=58501.9, bsz=1988.9, num_updates=64600, lr=0.000393445, gnorm=0.864, loss_scale=16384, train_wall=128, wall=85645
2023-01-13 15:36:58 | INFO | train_inner | epoch 033:   1410 / 1978 loss=3.351, nll_loss=1.205, word_ins=3.012, length=3.388, ppl=10.2, wps=46830.8, ups=0.78, wpb=59725.7, bsz=1966.7, num_updates=64700, lr=0.000393141, gnorm=0.894, loss_scale=16384, train_wall=127, wall=85773
2023-01-13 15:39:06 | INFO | train_inner | epoch 033:   1510 / 1978 loss=3.354, nll_loss=1.201, word_ins=3.008, length=3.452, ppl=10.22, wps=45777.2, ups=0.78, wpb=58409.8, bsz=2037.9, num_updates=64800, lr=0.000392837, gnorm=0.872, loss_scale=16384, train_wall=127, wall=85900
2023-01-13 15:41:14 | INFO | train_inner | epoch 033:   1610 / 1978 loss=3.364, nll_loss=1.214, word_ins=3.019, length=3.444, ppl=10.29, wps=46751.4, ups=0.78, wpb=59705.5, bsz=2027, num_updates=64900, lr=0.000392534, gnorm=0.888, loss_scale=16384, train_wall=127, wall=86028
2023-01-13 15:43:23 | INFO | train_inner | epoch 033:   1710 / 1978 loss=3.368, nll_loss=1.212, word_ins=3.018, length=3.503, ppl=10.32, wps=45639.1, ups=0.77, wpb=59079.5, bsz=2035.1, num_updates=65000, lr=0.000392232, gnorm=0.899, loss_scale=16384, train_wall=129, wall=86157
2023-01-13 15:45:31 | INFO | train_inner | epoch 033:   1810 / 1978 loss=3.38, nll_loss=1.226, word_ins=3.031, length=3.494, ppl=10.41, wps=46797.4, ups=0.78, wpb=59870.4, bsz=1965.8, num_updates=65100, lr=0.000391931, gnorm=0.896, loss_scale=16384, train_wall=128, wall=86285
2023-01-13 15:47:39 | INFO | train_inner | epoch 033:   1910 / 1978 loss=3.364, nll_loss=1.214, word_ins=3.02, length=3.433, ppl=10.29, wps=46541.7, ups=0.78, wpb=59506.6, bsz=2007.8, num_updates=65200, lr=0.00039163, gnorm=0.887, loss_scale=16384, train_wall=128, wall=86413
2023-01-13 15:49:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 15:49:17 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.546 | nll_loss 2.081 | word_ins 3.85 | length 6.969 | ppl 23.37 | wps 129854 | wpb 40242.5 | bsz 1500 | num_updates 65268 | best_loss 4.437
2023-01-13 15:49:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 15:49:44 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint33.pt (epoch 33 @ 65268 updates, score 4.546) (writing took 27.45325228292495 seconds)
2023-01-13 15:49:44 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-01-13 15:49:44 | INFO | train | epoch 033 | loss 3.367 | nll_loss 1.217 | word_ins 3.023 | length 3.443 | ppl 10.32 | wps 45400.5 | ups 0.77 | wpb 59287.4 | bsz 2002.8 | num_updates 65268 | lr 0.000391426 | gnorm 0.886 | loss_scale 16384 | train_wall 2526 | wall 86538
2023-01-13 15:49:44 | INFO | fairseq.trainer | begin training epoch 34
2023-01-13 15:50:36 | INFO | train_inner | epoch 034:     32 / 1978 loss=3.399, nll_loss=1.249, word_ins=3.052, length=3.467, ppl=10.55, wps=33216.4, ups=0.56, wpb=58842.4, bsz=1914, num_updates=65300, lr=0.00039133, gnorm=0.896, loss_scale=16384, train_wall=126, wall=86590
2023-01-13 15:52:44 | INFO | train_inner | epoch 034:    132 / 1978 loss=3.344, nll_loss=1.195, word_ins=3.004, length=3.402, ppl=10.16, wps=46141.2, ups=0.78, wpb=59119, bsz=2018, num_updates=65400, lr=0.000391031, gnorm=0.895, loss_scale=16384, train_wall=128, wall=86718
2023-01-13 15:54:52 | INFO | train_inner | epoch 034:    232 / 1978 loss=3.373, nll_loss=1.221, word_ins=3.026, length=3.462, ppl=10.36, wps=46601.8, ups=0.78, wpb=59707.7, bsz=1948.5, num_updates=65500, lr=0.000390732, gnorm=0.884, loss_scale=16384, train_wall=128, wall=86847
2023-01-13 15:57:01 | INFO | train_inner | epoch 034:    332 / 1978 loss=3.326, nll_loss=1.177, word_ins=2.987, length=3.39, ppl=10.03, wps=46207.4, ups=0.78, wpb=59252.5, bsz=2046.2, num_updates=65600, lr=0.000390434, gnorm=0.88, loss_scale=16384, train_wall=128, wall=86975
2023-01-13 15:59:09 | INFO | train_inner | epoch 034:    432 / 1978 loss=3.323, nll_loss=1.176, word_ins=2.986, length=3.378, ppl=10.01, wps=46306.5, ups=0.78, wpb=59227.2, bsz=2073.4, num_updates=65700, lr=0.000390137, gnorm=0.874, loss_scale=16384, train_wall=128, wall=87103
2023-01-13 16:01:17 | INFO | train_inner | epoch 034:    532 / 1978 loss=3.326, nll_loss=1.178, word_ins=2.987, length=3.388, ppl=10.03, wps=46558.6, ups=0.78, wpb=59794.1, bsz=2087.9, num_updates=65800, lr=0.000389841, gnorm=0.879, loss_scale=16384, train_wall=128, wall=87231
2023-01-13 16:03:26 | INFO | train_inner | epoch 034:    632 / 1978 loss=3.344, nll_loss=1.198, word_ins=3.005, length=3.388, ppl=10.15, wps=46171.6, ups=0.78, wpb=59426.6, bsz=2070.5, num_updates=65900, lr=0.000389545, gnorm=0.896, loss_scale=16384, train_wall=129, wall=87360
2023-01-13 16:05:33 | INFO | train_inner | epoch 034:    732 / 1978 loss=3.374, nll_loss=1.225, word_ins=3.029, length=3.451, ppl=10.37, wps=46496.5, ups=0.78, wpb=59366.7, bsz=1980.7, num_updates=66000, lr=0.000389249, gnorm=0.902, loss_scale=16384, train_wall=127, wall=87488
2023-01-13 16:07:41 | INFO | train_inner | epoch 034:    832 / 1978 loss=3.344, nll_loss=1.188, word_ins=2.996, length=3.482, ppl=10.15, wps=46448.2, ups=0.78, wpb=59372.3, bsz=1997.7, num_updates=66100, lr=0.000388955, gnorm=0.878, loss_scale=16384, train_wall=128, wall=87615
2023-01-13 16:09:48 | INFO | train_inner | epoch 034:    932 / 1978 loss=3.341, nll_loss=1.193, word_ins=3, length=3.402, ppl=10.13, wps=46587.1, ups=0.79, wpb=59116.1, bsz=1944.6, num_updates=66200, lr=0.000388661, gnorm=0.878, loss_scale=16384, train_wall=127, wall=87742
2023-01-13 16:11:56 | INFO | train_inner | epoch 034:   1032 / 1978 loss=3.337, nll_loss=1.183, word_ins=2.992, length=3.446, ppl=10.1, wps=46698.9, ups=0.78, wpb=59516.4, bsz=2054.6, num_updates=66300, lr=0.000388368, gnorm=0.896, loss_scale=16384, train_wall=127, wall=87870
2023-01-13 16:14:03 | INFO | train_inner | epoch 034:   1132 / 1978 loss=3.345, nll_loss=1.194, word_ins=3.002, length=3.43, ppl=10.16, wps=46312.9, ups=0.78, wpb=59181, bsz=2033.9, num_updates=66400, lr=0.000388075, gnorm=0.916, loss_scale=16384, train_wall=128, wall=87997
2023-01-13 16:16:10 | INFO | train_inner | epoch 034:   1232 / 1978 loss=3.403, nll_loss=1.248, word_ins=3.05, length=3.527, ppl=10.58, wps=45992.4, ups=0.79, wpb=58454.3, bsz=1923, num_updates=66500, lr=0.000387783, gnorm=0.878, loss_scale=16384, train_wall=127, wall=88125
2023-01-13 16:18:18 | INFO | train_inner | epoch 034:   1332 / 1978 loss=3.372, nll_loss=1.221, word_ins=3.026, length=3.458, ppl=10.35, wps=46510.8, ups=0.78, wpb=59322.5, bsz=1927.6, num_updates=66600, lr=0.000387492, gnorm=0.892, loss_scale=16384, train_wall=127, wall=88252
2023-01-13 16:20:26 | INFO | train_inner | epoch 034:   1432 / 1978 loss=3.358, nll_loss=1.21, word_ins=3.016, length=3.422, ppl=10.26, wps=46403.6, ups=0.78, wpb=59380.3, bsz=1964.2, num_updates=66700, lr=0.000387202, gnorm=0.911, loss_scale=16384, train_wall=128, wall=88380
2023-01-13 16:22:34 | INFO | train_inner | epoch 034:   1532 / 1978 loss=3.343, nll_loss=1.195, word_ins=3.002, length=3.404, ppl=10.14, wps=46594.1, ups=0.78, wpb=59509, bsz=2011.4, num_updates=66800, lr=0.000386912, gnorm=0.894, loss_scale=16384, train_wall=127, wall=88508
2023-01-13 16:24:42 | INFO | train_inner | epoch 034:   1632 / 1978 loss=3.345, nll_loss=1.2, word_ins=3.007, length=3.388, ppl=10.16, wps=46105.7, ups=0.78, wpb=58990.3, bsz=2046.6, num_updates=66900, lr=0.000386622, gnorm=0.871, loss_scale=16384, train_wall=128, wall=88636
2023-01-13 16:26:50 | INFO | train_inner | epoch 034:   1732 / 1978 loss=3.338, nll_loss=1.189, word_ins=2.997, length=3.415, ppl=10.11, wps=46542.1, ups=0.78, wpb=59776.6, bsz=2014, num_updates=67000, lr=0.000386334, gnorm=0.89, loss_scale=16384, train_wall=128, wall=88764
2023-01-13 16:28:58 | INFO | train_inner | epoch 034:   1832 / 1978 loss=3.351, nll_loss=1.2, word_ins=3.006, length=3.451, ppl=10.21, wps=46274.6, ups=0.78, wpb=59204, bsz=2012.3, num_updates=67100, lr=0.000386046, gnorm=0.884, loss_scale=16384, train_wall=128, wall=88892
2023-01-13 16:31:06 | INFO | train_inner | epoch 034:   1932 / 1978 loss=3.385, nll_loss=1.231, word_ins=3.035, length=3.501, ppl=10.45, wps=46090.5, ups=0.78, wpb=58918.7, bsz=1977.8, num_updates=67200, lr=0.000385758, gnorm=0.911, loss_scale=16384, train_wall=128, wall=89020
2023-01-13 16:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 16:32:21 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.537 | nll_loss 2.065 | word_ins 3.841 | length 6.952 | ppl 23.21 | wps 129486 | wpb 40242.5 | bsz 1500 | num_updates 67246 | best_loss 4.437
2023-01-13 16:32:21 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 16:32:48 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint34.pt (epoch 34 @ 67246 updates, score 4.537) (writing took 26.876314676832408 seconds)
2023-01-13 16:32:48 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-01-13 16:32:48 | INFO | train | epoch 034 | loss 3.352 | nll_loss 1.202 | word_ins 3.009 | length 3.431 | ppl 10.21 | wps 45393.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 67246 | lr 0.000385626 | gnorm 0.89 | loss_scale 16384 | train_wall 2524 | wall 89122
2023-01-13 16:32:48 | INFO | fairseq.trainer | begin training epoch 35
2023-01-13 16:34:09 | INFO | train_inner | epoch 035:     54 / 1978 loss=3.333, nll_loss=1.188, word_ins=2.996, length=3.362, ppl=10.08, wps=31777.4, ups=0.55, wpb=58295.2, bsz=2009.1, num_updates=67300, lr=0.000385472, gnorm=0.865, loss_scale=16384, train_wall=127, wall=89204
2023-01-13 16:36:18 | INFO | train_inner | epoch 035:    154 / 1978 loss=3.33, nll_loss=1.179, word_ins=2.988, length=3.423, ppl=10.06, wps=46272.5, ups=0.78, wpb=59397.2, bsz=2025.4, num_updates=67400, lr=0.000385186, gnorm=0.878, loss_scale=16384, train_wall=128, wall=89332
2023-01-13 16:38:25 | INFO | train_inner | epoch 035:    254 / 1978 loss=3.372, nll_loss=1.224, word_ins=3.029, length=3.433, ppl=10.35, wps=46027.5, ups=0.79, wpb=58420.7, bsz=1973.4, num_updates=67500, lr=0.0003849, gnorm=0.881, loss_scale=16384, train_wall=127, wall=89459
2023-01-13 16:40:32 | INFO | train_inner | epoch 035:    354 / 1978 loss=3.362, nll_loss=1.21, word_ins=3.016, length=3.457, ppl=10.28, wps=46901.5, ups=0.79, wpb=59662.5, bsz=1895.3, num_updates=67600, lr=0.000384615, gnorm=0.888, loss_scale=16384, train_wall=127, wall=89586
2023-01-13 16:42:40 | INFO | train_inner | epoch 035:    454 / 1978 loss=3.339, nll_loss=1.19, word_ins=2.998, length=3.404, ppl=10.12, wps=46232, ups=0.78, wpb=59273.9, bsz=1998.6, num_updates=67700, lr=0.000384331, gnorm=0.89, loss_scale=16384, train_wall=128, wall=89714
2023-01-13 16:44:48 | INFO | train_inner | epoch 035:    554 / 1978 loss=3.365, nll_loss=1.214, word_ins=3.02, length=3.45, ppl=10.3, wps=46180.3, ups=0.78, wpb=58988, bsz=1962, num_updates=67800, lr=0.000384048, gnorm=0.913, loss_scale=16384, train_wall=127, wall=89842
2023-01-13 16:46:56 | INFO | train_inner | epoch 035:    654 / 1978 loss=3.305, nll_loss=1.155, word_ins=2.966, length=3.384, ppl=9.88, wps=46571.3, ups=0.78, wpb=59758.1, bsz=2033.9, num_updates=67900, lr=0.000383765, gnorm=0.886, loss_scale=16384, train_wall=128, wall=89970
2023-01-13 16:49:04 | INFO | train_inner | epoch 035:    754 / 1978 loss=3.361, nll_loss=1.207, word_ins=3.014, length=3.477, ppl=10.28, wps=45975, ups=0.78, wpb=58913.6, bsz=1980.9, num_updates=68000, lr=0.000383482, gnorm=0.898, loss_scale=16384, train_wall=128, wall=90098
2023-01-13 16:51:13 | INFO | train_inner | epoch 035:    854 / 1978 loss=3.35, nll_loss=1.195, word_ins=3.003, length=3.468, ppl=10.2, wps=45948.1, ups=0.78, wpb=59104.3, bsz=1997.9, num_updates=68100, lr=0.000383201, gnorm=0.887, loss_scale=32768, train_wall=128, wall=90227
2023-01-13 16:53:21 | INFO | train_inner | epoch 035:    954 / 1978 loss=3.326, nll_loss=1.184, word_ins=2.992, length=3.341, ppl=10.03, wps=46572.4, ups=0.78, wpb=59802.8, bsz=2035.5, num_updates=68200, lr=0.00038292, gnorm=0.889, loss_scale=32768, train_wall=128, wall=90356
2023-01-13 16:55:31 | INFO | train_inner | epoch 035:   1054 / 1978 loss=3.297, nll_loss=1.15, word_ins=2.961, length=3.355, ppl=9.83, wps=46387.3, ups=0.77, wpb=59916.7, bsz=2067, num_updates=68300, lr=0.000382639, gnorm=0.871, loss_scale=32768, train_wall=128, wall=90485
2023-01-13 16:57:39 | INFO | train_inner | epoch 035:   1154 / 1978 loss=3.326, nll_loss=1.181, word_ins=2.99, length=3.367, ppl=10.03, wps=46479, ups=0.78, wpb=59492.9, bsz=2009.8, num_updates=68400, lr=0.00038236, gnorm=0.881, loss_scale=32768, train_wall=128, wall=90613
2023-01-13 16:59:47 | INFO | train_inner | epoch 035:   1254 / 1978 loss=3.313, nll_loss=1.166, word_ins=2.975, length=3.379, ppl=9.94, wps=46168.2, ups=0.78, wpb=59377.7, bsz=2060.4, num_updates=68500, lr=0.00038208, gnorm=0.86, loss_scale=32768, train_wall=128, wall=90741
2023-01-13 17:01:55 | INFO | train_inner | epoch 035:   1354 / 1978 loss=3.325, nll_loss=1.175, word_ins=2.983, length=3.415, ppl=10.02, wps=46311.5, ups=0.78, wpb=59203.7, bsz=2059, num_updates=68600, lr=0.000381802, gnorm=0.89, loss_scale=32768, train_wall=128, wall=90869
2023-01-13 17:04:02 | INFO | train_inner | epoch 035:   1454 / 1978 loss=3.352, nll_loss=1.207, word_ins=3.012, length=3.396, ppl=10.21, wps=46556.2, ups=0.79, wpb=59236.6, bsz=1953.8, num_updates=68700, lr=0.000381524, gnorm=0.894, loss_scale=32768, train_wall=127, wall=90996
2023-01-13 17:06:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 17:06:12 | INFO | train_inner | epoch 035:   1555 / 1978 loss=3.357, nll_loss=1.205, word_ins=3.011, length=3.457, ppl=10.24, wps=45382, ups=0.77, wpb=58889.1, bsz=2004, num_updates=68800, lr=0.000381246, gnorm=0.92, loss_scale=16384, train_wall=130, wall=91126
2023-01-13 17:08:19 | INFO | train_inner | epoch 035:   1655 / 1978 loss=3.358, nll_loss=1.202, word_ins=3.008, length=3.491, ppl=10.25, wps=46117.8, ups=0.79, wpb=58689.6, bsz=1954.9, num_updates=68900, lr=0.00038097, gnorm=0.893, loss_scale=16384, train_wall=127, wall=91253
2023-01-13 17:10:28 | INFO | train_inner | epoch 035:   1755 / 1978 loss=3.327, nll_loss=1.177, word_ins=2.985, length=3.424, ppl=10.04, wps=46447.3, ups=0.78, wpb=59905.7, bsz=2012.6, num_updates=69000, lr=0.000380693, gnorm=0.889, loss_scale=16384, train_wall=129, wall=91382
2023-01-13 17:12:36 | INFO | train_inner | epoch 035:   1855 / 1978 loss=3.333, nll_loss=1.179, word_ins=2.987, length=3.46, ppl=10.08, wps=46901.2, ups=0.79, wpb=59643.5, bsz=1982.8, num_updates=69100, lr=0.000380418, gnorm=0.908, loss_scale=16384, train_wall=127, wall=91510
2023-01-13 17:14:44 | INFO | train_inner | epoch 035:   1955 / 1978 loss=3.341, nll_loss=1.195, word_ins=3.002, length=3.386, ppl=10.13, wps=46418.7, ups=0.78, wpb=59753.5, bsz=2017, num_updates=69200, lr=0.000380143, gnorm=0.913, loss_scale=16384, train_wall=128, wall=91638
2023-01-13 17:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 17:15:27 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.609 | nll_loss 2.061 | word_ins 3.831 | length 7.78 | ppl 24.4 | wps 127917 | wpb 40242.5 | bsz 1500 | num_updates 69223 | best_loss 4.437
2023-01-13 17:15:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 17:15:54 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint35.pt (epoch 35 @ 69223 updates, score 4.609) (writing took 27.069950881879777 seconds)
2023-01-13 17:15:54 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-01-13 17:15:54 | INFO | train | epoch 035 | loss 3.339 | nll_loss 1.189 | word_ins 2.997 | length 3.417 | ppl 10.12 | wps 45306.3 | ups 0.76 | wpb 59284.6 | bsz 2002.6 | num_updates 69223 | lr 0.00038008 | gnorm 0.89 | loss_scale 16384 | train_wall 2528 | wall 91709
2023-01-13 17:15:54 | INFO | fairseq.trainer | begin training epoch 36
2023-01-13 17:17:47 | INFO | train_inner | epoch 036:     77 / 1978 loss=3.329, nll_loss=1.18, word_ins=2.989, length=3.406, ppl=10.05, wps=32299.6, ups=0.55, wpb=59015.3, bsz=2053.2, num_updates=69300, lr=0.000379869, gnorm=0.873, loss_scale=16384, train_wall=129, wall=91821
2023-01-13 17:19:55 | INFO | train_inner | epoch 036:    177 / 1978 loss=3.318, nll_loss=1.173, word_ins=2.982, length=3.353, ppl=9.97, wps=46325.7, ups=0.78, wpb=59128.9, bsz=2012.2, num_updates=69400, lr=0.000379595, gnorm=0.875, loss_scale=16384, train_wall=127, wall=91949
2023-01-13 17:22:02 | INFO | train_inner | epoch 036:    277 / 1978 loss=3.324, nll_loss=1.171, word_ins=2.98, length=3.445, ppl=10.02, wps=47057.2, ups=0.79, wpb=59944.6, bsz=1980.5, num_updates=69500, lr=0.000379322, gnorm=0.877, loss_scale=16384, train_wall=127, wall=92076
2023-01-13 17:24:10 | INFO | train_inner | epoch 036:    377 / 1978 loss=3.321, nll_loss=1.167, word_ins=2.977, length=3.444, ppl=9.99, wps=46558.4, ups=0.78, wpb=59373.5, bsz=2033.2, num_updates=69600, lr=0.000379049, gnorm=0.891, loss_scale=16384, train_wall=127, wall=92204
2023-01-13 17:26:17 | INFO | train_inner | epoch 036:    477 / 1978 loss=3.342, nll_loss=1.193, word_ins=3, length=3.416, ppl=10.14, wps=46267, ups=0.78, wpb=58970, bsz=1961.8, num_updates=69700, lr=0.000378777, gnorm=0.914, loss_scale=16384, train_wall=127, wall=92331
2023-01-13 17:28:26 | INFO | train_inner | epoch 036:    577 / 1978 loss=3.299, nll_loss=1.155, word_ins=2.966, length=3.337, ppl=9.85, wps=45990.8, ups=0.78, wpb=59107, bsz=2092.2, num_updates=69800, lr=0.000378506, gnorm=0.874, loss_scale=16384, train_wall=128, wall=92460
2023-01-13 17:30:33 | INFO | train_inner | epoch 036:    677 / 1978 loss=3.357, nll_loss=1.21, word_ins=3.015, length=3.425, ppl=10.25, wps=46243.8, ups=0.78, wpb=59079, bsz=1989.3, num_updates=69900, lr=0.000378235, gnorm=0.888, loss_scale=16384, train_wall=128, wall=92587
2023-01-13 17:32:42 | INFO | train_inner | epoch 036:    777 / 1978 loss=3.321, nll_loss=1.17, word_ins=2.98, length=3.414, ppl=9.99, wps=46249.2, ups=0.78, wpb=59348.9, bsz=2001, num_updates=70000, lr=0.000377964, gnorm=0.929, loss_scale=16384, train_wall=128, wall=92716
2023-01-13 17:34:49 | INFO | train_inner | epoch 036:    877 / 1978 loss=3.348, nll_loss=1.197, word_ins=3.003, length=3.445, ppl=10.18, wps=46240.2, ups=0.79, wpb=58900.7, bsz=1926, num_updates=70100, lr=0.000377695, gnorm=0.889, loss_scale=16384, train_wall=127, wall=92843
2023-01-13 17:36:58 | INFO | train_inner | epoch 036:    977 / 1978 loss=3.313, nll_loss=1.167, word_ins=2.976, length=3.371, ppl=9.94, wps=46355.8, ups=0.78, wpb=59575.6, bsz=2105.5, num_updates=70200, lr=0.000377426, gnorm=0.893, loss_scale=16384, train_wall=128, wall=92972
2023-01-13 17:39:04 | INFO | train_inner | epoch 036:   1077 / 1978 loss=3.299, nll_loss=1.148, word_ins=2.96, length=3.394, ppl=9.84, wps=46651.3, ups=0.79, wpb=59158.7, bsz=2027.8, num_updates=70300, lr=0.000377157, gnorm=0.882, loss_scale=16384, train_wall=127, wall=93098
2023-01-13 17:41:12 | INFO | train_inner | epoch 036:   1177 / 1978 loss=3.327, nll_loss=1.181, word_ins=2.989, length=3.38, ppl=10.03, wps=46632.9, ups=0.78, wpb=59650.2, bsz=1997.3, num_updates=70400, lr=0.000376889, gnorm=0.907, loss_scale=16384, train_wall=128, wall=93226
2023-01-13 17:43:19 | INFO | train_inner | epoch 036:   1277 / 1978 loss=3.358, nll_loss=1.206, word_ins=3.012, length=3.462, ppl=10.25, wps=46572.8, ups=0.79, wpb=59081, bsz=1926.8, num_updates=70500, lr=0.000376622, gnorm=0.896, loss_scale=16384, train_wall=127, wall=93353
2023-01-13 17:45:28 | INFO | train_inner | epoch 036:   1377 / 1978 loss=3.315, nll_loss=1.174, word_ins=2.982, length=3.326, ppl=9.95, wps=46538.4, ups=0.78, wpb=59782.6, bsz=2038.1, num_updates=70600, lr=0.000376355, gnorm=0.899, loss_scale=16384, train_wall=128, wall=93482
2023-01-13 17:47:37 | INFO | train_inner | epoch 036:   1477 / 1978 loss=3.279, nll_loss=1.131, word_ins=2.943, length=3.362, ppl=9.71, wps=46491, ups=0.77, wpb=60026.8, bsz=2112.6, num_updates=70700, lr=0.000376089, gnorm=0.876, loss_scale=16384, train_wall=129, wall=93611
2023-01-13 17:49:44 | INFO | train_inner | epoch 036:   1577 / 1978 loss=3.366, nll_loss=1.213, word_ins=3.018, length=3.48, ppl=10.31, wps=46336.9, ups=0.79, wpb=58740.3, bsz=1913.1, num_updates=70800, lr=0.000375823, gnorm=0.908, loss_scale=16384, train_wall=127, wall=93738
2023-01-13 17:51:52 | INFO | train_inner | epoch 036:   1677 / 1978 loss=3.331, nll_loss=1.181, word_ins=2.989, length=3.419, ppl=10.06, wps=46350.6, ups=0.78, wpb=59413, bsz=2008.8, num_updates=70900, lr=0.000375558, gnorm=0.887, loss_scale=16384, train_wall=128, wall=93866
2023-01-13 17:53:59 | INFO | train_inner | epoch 036:   1777 / 1978 loss=3.353, nll_loss=1.199, word_ins=3.005, length=3.475, ppl=10.21, wps=46088.8, ups=0.79, wpb=58646.7, bsz=1884.4, num_updates=71000, lr=0.000375293, gnorm=0.902, loss_scale=16384, train_wall=127, wall=93993
2023-01-13 17:56:06 | INFO | train_inner | epoch 036:   1877 / 1978 loss=3.333, nll_loss=1.18, word_ins=2.988, length=3.443, ppl=10.07, wps=46178.7, ups=0.79, wpb=58813.5, bsz=1937.3, num_updates=71100, lr=0.000375029, gnorm=0.894, loss_scale=16384, train_wall=127, wall=94120
2023-01-13 17:58:15 | INFO | train_inner | epoch 036:   1977 / 1978 loss=3.299, nll_loss=1.151, word_ins=2.961, length=3.377, ppl=9.84, wps=46613.9, ups=0.78, wpb=59898.5, bsz=2054.4, num_updates=71200, lr=0.000374766, gnorm=0.895, loss_scale=16384, train_wall=128, wall=94249
2023-01-13 17:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 17:58:31 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.475 | nll_loss 2.056 | word_ins 3.825 | length 6.508 | ppl 22.24 | wps 114601 | wpb 40242.5 | bsz 1500 | num_updates 71201 | best_loss 4.437
2023-01-13 17:58:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 17:58:58 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint36.pt (epoch 36 @ 71201 updates, score 4.475) (writing took 26.955040506087244 seconds)
2023-01-13 17:58:58 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-01-13 17:58:58 | INFO | train | epoch 036 | loss 3.326 | nll_loss 1.177 | word_ins 2.986 | length 3.409 | ppl 10.03 | wps 45396.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 71201 | lr 0.000374763 | gnorm 0.892 | loss_scale 16384 | train_wall 2524 | wall 94292
2023-01-13 17:58:58 | INFO | fairseq.trainer | begin training epoch 37
2023-01-13 18:01:18 | INFO | train_inner | epoch 037:     99 / 1978 loss=3.29, nll_loss=1.154, word_ins=2.964, length=3.26, ppl=9.78, wps=32412, ups=0.55, wpb=59342.8, bsz=2046.5, num_updates=71300, lr=0.000374503, gnorm=0.888, loss_scale=16384, train_wall=128, wall=94432
2023-01-13 18:03:27 | INFO | train_inner | epoch 037:    199 / 1978 loss=3.297, nll_loss=1.148, word_ins=2.959, length=3.38, ppl=9.83, wps=45895, ups=0.78, wpb=59189, bsz=2029.5, num_updates=71400, lr=0.000374241, gnorm=0.889, loss_scale=16384, train_wall=129, wall=94561
2023-01-13 18:05:34 | INFO | train_inner | epoch 037:    299 / 1978 loss=3.323, nll_loss=1.172, word_ins=2.981, length=3.421, ppl=10.01, wps=46380.8, ups=0.79, wpb=58855.7, bsz=1911.7, num_updates=71500, lr=0.000373979, gnorm=0.905, loss_scale=16384, train_wall=127, wall=94688
2023-01-13 18:07:41 | INFO | train_inner | epoch 037:    399 / 1978 loss=3.35, nll_loss=1.194, word_ins=3.001, length=3.494, ppl=10.2, wps=46648.6, ups=0.79, wpb=59333.5, bsz=1913.3, num_updates=71600, lr=0.000373718, gnorm=0.903, loss_scale=16384, train_wall=127, wall=94815
2023-01-13 18:09:50 | INFO | train_inner | epoch 037:    499 / 1978 loss=3.326, nll_loss=1.176, word_ins=2.985, length=3.411, ppl=10.03, wps=45674.8, ups=0.78, wpb=58726.5, bsz=2005.9, num_updates=71700, lr=0.000373457, gnorm=0.889, loss_scale=16384, train_wall=128, wall=94944
2023-01-13 18:11:57 | INFO | train_inner | epoch 037:    599 / 1978 loss=3.296, nll_loss=1.148, word_ins=2.958, length=3.371, ppl=9.82, wps=46735, ups=0.79, wpb=59391.7, bsz=1955.5, num_updates=71800, lr=0.000373197, gnorm=0.885, loss_scale=16384, train_wall=127, wall=95071
2023-01-13 18:14:06 | INFO | train_inner | epoch 037:    699 / 1978 loss=3.298, nll_loss=1.149, word_ins=2.96, length=3.383, ppl=9.83, wps=45809.9, ups=0.77, wpb=59179.7, bsz=2115.9, num_updates=71900, lr=0.000372937, gnorm=0.867, loss_scale=16384, train_wall=129, wall=95200
2023-01-13 18:16:12 | INFO | train_inner | epoch 037:    799 / 1978 loss=3.359, nll_loss=1.208, word_ins=3.013, length=3.46, ppl=10.26, wps=46746, ups=0.79, wpb=59135.9, bsz=1920.1, num_updates=72000, lr=0.000372678, gnorm=0.873, loss_scale=16384, train_wall=126, wall=95326
2023-01-13 18:18:20 | INFO | train_inner | epoch 037:    899 / 1978 loss=3.299, nll_loss=1.151, word_ins=2.962, length=3.366, ppl=9.84, wps=46228.3, ups=0.78, wpb=59191.1, bsz=2032.3, num_updates=72100, lr=0.000372419, gnorm=0.879, loss_scale=16384, train_wall=128, wall=95455
2023-01-13 18:20:29 | INFO | train_inner | epoch 037:    999 / 1978 loss=3.294, nll_loss=1.144, word_ins=2.954, length=3.4, ppl=9.81, wps=46949.3, ups=0.78, wpb=60210.3, bsz=2005.3, num_updates=72200, lr=0.000372161, gnorm=0.898, loss_scale=16384, train_wall=128, wall=95583
2023-01-13 18:22:37 | INFO | train_inner | epoch 037:   1099 / 1978 loss=3.308, nll_loss=1.159, word_ins=2.97, length=3.383, ppl=9.9, wps=45893.7, ups=0.78, wpb=59082.6, bsz=2033.4, num_updates=72300, lr=0.000371904, gnorm=0.865, loss_scale=16384, train_wall=128, wall=95712
2023-01-13 18:24:45 | INFO | train_inner | epoch 037:   1199 / 1978 loss=3.333, nll_loss=1.186, word_ins=2.993, length=3.397, ppl=10.08, wps=46252.8, ups=0.78, wpb=59093.6, bsz=1971.1, num_updates=72400, lr=0.000371647, gnorm=0.879, loss_scale=16384, train_wall=128, wall=95839
2023-01-13 18:26:55 | INFO | train_inner | epoch 037:   1299 / 1978 loss=3.279, nll_loss=1.133, word_ins=2.945, length=3.338, ppl=9.71, wps=45879.4, ups=0.77, wpb=59356.8, bsz=2130.8, num_updates=72500, lr=0.000371391, gnorm=0.882, loss_scale=16384, train_wall=129, wall=95969
2023-01-13 18:29:03 | INFO | train_inner | epoch 037:   1399 / 1978 loss=3.313, nll_loss=1.167, word_ins=2.976, length=3.376, ppl=9.94, wps=46146.5, ups=0.78, wpb=59427.7, bsz=2053.8, num_updates=72600, lr=0.000371135, gnorm=0.886, loss_scale=16384, train_wall=129, wall=96097
2023-01-13 18:31:13 | INFO | train_inner | epoch 037:   1499 / 1978 loss=3.283, nll_loss=1.133, word_ins=2.945, length=3.377, ppl=9.73, wps=46260.8, ups=0.77, wpb=59724.1, bsz=2066.8, num_updates=72700, lr=0.000370879, gnorm=0.9, loss_scale=16384, train_wall=129, wall=96227
2023-01-13 18:33:20 | INFO | train_inner | epoch 037:   1599 / 1978 loss=3.343, nll_loss=1.196, word_ins=3.001, length=3.415, ppl=10.15, wps=46613.5, ups=0.78, wpb=59441.7, bsz=1956.5, num_updates=72800, lr=0.000370625, gnorm=0.938, loss_scale=16384, train_wall=127, wall=96354
2023-01-13 18:35:28 | INFO | train_inner | epoch 037:   1699 / 1978 loss=3.336, nll_loss=1.183, word_ins=2.99, length=3.452, ppl=10.1, wps=45973.4, ups=0.78, wpb=58702.8, bsz=1926.9, num_updates=72900, lr=0.00037037, gnorm=0.879, loss_scale=32768, train_wall=127, wall=96482
2023-01-13 18:37:35 | INFO | train_inner | epoch 037:   1799 / 1978 loss=3.327, nll_loss=1.174, word_ins=2.982, length=3.443, ppl=10.03, wps=46527, ups=0.78, wpb=59315.9, bsz=1929.2, num_updates=73000, lr=0.000370117, gnorm=0.899, loss_scale=32768, train_wall=127, wall=96609
2023-01-13 18:38:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 18:39:44 | INFO | train_inner | epoch 037:   1900 / 1978 loss=3.312, nll_loss=1.168, word_ins=2.976, length=3.358, ppl=9.93, wps=46275.6, ups=0.78, wpb=59563.2, bsz=1976.3, num_updates=73100, lr=0.000369863, gnorm=0.874, loss_scale=16384, train_wall=128, wall=96738
2023-01-13 18:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 18:41:38 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.494 | nll_loss 2.035 | word_ins 3.81 | length 6.838 | ppl 22.53 | wps 161347 | wpb 40242.5 | bsz 1500 | num_updates 73178 | best_loss 4.437
2023-01-13 18:41:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 18:42:06 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint37.pt (epoch 37 @ 73178 updates, score 4.494) (writing took 27.55591598385945 seconds)
2023-01-13 18:42:06 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-01-13 18:42:06 | INFO | train | epoch 037 | loss 3.313 | nll_loss 1.164 | word_ins 2.974 | length 3.392 | ppl 9.94 | wps 45287.1 | ups 0.76 | wpb 59287.4 | bsz 2002.9 | num_updates 73178 | lr 0.000369666 | gnorm 0.889 | loss_scale 16384 | train_wall 2529 | wall 96880
2023-01-13 18:42:06 | INFO | fairseq.trainer | begin training epoch 38
2023-01-13 18:42:48 | INFO | train_inner | epoch 038:     22 / 1978 loss=3.291, nll_loss=1.141, word_ins=2.953, length=3.382, ppl=9.79, wps=32320.9, ups=0.54, wpb=59349.8, bsz=2083.1, num_updates=73200, lr=0.000369611, gnorm=0.911, loss_scale=16384, train_wall=129, wall=96922
2023-01-13 18:44:55 | INFO | train_inner | epoch 038:    122 / 1978 loss=3.306, nll_loss=1.153, word_ins=2.964, length=3.419, ppl=9.89, wps=46396.2, ups=0.79, wpb=58945.5, bsz=1953.1, num_updates=73300, lr=0.000369358, gnorm=0.889, loss_scale=16384, train_wall=127, wall=97049
2023-01-13 18:47:03 | INFO | train_inner | epoch 038:    222 / 1978 loss=3.312, nll_loss=1.169, word_ins=2.978, length=3.34, ppl=9.93, wps=46235.7, ups=0.78, wpb=59250.4, bsz=2014.2, num_updates=73400, lr=0.000369107, gnorm=0.879, loss_scale=16384, train_wall=128, wall=97177
2023-01-13 18:49:10 | INFO | train_inner | epoch 038:    322 / 1978 loss=3.307, nll_loss=1.162, word_ins=2.972, length=3.35, ppl=9.89, wps=46609.8, ups=0.78, wpb=59511.6, bsz=1986.1, num_updates=73500, lr=0.000368856, gnorm=0.88, loss_scale=16384, train_wall=127, wall=97305
2023-01-13 18:51:19 | INFO | train_inner | epoch 038:    422 / 1978 loss=3.313, nll_loss=1.164, word_ins=2.974, length=3.384, ppl=9.94, wps=45994, ups=0.78, wpb=58952.5, bsz=1953, num_updates=73600, lr=0.000368605, gnorm=0.893, loss_scale=16384, train_wall=128, wall=97433
2023-01-13 18:53:26 | INFO | train_inner | epoch 038:    522 / 1978 loss=3.321, nll_loss=1.174, word_ins=2.982, length=3.386, ppl=9.99, wps=45980.8, ups=0.78, wpb=58709.9, bsz=1993.3, num_updates=73700, lr=0.000368355, gnorm=0.872, loss_scale=16384, train_wall=127, wall=97560
2023-01-13 18:55:35 | INFO | train_inner | epoch 038:    622 / 1978 loss=3.286, nll_loss=1.139, word_ins=2.951, length=3.357, ppl=9.76, wps=45826.1, ups=0.78, wpb=58949.1, bsz=2073.8, num_updates=73800, lr=0.000368105, gnorm=0.899, loss_scale=16384, train_wall=128, wall=97689
2023-01-13 18:57:42 | INFO | train_inner | epoch 038:    722 / 1978 loss=3.302, nll_loss=1.153, word_ins=2.963, length=3.382, ppl=9.86, wps=46483, ups=0.79, wpb=59147.6, bsz=1980.3, num_updates=73900, lr=0.000367856, gnorm=0.876, loss_scale=16384, train_wall=127, wall=97816
2023-01-13 18:59:49 | INFO | train_inner | epoch 038:    822 / 1978 loss=3.306, nll_loss=1.16, word_ins=2.969, length=3.374, ppl=9.89, wps=47038.9, ups=0.79, wpb=59693, bsz=1970.1, num_updates=74000, lr=0.000367607, gnorm=0.877, loss_scale=16384, train_wall=127, wall=97943
2023-01-13 19:01:58 | INFO | train_inner | epoch 038:    922 / 1978 loss=3.286, nll_loss=1.142, word_ins=2.953, length=3.321, ppl=9.75, wps=46003.2, ups=0.77, wpb=59456.1, bsz=2133.1, num_updates=74100, lr=0.000367359, gnorm=0.889, loss_scale=16384, train_wall=129, wall=98073
2023-01-13 19:04:06 | INFO | train_inner | epoch 038:   1022 / 1978 loss=3.281, nll_loss=1.135, word_ins=2.946, length=3.347, ppl=9.72, wps=46552.7, ups=0.78, wpb=59482.7, bsz=2053.1, num_updates=74200, lr=0.000367112, gnorm=0.896, loss_scale=16384, train_wall=128, wall=98200
2023-01-13 19:06:13 | INFO | train_inner | epoch 038:   1122 / 1978 loss=3.288, nll_loss=1.14, word_ins=2.951, length=3.363, ppl=9.77, wps=46900.9, ups=0.79, wpb=59527.3, bsz=2008.2, num_updates=74300, lr=0.000366864, gnorm=0.902, loss_scale=16384, train_wall=127, wall=98327
2023-01-13 19:08:20 | INFO | train_inner | epoch 038:   1222 / 1978 loss=3.317, nll_loss=1.164, word_ins=2.973, length=3.44, ppl=9.96, wps=46707.9, ups=0.79, wpb=59239.9, bsz=1906.7, num_updates=74400, lr=0.000366618, gnorm=0.892, loss_scale=16384, train_wall=127, wall=98454
2023-01-13 19:10:28 | INFO | train_inner | epoch 038:   1322 / 1978 loss=3.313, nll_loss=1.156, word_ins=2.966, length=3.472, ppl=9.94, wps=46502.7, ups=0.78, wpb=59411.1, bsz=1988.5, num_updates=74500, lr=0.000366372, gnorm=0.875, loss_scale=16384, train_wall=128, wall=98582
2023-01-13 19:12:35 | INFO | train_inner | epoch 038:   1422 / 1978 loss=3.293, nll_loss=1.144, word_ins=2.954, length=3.39, ppl=9.8, wps=46393.1, ups=0.78, wpb=59180.1, bsz=2000.2, num_updates=74600, lr=0.000366126, gnorm=0.884, loss_scale=16384, train_wall=127, wall=98709
2023-01-13 19:14:43 | INFO | train_inner | epoch 038:   1522 / 1978 loss=3.33, nll_loss=1.179, word_ins=2.986, length=3.438, ppl=10.06, wps=46466.9, ups=0.78, wpb=59339.7, bsz=1951.8, num_updates=74700, lr=0.000365881, gnorm=0.926, loss_scale=16384, train_wall=127, wall=98837
2023-01-13 19:16:52 | INFO | train_inner | epoch 038:   1622 / 1978 loss=3.293, nll_loss=1.142, word_ins=2.953, length=3.395, ppl=9.8, wps=46332.2, ups=0.78, wpb=59589.4, bsz=2067.8, num_updates=74800, lr=0.000365636, gnorm=0.862, loss_scale=16384, train_wall=128, wall=98966
2023-01-13 19:19:00 | INFO | train_inner | epoch 038:   1722 / 1978 loss=3.31, nll_loss=1.161, word_ins=2.971, length=3.391, ppl=9.91, wps=45861.7, ups=0.78, wpb=58870.3, bsz=1997.8, num_updates=74900, lr=0.000365392, gnorm=0.882, loss_scale=16384, train_wall=128, wall=99094
2023-01-13 19:21:07 | INFO | train_inner | epoch 038:   1822 / 1978 loss=3.293, nll_loss=1.141, word_ins=2.951, length=3.42, ppl=9.8, wps=46971, ups=0.79, wpb=59828.9, bsz=1998.6, num_updates=75000, lr=0.000365148, gnorm=0.882, loss_scale=16384, train_wall=127, wall=99221
2023-01-13 19:23:16 | INFO | train_inner | epoch 038:   1922 / 1978 loss=3.29, nll_loss=1.143, word_ins=2.953, length=3.369, ppl=9.78, wps=46297.9, ups=0.78, wpb=59512, bsz=2022.6, num_updates=75100, lr=0.000364905, gnorm=0.885, loss_scale=16384, train_wall=128, wall=99350
2023-01-13 19:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 19:24:38 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.519 | nll_loss 2.043 | word_ins 3.809 | length 7.096 | ppl 22.92 | wps 124417 | wpb 40242.5 | bsz 1500 | num_updates 75156 | best_loss 4.437
2023-01-13 19:24:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 19:25:06 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint38.pt (epoch 38 @ 75156 updates, score 4.519) (writing took 27.65594839118421 seconds)
2023-01-13 19:25:06 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-01-13 19:25:06 | INFO | train | epoch 038 | loss 3.303 | nll_loss 1.154 | word_ins 2.964 | length 3.388 | ppl 9.87 | wps 45449.4 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 75156 | lr 0.000364769 | gnorm 0.887 | loss_scale 16384 | train_wall 2524 | wall 99460
2023-01-13 19:25:06 | INFO | fairseq.trainer | begin training epoch 39
2023-01-13 19:26:14 | INFO | train_inner | epoch 039:     44 / 1978 loss=3.282, nll_loss=1.141, word_ins=2.952, length=3.301, ppl=9.73, wps=33316.4, ups=0.56, wpb=59327.6, bsz=2041.3, num_updates=75200, lr=0.000364662, gnorm=0.912, loss_scale=16384, train_wall=128, wall=99528
2023-01-13 19:28:21 | INFO | train_inner | epoch 039:    144 / 1978 loss=3.312, nll_loss=1.16, word_ins=2.97, length=3.428, ppl=9.93, wps=46482.5, ups=0.79, wpb=58885.4, bsz=1930.9, num_updates=75300, lr=0.00036442, gnorm=0.892, loss_scale=16384, train_wall=126, wall=99655
2023-01-13 19:30:28 | INFO | train_inner | epoch 039:    244 / 1978 loss=3.311, nll_loss=1.161, word_ins=2.971, length=3.408, ppl=9.93, wps=46912.8, ups=0.79, wpb=59734, bsz=1895.8, num_updates=75400, lr=0.000364179, gnorm=0.898, loss_scale=16384, train_wall=127, wall=99782
2023-01-13 19:32:37 | INFO | train_inner | epoch 039:    344 / 1978 loss=3.289, nll_loss=1.145, word_ins=2.956, length=3.331, ppl=9.77, wps=45623, ups=0.77, wpb=58962.1, bsz=2082.6, num_updates=75500, lr=0.000363937, gnorm=0.869, loss_scale=16384, train_wall=129, wall=99911
2023-01-13 19:34:45 | INFO | train_inner | epoch 039:    444 / 1978 loss=3.309, nll_loss=1.159, word_ins=2.968, length=3.41, ppl=9.91, wps=46606.7, ups=0.78, wpb=59413.4, bsz=1927.8, num_updates=75600, lr=0.000363696, gnorm=0.895, loss_scale=16384, train_wall=127, wall=100039
2023-01-13 19:36:52 | INFO | train_inner | epoch 039:    544 / 1978 loss=3.268, nll_loss=1.121, word_ins=2.934, length=3.349, ppl=9.64, wps=46833.9, ups=0.78, wpb=59769.3, bsz=2019.4, num_updates=75700, lr=0.000363456, gnorm=0.907, loss_scale=16384, train_wall=127, wall=100166
2023-01-13 19:38:59 | INFO | train_inner | epoch 039:    644 / 1978 loss=3.297, nll_loss=1.146, word_ins=2.957, length=3.405, ppl=9.83, wps=46840.3, ups=0.79, wpb=59269.1, bsz=1900.1, num_updates=75800, lr=0.000363216, gnorm=0.882, loss_scale=16384, train_wall=126, wall=100293
2023-01-13 19:41:07 | INFO | train_inner | epoch 039:    744 / 1978 loss=3.305, nll_loss=1.159, word_ins=2.968, length=3.369, ppl=9.88, wps=46191, ups=0.78, wpb=58989.1, bsz=1973.3, num_updates=75900, lr=0.000362977, gnorm=0.9, loss_scale=16384, train_wall=127, wall=100421
2023-01-13 19:43:15 | INFO | train_inner | epoch 039:    844 / 1978 loss=3.3, nll_loss=1.154, word_ins=2.964, length=3.367, ppl=9.85, wps=46229.5, ups=0.78, wpb=59418.2, bsz=2005, num_updates=76000, lr=0.000362738, gnorm=0.873, loss_scale=16384, train_wall=128, wall=100549
2023-01-13 19:45:23 | INFO | train_inner | epoch 039:    944 / 1978 loss=3.292, nll_loss=1.143, word_ins=2.954, length=3.383, ppl=9.8, wps=46261.5, ups=0.78, wpb=58979.2, bsz=2019.8, num_updates=76100, lr=0.0003625, gnorm=0.876, loss_scale=16384, train_wall=127, wall=100677
2023-01-13 19:47:30 | INFO | train_inner | epoch 039:   1044 / 1978 loss=3.297, nll_loss=1.154, word_ins=2.963, length=3.335, ppl=9.83, wps=46609.1, ups=0.78, wpb=59567.6, bsz=2008.4, num_updates=76200, lr=0.000362262, gnorm=0.912, loss_scale=16384, train_wall=128, wall=100805
2023-01-13 19:49:38 | INFO | train_inner | epoch 039:   1144 / 1978 loss=3.32, nll_loss=1.169, word_ins=2.976, length=3.436, ppl=9.99, wps=46315.2, ups=0.78, wpb=59070, bsz=2003.6, num_updates=76300, lr=0.000362024, gnorm=0.878, loss_scale=16384, train_wall=127, wall=100932
2023-01-13 19:51:47 | INFO | train_inner | epoch 039:   1244 / 1978 loss=3.243, nll_loss=1.097, word_ins=2.912, length=3.307, ppl=9.47, wps=46420.4, ups=0.77, wpb=59991.4, bsz=2137.5, num_updates=76400, lr=0.000361787, gnorm=0.874, loss_scale=16384, train_wall=129, wall=101061
2023-01-13 19:53:56 | INFO | train_inner | epoch 039:   1344 / 1978 loss=3.298, nll_loss=1.153, word_ins=2.962, length=3.358, ppl=9.84, wps=45809.4, ups=0.78, wpb=58989.1, bsz=2028.2, num_updates=76500, lr=0.000361551, gnorm=0.901, loss_scale=16384, train_wall=129, wall=101190
2023-01-13 19:56:03 | INFO | train_inner | epoch 039:   1444 / 1978 loss=3.262, nll_loss=1.113, word_ins=2.926, length=3.361, ppl=9.59, wps=46961.1, ups=0.79, wpb=59716.8, bsz=2008.1, num_updates=76600, lr=0.000361315, gnorm=0.862, loss_scale=16384, train_wall=127, wall=101317
2023-01-13 19:58:12 | INFO | train_inner | epoch 039:   1544 / 1978 loss=3.273, nll_loss=1.129, word_ins=2.941, length=3.325, ppl=9.67, wps=46206.8, ups=0.77, wpb=59695.4, bsz=2089, num_updates=76700, lr=0.000361079, gnorm=0.897, loss_scale=16384, train_wall=129, wall=101446
2023-01-13 20:00:20 | INFO | train_inner | epoch 039:   1644 / 1978 loss=3.296, nll_loss=1.146, word_ins=2.957, length=3.39, ppl=9.82, wps=45985.7, ups=0.79, wpb=58528.5, bsz=1970, num_updates=76800, lr=0.000360844, gnorm=0.904, loss_scale=16384, train_wall=127, wall=101574
2023-01-13 20:02:27 | INFO | train_inner | epoch 039:   1744 / 1978 loss=3.313, nll_loss=1.167, word_ins=2.974, length=3.388, ppl=9.94, wps=46355.2, ups=0.79, wpb=59049, bsz=1967, num_updates=76900, lr=0.000360609, gnorm=0.879, loss_scale=16384, train_wall=127, wall=101701
2023-01-13 20:04:36 | INFO | train_inner | epoch 039:   1844 / 1978 loss=3.261, nll_loss=1.116, word_ins=2.929, length=3.325, ppl=9.59, wps=46141.7, ups=0.78, wpb=59267.1, bsz=2061.1, num_updates=77000, lr=0.000360375, gnorm=0.878, loss_scale=16384, train_wall=128, wall=101830
2023-01-13 20:06:43 | INFO | train_inner | epoch 039:   1944 / 1978 loss=3.321, nll_loss=1.171, word_ins=2.978, length=3.431, ppl=9.99, wps=45887.8, ups=0.78, wpb=58649.8, bsz=2008.4, num_updates=77100, lr=0.000360141, gnorm=0.929, loss_scale=16384, train_wall=128, wall=101957
2023-01-13 20:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 20:07:39 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 4.443 | nll_loss 2.023 | word_ins 3.795 | length 6.477 | ppl 21.75 | wps 113863 | wpb 40242.5 | bsz 1500 | num_updates 77134 | best_loss 4.437
2023-01-13 20:07:39 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 20:08:07 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint39.pt (epoch 39 @ 77134 updates, score 4.443) (writing took 28.710382582619786 seconds)
2023-01-13 20:08:07 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-01-13 20:08:07 | INFO | train | epoch 039 | loss 3.292 | nll_loss 1.144 | word_ins 2.955 | length 3.368 | ppl 9.79 | wps 45426.7 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 77134 | lr 0.000360062 | gnorm 0.89 | loss_scale 16384 | train_wall 2525 | wall 102041
2023-01-13 20:08:07 | INFO | fairseq.trainer | begin training epoch 40
2023-01-13 20:09:43 | INFO | train_inner | epoch 040:     66 / 1978 loss=3.29, nll_loss=1.142, word_ins=2.952, length=3.386, ppl=9.78, wps=33241.5, ups=0.56, wpb=59821, bsz=1917.5, num_updates=77200, lr=0.000359908, gnorm=0.889, loss_scale=32768, train_wall=127, wall=102137
2023-01-13 20:11:52 | INFO | train_inner | epoch 040:    166 / 1978 loss=3.243, nll_loss=1.104, word_ins=2.919, length=3.24, ppl=9.47, wps=46236.7, ups=0.78, wpb=59468.7, bsz=2093.5, num_updates=77300, lr=0.000359675, gnorm=0.89, loss_scale=32768, train_wall=128, wall=102266
2023-01-13 20:14:00 | INFO | train_inner | epoch 040:    266 / 1978 loss=3.256, nll_loss=1.101, word_ins=2.916, length=3.395, ppl=9.55, wps=46572.1, ups=0.78, wpb=59759.6, bsz=2051.7, num_updates=77400, lr=0.000359443, gnorm=0.904, loss_scale=32768, train_wall=128, wall=102394
2023-01-13 20:14:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 20:16:09 | INFO | train_inner | epoch 040:    367 / 1978 loss=3.271, nll_loss=1.125, word_ins=2.937, length=3.341, ppl=9.66, wps=45705.5, ups=0.77, wpb=58980, bsz=1989.4, num_updates=77500, lr=0.000359211, gnorm=0.891, loss_scale=16384, train_wall=129, wall=102523
2023-01-13 20:18:17 | INFO | train_inner | epoch 040:    467 / 1978 loss=3.295, nll_loss=1.144, word_ins=2.955, length=3.409, ppl=9.82, wps=46256.6, ups=0.78, wpb=59068.3, bsz=1961.2, num_updates=77600, lr=0.000358979, gnorm=0.904, loss_scale=16384, train_wall=127, wall=102651
2023-01-13 20:20:25 | INFO | train_inner | epoch 040:    567 / 1978 loss=3.279, nll_loss=1.132, word_ins=2.943, length=3.352, ppl=9.7, wps=46193.1, ups=0.78, wpb=59347.6, bsz=2001, num_updates=77700, lr=0.000358748, gnorm=0.904, loss_scale=16384, train_wall=128, wall=102780
2023-01-13 20:22:33 | INFO | train_inner | epoch 040:    667 / 1978 loss=3.265, nll_loss=1.122, word_ins=2.934, length=3.31, ppl=9.61, wps=46501.5, ups=0.79, wpb=59178.1, bsz=2032.3, num_updates=77800, lr=0.000358517, gnorm=0.88, loss_scale=16384, train_wall=127, wall=102907
2023-01-13 20:24:41 | INFO | train_inner | epoch 040:    767 / 1978 loss=3.279, nll_loss=1.13, word_ins=2.942, length=3.362, ppl=9.7, wps=46218, ups=0.78, wpb=59059, bsz=2037, num_updates=77900, lr=0.000358287, gnorm=0.87, loss_scale=16384, train_wall=128, wall=103035
2023-01-13 20:26:49 | INFO | train_inner | epoch 040:    867 / 1978 loss=3.304, nll_loss=1.153, word_ins=2.962, length=3.417, ppl=9.88, wps=46406.2, ups=0.78, wpb=59525.8, bsz=1990, num_updates=78000, lr=0.000358057, gnorm=0.876, loss_scale=16384, train_wall=128, wall=103163
2023-01-13 20:28:57 | INFO | train_inner | epoch 040:    967 / 1978 loss=3.28, nll_loss=1.133, word_ins=2.944, length=3.36, ppl=9.71, wps=46340.2, ups=0.78, wpb=59448.6, bsz=1964.3, num_updates=78100, lr=0.000357828, gnorm=0.883, loss_scale=16384, train_wall=128, wall=103291
2023-01-13 20:31:04 | INFO | train_inner | epoch 040:   1067 / 1978 loss=3.307, nll_loss=1.158, word_ins=2.967, length=3.397, ppl=9.9, wps=46246.3, ups=0.79, wpb=58726.4, bsz=1943.4, num_updates=78200, lr=0.000357599, gnorm=0.891, loss_scale=16384, train_wall=127, wall=103418
2023-01-13 20:33:11 | INFO | train_inner | epoch 040:   1167 / 1978 loss=3.292, nll_loss=1.143, word_ins=2.953, length=3.395, ppl=9.8, wps=46517.4, ups=0.79, wpb=59168, bsz=1980.3, num_updates=78300, lr=0.000357371, gnorm=0.894, loss_scale=16384, train_wall=127, wall=103545
2023-01-13 20:35:20 | INFO | train_inner | epoch 040:   1267 / 1978 loss=3.296, nll_loss=1.149, word_ins=2.959, length=3.378, ppl=9.83, wps=46561, ups=0.78, wpb=59780.3, bsz=1944.6, num_updates=78400, lr=0.000357143, gnorm=0.896, loss_scale=16384, train_wall=128, wall=103674
2023-01-13 20:37:28 | INFO | train_inner | epoch 040:   1367 / 1978 loss=3.27, nll_loss=1.126, word_ins=2.938, length=3.321, ppl=9.65, wps=46402.2, ups=0.78, wpb=59602.7, bsz=1998.3, num_updates=78500, lr=0.000356915, gnorm=0.907, loss_scale=16384, train_wall=128, wall=103802
2023-01-13 20:39:38 | INFO | train_inner | epoch 040:   1467 / 1978 loss=3.27, nll_loss=1.122, word_ins=2.934, length=3.36, ppl=9.65, wps=45409.9, ups=0.77, wpb=59064.1, bsz=2005.7, num_updates=78600, lr=0.000356688, gnorm=0.888, loss_scale=16384, train_wall=130, wall=103932
2023-01-13 20:41:45 | INFO | train_inner | epoch 040:   1567 / 1978 loss=3.312, nll_loss=1.161, word_ins=2.97, length=3.419, ppl=9.93, wps=46621.4, ups=0.79, wpb=59209, bsz=1969.2, num_updates=78700, lr=0.000356462, gnorm=0.892, loss_scale=16384, train_wall=127, wall=104059
2023-01-13 20:43:53 | INFO | train_inner | epoch 040:   1667 / 1978 loss=3.279, nll_loss=1.133, word_ins=2.944, length=3.355, ppl=9.71, wps=46484.5, ups=0.78, wpb=59442.5, bsz=2051.8, num_updates=78800, lr=0.000356235, gnorm=0.875, loss_scale=16384, train_wall=128, wall=104187
2023-01-13 20:46:00 | INFO | train_inner | epoch 040:   1767 / 1978 loss=3.301, nll_loss=1.149, word_ins=2.959, length=3.428, ppl=9.86, wps=46490.3, ups=0.79, wpb=59030.5, bsz=2004.3, num_updates=78900, lr=0.000356009, gnorm=0.925, loss_scale=16384, train_wall=127, wall=104314
2023-01-13 20:48:07 | INFO | train_inner | epoch 040:   1867 / 1978 loss=3.281, nll_loss=1.139, word_ins=2.949, length=3.322, ppl=9.72, wps=46547.6, ups=0.79, wpb=59242.5, bsz=2014.9, num_updates=79000, lr=0.000355784, gnorm=0.891, loss_scale=16384, train_wall=127, wall=104441
2023-01-13 20:50:16 | INFO | train_inner | epoch 040:   1967 / 1978 loss=3.249, nll_loss=1.107, word_ins=2.92, length=3.291, ppl=9.51, wps=46030.2, ups=0.78, wpb=59155.2, bsz=2097.6, num_updates=79100, lr=0.000355559, gnorm=0.873, loss_scale=16384, train_wall=128, wall=104570
2023-01-13 20:50:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 20:50:41 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.571 | nll_loss 2.057 | word_ins 3.826 | length 7.452 | ppl 23.77 | wps 109242 | wpb 40242.5 | bsz 1500 | num_updates 79111 | best_loss 4.437
2023-01-13 20:50:41 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 20:51:10 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint40.pt (epoch 40 @ 79111 updates, score 4.571) (writing took 28.519507483113557 seconds)
2023-01-13 20:51:10 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-01-13 20:51:10 | INFO | train | epoch 040 | loss 3.281 | nll_loss 1.134 | word_ins 2.945 | length 3.363 | ppl 9.72 | wps 45382.4 | ups 0.77 | wpb 59283 | bsz 2002.6 | num_updates 79111 | lr 0.000355534 | gnorm 0.892 | loss_scale 16384 | train_wall 2526 | wall 104624
2023-01-13 20:51:10 | INFO | fairseq.trainer | begin training epoch 41
2023-01-13 20:53:16 | INFO | train_inner | epoch 041:     89 / 1978 loss=3.253, nll_loss=1.105, word_ins=2.919, length=3.344, ppl=9.54, wps=33044.7, ups=0.56, wpb=59516.7, bsz=2017.2, num_updates=79200, lr=0.000355335, gnorm=0.889, loss_scale=16384, train_wall=128, wall=104750
2023-01-13 20:55:24 | INFO | train_inner | epoch 041:    189 / 1978 loss=3.268, nll_loss=1.122, word_ins=2.935, length=3.329, ppl=9.63, wps=46274.1, ups=0.78, wpb=59192.4, bsz=2001.4, num_updates=79300, lr=0.00035511, gnorm=0.88, loss_scale=16384, train_wall=128, wall=104878
2023-01-13 20:57:34 | INFO | train_inner | epoch 041:    289 / 1978 loss=3.254, nll_loss=1.116, word_ins=2.929, length=3.248, ppl=9.54, wps=46391, ups=0.77, wpb=60186.7, bsz=2101.8, num_updates=79400, lr=0.000354887, gnorm=0.901, loss_scale=16384, train_wall=130, wall=105008
2023-01-13 20:59:41 | INFO | train_inner | epoch 041:    389 / 1978 loss=3.263, nll_loss=1.117, word_ins=2.929, length=3.333, ppl=9.6, wps=46607.7, ups=0.79, wpb=59304.6, bsz=2009.7, num_updates=79500, lr=0.000354663, gnorm=0.885, loss_scale=16384, train_wall=127, wall=105135
2023-01-13 21:01:50 | INFO | train_inner | epoch 041:    489 / 1978 loss=3.234, nll_loss=1.09, word_ins=2.905, length=3.294, ppl=9.41, wps=46423.6, ups=0.78, wpb=59756.2, bsz=2063.4, num_updates=79600, lr=0.000354441, gnorm=0.89, loss_scale=16384, train_wall=128, wall=105264
2023-01-13 21:03:58 | INFO | train_inner | epoch 041:    589 / 1978 loss=3.272, nll_loss=1.125, word_ins=2.937, length=3.352, ppl=9.66, wps=45999.6, ups=0.78, wpb=58893.5, bsz=2051.6, num_updates=79700, lr=0.000354218, gnorm=0.886, loss_scale=16384, train_wall=128, wall=105392
2023-01-13 21:06:05 | INFO | train_inner | epoch 041:    689 / 1978 loss=3.303, nll_loss=1.156, word_ins=2.965, length=3.379, ppl=9.87, wps=46342.2, ups=0.79, wpb=58893.9, bsz=1926.5, num_updates=79800, lr=0.000353996, gnorm=0.903, loss_scale=16384, train_wall=127, wall=105519
2023-01-13 21:08:12 | INFO | train_inner | epoch 041:    789 / 1978 loss=3.3, nll_loss=1.147, word_ins=2.956, length=3.436, ppl=9.85, wps=46695.5, ups=0.79, wpb=59209, bsz=1923.3, num_updates=79900, lr=0.000353775, gnorm=0.884, loss_scale=16384, train_wall=127, wall=105646
2023-01-13 21:10:21 | INFO | train_inner | epoch 041:    889 / 1978 loss=3.244, nll_loss=1.101, word_ins=2.914, length=3.294, ppl=9.47, wps=45887.5, ups=0.77, wpb=59319.9, bsz=2105.2, num_updates=80000, lr=0.000353553, gnorm=0.887, loss_scale=16384, train_wall=129, wall=105775
2023-01-13 21:12:28 | INFO | train_inner | epoch 041:    989 / 1978 loss=3.26, nll_loss=1.116, word_ins=2.929, length=3.309, ppl=9.58, wps=46592.7, ups=0.78, wpb=59402.3, bsz=1980.2, num_updates=80100, lr=0.000353333, gnorm=0.911, loss_scale=16384, train_wall=127, wall=105902
2023-01-13 21:14:35 | INFO | train_inner | epoch 041:   1089 / 1978 loss=3.279, nll_loss=1.135, word_ins=2.945, length=3.343, ppl=9.71, wps=46873.7, ups=0.79, wpb=59561.9, bsz=1983.4, num_updates=80200, lr=0.000353112, gnorm=0.882, loss_scale=16384, train_wall=127, wall=106030
2023-01-13 21:16:42 | INFO | train_inner | epoch 041:   1189 / 1978 loss=3.306, nll_loss=1.149, word_ins=2.959, length=3.472, ppl=9.89, wps=46662.8, ups=0.79, wpb=59059.1, bsz=1904.1, num_updates=80300, lr=0.000352892, gnorm=0.904, loss_scale=16384, train_wall=126, wall=106156
2023-01-13 21:18:50 | INFO | train_inner | epoch 041:   1289 / 1978 loss=3.272, nll_loss=1.123, word_ins=2.935, length=3.369, ppl=9.66, wps=46610.6, ups=0.78, wpb=59446.7, bsz=1947.1, num_updates=80400, lr=0.000352673, gnorm=0.904, loss_scale=16384, train_wall=127, wall=106284
2023-01-13 21:20:58 | INFO | train_inner | epoch 041:   1389 / 1978 loss=3.272, nll_loss=1.127, word_ins=2.938, length=3.34, ppl=9.66, wps=46643.8, ups=0.78, wpb=59761.6, bsz=1975.5, num_updates=80500, lr=0.000352454, gnorm=0.893, loss_scale=16384, train_wall=128, wall=106412
2023-01-13 21:23:08 | INFO | train_inner | epoch 041:   1489 / 1978 loss=3.241, nll_loss=1.104, word_ins=2.918, length=3.238, ppl=9.46, wps=45296.2, ups=0.77, wpb=59074.7, bsz=2113, num_updates=80600, lr=0.000352235, gnorm=0.895, loss_scale=16384, train_wall=130, wall=106542
2023-01-13 21:25:16 | INFO | train_inner | epoch 041:   1589 / 1978 loss=3.259, nll_loss=1.115, word_ins=2.928, length=3.307, ppl=9.57, wps=46171.2, ups=0.78, wpb=59235.7, bsz=2067, num_updates=80700, lr=0.000352017, gnorm=0.895, loss_scale=16384, train_wall=128, wall=106670
2023-01-13 21:27:23 | INFO | train_inner | epoch 041:   1689 / 1978 loss=3.296, nll_loss=1.144, word_ins=2.954, length=3.415, ppl=9.82, wps=46133.1, ups=0.79, wpb=58474.3, bsz=1961.8, num_updates=80800, lr=0.000351799, gnorm=0.902, loss_scale=16384, train_wall=127, wall=106797
2023-01-13 21:29:31 | INFO | train_inner | epoch 041:   1789 / 1978 loss=3.255, nll_loss=1.105, word_ins=2.918, length=3.375, ppl=9.55, wps=46582.4, ups=0.79, wpb=59336.6, bsz=1985, num_updates=80900, lr=0.000351581, gnorm=0.89, loss_scale=16384, train_wall=127, wall=106925
2023-01-13 21:31:38 | INFO | train_inner | epoch 041:   1889 / 1978 loss=3.289, nll_loss=1.144, word_ins=2.954, length=3.355, ppl=9.78, wps=46445.9, ups=0.79, wpb=59160.4, bsz=1968.9, num_updates=81000, lr=0.000351364, gnorm=0.908, loss_scale=16384, train_wall=127, wall=107052
2023-01-13 21:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 21:33:44 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 4.544 | nll_loss 2.039 | word_ins 3.812 | length 7.325 | ppl 23.33 | wps 140995 | wpb 40242.5 | bsz 1500 | num_updates 81089 | best_loss 4.437
2023-01-13 21:33:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 21:34:12 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint41.pt (epoch 41 @ 81089 updates, score 4.544) (writing took 28.50534991081804 seconds)
2023-01-13 21:34:12 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-01-13 21:34:12 | INFO | train | epoch 041 | loss 3.27 | nll_loss 1.124 | word_ins 2.936 | length 3.346 | ppl 9.65 | wps 45411.1 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 81089 | lr 0.000351171 | gnorm 0.894 | loss_scale 16384 | train_wall 2526 | wall 107206
2023-01-13 21:34:12 | INFO | fairseq.trainer | begin training epoch 42
2023-01-13 21:34:38 | INFO | train_inner | epoch 042:     11 / 1978 loss=3.294, nll_loss=1.145, word_ins=2.954, length=3.395, ppl=9.81, wps=32655.6, ups=0.56, wpb=58791, bsz=1927.6, num_updates=81100, lr=0.000351147, gnorm=0.896, loss_scale=16384, train_wall=128, wall=107232
2023-01-13 21:36:47 | INFO | train_inner | epoch 042:    111 / 1978 loss=3.228, nll_loss=1.086, word_ins=2.901, length=3.272, ppl=9.37, wps=46489.8, ups=0.78, wpb=59925.9, bsz=2071, num_updates=81200, lr=0.000350931, gnorm=0.908, loss_scale=16384, train_wall=129, wall=107361
2023-01-13 21:38:55 | INFO | train_inner | epoch 042:    211 / 1978 loss=3.268, nll_loss=1.12, word_ins=2.932, length=3.361, ppl=9.64, wps=46147.2, ups=0.78, wpb=58973.4, bsz=2009.8, num_updates=81300, lr=0.000350715, gnorm=0.9, loss_scale=16384, train_wall=128, wall=107489
2023-01-13 21:41:03 | INFO | train_inner | epoch 042:    311 / 1978 loss=3.199, nll_loss=1.061, word_ins=2.878, length=3.205, ppl=9.18, wps=46439, ups=0.78, wpb=59635.3, bsz=2130, num_updates=81400, lr=0.0003505, gnorm=0.871, loss_scale=16384, train_wall=128, wall=107617
2023-01-13 21:43:11 | INFO | train_inner | epoch 042:    411 / 1978 loss=3.31, nll_loss=1.161, word_ins=2.969, length=3.412, ppl=9.92, wps=46363.5, ups=0.78, wpb=59295.5, bsz=1893, num_updates=81500, lr=0.000350285, gnorm=0.92, loss_scale=16384, train_wall=128, wall=107745
2023-01-13 21:43:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 21:45:19 | INFO | train_inner | epoch 042:    512 / 1978 loss=3.28, nll_loss=1.134, word_ins=2.945, length=3.348, ppl=9.71, wps=46329, ups=0.78, wpb=59254.3, bsz=1928.1, num_updates=81600, lr=0.00035007, gnorm=0.923, loss_scale=16384, train_wall=128, wall=107873
2023-01-13 21:47:27 | INFO | train_inner | epoch 042:    612 / 1978 loss=3.247, nll_loss=1.102, word_ins=2.915, length=3.321, ppl=9.5, wps=46823.9, ups=0.78, wpb=60033.6, bsz=1981.9, num_updates=81700, lr=0.000349856, gnorm=0.921, loss_scale=16384, train_wall=128, wall=108001
2023-01-13 21:49:35 | INFO | train_inner | epoch 042:    712 / 1978 loss=3.267, nll_loss=1.123, word_ins=2.935, length=3.317, ppl=9.62, wps=46517.8, ups=0.78, wpb=59590.4, bsz=1996.4, num_updates=81800, lr=0.000349642, gnorm=0.913, loss_scale=16384, train_wall=128, wall=108129
2023-01-13 21:51:43 | INFO | train_inner | epoch 042:    812 / 1978 loss=3.254, nll_loss=1.108, word_ins=2.921, length=3.333, ppl=9.54, wps=46187.2, ups=0.78, wpb=59009.5, bsz=1973.8, num_updates=81900, lr=0.000349428, gnorm=0.878, loss_scale=16384, train_wall=128, wall=108257
2023-01-13 21:53:51 | INFO | train_inner | epoch 042:    912 / 1978 loss=3.246, nll_loss=1.103, word_ins=2.917, length=3.293, ppl=9.49, wps=46357.4, ups=0.78, wpb=59251.5, bsz=2100.4, num_updates=82000, lr=0.000349215, gnorm=0.894, loss_scale=16384, train_wall=128, wall=108385
2023-01-13 21:55:59 | INFO | train_inner | epoch 042:   1012 / 1978 loss=3.281, nll_loss=1.129, word_ins=2.941, length=3.406, ppl=9.72, wps=46013.5, ups=0.78, wpb=58902.4, bsz=1972.1, num_updates=82100, lr=0.000349002, gnorm=0.913, loss_scale=16384, train_wall=128, wall=108513
2023-01-13 21:58:07 | INFO | train_inner | epoch 042:   1112 / 1978 loss=3.265, nll_loss=1.113, word_ins=2.926, length=3.39, ppl=9.61, wps=46102.3, ups=0.78, wpb=59133.3, bsz=2007.9, num_updates=82200, lr=0.00034879, gnorm=0.89, loss_scale=16384, train_wall=128, wall=108641
2023-01-13 22:00:15 | INFO | train_inner | epoch 042:   1212 / 1978 loss=3.261, nll_loss=1.113, word_ins=2.925, length=3.36, ppl=9.59, wps=46066.4, ups=0.78, wpb=58924.4, bsz=1964.3, num_updates=82300, lr=0.000348578, gnorm=0.9, loss_scale=16384, train_wall=128, wall=108769
2023-01-13 22:02:24 | INFO | train_inner | epoch 042:   1312 / 1978 loss=3.247, nll_loss=1.105, word_ins=2.918, length=3.284, ppl=9.49, wps=46156.4, ups=0.78, wpb=59538.7, bsz=2003.4, num_updates=82400, lr=0.000348367, gnorm=0.91, loss_scale=16384, train_wall=129, wall=108898
2023-01-13 22:04:33 | INFO | train_inner | epoch 042:   1412 / 1978 loss=3.235, nll_loss=1.096, word_ins=2.91, length=3.245, ppl=9.41, wps=45910.3, ups=0.77, wpb=59288.1, bsz=2164.6, num_updates=82500, lr=0.000348155, gnorm=0.906, loss_scale=16384, train_wall=129, wall=109027
2023-01-13 22:06:40 | INFO | train_inner | epoch 042:   1512 / 1978 loss=3.281, nll_loss=1.134, word_ins=2.944, length=3.374, ppl=9.72, wps=46605.7, ups=0.79, wpb=59029.2, bsz=1915.2, num_updates=82600, lr=0.000347945, gnorm=0.902, loss_scale=16384, train_wall=126, wall=109154
2023-01-13 22:08:47 | INFO | train_inner | epoch 042:   1612 / 1978 loss=3.258, nll_loss=1.111, word_ins=2.923, length=3.355, ppl=9.57, wps=46470.9, ups=0.78, wpb=59330.8, bsz=2014.8, num_updates=82700, lr=0.000347734, gnorm=0.914, loss_scale=16384, train_wall=127, wall=109282
2023-01-13 22:10:55 | INFO | train_inner | epoch 042:   1712 / 1978 loss=3.252, nll_loss=1.105, word_ins=2.918, length=3.338, ppl=9.53, wps=46672.9, ups=0.78, wpb=59649.4, bsz=1963.9, num_updates=82800, lr=0.000347524, gnorm=0.901, loss_scale=16384, train_wall=128, wall=109409
2023-01-13 22:13:02 | INFO | train_inner | epoch 042:   1812 / 1978 loss=3.296, nll_loss=1.148, word_ins=2.957, length=3.39, ppl=9.82, wps=46571, ups=0.79, wpb=59199.1, bsz=1978.3, num_updates=82900, lr=0.000347314, gnorm=0.9, loss_scale=16384, train_wall=127, wall=109536
2023-01-13 22:15:10 | INFO | train_inner | epoch 042:   1912 / 1978 loss=3.293, nll_loss=1.143, word_ins=2.953, length=3.395, ppl=9.8, wps=45952.6, ups=0.78, wpb=58742, bsz=2006.6, num_updates=83000, lr=0.000347105, gnorm=0.898, loss_scale=16384, train_wall=128, wall=109664
2023-01-13 22:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 22:16:48 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 4.536 | nll_loss 2.038 | word_ins 3.807 | length 7.287 | ppl 23.2 | wps 132278 | wpb 40242.5 | bsz 1500 | num_updates 83066 | best_loss 4.437
2023-01-13 22:16:48 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 22:17:17 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint42.pt (epoch 42 @ 83066 updates, score 4.536) (writing took 29.67060362873599 seconds)
2023-01-13 22:17:17 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-01-13 22:17:17 | INFO | train | epoch 042 | loss 3.262 | nll_loss 1.116 | word_ins 2.929 | length 3.338 | ppl 9.6 | wps 45338.9 | ups 0.76 | wpb 59284.4 | bsz 2002.9 | num_updates 83066 | lr 0.000346967 | gnorm 0.904 | loss_scale 16384 | train_wall 2526 | wall 109791
2023-01-13 22:17:17 | INFO | fairseq.trainer | begin training epoch 43
2023-01-13 22:18:13 | INFO | train_inner | epoch 043:     34 / 1978 loss=3.273, nll_loss=1.125, word_ins=2.936, length=3.366, ppl=9.66, wps=32044.5, ups=0.55, wpb=58693.3, bsz=1977.1, num_updates=83100, lr=0.000346896, gnorm=0.913, loss_scale=16384, train_wall=128, wall=109848
2023-01-13 22:20:21 | INFO | train_inner | epoch 043:    134 / 1978 loss=3.232, nll_loss=1.087, word_ins=2.902, length=3.299, ppl=9.4, wps=46421, ups=0.78, wpb=59410.5, bsz=2012.4, num_updates=83200, lr=0.000346688, gnorm=0.909, loss_scale=16384, train_wall=128, wall=109975
2023-01-13 22:22:29 | INFO | train_inner | epoch 043:    234 / 1978 loss=3.251, nll_loss=1.107, word_ins=2.92, length=3.304, ppl=9.52, wps=46497.2, ups=0.78, wpb=59515.4, bsz=2000.9, num_updates=83300, lr=0.000346479, gnorm=0.918, loss_scale=16384, train_wall=128, wall=110103
2023-01-13 22:24:36 | INFO | train_inner | epoch 043:    334 / 1978 loss=3.269, nll_loss=1.118, word_ins=2.931, length=3.379, ppl=9.64, wps=46496.1, ups=0.79, wpb=59084.8, bsz=1889.9, num_updates=83400, lr=0.000346272, gnorm=0.912, loss_scale=16384, train_wall=127, wall=110231
2023-01-13 22:26:43 | INFO | train_inner | epoch 043:    434 / 1978 loss=3.258, nll_loss=1.106, word_ins=2.92, length=3.379, ppl=9.56, wps=46685, ups=0.79, wpb=59250.6, bsz=1943.8, num_updates=83500, lr=0.000346064, gnorm=0.924, loss_scale=16384, train_wall=127, wall=110358
2023-01-13 22:28:52 | INFO | train_inner | epoch 043:    534 / 1978 loss=3.254, nll_loss=1.109, word_ins=2.922, length=3.32, ppl=9.54, wps=46282, ups=0.78, wpb=59454.7, bsz=2038.2, num_updates=83600, lr=0.000345857, gnorm=0.893, loss_scale=16384, train_wall=128, wall=110486
2023-01-13 22:31:00 | INFO | train_inner | epoch 043:    634 / 1978 loss=3.238, nll_loss=1.093, word_ins=2.907, length=3.305, ppl=9.43, wps=46506.6, ups=0.78, wpb=59558.3, bsz=2020.6, num_updates=83700, lr=0.000345651, gnorm=0.902, loss_scale=16384, train_wall=128, wall=110614
2023-01-13 22:33:08 | INFO | train_inner | epoch 043:    734 / 1978 loss=3.239, nll_loss=1.091, word_ins=2.905, length=3.34, ppl=9.44, wps=46510.1, ups=0.78, wpb=59363.9, bsz=2005.8, num_updates=83800, lr=0.000345444, gnorm=0.894, loss_scale=16384, train_wall=127, wall=110742
2023-01-13 22:35:15 | INFO | train_inner | epoch 043:    834 / 1978 loss=3.256, nll_loss=1.102, word_ins=2.916, length=3.404, ppl=9.55, wps=46412, ups=0.78, wpb=59131.6, bsz=1952.6, num_updates=83900, lr=0.000345238, gnorm=0.918, loss_scale=16384, train_wall=127, wall=110869
2023-01-13 22:37:23 | INFO | train_inner | epoch 043:    934 / 1978 loss=3.27, nll_loss=1.125, word_ins=2.936, length=3.346, ppl=9.65, wps=46388.7, ups=0.78, wpb=59364.5, bsz=1992.6, num_updates=84000, lr=0.000345033, gnorm=0.908, loss_scale=16384, train_wall=128, wall=110997
2023-01-13 22:39:31 | INFO | train_inner | epoch 043:   1034 / 1978 loss=3.259, nll_loss=1.107, word_ins=2.92, length=3.386, ppl=9.57, wps=46207.5, ups=0.78, wpb=59058.5, bsz=1991.8, num_updates=84100, lr=0.000344828, gnorm=0.911, loss_scale=16384, train_wall=128, wall=111125
2023-01-13 22:41:39 | INFO | train_inner | epoch 043:   1134 / 1978 loss=3.257, nll_loss=1.114, word_ins=2.926, length=3.31, ppl=9.56, wps=46271.9, ups=0.78, wpb=59541.9, bsz=2041.3, num_updates=84200, lr=0.000344623, gnorm=0.908, loss_scale=16384, train_wall=128, wall=111254
2023-01-13 22:43:48 | INFO | train_inner | epoch 043:   1234 / 1978 loss=3.265, nll_loss=1.117, word_ins=2.928, length=3.369, ppl=9.61, wps=46324.3, ups=0.78, wpb=59488.2, bsz=1976.2, num_updates=84300, lr=0.000344418, gnorm=0.929, loss_scale=16384, train_wall=128, wall=111382
2023-01-13 22:45:56 | INFO | train_inner | epoch 043:   1334 / 1978 loss=3.248, nll_loss=1.102, word_ins=2.914, length=3.335, ppl=9.5, wps=46361.5, ups=0.78, wpb=59391, bsz=1990.8, num_updates=84400, lr=0.000344214, gnorm=0.897, loss_scale=16384, train_wall=128, wall=111510
2023-01-13 22:48:03 | INFO | train_inner | epoch 043:   1434 / 1978 loss=3.292, nll_loss=1.147, word_ins=2.956, length=3.36, ppl=9.79, wps=46227.4, ups=0.79, wpb=58735.6, bsz=1964.8, num_updates=84500, lr=0.00034401, gnorm=0.922, loss_scale=16384, train_wall=127, wall=111637
2023-01-13 22:50:11 | INFO | train_inner | epoch 043:   1534 / 1978 loss=3.261, nll_loss=1.113, word_ins=2.925, length=3.36, ppl=9.59, wps=46256.2, ups=0.78, wpb=59313.7, bsz=2014, num_updates=84600, lr=0.000343807, gnorm=0.903, loss_scale=16384, train_wall=128, wall=111765
2023-01-13 22:52:20 | INFO | train_inner | epoch 043:   1634 / 1978 loss=3.24, nll_loss=1.1, word_ins=2.913, length=3.278, ppl=9.45, wps=45752.1, ups=0.78, wpb=59026.3, bsz=2099.8, num_updates=84700, lr=0.000343604, gnorm=0.909, loss_scale=16384, train_wall=129, wall=111894
2023-01-13 22:54:28 | INFO | train_inner | epoch 043:   1734 / 1978 loss=3.276, nll_loss=1.127, word_ins=2.938, length=3.378, ppl=9.68, wps=46121.4, ups=0.78, wpb=58784.8, bsz=2006.6, num_updates=84800, lr=0.000343401, gnorm=0.903, loss_scale=16384, train_wall=127, wall=112022
2023-01-13 22:56:36 | INFO | train_inner | epoch 043:   1834 / 1978 loss=3.23, nll_loss=1.091, word_ins=2.906, length=3.236, ppl=9.38, wps=45888.3, ups=0.78, wpb=59000.7, bsz=2098.6, num_updates=84900, lr=0.000343199, gnorm=0.891, loss_scale=16384, train_wall=128, wall=112151
2023-01-13 22:58:45 | INFO | train_inner | epoch 043:   1934 / 1978 loss=3.241, nll_loss=1.1, word_ins=2.913, length=3.281, ppl=9.46, wps=46532, ups=0.78, wpb=59959.4, bsz=2008.1, num_updates=85000, lr=0.000342997, gnorm=0.909, loss_scale=16384, train_wall=129, wall=112279
2023-01-13 22:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 22:59:56 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 4.509 | nll_loss 2.017 | word_ins 3.788 | length 7.204 | ppl 22.77 | wps 120008 | wpb 40242.5 | bsz 1500 | num_updates 85044 | best_loss 4.437
2023-01-13 22:59:56 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 23:00:24 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint43.pt (epoch 43 @ 85044 updates, score 4.509) (writing took 27.42365710902959 seconds)
2023-01-13 23:00:24 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-01-13 23:00:24 | INFO | train | epoch 043 | loss 3.254 | nll_loss 1.107 | word_ins 2.92 | length 3.336 | ppl 9.54 | wps 45338.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 85044 | lr 0.000342908 | gnorm 0.908 | loss_scale 16384 | train_wall 2527 | wall 112378
2023-01-13 23:00:24 | INFO | fairseq.trainer | begin training epoch 44
2023-01-13 23:01:49 | INFO | train_inner | epoch 044:     56 / 1978 loss=3.227, nll_loss=1.083, word_ins=2.898, length=3.29, ppl=9.36, wps=32466.8, ups=0.54, wpb=59701.7, bsz=2043, num_updates=85100, lr=0.000342796, gnorm=0.899, loss_scale=16384, train_wall=129, wall=112463
2023-01-13 23:03:57 | INFO | train_inner | epoch 044:    156 / 1978 loss=3.233, nll_loss=1.088, word_ins=2.903, length=3.308, ppl=9.4, wps=46233.7, ups=0.78, wpb=59127, bsz=2053.8, num_updates=85200, lr=0.000342594, gnorm=0.89, loss_scale=16384, train_wall=128, wall=112591
2023-01-13 23:06:04 | INFO | train_inner | epoch 044:    256 / 1978 loss=3.263, nll_loss=1.116, word_ins=2.928, length=3.348, ppl=9.6, wps=46433.8, ups=0.79, wpb=59140.3, bsz=1993, num_updates=85300, lr=0.000342393, gnorm=0.907, loss_scale=16384, train_wall=127, wall=112719
2023-01-13 23:08:13 | INFO | train_inner | epoch 044:    356 / 1978 loss=3.228, nll_loss=1.085, word_ins=2.9, length=3.285, ppl=9.37, wps=46486.2, ups=0.78, wpb=59539.2, bsz=2058.6, num_updates=85400, lr=0.000342193, gnorm=0.915, loss_scale=16384, train_wall=128, wall=112847
2023-01-13 23:10:20 | INFO | train_inner | epoch 044:    456 / 1978 loss=3.259, nll_loss=1.114, word_ins=2.926, length=3.324, ppl=9.57, wps=46448.7, ups=0.78, wpb=59250.9, bsz=1957.5, num_updates=85500, lr=0.000341993, gnorm=0.918, loss_scale=16384, train_wall=127, wall=112974
2023-01-13 23:12:28 | INFO | train_inner | epoch 044:    556 / 1978 loss=3.237, nll_loss=1.094, word_ins=2.909, length=3.28, ppl=9.43, wps=45963, ups=0.78, wpb=59001.9, bsz=2076.4, num_updates=85600, lr=0.000341793, gnorm=0.92, loss_scale=16384, train_wall=128, wall=113103
2023-01-13 23:13:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-13 23:14:37 | INFO | train_inner | epoch 044:    657 / 1978 loss=3.237, nll_loss=1.087, word_ins=2.902, length=3.348, ppl=9.43, wps=46411.9, ups=0.78, wpb=59834.7, bsz=1962.6, num_updates=85700, lr=0.000341593, gnorm=0.916, loss_scale=16384, train_wall=129, wall=113231
2023-01-13 23:16:45 | INFO | train_inner | epoch 044:    757 / 1978 loss=3.254, nll_loss=1.106, word_ins=2.918, length=3.361, ppl=9.54, wps=46121.1, ups=0.78, wpb=59014.2, bsz=2049.5, num_updates=85800, lr=0.000341394, gnorm=0.928, loss_scale=16384, train_wall=128, wall=113359
2023-01-13 23:18:53 | INFO | train_inner | epoch 044:    857 / 1978 loss=3.232, nll_loss=1.086, word_ins=2.901, length=3.317, ppl=9.4, wps=46335.8, ups=0.78, wpb=59171.4, bsz=2001.7, num_updates=85900, lr=0.000341196, gnorm=0.913, loss_scale=16384, train_wall=127, wall=113487
2023-01-13 23:21:01 | INFO | train_inner | epoch 044:    957 / 1978 loss=3.238, nll_loss=1.092, word_ins=2.906, length=3.325, ppl=9.44, wps=46575.7, ups=0.78, wpb=59411.8, bsz=1952.4, num_updates=86000, lr=0.000340997, gnorm=0.912, loss_scale=16384, train_wall=127, wall=113615
2023-01-13 23:23:10 | INFO | train_inner | epoch 044:   1057 / 1978 loss=3.256, nll_loss=1.11, word_ins=2.922, length=3.341, ppl=9.55, wps=46369.4, ups=0.78, wpb=59810.6, bsz=1977.9, num_updates=86100, lr=0.000340799, gnorm=0.926, loss_scale=16384, train_wall=129, wall=113744
2023-01-13 23:25:17 | INFO | train_inner | epoch 044:   1157 / 1978 loss=3.283, nll_loss=1.135, word_ins=2.945, length=3.384, ppl=9.73, wps=46235.7, ups=0.78, wpb=59055.6, bsz=1979.6, num_updates=86200, lr=0.000340601, gnorm=0.939, loss_scale=16384, train_wall=127, wall=113871
2023-01-13 23:27:25 | INFO | train_inner | epoch 044:   1257 / 1978 loss=3.255, nll_loss=1.111, word_ins=2.923, length=3.324, ppl=9.55, wps=46223.7, ups=0.78, wpb=59120.7, bsz=1987.7, num_updates=86300, lr=0.000340404, gnorm=0.915, loss_scale=16384, train_wall=128, wall=113999
2023-01-13 23:29:33 | INFO | train_inner | epoch 044:   1357 / 1978 loss=3.228, nll_loss=1.086, word_ins=2.9, length=3.282, ppl=9.37, wps=46237.5, ups=0.78, wpb=59102.4, bsz=2104.6, num_updates=86400, lr=0.000340207, gnorm=0.908, loss_scale=16384, train_wall=128, wall=114127
2023-01-13 23:31:41 | INFO | train_inner | epoch 044:   1457 / 1978 loss=3.231, nll_loss=1.09, word_ins=2.904, length=3.274, ppl=9.39, wps=46387.7, ups=0.78, wpb=59469.8, bsz=2023, num_updates=86500, lr=0.00034001, gnorm=0.908, loss_scale=16384, train_wall=128, wall=114255
2023-01-13 23:33:49 | INFO | train_inner | epoch 044:   1557 / 1978 loss=3.253, nll_loss=1.103, word_ins=2.916, length=3.375, ppl=9.54, wps=46618.1, ups=0.78, wpb=59456, bsz=1941.4, num_updates=86600, lr=0.000339814, gnorm=0.934, loss_scale=16384, train_wall=127, wall=114383
2023-01-13 23:35:57 | INFO | train_inner | epoch 044:   1657 / 1978 loss=3.246, nll_loss=1.102, word_ins=2.915, length=3.312, ppl=9.49, wps=46043.9, ups=0.78, wpb=58928.6, bsz=2036.3, num_updates=86700, lr=0.000339618, gnorm=0.938, loss_scale=16384, train_wall=128, wall=114511
2023-01-13 23:38:04 | INFO | train_inner | epoch 044:   1757 / 1978 loss=3.265, nll_loss=1.111, word_ins=2.923, length=3.419, ppl=9.61, wps=46533.1, ups=0.78, wpb=59324.9, bsz=1956.9, num_updates=86800, lr=0.000339422, gnorm=0.938, loss_scale=16384, train_wall=127, wall=114638
2023-01-13 23:40:13 | INFO | train_inner | epoch 044:   1857 / 1978 loss=3.25, nll_loss=1.107, word_ins=2.919, length=3.31, ppl=9.51, wps=46476.3, ups=0.78, wpb=59748.6, bsz=1944.4, num_updates=86900, lr=0.000339227, gnorm=0.916, loss_scale=16384, train_wall=128, wall=114767
2023-01-13 23:42:21 | INFO | train_inner | epoch 044:   1957 / 1978 loss=3.243, nll_loss=1.096, word_ins=2.909, length=3.345, ppl=9.47, wps=46188.6, ups=0.78, wpb=58971.8, bsz=1979.8, num_updates=87000, lr=0.000339032, gnorm=0.91, loss_scale=16384, train_wall=127, wall=114895
2023-01-13 23:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-13 23:43:03 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 4.473 | nll_loss 2.022 | word_ins 3.792 | length 6.808 | ppl 22.21 | wps 107572 | wpb 40242.5 | bsz 1500 | num_updates 87021 | best_loss 4.437
2023-01-13 23:43:03 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-13 23:43:32 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint44.pt (epoch 44 @ 87021 updates, score 4.473) (writing took 28.60761463828385 seconds)
2023-01-13 23:43:32 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-01-13 23:43:32 | INFO | train | epoch 044 | loss 3.246 | nll_loss 1.101 | word_ins 2.914 | length 3.326 | ppl 9.49 | wps 45290.6 | ups 0.76 | wpb 59287.1 | bsz 2003.1 | num_updates 87021 | lr 0.000338991 | gnorm 0.919 | loss_scale 16384 | train_wall 2525 | wall 114966
2023-01-13 23:43:32 | INFO | fairseq.trainer | begin training epoch 45
2023-01-13 23:45:25 | INFO | train_inner | epoch 045:     79 / 1978 loss=3.273, nll_loss=1.125, word_ins=2.937, length=3.362, ppl=9.67, wps=31649, ups=0.54, wpb=58492.2, bsz=1906, num_updates=87100, lr=0.000338837, gnorm=0.955, loss_scale=16384, train_wall=127, wall=115080
2023-01-13 23:47:34 | INFO | train_inner | epoch 045:    179 / 1978 loss=3.232, nll_loss=1.088, word_ins=2.902, length=3.303, ppl=9.4, wps=46061.5, ups=0.78, wpb=59252.5, bsz=2039.6, num_updates=87200, lr=0.000338643, gnorm=0.916, loss_scale=16384, train_wall=128, wall=115208
2023-01-13 23:49:41 | INFO | train_inner | epoch 045:    279 / 1978 loss=3.259, nll_loss=1.11, word_ins=2.923, length=3.362, ppl=9.57, wps=46487.1, ups=0.79, wpb=59051.1, bsz=1875, num_updates=87300, lr=0.000338449, gnorm=0.926, loss_scale=16384, train_wall=127, wall=115335
2023-01-13 23:51:48 | INFO | train_inner | epoch 045:    379 / 1978 loss=3.259, nll_loss=1.113, word_ins=2.924, length=3.349, ppl=9.58, wps=46137.6, ups=0.79, wpb=58708.2, bsz=1920.1, num_updates=87400, lr=0.000338255, gnorm=0.901, loss_scale=16384, train_wall=127, wall=115462
2023-01-13 23:53:57 | INFO | train_inner | epoch 045:    479 / 1978 loss=3.195, nll_loss=1.057, word_ins=2.875, length=3.207, ppl=9.16, wps=46268.7, ups=0.78, wpb=59547.2, bsz=2131.8, num_updates=87500, lr=0.000338062, gnorm=0.917, loss_scale=16384, train_wall=128, wall=115591
2023-01-13 23:56:06 | INFO | train_inner | epoch 045:    579 / 1978 loss=3.263, nll_loss=1.113, word_ins=2.925, length=3.382, ppl=9.6, wps=45666.6, ups=0.78, wpb=58809.3, bsz=1988.6, num_updates=87600, lr=0.000337869, gnorm=0.931, loss_scale=16384, train_wall=128, wall=115720
2023-01-13 23:58:14 | INFO | train_inner | epoch 045:    679 / 1978 loss=3.229, nll_loss=1.083, word_ins=2.897, length=3.321, ppl=9.38, wps=46202.7, ups=0.78, wpb=59220.3, bsz=2078.9, num_updates=87700, lr=0.000337676, gnorm=0.938, loss_scale=16384, train_wall=128, wall=115848
2023-01-14 00:00:23 | INFO | train_inner | epoch 045:    779 / 1978 loss=3.225, nll_loss=1.079, word_ins=2.894, length=3.31, ppl=9.35, wps=46276.2, ups=0.78, wpb=59657.1, bsz=2046.6, num_updates=87800, lr=0.000337484, gnorm=0.919, loss_scale=16384, train_wall=129, wall=115977
2023-01-14 00:02:31 | INFO | train_inner | epoch 045:    879 / 1978 loss=3.256, nll_loss=1.11, word_ins=2.922, length=3.342, ppl=9.55, wps=46386.6, ups=0.78, wpb=59226.4, bsz=1989.6, num_updates=87900, lr=0.000337292, gnorm=0.919, loss_scale=16384, train_wall=127, wall=116105
2023-01-14 00:04:39 | INFO | train_inner | epoch 045:    979 / 1978 loss=3.241, nll_loss=1.098, word_ins=2.911, length=3.3, ppl=9.45, wps=46226.4, ups=0.78, wpb=59397.4, bsz=2030.2, num_updates=88000, lr=0.0003371, gnorm=0.92, loss_scale=16384, train_wall=128, wall=116233
2023-01-14 00:06:48 | INFO | train_inner | epoch 045:   1079 / 1978 loss=3.204, nll_loss=1.062, word_ins=2.878, length=3.255, ppl=9.21, wps=46734, ups=0.78, wpb=60184.9, bsz=2063.8, num_updates=88100, lr=0.000336909, gnorm=0.94, loss_scale=16384, train_wall=129, wall=116362
2023-01-14 00:10:33 | INFO | train_inner | epoch 045:   1179 / 1978 loss=3.243, nll_loss=1.095, word_ins=2.909, length=3.342, ppl=9.47, wps=26309.3, ups=0.44, wpb=59295.2, bsz=2010.2, num_updates=88200, lr=0.000336718, gnorm=0.959, loss_scale=16384, train_wall=225, wall=116587
2023-01-14 00:12:40 | INFO | train_inner | epoch 045:   1279 / 1978 loss=3.244, nll_loss=1.1, word_ins=2.913, length=3.307, ppl=9.47, wps=46682.4, ups=0.79, wpb=59368.9, bsz=1972.9, num_updates=88300, lr=0.000336527, gnorm=0.94, loss_scale=16384, train_wall=127, wall=116715
2023-01-14 00:14:48 | INFO | train_inner | epoch 045:   1379 / 1978 loss=3.235, nll_loss=1.091, word_ins=2.904, length=3.307, ppl=9.41, wps=46531.8, ups=0.78, wpb=59534.3, bsz=2003.4, num_updates=88400, lr=0.000336336, gnorm=0.93, loss_scale=16384, train_wall=128, wall=116843
2023-01-14 00:16:57 | INFO | train_inner | epoch 045:   1479 / 1978 loss=3.23, nll_loss=1.082, word_ins=2.896, length=3.346, ppl=9.39, wps=46181, ups=0.78, wpb=59536.5, bsz=2067.7, num_updates=88500, lr=0.000336146, gnorm=0.94, loss_scale=16384, train_wall=129, wall=116971
2023-01-14 00:19:05 | INFO | train_inner | epoch 045:   1579 / 1978 loss=3.252, nll_loss=1.111, word_ins=2.923, length=3.288, ppl=9.52, wps=46266.5, ups=0.78, wpb=59098.6, bsz=1976.8, num_updates=88600, lr=0.000335957, gnorm=0.939, loss_scale=16384, train_wall=127, wall=117099
2023-01-14 00:21:14 | INFO | train_inner | epoch 045:   1679 / 1978 loss=3.217, nll_loss=1.073, word_ins=2.888, length=3.294, ppl=9.3, wps=46124.6, ups=0.77, wpb=59657.5, bsz=2064.9, num_updates=88700, lr=0.000335767, gnorm=0.93, loss_scale=16384, train_wall=129, wall=117229
2023-01-14 00:23:22 | INFO | train_inner | epoch 045:   1779 / 1978 loss=3.222, nll_loss=1.078, word_ins=2.892, length=3.298, ppl=9.33, wps=46163.8, ups=0.78, wpb=58942.1, bsz=1982.4, num_updates=88800, lr=0.000335578, gnorm=0.912, loss_scale=16384, train_wall=127, wall=117356
2023-01-14 00:25:29 | INFO | train_inner | epoch 045:   1879 / 1978 loss=3.276, nll_loss=1.127, word_ins=2.937, length=3.39, ppl=9.69, wps=46562.1, ups=0.79, wpb=59079.8, bsz=1921.5, num_updates=88900, lr=0.000335389, gnorm=0.939, loss_scale=16384, train_wall=127, wall=117483
2023-01-14 00:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 00:27:48 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 4.496 | nll_loss 2.015 | word_ins 3.786 | length 7.103 | ppl 22.57 | wps 106724 | wpb 40242.5 | bsz 1500 | num_updates 88999 | best_loss 4.437
2023-01-14 00:27:48 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 00:28:15 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint45.pt (epoch 45 @ 88999 updates, score 4.496) (writing took 27.286576077807695 seconds)
2023-01-14 00:28:15 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-01-14 00:28:15 | INFO | train | epoch 045 | loss 3.24 | nll_loss 1.094 | word_ins 2.907 | length 3.322 | ppl 9.44 | wps 43693.5 | ups 0.74 | wpb 59284.3 | bsz 2002.6 | num_updates 88999 | lr 0.000335203 | gnorm 0.929 | loss_scale 16384 | train_wall 2626 | wall 117650
2023-01-14 00:28:15 | INFO | fairseq.trainer | begin training epoch 46
2023-01-14 00:28:29 | INFO | train_inner | epoch 046:      1 / 1978 loss=3.238, nll_loss=1.088, word_ins=2.901, length=3.363, ppl=9.43, wps=32965.8, ups=0.56, wpb=59363.1, bsz=1982.7, num_updates=89000, lr=0.000335201, gnorm=0.921, loss_scale=16384, train_wall=128, wall=117663
2023-01-14 00:30:38 | INFO | train_inner | epoch 046:    101 / 1978 loss=3.197, nll_loss=1.055, word_ins=2.872, length=3.253, ppl=9.17, wps=46197.7, ups=0.78, wpb=59408.2, bsz=2072.7, num_updates=89100, lr=0.000335013, gnorm=0.921, loss_scale=16384, train_wall=128, wall=117792
2023-01-14 00:32:45 | INFO | train_inner | epoch 046:    201 / 1978 loss=3.243, nll_loss=1.097, word_ins=2.91, length=3.325, ppl=9.47, wps=46342.2, ups=0.78, wpb=59043.5, bsz=1984, num_updates=89200, lr=0.000334825, gnorm=0.949, loss_scale=16384, train_wall=127, wall=117919
2023-01-14 00:34:52 | INFO | train_inner | epoch 046:    301 / 1978 loss=3.24, nll_loss=1.095, word_ins=2.908, length=3.314, ppl=9.45, wps=46767.2, ups=0.79, wpb=59354.9, bsz=1918.1, num_updates=89300, lr=0.000334637, gnorm=0.941, loss_scale=16384, train_wall=127, wall=118046
2023-01-14 00:37:02 | INFO | train_inner | epoch 046:    401 / 1978 loss=3.225, nll_loss=1.077, word_ins=2.893, length=3.325, ppl=9.35, wps=45789.5, ups=0.77, wpb=59539.9, bsz=2038.9, num_updates=89400, lr=0.00033445, gnorm=0.945, loss_scale=16384, train_wall=130, wall=118176
2023-01-14 00:39:11 | INFO | train_inner | epoch 046:    501 / 1978 loss=3.214, nll_loss=1.065, word_ins=2.881, length=3.331, ppl=9.28, wps=46516.1, ups=0.78, wpb=59783.1, bsz=2011.2, num_updates=89500, lr=0.000334263, gnorm=0.905, loss_scale=16384, train_wall=128, wall=118305
2023-01-14 00:41:20 | INFO | train_inner | epoch 046:    601 / 1978 loss=3.199, nll_loss=1.059, word_ins=2.876, length=3.224, ppl=9.18, wps=45730.9, ups=0.77, wpb=59366.3, bsz=2146.6, num_updates=89600, lr=0.000334077, gnorm=0.919, loss_scale=16384, train_wall=130, wall=118435
2023-01-14 00:43:28 | INFO | train_inner | epoch 046:    701 / 1978 loss=3.235, nll_loss=1.089, word_ins=2.903, length=3.316, ppl=9.41, wps=46417.5, ups=0.78, wpb=59400.9, bsz=1955.4, num_updates=89700, lr=0.00033389, gnorm=0.939, loss_scale=16384, train_wall=128, wall=118563
2023-01-14 00:44:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 00:45:38 | INFO | train_inner | epoch 046:    802 / 1978 loss=3.242, nll_loss=1.096, word_ins=2.909, length=3.33, ppl=9.46, wps=45668.2, ups=0.77, wpb=59024.1, bsz=2005.3, num_updates=89800, lr=0.000333704, gnorm=0.92, loss_scale=16384, train_wall=129, wall=118692
2023-01-14 00:47:45 | INFO | train_inner | epoch 046:    902 / 1978 loss=3.225, nll_loss=1.079, word_ins=2.894, length=3.312, ppl=9.35, wps=46339.9, ups=0.79, wpb=58969.1, bsz=2007.3, num_updates=89900, lr=0.000333519, gnorm=0.949, loss_scale=16384, train_wall=127, wall=118819
2023-01-14 00:49:52 | INFO | train_inner | epoch 046:   1002 / 1978 loss=3.209, nll_loss=1.068, word_ins=2.884, length=3.248, ppl=9.25, wps=46890, ups=0.79, wpb=59633.2, bsz=2047.4, num_updates=90000, lr=0.000333333, gnorm=0.933, loss_scale=16384, train_wall=127, wall=118946
2023-01-14 00:52:00 | INFO | train_inner | epoch 046:   1102 / 1978 loss=3.241, nll_loss=1.098, word_ins=2.91, length=3.306, ppl=9.45, wps=46156.6, ups=0.78, wpb=59099.8, bsz=2026, num_updates=90100, lr=0.000333148, gnorm=0.949, loss_scale=16384, train_wall=128, wall=119074
2023-01-14 00:54:09 | INFO | train_inner | epoch 046:   1202 / 1978 loss=3.237, nll_loss=1.094, word_ins=2.907, length=3.296, ppl=9.43, wps=46175.4, ups=0.78, wpb=59387, bsz=2015.4, num_updates=90200, lr=0.000332964, gnorm=0.935, loss_scale=16384, train_wall=128, wall=119203
2023-01-14 00:56:16 | INFO | train_inner | epoch 046:   1302 / 1978 loss=3.249, nll_loss=1.105, word_ins=2.917, length=3.321, ppl=9.51, wps=46495.4, ups=0.78, wpb=59253.7, bsz=1983.8, num_updates=90300, lr=0.000332779, gnorm=0.928, loss_scale=16384, train_wall=127, wall=119330
2023-01-14 00:58:24 | INFO | train_inner | epoch 046:   1402 / 1978 loss=3.225, nll_loss=1.083, word_ins=2.896, length=3.286, ppl=9.35, wps=46441.9, ups=0.78, wpb=59398.1, bsz=2036.7, num_updates=90400, lr=0.000332595, gnorm=0.944, loss_scale=16384, train_wall=128, wall=119458
2023-01-14 01:00:31 | INFO | train_inner | epoch 046:   1502 / 1978 loss=3.237, nll_loss=1.088, word_ins=2.902, length=3.352, ppl=9.43, wps=46630.2, ups=0.79, wpb=58980.6, bsz=1884.2, num_updates=90500, lr=0.000332411, gnorm=0.984, loss_scale=16384, train_wall=126, wall=119585
2023-01-14 01:02:38 | INFO | train_inner | epoch 046:   1602 / 1978 loss=3.217, nll_loss=1.072, word_ins=2.888, length=3.296, ppl=9.3, wps=46460.6, ups=0.78, wpb=59334.1, bsz=2015, num_updates=90600, lr=0.000332228, gnorm=0.951, loss_scale=16384, train_wall=127, wall=119712
2023-01-14 01:04:46 | INFO | train_inner | epoch 046:   1702 / 1978 loss=3.238, nll_loss=1.094, word_ins=2.907, length=3.316, ppl=9.44, wps=46483, ups=0.78, wpb=59472.7, bsz=1991.1, num_updates=90700, lr=0.000332045, gnorm=0.924, loss_scale=16384, train_wall=128, wall=119840
2023-01-14 01:06:54 | INFO | train_inner | epoch 046:   1802 / 1978 loss=3.242, nll_loss=1.095, word_ins=2.908, length=3.339, ppl=9.46, wps=46534.5, ups=0.78, wpb=59373.3, bsz=1952.6, num_updates=90800, lr=0.000331862, gnorm=0.958, loss_scale=16384, train_wall=127, wall=119968
2023-01-14 01:09:03 | INFO | train_inner | epoch 046:   1902 / 1978 loss=3.248, nll_loss=1.103, word_ins=2.915, length=3.325, ppl=9.5, wps=45624.4, ups=0.78, wpb=58824, bsz=2046.8, num_updates=90900, lr=0.000331679, gnorm=0.95, loss_scale=16384, train_wall=129, wall=120097
2023-01-14 01:10:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 01:10:51 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 4.567 | nll_loss 2.02 | word_ins 3.791 | length 7.764 | ppl 23.7 | wps 164761 | wpb 40242.5 | bsz 1500 | num_updates 90976 | best_loss 4.437
2023-01-14 01:10:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 01:11:18 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint46.pt (epoch 46 @ 90976 updates, score 4.567) (writing took 27.13482624804601 seconds)
2023-01-14 01:11:18 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-01-14 01:11:18 | INFO | train | epoch 046 | loss 3.231 | nll_loss 1.086 | word_ins 2.9 | length 3.31 | ppl 9.39 | wps 45385.6 | ups 0.77 | wpb 59282.4 | bsz 2003.2 | num_updates 90976 | lr 0.00033154 | gnorm 0.939 | loss_scale 16384 | train_wall 2527 | wall 120232
2023-01-14 01:11:18 | INFO | fairseq.trainer | begin training epoch 47
2023-01-14 01:12:00 | INFO | train_inner | epoch 047:     24 / 1978 loss=3.257, nll_loss=1.108, word_ins=2.92, length=3.37, ppl=9.56, wps=33230.3, ups=0.56, wpb=58956, bsz=1923.2, num_updates=91000, lr=0.000331497, gnorm=0.928, loss_scale=16384, train_wall=128, wall=120274
2023-01-14 01:14:07 | INFO | train_inner | epoch 047:    124 / 1978 loss=3.263, nll_loss=1.122, word_ins=2.934, length=3.291, ppl=9.6, wps=46945, ups=0.79, wpb=59714.3, bsz=1935, num_updates=91100, lr=0.000331315, gnorm=0.977, loss_scale=16384, train_wall=127, wall=120402
2023-01-14 01:16:15 | INFO | train_inner | epoch 047:    224 / 1978 loss=3.211, nll_loss=1.064, word_ins=2.88, length=3.307, ppl=9.26, wps=46802.3, ups=0.79, wpb=59470.2, bsz=1988.4, num_updates=91200, lr=0.000331133, gnorm=0.984, loss_scale=16384, train_wall=127, wall=120529
2023-01-14 01:18:22 | INFO | train_inner | epoch 047:    324 / 1978 loss=3.212, nll_loss=1.064, word_ins=2.88, length=3.317, ppl=9.27, wps=46404.8, ups=0.78, wpb=59205.8, bsz=2010.2, num_updates=91300, lr=0.000330952, gnorm=0.94, loss_scale=16384, train_wall=127, wall=120656
2023-01-14 01:20:30 | INFO | train_inner | epoch 047:    424 / 1978 loss=3.252, nll_loss=1.103, word_ins=2.916, length=3.361, ppl=9.53, wps=46383.9, ups=0.78, wpb=59100.2, bsz=1907.7, num_updates=91400, lr=0.000330771, gnorm=0.95, loss_scale=16384, train_wall=127, wall=120784
2023-01-14 01:22:38 | INFO | train_inner | epoch 047:    524 / 1978 loss=3.212, nll_loss=1.065, word_ins=2.881, length=3.311, ppl=9.27, wps=46336.8, ups=0.78, wpb=59366.4, bsz=1986.4, num_updates=91500, lr=0.00033059, gnorm=0.946, loss_scale=16384, train_wall=128, wall=120912
2023-01-14 01:24:47 | INFO | train_inner | epoch 047:    624 / 1978 loss=3.215, nll_loss=1.076, word_ins=2.891, length=3.236, ppl=9.29, wps=46187.4, ups=0.77, wpb=59916.7, bsz=2042.6, num_updates=91600, lr=0.000330409, gnorm=0.96, loss_scale=16384, train_wall=129, wall=121041
2023-01-14 01:26:56 | INFO | train_inner | epoch 047:    724 / 1978 loss=3.191, nll_loss=1.053, word_ins=2.87, length=3.213, ppl=9.13, wps=46168.8, ups=0.78, wpb=59187.6, bsz=2099.4, num_updates=91700, lr=0.000330229, gnorm=0.947, loss_scale=16384, train_wall=128, wall=121170
2023-01-14 01:29:03 | INFO | train_inner | epoch 047:    824 / 1978 loss=3.245, nll_loss=1.102, word_ins=2.914, length=3.307, ppl=9.48, wps=46537, ups=0.78, wpb=59485.5, bsz=1938.9, num_updates=91800, lr=0.000330049, gnorm=0.971, loss_scale=16384, train_wall=128, wall=121298
2023-01-14 01:31:11 | INFO | train_inner | epoch 047:    924 / 1978 loss=3.255, nll_loss=1.1, word_ins=2.913, length=3.418, ppl=9.54, wps=46316.1, ups=0.79, wpb=58958.2, bsz=1934.7, num_updates=91900, lr=0.00032987, gnorm=0.951, loss_scale=16384, train_wall=127, wall=121425
2023-01-14 01:33:19 | INFO | train_inner | epoch 047:   1024 / 1978 loss=3.198, nll_loss=1.06, word_ins=2.875, length=3.225, ppl=9.18, wps=46695.6, ups=0.78, wpb=59948.6, bsz=2041, num_updates=92000, lr=0.00032969, gnorm=0.917, loss_scale=16384, train_wall=128, wall=121553
2023-01-14 01:35:27 | INFO | train_inner | epoch 047:   1124 / 1978 loss=3.234, nll_loss=1.087, word_ins=2.901, length=3.325, ppl=9.41, wps=46370.3, ups=0.78, wpb=59520.9, bsz=1967.4, num_updates=92100, lr=0.000329511, gnorm=0.956, loss_scale=16384, train_wall=128, wall=121682
2023-01-14 01:37:35 | INFO | train_inner | epoch 047:   1224 / 1978 loss=3.203, nll_loss=1.057, word_ins=2.873, length=3.296, ppl=9.21, wps=46496.1, ups=0.78, wpb=59382.5, bsz=2022.7, num_updates=92200, lr=0.000329332, gnorm=0.925, loss_scale=16384, train_wall=127, wall=121809
2023-01-14 01:39:43 | INFO | train_inner | epoch 047:   1324 / 1978 loss=3.238, nll_loss=1.089, word_ins=2.902, length=3.356, ppl=9.43, wps=45813.4, ups=0.78, wpb=58741.3, bsz=1998, num_updates=92300, lr=0.000329154, gnorm=0.942, loss_scale=16384, train_wall=128, wall=121938
2023-01-14 01:41:52 | INFO | train_inner | epoch 047:   1424 / 1978 loss=3.214, nll_loss=1.075, word_ins=2.889, length=3.252, ppl=9.28, wps=46287, ups=0.78, wpb=59557.4, bsz=2042.3, num_updates=92400, lr=0.000328976, gnorm=0.952, loss_scale=16384, train_wall=128, wall=122066
2023-01-14 01:44:01 | INFO | train_inner | epoch 047:   1524 / 1978 loss=3.229, nll_loss=1.079, word_ins=2.893, length=3.353, ppl=9.37, wps=45734.8, ups=0.77, wpb=59139, bsz=2011.1, num_updates=92500, lr=0.000328798, gnorm=0.951, loss_scale=16384, train_wall=129, wall=122195
2023-01-14 01:46:11 | INFO | train_inner | epoch 047:   1624 / 1978 loss=3.234, nll_loss=1.087, word_ins=2.901, length=3.328, ppl=9.41, wps=45555.4, ups=0.77, wpb=58813.7, bsz=2033, num_updates=92600, lr=0.00032862, gnorm=0.944, loss_scale=16384, train_wall=129, wall=122325
2023-01-14 01:48:17 | INFO | train_inner | epoch 047:   1724 / 1978 loss=3.247, nll_loss=1.096, word_ins=2.909, length=3.383, ppl=9.49, wps=46184.3, ups=0.79, wpb=58484.2, bsz=1993.2, num_updates=92700, lr=0.000328443, gnorm=0.944, loss_scale=16384, train_wall=126, wall=122451
2023-01-14 01:50:25 | INFO | train_inner | epoch 047:   1824 / 1978 loss=3.218, nll_loss=1.072, word_ins=2.887, length=3.312, ppl=9.3, wps=46060.3, ups=0.78, wpb=58946.2, bsz=2063.9, num_updates=92800, lr=0.000328266, gnorm=0.916, loss_scale=16384, train_wall=128, wall=122579
2023-01-14 01:52:34 | INFO | train_inner | epoch 047:   1924 / 1978 loss=3.212, nll_loss=1.068, word_ins=2.884, length=3.281, ppl=9.27, wps=46216.6, ups=0.78, wpb=59544.6, bsz=2029.8, num_updates=92900, lr=0.000328089, gnorm=0.97, loss_scale=16384, train_wall=128, wall=122708
2023-01-14 01:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 01:53:54 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 4.532 | nll_loss 2.027 | word_ins 3.797 | length 7.349 | ppl 23.14 | wps 123904 | wpb 40242.5 | bsz 1500 | num_updates 92954 | best_loss 4.437
2023-01-14 01:53:54 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 01:54:22 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint47.pt (epoch 47 @ 92954 updates, score 4.532) (writing took 27.89093597093597 seconds)
2023-01-14 01:54:22 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-01-14 01:54:22 | INFO | train | epoch 047 | loss 3.224 | nll_loss 1.079 | word_ins 2.893 | length 3.308 | ppl 9.35 | wps 45381.1 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 92954 | lr 0.000327994 | gnorm 0.948 | loss_scale 16384 | train_wall 2528 | wall 122816
2023-01-14 01:54:22 | INFO | fairseq.trainer | begin training epoch 48
2023-01-14 01:55:33 | INFO | train_inner | epoch 048:     46 / 1978 loss=3.189, nll_loss=1.046, word_ins=2.863, length=3.258, ppl=9.12, wps=33098.9, ups=0.56, wpb=59317, bsz=2051.4, num_updates=93000, lr=0.000327913, gnorm=0.925, loss_scale=16384, train_wall=127, wall=122887
2023-01-14 01:57:42 | INFO | train_inner | epoch 048:    146 / 1978 loss=3.182, nll_loss=1.047, word_ins=2.864, length=3.174, ppl=9.07, wps=46283.2, ups=0.77, wpb=59772.8, bsz=2091, num_updates=93100, lr=0.000327737, gnorm=0.957, loss_scale=16384, train_wall=129, wall=123016
2023-01-14 01:59:49 | INFO | train_inner | epoch 048:    246 / 1978 loss=3.246, nll_loss=1.093, word_ins=2.906, length=3.4, ppl=9.49, wps=46751.5, ups=0.79, wpb=59218.1, bsz=1923.7, num_updates=93200, lr=0.000327561, gnorm=0.975, loss_scale=16384, train_wall=126, wall=123143
2023-01-14 02:01:58 | INFO | train_inner | epoch 048:    346 / 1978 loss=3.204, nll_loss=1.059, word_ins=2.875, length=3.288, ppl=9.21, wps=45843.8, ups=0.78, wpb=59091.1, bsz=2030.5, num_updates=93300, lr=0.000327385, gnorm=0.95, loss_scale=16384, train_wall=129, wall=123272
2023-01-14 02:04:05 | INFO | train_inner | epoch 048:    446 / 1978 loss=3.259, nll_loss=1.113, word_ins=2.925, length=3.347, ppl=9.58, wps=46578.1, ups=0.79, wpb=59124.9, bsz=1876.7, num_updates=93400, lr=0.00032721, gnorm=0.985, loss_scale=16384, train_wall=127, wall=123399
2023-01-14 02:06:13 | INFO | train_inner | epoch 048:    546 / 1978 loss=3.206, nll_loss=1.06, word_ins=2.876, length=3.307, ppl=9.23, wps=46459.1, ups=0.78, wpb=59379.6, bsz=2018.5, num_updates=93500, lr=0.000327035, gnorm=0.957, loss_scale=16384, train_wall=128, wall=123527
2023-01-14 02:08:21 | INFO | train_inner | epoch 048:    646 / 1978 loss=3.203, nll_loss=1.059, word_ins=2.876, length=3.273, ppl=9.21, wps=46271.7, ups=0.78, wpb=59346.3, bsz=2037, num_updates=93600, lr=0.00032686, gnorm=0.957, loss_scale=16384, train_wall=128, wall=123655
2023-01-14 02:10:29 | INFO | train_inner | epoch 048:    746 / 1978 loss=3.213, nll_loss=1.068, word_ins=2.883, length=3.303, ppl=9.28, wps=46407.1, ups=0.78, wpb=59430.2, bsz=1970.2, num_updates=93700, lr=0.000326686, gnorm=0.944, loss_scale=16384, train_wall=128, wall=123783
2023-01-14 02:12:36 | INFO | train_inner | epoch 048:    846 / 1978 loss=3.221, nll_loss=1.07, word_ins=2.886, length=3.356, ppl=9.32, wps=46150.9, ups=0.79, wpb=58546.7, bsz=1977, num_updates=93800, lr=0.000326512, gnorm=0.932, loss_scale=16384, train_wall=127, wall=123910
2023-01-14 02:13:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 02:14:45 | INFO | train_inner | epoch 048:    947 / 1978 loss=3.242, nll_loss=1.099, word_ins=2.911, length=3.306, ppl=9.46, wps=45451.8, ups=0.77, wpb=58830.6, bsz=1987, num_updates=93900, lr=0.000326338, gnorm=0.945, loss_scale=16384, train_wall=129, wall=124039
2023-01-14 02:16:53 | INFO | train_inner | epoch 048:   1047 / 1978 loss=3.215, nll_loss=1.066, word_ins=2.881, length=3.332, ppl=9.28, wps=46509.7, ups=0.78, wpb=59529.8, bsz=1969.9, num_updates=94000, lr=0.000326164, gnorm=0.956, loss_scale=16384, train_wall=128, wall=124167
2023-01-14 02:19:01 | INFO | train_inner | epoch 048:   1147 / 1978 loss=3.22, nll_loss=1.074, word_ins=2.889, length=3.313, ppl=9.32, wps=46486.4, ups=0.78, wpb=59393.9, bsz=1982.2, num_updates=94100, lr=0.000325991, gnorm=0.958, loss_scale=16384, train_wall=128, wall=124295
2023-01-14 02:21:10 | INFO | train_inner | epoch 048:   1247 / 1978 loss=3.177, nll_loss=1.038, word_ins=2.856, length=3.214, ppl=9.05, wps=46298.9, ups=0.78, wpb=59590, bsz=2088.2, num_updates=94200, lr=0.000325818, gnorm=0.953, loss_scale=16384, train_wall=128, wall=124424
2023-01-14 02:23:17 | INFO | train_inner | epoch 048:   1347 / 1978 loss=3.232, nll_loss=1.092, word_ins=2.905, length=3.267, ppl=9.39, wps=46598.3, ups=0.78, wpb=59406.8, bsz=1996.1, num_updates=94300, lr=0.000325645, gnorm=0.967, loss_scale=16384, train_wall=127, wall=124551
2023-01-14 02:25:25 | INFO | train_inner | epoch 048:   1447 / 1978 loss=3.203, nll_loss=1.055, word_ins=2.871, length=3.313, ppl=9.21, wps=46492.2, ups=0.78, wpb=59545, bsz=2050.7, num_updates=94400, lr=0.000325472, gnorm=0.959, loss_scale=16384, train_wall=128, wall=124679
2023-01-14 02:27:34 | INFO | train_inner | epoch 048:   1547 / 1978 loss=3.225, nll_loss=1.083, word_ins=2.896, length=3.291, ppl=9.35, wps=46409.5, ups=0.78, wpb=59480.8, bsz=1988.6, num_updates=94500, lr=0.0003253, gnorm=0.97, loss_scale=16384, train_wall=128, wall=124808
2023-01-14 02:29:41 | INFO | train_inner | epoch 048:   1647 / 1978 loss=3.242, nll_loss=1.097, word_ins=2.909, length=3.329, ppl=9.46, wps=46255.9, ups=0.79, wpb=58905, bsz=1957.3, num_updates=94600, lr=0.000325128, gnorm=0.967, loss_scale=16384, train_wall=127, wall=124935
2023-01-14 02:31:48 | INFO | train_inner | epoch 048:   1747 / 1978 loss=3.221, nll_loss=1.075, word_ins=2.889, length=3.321, ppl=9.33, wps=46643.4, ups=0.78, wpb=59509.6, bsz=2034.7, num_updates=94700, lr=0.000324956, gnorm=0.968, loss_scale=16384, train_wall=127, wall=125063
2023-01-14 02:33:57 | INFO | train_inner | epoch 048:   1847 / 1978 loss=3.217, nll_loss=1.075, word_ins=2.889, length=3.284, ppl=9.3, wps=46180.1, ups=0.78, wpb=59134.9, bsz=2042.9, num_updates=94800, lr=0.000324785, gnorm=0.977, loss_scale=16384, train_wall=128, wall=125191
2023-01-14 02:36:04 | INFO | train_inner | epoch 048:   1947 / 1978 loss=3.191, nll_loss=1.055, word_ins=2.871, length=3.208, ppl=9.13, wps=46593.2, ups=0.78, wpb=59425.1, bsz=2070.6, num_updates=94900, lr=0.000324614, gnorm=0.943, loss_scale=16384, train_wall=127, wall=125318
2023-01-14 02:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 02:36:53 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 4.611 | nll_loss 2.042 | word_ins 3.811 | length 7.997 | ppl 24.44 | wps 156988 | wpb 40242.5 | bsz 1500 | num_updates 94931 | best_loss 4.437
2023-01-14 02:36:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 02:37:21 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint48.pt (epoch 48 @ 94931 updates, score 4.611) (writing took 28.43386808782816 seconds)
2023-01-14 02:37:21 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-01-14 02:37:21 | INFO | train | epoch 048 | loss 3.217 | nll_loss 1.072 | word_ins 2.887 | length 3.297 | ppl 9.3 | wps 45438.1 | ups 0.77 | wpb 59285 | bsz 2003 | num_updates 94931 | lr 0.000324561 | gnorm 0.959 | loss_scale 16384 | train_wall 2523 | wall 125395
2023-01-14 02:37:21 | INFO | fairseq.trainer | begin training epoch 49
2023-01-14 02:39:01 | INFO | train_inner | epoch 049:     69 / 1978 loss=3.24, nll_loss=1.091, word_ins=2.905, length=3.357, ppl=9.45, wps=33072.2, ups=0.57, wpb=58493.5, bsz=1979.6, num_updates=95000, lr=0.000324443, gnorm=0.988, loss_scale=16384, train_wall=126, wall=125495
2023-01-14 02:41:08 | INFO | train_inner | epoch 049:    169 / 1978 loss=3.219, nll_loss=1.071, word_ins=2.886, length=3.331, ppl=9.31, wps=47027.9, ups=0.79, wpb=59591.7, bsz=1952.8, num_updates=95100, lr=0.000324272, gnorm=0.967, loss_scale=16384, train_wall=126, wall=125622
2023-01-14 02:43:15 | INFO | train_inner | epoch 049:    269 / 1978 loss=3.204, nll_loss=1.055, word_ins=2.871, length=3.329, ppl=9.22, wps=46647, ups=0.78, wpb=59498.1, bsz=1918.5, num_updates=95200, lr=0.000324102, gnorm=0.941, loss_scale=16384, train_wall=127, wall=125749
2023-01-14 02:45:22 | INFO | train_inner | epoch 049:    369 / 1978 loss=3.218, nll_loss=1.07, word_ins=2.886, length=3.328, ppl=9.31, wps=46451.4, ups=0.79, wpb=58956.3, bsz=1939.8, num_updates=95300, lr=0.000323932, gnorm=0.978, loss_scale=16384, train_wall=127, wall=125876
2023-01-14 02:47:30 | INFO | train_inner | epoch 049:    469 / 1978 loss=3.187, nll_loss=1.045, word_ins=2.863, length=3.248, ppl=9.11, wps=46477.9, ups=0.78, wpb=59420.1, bsz=2054.6, num_updates=95400, lr=0.000323762, gnorm=0.975, loss_scale=16384, train_wall=128, wall=126004
2023-01-14 02:49:38 | INFO | train_inner | epoch 049:    569 / 1978 loss=3.248, nll_loss=1.102, word_ins=2.914, length=3.337, ppl=9.5, wps=46217.7, ups=0.78, wpb=59286.1, bsz=1956.8, num_updates=95500, lr=0.000323592, gnorm=0.988, loss_scale=16384, train_wall=128, wall=126132
2023-01-14 02:51:46 | INFO | train_inner | epoch 049:    669 / 1978 loss=3.212, nll_loss=1.066, word_ins=2.881, length=3.31, ppl=9.27, wps=46256.7, ups=0.78, wpb=59152, bsz=1951.9, num_updates=95600, lr=0.000323423, gnorm=0.965, loss_scale=16384, train_wall=128, wall=126260
2023-01-14 02:53:53 | INFO | train_inner | epoch 049:    769 / 1978 loss=3.212, nll_loss=1.064, word_ins=2.879, length=3.33, ppl=9.27, wps=47024.6, ups=0.79, wpb=59636.2, bsz=1936.3, num_updates=95700, lr=0.000323254, gnorm=0.97, loss_scale=16384, train_wall=127, wall=126387
2023-01-14 02:56:01 | INFO | train_inner | epoch 049:    869 / 1978 loss=3.229, nll_loss=1.086, word_ins=2.9, length=3.291, ppl=9.37, wps=46513.3, ups=0.78, wpb=59403.6, bsz=1960.2, num_updates=95800, lr=0.000323085, gnorm=0.955, loss_scale=16384, train_wall=127, wall=126515
2023-01-14 02:58:09 | INFO | train_inner | epoch 049:    969 / 1978 loss=3.179, nll_loss=1.04, word_ins=2.858, length=3.209, ppl=9.06, wps=46811.9, ups=0.78, wpb=60000, bsz=2051.9, num_updates=95900, lr=0.000322917, gnorm=0.965, loss_scale=16384, train_wall=128, wall=126643
2023-01-14 03:00:18 | INFO | train_inner | epoch 049:   1069 / 1978 loss=3.16, nll_loss=1.016, word_ins=2.836, length=3.24, ppl=8.94, wps=46072.6, ups=0.77, wpb=59503.9, bsz=2152.6, num_updates=96000, lr=0.000322749, gnorm=0.959, loss_scale=16384, train_wall=129, wall=126772
2023-01-14 03:02:26 | INFO | train_inner | epoch 049:   1169 / 1978 loss=3.232, nll_loss=1.081, word_ins=2.896, length=3.362, ppl=9.39, wps=46329.5, ups=0.78, wpb=59065.4, bsz=1984, num_updates=96100, lr=0.000322581, gnorm=0.964, loss_scale=16384, train_wall=127, wall=126900
2023-01-14 03:04:34 | INFO | train_inner | epoch 049:   1269 / 1978 loss=3.182, nll_loss=1.046, word_ins=2.863, length=3.195, ppl=9.08, wps=45822.4, ups=0.78, wpb=59091.9, bsz=2122.7, num_updates=96200, lr=0.000322413, gnorm=0.951, loss_scale=16384, train_wall=128, wall=127029
2023-01-14 03:06:42 | INFO | train_inner | epoch 049:   1369 / 1978 loss=3.227, nll_loss=1.08, word_ins=2.894, length=3.332, ppl=9.36, wps=45694.8, ups=0.78, wpb=58419.8, bsz=2013, num_updates=96300, lr=0.000322245, gnorm=0.964, loss_scale=16384, train_wall=127, wall=127156
2023-01-14 03:08:51 | INFO | train_inner | epoch 049:   1469 / 1978 loss=3.207, nll_loss=1.058, word_ins=2.874, length=3.33, ppl=9.24, wps=46198.1, ups=0.78, wpb=59408.7, bsz=2016.3, num_updates=96400, lr=0.000322078, gnorm=0.969, loss_scale=16384, train_wall=128, wall=127285
2023-01-14 03:10:58 | INFO | train_inner | epoch 049:   1569 / 1978 loss=3.249, nll_loss=1.105, word_ins=2.917, length=3.329, ppl=9.51, wps=46171.5, ups=0.79, wpb=58721.2, bsz=1941.4, num_updates=96500, lr=0.000321911, gnorm=0.963, loss_scale=16384, train_wall=127, wall=127412
2023-01-14 03:13:07 | INFO | train_inner | epoch 049:   1669 / 1978 loss=3.197, nll_loss=1.056, word_ins=2.872, length=3.247, ppl=9.17, wps=46452.4, ups=0.78, wpb=59728.2, bsz=2017.4, num_updates=96600, lr=0.000321745, gnorm=0.974, loss_scale=16384, train_wall=128, wall=127541
2023-01-14 03:15:15 | INFO | train_inner | epoch 049:   1769 / 1978 loss=3.21, nll_loss=1.063, word_ins=2.879, length=3.315, ppl=9.25, wps=46184.7, ups=0.78, wpb=59199.2, bsz=1997.4, num_updates=96700, lr=0.000321578, gnorm=0.97, loss_scale=16384, train_wall=128, wall=127669
2023-01-14 03:17:22 | INFO | train_inner | epoch 049:   1869 / 1978 loss=3.217, nll_loss=1.073, word_ins=2.887, length=3.303, ppl=9.3, wps=46875.1, ups=0.79, wpb=59518.5, bsz=1967.3, num_updates=96800, lr=0.000321412, gnorm=0.981, loss_scale=16384, train_wall=127, wall=127796
2023-01-14 03:19:30 | INFO | train_inner | epoch 049:   1969 / 1978 loss=3.202, nll_loss=1.062, word_ins=2.877, length=3.248, ppl=9.2, wps=46379.3, ups=0.78, wpb=59626.7, bsz=2057.5, num_updates=96900, lr=0.000321246, gnorm=1.006, loss_scale=16384, train_wall=128, wall=127925
2023-01-14 03:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 03:19:53 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 4.422 | nll_loss 2.028 | word_ins 3.795 | length 6.276 | ppl 21.44 | wps 126189 | wpb 40242.5 | bsz 1500 | num_updates 96909 | best_loss 4.422
2023-01-14 03:19:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 03:20:34 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint49.pt (epoch 49 @ 96909 updates, score 4.422) (writing took 41.217912043910474 seconds)
2023-01-14 03:20:34 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-01-14 03:20:34 | INFO | train | epoch 049 | loss 3.211 | nll_loss 1.066 | word_ins 2.881 | length 3.296 | ppl 9.26 | wps 45229.1 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 96909 | lr 0.000321231 | gnorm 0.969 | loss_scale 16384 | train_wall 2523 | wall 127988
2023-01-14 03:20:34 | INFO | fairseq.trainer | begin training epoch 50
2023-01-14 03:22:42 | INFO | train_inner | epoch 050:     91 / 1978 loss=3.214, nll_loss=1.067, word_ins=2.882, length=3.32, ppl=9.28, wps=30514.8, ups=0.52, wpb=58597.1, bsz=2003.5, num_updates=97000, lr=0.000321081, gnorm=0.975, loss_scale=16384, train_wall=128, wall=128117
2023-01-14 03:24:50 | INFO | train_inner | epoch 050:    191 / 1978 loss=3.192, nll_loss=1.044, word_ins=2.862, length=3.3, ppl=9.14, wps=46496.6, ups=0.78, wpb=59251.4, bsz=1955.5, num_updates=97100, lr=0.000320915, gnorm=0.983, loss_scale=16384, train_wall=127, wall=128244
2023-01-14 03:26:58 | INFO | train_inner | epoch 050:    291 / 1978 loss=3.204, nll_loss=1.063, word_ins=2.878, length=3.259, ppl=9.22, wps=46458.7, ups=0.78, wpb=59342.7, bsz=1976.8, num_updates=97200, lr=0.00032075, gnorm=0.998, loss_scale=16384, train_wall=128, wall=128372
2023-01-14 03:29:06 | INFO | train_inner | epoch 050:    391 / 1978 loss=3.212, nll_loss=1.066, word_ins=2.882, length=3.308, ppl=9.27, wps=45965.6, ups=0.78, wpb=58971.9, bsz=2033.8, num_updates=97300, lr=0.000320585, gnorm=0.958, loss_scale=16384, train_wall=128, wall=128500
2023-01-14 03:31:15 | INFO | train_inner | epoch 050:    491 / 1978 loss=3.195, nll_loss=1.052, word_ins=2.869, length=3.259, ppl=9.16, wps=46092.2, ups=0.77, wpb=59490.2, bsz=2051.8, num_updates=97400, lr=0.000320421, gnorm=0.971, loss_scale=16384, train_wall=129, wall=128629
2023-01-14 03:33:24 | INFO | train_inner | epoch 050:    591 / 1978 loss=3.205, nll_loss=1.059, word_ins=2.875, length=3.295, ppl=9.22, wps=46189.9, ups=0.78, wpb=59399.6, bsz=2034.5, num_updates=97500, lr=0.000320256, gnorm=0.966, loss_scale=16384, train_wall=128, wall=128758
2023-01-14 03:35:31 | INFO | train_inner | epoch 050:    691 / 1978 loss=3.199, nll_loss=1.051, word_ins=2.867, length=3.313, ppl=9.18, wps=46861.5, ups=0.79, wpb=59466, bsz=2015.4, num_updates=97600, lr=0.000320092, gnorm=0.999, loss_scale=16384, train_wall=127, wall=128885
2023-01-14 03:37:38 | INFO | train_inner | epoch 050:    791 / 1978 loss=3.211, nll_loss=1.066, word_ins=2.881, length=3.298, ppl=9.26, wps=46712, ups=0.79, wpb=59345.1, bsz=1950, num_updates=97700, lr=0.000319928, gnorm=0.981, loss_scale=16384, train_wall=127, wall=129012
2023-01-14 03:39:45 | INFO | train_inner | epoch 050:    891 / 1978 loss=3.255, nll_loss=1.107, word_ins=2.918, length=3.366, ppl=9.55, wps=46678, ups=0.78, wpb=59479.2, bsz=1908.6, num_updates=97800, lr=0.000319765, gnorm=1.001, loss_scale=16384, train_wall=127, wall=129139
2023-01-14 03:41:53 | INFO | train_inner | epoch 050:    991 / 1978 loss=3.196, nll_loss=1.054, word_ins=2.869, length=3.266, ppl=9.16, wps=46302.1, ups=0.78, wpb=59151.6, bsz=2050.7, num_updates=97900, lr=0.000319601, gnorm=0.966, loss_scale=16384, train_wall=128, wall=129267
2023-01-14 03:42:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 03:44:03 | INFO | train_inner | epoch 050:   1092 / 1978 loss=3.203, nll_loss=1.055, word_ins=2.871, length=3.318, ppl=9.21, wps=46041.5, ups=0.77, wpb=59802.3, bsz=2007.4, num_updates=98000, lr=0.000319438, gnorm=1.01, loss_scale=16384, train_wall=130, wall=129397
2023-01-14 03:46:11 | INFO | train_inner | epoch 050:   1192 / 1978 loss=3.206, nll_loss=1.064, word_ins=2.879, length=3.272, ppl=9.23, wps=46082.3, ups=0.78, wpb=59247.8, bsz=2059.6, num_updates=98100, lr=0.000319275, gnorm=0.988, loss_scale=16384, train_wall=128, wall=129525
2023-01-14 03:48:18 | INFO | train_inner | epoch 050:   1292 / 1978 loss=3.201, nll_loss=1.053, word_ins=2.869, length=3.317, ppl=9.2, wps=46712.7, ups=0.79, wpb=59329.2, bsz=1963.7, num_updates=98200, lr=0.000319113, gnorm=0.995, loss_scale=16384, train_wall=127, wall=129652
2023-01-14 03:50:25 | INFO | train_inner | epoch 050:   1392 / 1978 loss=3.229, nll_loss=1.08, word_ins=2.894, length=3.359, ppl=9.38, wps=46246.6, ups=0.79, wpb=58579.3, bsz=1950.3, num_updates=98300, lr=0.00031895, gnorm=0.953, loss_scale=16384, train_wall=126, wall=129779
2023-01-14 03:52:33 | INFO | train_inner | epoch 050:   1492 / 1978 loss=3.212, nll_loss=1.071, word_ins=2.885, length=3.272, ppl=9.27, wps=46667.7, ups=0.78, wpb=59612.4, bsz=1949.3, num_updates=98400, lr=0.000318788, gnorm=0.981, loss_scale=16384, train_wall=127, wall=129907
2023-01-14 03:54:40 | INFO | train_inner | epoch 050:   1592 / 1978 loss=3.187, nll_loss=1.045, word_ins=2.862, length=3.25, ppl=9.11, wps=46532.1, ups=0.78, wpb=59428.8, bsz=2037.4, num_updates=98500, lr=0.000318626, gnorm=1.002, loss_scale=16384, train_wall=127, wall=130034
2023-01-14 03:56:49 | INFO | train_inner | epoch 050:   1692 / 1978 loss=3.197, nll_loss=1.049, word_ins=2.865, length=3.311, ppl=9.17, wps=46353.2, ups=0.78, wpb=59480.3, bsz=2056.3, num_updates=98600, lr=0.000318465, gnorm=1.002, loss_scale=16384, train_wall=128, wall=130163
2023-01-14 03:58:55 | INFO | train_inner | epoch 050:   1792 / 1978 loss=3.221, nll_loss=1.074, word_ins=2.887, length=3.333, ppl=9.32, wps=46618.5, ups=0.79, wpb=59074, bsz=1932, num_updates=98700, lr=0.000318304, gnorm=0.981, loss_scale=16384, train_wall=126, wall=130290
2023-01-14 04:01:04 | INFO | train_inner | epoch 050:   1892 / 1978 loss=3.169, nll_loss=1.026, word_ins=2.844, length=3.243, ppl=8.99, wps=46187.2, ups=0.78, wpb=59433.1, bsz=2084.3, num_updates=98800, lr=0.000318142, gnorm=0.954, loss_scale=16384, train_wall=128, wall=130418
2023-01-14 04:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 04:03:06 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 4.651 | nll_loss 2.015 | word_ins 3.781 | length 8.701 | ppl 25.13 | wps 107270 | wpb 40242.5 | bsz 1500 | num_updates 98886 | best_loss 4.422
2023-01-14 04:03:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 04:03:34 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint50.pt (epoch 50 @ 98886 updates, score 4.651) (writing took 27.838084268849343 seconds)
2023-01-14 04:03:34 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-01-14 04:03:34 | INFO | train | epoch 050 | loss 3.207 | nll_loss 1.061 | word_ins 2.877 | length 3.3 | ppl 9.23 | wps 45430.9 | ups 0.77 | wpb 59281.9 | bsz 2002.4 | num_updates 98886 | lr 0.000318004 | gnorm 0.982 | loss_scale 16384 | train_wall 2524 | wall 130568
2023-01-14 04:03:34 | INFO | fairseq.trainer | begin training epoch 51
2023-01-14 04:04:04 | INFO | train_inner | epoch 051:     14 / 1978 loss=3.239, nll_loss=1.088, word_ins=2.901, length=3.378, ppl=9.44, wps=32694.1, ups=0.56, wpb=58793.8, bsz=1996.9, num_updates=98900, lr=0.000317982, gnorm=0.997, loss_scale=16384, train_wall=128, wall=130598
2023-01-14 04:06:11 | INFO | train_inner | epoch 051:    114 / 1978 loss=3.202, nll_loss=1.055, word_ins=2.872, length=3.3, ppl=9.2, wps=46607.8, ups=0.78, wpb=59381.5, bsz=1871.1, num_updates=99000, lr=0.000317821, gnorm=1.016, loss_scale=16384, train_wall=127, wall=130725
2023-01-14 04:08:19 | INFO | train_inner | epoch 051:    214 / 1978 loss=3.2, nll_loss=1.059, word_ins=2.874, length=3.25, ppl=9.19, wps=46241.2, ups=0.78, wpb=59137.7, bsz=2018.2, num_updates=99100, lr=0.00031766, gnorm=0.995, loss_scale=16384, train_wall=127, wall=130853
2023-01-14 04:10:28 | INFO | train_inner | epoch 051:    314 / 1978 loss=3.187, nll_loss=1.051, word_ins=2.868, length=3.193, ppl=9.11, wps=45823.8, ups=0.78, wpb=59033.2, bsz=2059.9, num_updates=99200, lr=0.0003175, gnorm=1, loss_scale=16384, train_wall=128, wall=130982
2023-01-14 04:12:36 | INFO | train_inner | epoch 051:    414 / 1978 loss=3.203, nll_loss=1.061, word_ins=2.877, length=3.258, ppl=9.21, wps=45927.2, ups=0.78, wpb=58595.5, bsz=2026.4, num_updates=99300, lr=0.00031734, gnorm=0.981, loss_scale=16384, train_wall=127, wall=131110
2023-01-14 04:14:44 | INFO | train_inner | epoch 051:    514 / 1978 loss=3.2, nll_loss=1.055, word_ins=2.871, length=3.291, ppl=9.19, wps=46220.8, ups=0.78, wpb=59163.1, bsz=2022.7, num_updates=99400, lr=0.000317181, gnorm=0.981, loss_scale=16384, train_wall=128, wall=131238
2023-01-14 04:16:52 | INFO | train_inner | epoch 051:    614 / 1978 loss=3.174, nll_loss=1.031, word_ins=2.849, length=3.243, ppl=9.02, wps=46297.9, ups=0.78, wpb=59608.3, bsz=2068.5, num_updates=99500, lr=0.000317021, gnorm=0.979, loss_scale=16384, train_wall=129, wall=131367
2023-01-14 04:19:02 | INFO | train_inner | epoch 051:    714 / 1978 loss=3.187, nll_loss=1.045, word_ins=2.862, length=3.253, ppl=9.11, wps=45758, ups=0.77, wpb=59141.2, bsz=2040.2, num_updates=99600, lr=0.000316862, gnorm=0.985, loss_scale=16384, train_wall=129, wall=131496
2023-01-14 04:21:10 | INFO | train_inner | epoch 051:    814 / 1978 loss=3.175, nll_loss=1.03, word_ins=2.848, length=3.274, ppl=9.03, wps=46453.2, ups=0.78, wpb=59667.8, bsz=2021, num_updates=99700, lr=0.000316703, gnorm=1.009, loss_scale=16384, train_wall=128, wall=131624
2023-01-14 04:23:19 | INFO | train_inner | epoch 051:    914 / 1978 loss=3.189, nll_loss=1.051, word_ins=2.867, length=3.227, ppl=9.12, wps=46196.1, ups=0.78, wpb=59509.5, bsz=2074.8, num_updates=99800, lr=0.000316544, gnorm=1.019, loss_scale=16384, train_wall=129, wall=131753
2023-01-14 04:25:27 | INFO | train_inner | epoch 051:   1014 / 1978 loss=3.194, nll_loss=1.049, word_ins=2.865, length=3.289, ppl=9.15, wps=46288, ups=0.78, wpb=59458, bsz=2061.2, num_updates=99900, lr=0.000316386, gnorm=0.98, loss_scale=16384, train_wall=128, wall=131881
2023-01-14 04:27:35 | INFO | train_inner | epoch 051:   1114 / 1978 loss=3.217, nll_loss=1.069, word_ins=2.883, length=3.337, ppl=9.3, wps=46027, ups=0.78, wpb=58874.5, bsz=1973, num_updates=100000, lr=0.000316228, gnorm=1.01, loss_scale=16384, train_wall=128, wall=132009
2023-01-14 04:29:43 | INFO | train_inner | epoch 051:   1214 / 1978 loss=3.18, nll_loss=1.036, word_ins=2.854, length=3.262, ppl=9.06, wps=46906.8, ups=0.78, wpb=59820.4, bsz=1992.6, num_updates=100100, lr=0.00031607, gnorm=1.009, loss_scale=16384, train_wall=127, wall=132137
2023-01-14 04:31:52 | INFO | train_inner | epoch 051:   1314 / 1978 loss=3.171, nll_loss=1.032, word_ins=2.849, length=3.214, ppl=9.01, wps=46003.4, ups=0.77, wpb=59549.9, bsz=2089.3, num_updates=100200, lr=0.000315912, gnorm=0.979, loss_scale=16384, train_wall=129, wall=132266
2023-01-14 04:33:59 | INFO | train_inner | epoch 051:   1414 / 1978 loss=3.215, nll_loss=1.068, word_ins=2.883, length=3.317, ppl=9.28, wps=46780.4, ups=0.79, wpb=59115.2, bsz=1967.4, num_updates=100300, lr=0.000315754, gnorm=0.968, loss_scale=16384, train_wall=126, wall=132393
2023-01-14 04:36:08 | INFO | train_inner | epoch 051:   1514 / 1978 loss=3.193, nll_loss=1.055, word_ins=2.87, length=3.224, ppl=9.14, wps=45883.4, ups=0.77, wpb=59383.5, bsz=2085.8, num_updates=100400, lr=0.000315597, gnorm=0.969, loss_scale=16384, train_wall=129, wall=132522
2023-01-14 04:38:15 | INFO | train_inner | epoch 051:   1614 / 1978 loss=3.231, nll_loss=1.082, word_ins=2.895, length=3.359, ppl=9.39, wps=46197.8, ups=0.79, wpb=58777, bsz=1900.1, num_updates=100500, lr=0.00031544, gnorm=1.006, loss_scale=16384, train_wall=127, wall=132649
2023-01-14 04:40:23 | INFO | train_inner | epoch 051:   1714 / 1978 loss=3.22, nll_loss=1.071, word_ins=2.885, length=3.352, ppl=9.32, wps=46690.1, ups=0.78, wpb=59556.4, bsz=1923.8, num_updates=100600, lr=0.000315283, gnorm=1.01, loss_scale=16384, train_wall=127, wall=132777
2023-01-14 04:42:30 | INFO | train_inner | epoch 051:   1814 / 1978 loss=3.219, nll_loss=1.071, word_ins=2.885, length=3.334, ppl=9.31, wps=46670.1, ups=0.79, wpb=59353.4, bsz=1901.2, num_updates=100700, lr=0.000315127, gnorm=1.04, loss_scale=16384, train_wall=127, wall=132904
2023-01-14 04:44:39 | INFO | train_inner | epoch 051:   1914 / 1978 loss=3.183, nll_loss=1.042, word_ins=2.859, length=3.239, ppl=9.08, wps=46536.4, ups=0.78, wpb=59775.3, bsz=2028.8, num_updates=100800, lr=0.00031497, gnorm=0.992, loss_scale=16384, train_wall=128, wall=133033
2023-01-14 04:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 04:46:11 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 4.44 | nll_loss 2 | word_ins 3.774 | length 6.668 | ppl 21.71 | wps 138293 | wpb 40242.5 | bsz 1500 | num_updates 100864 | best_loss 4.422
2023-01-14 04:46:11 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 04:46:39 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint51.pt (epoch 51 @ 100864 updates, score 4.44) (writing took 27.596730229910463 seconds)
2023-01-14 04:46:39 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-01-14 04:46:39 | INFO | train | epoch 051 | loss 3.199 | nll_loss 1.055 | word_ins 2.871 | length 3.278 | ppl 9.18 | wps 45356.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 100864 | lr 0.00031487 | gnorm 0.996 | loss_scale 16384 | train_wall 2528 | wall 133153
2023-01-14 04:46:39 | INFO | fairseq.trainer | begin training epoch 52
2023-01-14 04:47:36 | INFO | train_inner | epoch 052:     36 / 1978 loss=3.228, nll_loss=1.079, word_ins=2.893, length=3.344, ppl=9.37, wps=32967.9, ups=0.56, wpb=58549.2, bsz=1918, num_updates=100900, lr=0.000314814, gnorm=0.987, loss_scale=16384, train_wall=126, wall=133210
2023-01-14 04:49:43 | INFO | train_inner | epoch 052:    136 / 1978 loss=3.205, nll_loss=1.062, word_ins=2.877, length=3.278, ppl=9.22, wps=46659.4, ups=0.79, wpb=59367.8, bsz=1936.6, num_updates=101000, lr=0.000314658, gnorm=1.002, loss_scale=16384, train_wall=127, wall=133337
2023-01-14 04:51:51 | INFO | train_inner | epoch 052:    236 / 1978 loss=3.188, nll_loss=1.05, word_ins=2.867, length=3.216, ppl=9.12, wps=46380.7, ups=0.78, wpb=59341.7, bsz=2044, num_updates=101100, lr=0.000314503, gnorm=1.016, loss_scale=16384, train_wall=128, wall=133465
2023-01-14 04:53:59 | INFO | train_inner | epoch 052:    336 / 1978 loss=3.2, nll_loss=1.054, word_ins=2.87, length=3.299, ppl=9.19, wps=46082.4, ups=0.78, wpb=59050.9, bsz=2011.8, num_updates=101200, lr=0.000314347, gnorm=1.013, loss_scale=16384, train_wall=128, wall=133594
2023-01-14 04:56:08 | INFO | train_inner | epoch 052:    436 / 1978 loss=3.183, nll_loss=1.038, word_ins=2.856, length=3.27, ppl=9.08, wps=46299.3, ups=0.78, wpb=59431.1, bsz=1985.8, num_updates=101300, lr=0.000314192, gnorm=1.009, loss_scale=16384, train_wall=128, wall=133722
2023-01-14 04:58:15 | INFO | train_inner | epoch 052:    536 / 1978 loss=3.189, nll_loss=1.043, word_ins=2.86, length=3.291, ppl=9.12, wps=46727.6, ups=0.79, wpb=59372, bsz=1981.4, num_updates=101400, lr=0.000314037, gnorm=0.987, loss_scale=16384, train_wall=127, wall=133849
2023-01-14 05:00:24 | INFO | train_inner | epoch 052:    636 / 1978 loss=3.172, nll_loss=1.032, word_ins=2.85, length=3.219, ppl=9.01, wps=46455.2, ups=0.78, wpb=59923.4, bsz=2062.1, num_updates=101500, lr=0.000313882, gnorm=1.009, loss_scale=16384, train_wall=129, wall=133978
2023-01-14 05:02:31 | INFO | train_inner | epoch 052:    736 / 1978 loss=3.191, nll_loss=1.044, word_ins=2.861, length=3.299, ppl=9.13, wps=46264.9, ups=0.79, wpb=58834.5, bsz=1962.8, num_updates=101600, lr=0.000313728, gnorm=1.001, loss_scale=16384, train_wall=127, wall=134105
2023-01-14 05:04:40 | INFO | train_inner | epoch 052:    836 / 1978 loss=3.202, nll_loss=1.059, word_ins=2.874, length=3.271, ppl=9.2, wps=45915.7, ups=0.78, wpb=59089.8, bsz=2031.8, num_updates=101700, lr=0.000313574, gnorm=1.002, loss_scale=16384, train_wall=128, wall=134234
2023-01-14 05:06:47 | INFO | train_inner | epoch 052:    936 / 1978 loss=3.194, nll_loss=1.051, word_ins=2.867, length=3.266, ppl=9.15, wps=46458.8, ups=0.79, wpb=59136.7, bsz=2011.7, num_updates=101800, lr=0.00031342, gnorm=0.978, loss_scale=16384, train_wall=127, wall=134361
2023-01-14 05:08:55 | INFO | train_inner | epoch 052:   1036 / 1978 loss=3.171, nll_loss=1.027, word_ins=2.845, length=3.254, ppl=9.01, wps=46648, ups=0.78, wpb=59568.8, bsz=2002.7, num_updates=101900, lr=0.000313266, gnorm=1, loss_scale=16384, train_wall=127, wall=134489
2023-01-14 05:11:03 | INFO | train_inner | epoch 052:   1136 / 1978 loss=3.186, nll_loss=1.044, word_ins=2.861, length=3.249, ppl=9.1, wps=46531.5, ups=0.78, wpb=59459.6, bsz=2042.4, num_updates=102000, lr=0.000313112, gnorm=1.033, loss_scale=16384, train_wall=128, wall=134617
2023-01-14 05:11:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 05:13:11 | INFO | train_inner | epoch 052:   1237 / 1978 loss=3.188, nll_loss=1.044, word_ins=2.861, length=3.274, ppl=9.12, wps=46225.1, ups=0.78, wpb=59588.4, bsz=1994.7, num_updates=102100, lr=0.000312959, gnorm=1.03, loss_scale=16384, train_wall=129, wall=134746
2023-01-14 05:15:19 | INFO | train_inner | epoch 052:   1337 / 1978 loss=3.214, nll_loss=1.068, word_ins=2.883, length=3.315, ppl=9.28, wps=46509.3, ups=0.78, wpb=59386.7, bsz=2003.6, num_updates=102200, lr=0.000312806, gnorm=1.029, loss_scale=16384, train_wall=127, wall=134873
2023-01-14 05:17:26 | INFO | train_inner | epoch 052:   1437 / 1978 loss=3.224, nll_loss=1.078, word_ins=2.892, length=3.325, ppl=9.35, wps=46210.6, ups=0.79, wpb=58608.2, bsz=1937.8, num_updates=102300, lr=0.000312653, gnorm=1.009, loss_scale=16384, train_wall=127, wall=135000
2023-01-14 05:19:34 | INFO | train_inner | epoch 052:   1537 / 1978 loss=3.147, nll_loss=1.012, word_ins=2.832, length=3.156, ppl=8.86, wps=46484.2, ups=0.78, wpb=59521.8, bsz=2107.4, num_updates=102400, lr=0.0003125, gnorm=0.966, loss_scale=16384, train_wall=128, wall=135128
2023-01-14 05:21:42 | INFO | train_inner | epoch 052:   1637 / 1978 loss=3.205, nll_loss=1.062, word_ins=2.877, length=3.279, ppl=9.22, wps=46498.3, ups=0.78, wpb=59317.2, bsz=1995.8, num_updates=102500, lr=0.000312348, gnorm=1.034, loss_scale=16384, train_wall=127, wall=135256
2023-01-14 05:23:49 | INFO | train_inner | epoch 052:   1737 / 1978 loss=3.188, nll_loss=1.042, word_ins=2.858, length=3.302, ppl=9.12, wps=46916.5, ups=0.79, wpb=59556.1, bsz=1953.8, num_updates=102600, lr=0.000312195, gnorm=1.003, loss_scale=16384, train_wall=127, wall=135383
2023-01-14 05:25:56 | INFO | train_inner | epoch 052:   1837 / 1978 loss=3.214, nll_loss=1.064, word_ins=2.879, length=3.351, ppl=9.28, wps=46201.5, ups=0.78, wpb=59030.3, bsz=1956.2, num_updates=102700, lr=0.000312043, gnorm=1.031, loss_scale=16384, train_wall=127, wall=135510
2023-01-14 05:28:04 | INFO | train_inner | epoch 052:   1937 / 1978 loss=3.193, nll_loss=1.049, word_ins=2.866, length=3.273, ppl=9.14, wps=46335.2, ups=0.78, wpb=59164.3, bsz=1994.6, num_updates=102800, lr=0.000311891, gnorm=1.02, loss_scale=16384, train_wall=127, wall=135638
2023-01-14 05:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 05:29:09 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 4.473 | nll_loss 1.995 | word_ins 3.767 | length 7.056 | ppl 22.21 | wps 104393 | wpb 40242.5 | bsz 1500 | num_updates 102841 | best_loss 4.422
2023-01-14 05:29:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 05:29:37 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint52.pt (epoch 52 @ 102841 updates, score 4.473) (writing took 27.776147558819503 seconds)
2023-01-14 05:29:37 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-01-14 05:29:37 | INFO | train | epoch 052 | loss 3.191 | nll_loss 1.048 | word_ins 2.864 | length 3.273 | ppl 9.13 | wps 45466.3 | ups 0.77 | wpb 59283.8 | bsz 2002.8 | num_updates 102841 | lr 0.000311829 | gnorm 1.009 | loss_scale 16384 | train_wall 2522 | wall 135731
2023-01-14 05:29:37 | INFO | fairseq.trainer | begin training epoch 53
2023-01-14 05:31:04 | INFO | train_inner | epoch 053:     59 / 1978 loss=3.158, nll_loss=1.016, word_ins=2.835, length=3.231, ppl=8.93, wps=32773.2, ups=0.56, wpb=59041.3, bsz=2096.5, num_updates=102900, lr=0.00031174, gnorm=1.013, loss_scale=16384, train_wall=129, wall=135818
2023-01-14 05:33:12 | INFO | train_inner | epoch 053:    159 / 1978 loss=3.18, nll_loss=1.039, word_ins=2.856, length=3.242, ppl=9.06, wps=46795.4, ups=0.78, wpb=59833.2, bsz=1960.6, num_updates=103000, lr=0.000311588, gnorm=1.042, loss_scale=16384, train_wall=128, wall=135946
2023-01-14 05:35:20 | INFO | train_inner | epoch 053:    259 / 1978 loss=3.161, nll_loss=1.02, word_ins=2.84, length=3.211, ppl=8.94, wps=46470.5, ups=0.78, wpb=59229.1, bsz=2082.4, num_updates=103100, lr=0.000311437, gnorm=0.992, loss_scale=16384, train_wall=127, wall=136074
2023-01-14 05:37:25 | INFO | train_inner | epoch 053:    359 / 1978 loss=3.223, nll_loss=1.075, word_ins=2.889, length=3.34, ppl=9.34, wps=46835.7, ups=0.8, wpb=58816.5, bsz=1834.8, num_updates=103200, lr=0.000311286, gnorm=1.036, loss_scale=16384, train_wall=125, wall=136199
2023-01-14 05:39:34 | INFO | train_inner | epoch 053:    459 / 1978 loss=3.149, nll_loss=1.01, word_ins=2.829, length=3.199, ppl=8.87, wps=46133.7, ups=0.77, wpb=59649.2, bsz=2125.8, num_updates=103300, lr=0.000311136, gnorm=1.012, loss_scale=16384, train_wall=129, wall=136328
2023-01-14 05:41:42 | INFO | train_inner | epoch 053:    559 / 1978 loss=3.175, nll_loss=1.033, word_ins=2.85, length=3.25, ppl=9.03, wps=47065.8, ups=0.78, wpb=60017.6, bsz=2022.2, num_updates=103400, lr=0.000310985, gnorm=1.032, loss_scale=16384, train_wall=127, wall=136456
2023-01-14 05:43:50 | INFO | train_inner | epoch 053:    659 / 1978 loss=3.197, nll_loss=1.057, word_ins=2.873, length=3.239, ppl=9.17, wps=46056.7, ups=0.78, wpb=58759.8, bsz=2003.2, num_updates=103500, lr=0.000310835, gnorm=1.029, loss_scale=16384, train_wall=127, wall=136584
2023-01-14 05:45:57 | INFO | train_inner | epoch 053:    759 / 1978 loss=3.203, nll_loss=1.055, word_ins=2.872, length=3.312, ppl=9.21, wps=46099.3, ups=0.79, wpb=58666.7, bsz=2006.5, num_updates=103600, lr=0.000310685, gnorm=1.025, loss_scale=16384, train_wall=127, wall=136711
2023-01-14 05:48:04 | INFO | train_inner | epoch 053:    859 / 1978 loss=3.191, nll_loss=1.043, word_ins=2.86, length=3.307, ppl=9.13, wps=46290.1, ups=0.79, wpb=58935.5, bsz=1967.2, num_updates=103700, lr=0.000310535, gnorm=0.99, loss_scale=16384, train_wall=127, wall=136838
2023-01-14 05:50:12 | INFO | train_inner | epoch 053:    959 / 1978 loss=3.218, nll_loss=1.074, word_ins=2.889, length=3.294, ppl=9.3, wps=46788.4, ups=0.78, wpb=59722.2, bsz=1928.4, num_updates=103800, lr=0.000310385, gnorm=1.06, loss_scale=16384, train_wall=127, wall=136966
2023-01-14 05:52:19 | INFO | train_inner | epoch 053:   1059 / 1978 loss=3.209, nll_loss=1.062, word_ins=2.877, length=3.317, ppl=9.25, wps=46129.4, ups=0.79, wpb=58725.5, bsz=1959.2, num_updates=103900, lr=0.000310236, gnorm=1.011, loss_scale=16384, train_wall=127, wall=137093
2023-01-14 05:54:27 | INFO | train_inner | epoch 053:   1159 / 1978 loss=3.176, nll_loss=1.028, word_ins=2.846, length=3.298, ppl=9.04, wps=46346.9, ups=0.78, wpb=59390.8, bsz=2043.5, num_updates=104000, lr=0.000310087, gnorm=1.04, loss_scale=16384, train_wall=128, wall=137221
2023-01-14 05:56:36 | INFO | train_inner | epoch 053:   1259 / 1978 loss=3.17, nll_loss=1.032, word_ins=2.849, length=3.203, ppl=9, wps=45938, ups=0.78, wpb=59162.6, bsz=2047.9, num_updates=104100, lr=0.000309938, gnorm=1.029, loss_scale=16384, train_wall=128, wall=137350
2023-01-14 05:58:42 | INFO | train_inner | epoch 053:   1359 / 1978 loss=3.21, nll_loss=1.058, word_ins=2.874, length=3.365, ppl=9.26, wps=46871.3, ups=0.79, wpb=59290.7, bsz=1881.4, num_updates=104200, lr=0.000309789, gnorm=1.04, loss_scale=16384, train_wall=126, wall=137477
2023-01-14 06:00:52 | INFO | train_inner | epoch 053:   1459 / 1978 loss=3.164, nll_loss=1.025, word_ins=2.843, length=3.208, ppl=8.96, wps=46005.3, ups=0.77, wpb=59401.5, bsz=2077, num_updates=104300, lr=0.000309641, gnorm=1.027, loss_scale=16384, train_wall=129, wall=137606
2023-01-14 06:02:59 | INFO | train_inner | epoch 053:   1559 / 1978 loss=3.186, nll_loss=1.041, word_ins=2.858, length=3.287, ppl=9.1, wps=47034.1, ups=0.79, wpb=59908.8, bsz=1976.8, num_updates=104400, lr=0.000309492, gnorm=1.035, loss_scale=16384, train_wall=127, wall=137733
2023-01-14 06:05:07 | INFO | train_inner | epoch 053:   1659 / 1978 loss=3.167, nll_loss=1.026, word_ins=2.844, length=3.233, ppl=8.98, wps=46682.1, ups=0.78, wpb=59722.8, bsz=2049.1, num_updates=104500, lr=0.000309344, gnorm=1.007, loss_scale=16384, train_wall=128, wall=137861
2023-01-14 06:07:14 | INFO | train_inner | epoch 053:   1759 / 1978 loss=3.216, nll_loss=1.067, word_ins=2.88, length=3.354, ppl=9.29, wps=46564.3, ups=0.78, wpb=59340.2, bsz=1958.6, num_updates=104600, lr=0.000309196, gnorm=1.024, loss_scale=16384, train_wall=127, wall=137988
2023-01-14 06:09:22 | INFO | train_inner | epoch 053:   1859 / 1978 loss=3.187, nll_loss=1.042, word_ins=2.858, length=3.286, ppl=9.11, wps=46026.3, ups=0.78, wpb=58900.1, bsz=2050.3, num_updates=104700, lr=0.000309049, gnorm=1.02, loss_scale=16384, train_wall=128, wall=138116
2023-01-14 06:11:31 | INFO | train_inner | epoch 053:   1959 / 1978 loss=3.176, nll_loss=1.027, word_ins=2.845, length=3.314, ppl=9.04, wps=46190.8, ups=0.78, wpb=59332.7, bsz=2063, num_updates=104800, lr=0.000308901, gnorm=1.006, loss_scale=16384, train_wall=128, wall=138245
2023-01-14 06:11:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 06:12:06 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 4.524 | nll_loss 2.021 | word_ins 3.787 | length 7.366 | ppl 23.01 | wps 161512 | wpb 40242.5 | bsz 1500 | num_updates 104819 | best_loss 4.422
2023-01-14 06:12:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 06:12:35 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint53.pt (epoch 53 @ 104819 updates, score 4.524) (writing took 28.22848756564781 seconds)
2023-01-14 06:12:35 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-01-14 06:12:35 | INFO | train | epoch 053 | loss 3.187 | nll_loss 1.043 | word_ins 2.859 | length 3.276 | ppl 9.11 | wps 45490.7 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 104819 | lr 0.000308873 | gnorm 1.023 | loss_scale 16384 | train_wall 2521 | wall 138309
2023-01-14 06:12:35 | INFO | fairseq.trainer | begin training epoch 54
2023-01-14 06:14:30 | INFO | train_inner | epoch 054:     81 / 1978 loss=3.172, nll_loss=1.03, word_ins=2.848, length=3.245, ppl=9.02, wps=33022.2, ups=0.56, wpb=59178.4, bsz=1977.4, num_updates=104900, lr=0.000308754, gnorm=1.013, loss_scale=16384, train_wall=127, wall=138424
2023-01-14 06:16:38 | INFO | train_inner | epoch 054:    181 / 1978 loss=3.152, nll_loss=1.009, word_ins=2.83, length=3.222, ppl=8.89, wps=46324.1, ups=0.78, wpb=59123.1, bsz=2003.6, num_updates=105000, lr=0.000308607, gnorm=1.026, loss_scale=16384, train_wall=127, wall=138552
2023-01-14 06:18:47 | INFO | train_inner | epoch 054:    281 / 1978 loss=3.159, nll_loss=1.018, word_ins=2.837, length=3.226, ppl=8.93, wps=46143.6, ups=0.77, wpb=59636.9, bsz=2117.9, num_updates=105100, lr=0.00030846, gnorm=1.03, loss_scale=16384, train_wall=129, wall=138681
2023-01-14 06:20:55 | INFO | train_inner | epoch 054:    381 / 1978 loss=3.178, nll_loss=1.033, word_ins=2.85, length=3.276, ppl=9.05, wps=46443.8, ups=0.78, wpb=59301.5, bsz=1994.3, num_updates=105200, lr=0.000308313, gnorm=1.009, loss_scale=16384, train_wall=127, wall=138809
2023-01-14 06:23:02 | INFO | train_inner | epoch 054:    481 / 1978 loss=3.19, nll_loss=1.05, word_ins=2.866, length=3.236, ppl=9.13, wps=46453.1, ups=0.78, wpb=59350.2, bsz=1998.4, num_updates=105300, lr=0.000308167, gnorm=1.038, loss_scale=16384, train_wall=128, wall=138936
2023-01-14 06:25:11 | INFO | train_inner | epoch 054:    581 / 1978 loss=3.162, nll_loss=1.022, word_ins=2.84, length=3.221, ppl=8.95, wps=46180.6, ups=0.78, wpb=59428.8, bsz=2085, num_updates=105400, lr=0.000308021, gnorm=1.032, loss_scale=16384, train_wall=128, wall=139065
2023-01-14 06:27:20 | INFO | train_inner | epoch 054:    681 / 1978 loss=3.195, nll_loss=1.05, word_ins=2.866, length=3.291, ppl=9.16, wps=46245.6, ups=0.78, wpb=59652.4, bsz=2041.8, num_updates=105500, lr=0.000307875, gnorm=1.045, loss_scale=16384, train_wall=129, wall=139194
2023-01-14 06:29:28 | INFO | train_inner | epoch 054:    781 / 1978 loss=3.18, nll_loss=1.029, word_ins=2.847, length=3.331, ppl=9.06, wps=46659.8, ups=0.78, wpb=59552.6, bsz=1959.2, num_updates=105600, lr=0.000307729, gnorm=1.047, loss_scale=16384, train_wall=127, wall=139322
2023-01-14 06:31:35 | INFO | train_inner | epoch 054:    881 / 1978 loss=3.198, nll_loss=1.057, word_ins=2.872, length=3.261, ppl=9.18, wps=46592.5, ups=0.79, wpb=59151.4, bsz=1919.2, num_updates=105700, lr=0.000307583, gnorm=1.046, loss_scale=16384, train_wall=127, wall=139449
2023-01-14 06:33:43 | INFO | train_inner | epoch 054:    981 / 1978 loss=3.179, nll_loss=1.039, word_ins=2.856, length=3.238, ppl=9.06, wps=46340.2, ups=0.78, wpb=59267, bsz=2022.5, num_updates=105800, lr=0.000307438, gnorm=1.017, loss_scale=16384, train_wall=128, wall=139577
2023-01-14 06:35:50 | INFO | train_inner | epoch 054:   1081 / 1978 loss=3.201, nll_loss=1.055, word_ins=2.87, length=3.311, ppl=9.2, wps=46469.1, ups=0.78, wpb=59255.6, bsz=1984.5, num_updates=105900, lr=0.000307293, gnorm=1.067, loss_scale=16384, train_wall=127, wall=139704
2023-01-14 06:37:58 | INFO | train_inner | epoch 054:   1181 / 1978 loss=3.18, nll_loss=1.034, word_ins=2.851, length=3.29, ppl=9.06, wps=46352.4, ups=0.78, wpb=59149.6, bsz=2003.8, num_updates=106000, lr=0.000307148, gnorm=1.034, loss_scale=16384, train_wall=127, wall=139832
2023-01-14 06:40:06 | INFO | train_inner | epoch 054:   1281 / 1978 loss=3.18, nll_loss=1.038, word_ins=2.855, length=3.259, ppl=9.07, wps=46586.5, ups=0.78, wpb=59618.1, bsz=1946.3, num_updates=106100, lr=0.000307003, gnorm=1.051, loss_scale=16384, train_wall=128, wall=139960
2023-01-14 06:40:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 06:42:15 | INFO | train_inner | epoch 054:   1382 / 1978 loss=3.187, nll_loss=1.043, word_ins=2.86, length=3.267, ppl=9.1, wps=45614.1, ups=0.77, wpb=58965.9, bsz=2015.8, num_updates=106200, lr=0.000306858, gnorm=1.056, loss_scale=16384, train_wall=129, wall=140089
2023-01-14 06:44:23 | INFO | train_inner | epoch 054:   1482 / 1978 loss=3.167, nll_loss=1.019, word_ins=2.837, length=3.303, ppl=8.98, wps=46303.7, ups=0.78, wpb=59176.2, bsz=2010.2, num_updates=106300, lr=0.000306714, gnorm=1.01, loss_scale=16384, train_wall=127, wall=140217
2023-01-14 06:46:30 | INFO | train_inner | epoch 054:   1582 / 1978 loss=3.196, nll_loss=1.049, word_ins=2.866, length=3.301, ppl=9.16, wps=46658.8, ups=0.79, wpb=59244.8, bsz=1962.1, num_updates=106400, lr=0.00030657, gnorm=1.041, loss_scale=16384, train_wall=127, wall=140344
2023-01-14 06:48:38 | INFO | train_inner | epoch 054:   1682 / 1978 loss=3.168, nll_loss=1.032, word_ins=2.849, length=3.189, ppl=8.99, wps=46338.2, ups=0.78, wpb=59445.4, bsz=2118.2, num_updates=106500, lr=0.000306426, gnorm=1.032, loss_scale=16384, train_wall=128, wall=140472
2023-01-14 06:50:47 | INFO | train_inner | epoch 054:   1782 / 1978 loss=3.167, nll_loss=1.022, word_ins=2.84, length=3.276, ppl=8.98, wps=46180.7, ups=0.78, wpb=59492.5, bsz=2039.8, num_updates=106600, lr=0.000306282, gnorm=1.044, loss_scale=16384, train_wall=129, wall=140601
2023-01-14 06:52:52 | INFO | train_inner | epoch 054:   1882 / 1978 loss=3.236, nll_loss=1.085, word_ins=2.898, length=3.379, ppl=9.42, wps=46972.1, ups=0.8, wpb=58844.5, bsz=1835.2, num_updates=106700, lr=0.000306138, gnorm=1.069, loss_scale=16384, train_wall=125, wall=140726
2023-01-14 06:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 06:55:06 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 4.566 | nll_loss 2.012 | word_ins 3.781 | length 7.854 | ppl 23.68 | wps 136410 | wpb 40242.5 | bsz 1500 | num_updates 106796 | best_loss 4.422
2023-01-14 06:55:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 06:55:34 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint54.pt (epoch 54 @ 106796 updates, score 4.566) (writing took 27.845183136872947 seconds)
2023-01-14 06:55:34 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-01-14 06:55:34 | INFO | train | epoch 054 | loss 3.181 | nll_loss 1.037 | word_ins 2.854 | length 3.271 | ppl 9.07 | wps 45438.4 | ups 0.77 | wpb 59283.8 | bsz 2002.4 | num_updates 106796 | lr 0.000306001 | gnorm 1.038 | loss_scale 16384 | train_wall 2522 | wall 140888
2023-01-14 06:55:34 | INFO | fairseq.trainer | begin training epoch 55
2023-01-14 06:55:51 | INFO | train_inner | epoch 055:      4 / 1978 loss=3.185, nll_loss=1.037, word_ins=2.854, length=3.306, ppl=9.09, wps=32797.2, ups=0.56, wpb=58578.5, bsz=1996.8, num_updates=106800, lr=0.000305995, gnorm=1.049, loss_scale=16384, train_wall=127, wall=140905
2023-01-14 06:57:57 | INFO | train_inner | epoch 055:    104 / 1978 loss=3.184, nll_loss=1.042, word_ins=2.859, length=3.251, ppl=9.09, wps=46633.8, ups=0.79, wpb=59058.9, bsz=1928.4, num_updates=106900, lr=0.000305852, gnorm=1.019, loss_scale=16384, train_wall=126, wall=141031
2023-01-14 07:00:05 | INFO | train_inner | epoch 055:    204 / 1978 loss=3.202, nll_loss=1.06, word_ins=2.875, length=3.267, ppl=9.2, wps=46433.5, ups=0.78, wpb=59290.7, bsz=1945.9, num_updates=107000, lr=0.000305709, gnorm=1.063, loss_scale=16384, train_wall=127, wall=141159
2023-01-14 07:02:14 | INFO | train_inner | epoch 055:    304 / 1978 loss=3.158, nll_loss=1.019, word_ins=2.838, length=3.197, ppl=8.92, wps=45723.7, ups=0.78, wpb=58978, bsz=2092.2, num_updates=107100, lr=0.000305566, gnorm=1.033, loss_scale=16384, train_wall=129, wall=141288
2023-01-14 07:04:22 | INFO | train_inner | epoch 055:    404 / 1978 loss=3.147, nll_loss=1.009, word_ins=2.829, length=3.187, ppl=8.86, wps=46314.3, ups=0.78, wpb=59420.6, bsz=2004.2, num_updates=107200, lr=0.000305424, gnorm=1.032, loss_scale=16384, train_wall=128, wall=141416
2023-01-14 07:06:29 | INFO | train_inner | epoch 055:    504 / 1978 loss=3.203, nll_loss=1.055, word_ins=2.871, length=3.324, ppl=9.21, wps=46495.1, ups=0.79, wpb=59020.5, bsz=1930.9, num_updates=107300, lr=0.000305281, gnorm=1.071, loss_scale=16384, train_wall=127, wall=141543
2023-01-14 07:08:36 | INFO | train_inner | epoch 055:    604 / 1978 loss=3.184, nll_loss=1.042, word_ins=2.859, length=3.256, ppl=9.09, wps=46712.9, ups=0.79, wpb=59082.2, bsz=1927.4, num_updates=107400, lr=0.000305139, gnorm=1.043, loss_scale=16384, train_wall=126, wall=141670
2023-01-14 07:10:45 | INFO | train_inner | epoch 055:    704 / 1978 loss=3.167, nll_loss=1.021, word_ins=2.84, length=3.275, ppl=8.98, wps=45793.5, ups=0.78, wpb=58992.9, bsz=2088.1, num_updates=107500, lr=0.000304997, gnorm=1.035, loss_scale=16384, train_wall=129, wall=141799
2023-01-14 07:12:54 | INFO | train_inner | epoch 055:    804 / 1978 loss=3.145, nll_loss=1.007, word_ins=2.826, length=3.187, ppl=8.85, wps=46376.2, ups=0.77, wpb=59965.7, bsz=2075.5, num_updates=107600, lr=0.000304855, gnorm=1.034, loss_scale=16384, train_wall=129, wall=141928
2023-01-14 07:15:02 | INFO | train_inner | epoch 055:    904 / 1978 loss=3.174, nll_loss=1.025, word_ins=2.843, length=3.305, ppl=9.02, wps=46390, ups=0.78, wpb=59283.3, bsz=2053.3, num_updates=107700, lr=0.000304714, gnorm=1.039, loss_scale=16384, train_wall=128, wall=142056
2023-01-14 07:17:09 | INFO | train_inner | epoch 055:   1004 / 1978 loss=3.17, nll_loss=1.027, word_ins=2.845, length=3.246, ppl=9, wps=46375.1, ups=0.78, wpb=59225.7, bsz=2006.7, num_updates=107800, lr=0.000304572, gnorm=1.073, loss_scale=16384, train_wall=127, wall=142184
2023-01-14 07:19:17 | INFO | train_inner | epoch 055:   1104 / 1978 loss=3.18, nll_loss=1.038, word_ins=2.855, length=3.253, ppl=9.06, wps=46507.6, ups=0.78, wpb=59331.8, bsz=2000.2, num_updates=107900, lr=0.000304431, gnorm=1.073, loss_scale=16384, train_wall=127, wall=142311
2023-01-14 07:21:25 | INFO | train_inner | epoch 055:   1204 / 1978 loss=3.169, nll_loss=1.027, word_ins=2.845, length=3.243, ppl=8.99, wps=46757.2, ups=0.78, wpb=59634.8, bsz=2005, num_updates=108000, lr=0.00030429, gnorm=1.091, loss_scale=16384, train_wall=127, wall=142439
2023-01-14 07:23:33 | INFO | train_inner | epoch 055:   1304 / 1978 loss=3.165, nll_loss=1.023, word_ins=2.841, length=3.243, ppl=8.97, wps=46268, ups=0.78, wpb=59272.1, bsz=2017.1, num_updates=108100, lr=0.00030415, gnorm=1.056, loss_scale=16384, train_wall=128, wall=142567
2023-01-14 07:25:41 | INFO | train_inner | epoch 055:   1404 / 1978 loss=3.163, nll_loss=1.02, word_ins=2.839, length=3.239, ppl=8.96, wps=46163.4, ups=0.78, wpb=59070, bsz=2035.2, num_updates=108200, lr=0.000304009, gnorm=1.055, loss_scale=16384, train_wall=128, wall=142695
2023-01-14 07:27:48 | INFO | train_inner | epoch 055:   1504 / 1978 loss=3.176, nll_loss=1.031, word_ins=2.848, length=3.283, ppl=9.04, wps=46381.6, ups=0.78, wpb=59263.9, bsz=2011.5, num_updates=108300, lr=0.000303869, gnorm=1.031, loss_scale=16384, train_wall=128, wall=142823
2023-01-14 07:29:56 | INFO | train_inner | epoch 055:   1604 / 1978 loss=3.208, nll_loss=1.057, word_ins=2.872, length=3.362, ppl=9.24, wps=46578.7, ups=0.79, wpb=59210.2, bsz=1907.4, num_updates=108400, lr=0.000303728, gnorm=1.067, loss_scale=16384, train_wall=127, wall=142950
2023-01-14 07:32:03 | INFO | train_inner | epoch 055:   1704 / 1978 loss=3.173, nll_loss=1.03, word_ins=2.847, length=3.255, ppl=9.02, wps=46405.6, ups=0.78, wpb=59206, bsz=2020.8, num_updates=108500, lr=0.000303588, gnorm=1.049, loss_scale=16384, train_wall=127, wall=143077
2023-01-14 07:34:11 | INFO | train_inner | epoch 055:   1804 / 1978 loss=3.179, nll_loss=1.037, word_ins=2.853, length=3.262, ppl=9.06, wps=46608.6, ups=0.78, wpb=59677.5, bsz=2009.4, num_updates=108600, lr=0.000303449, gnorm=1.064, loss_scale=16384, train_wall=128, wall=143205
2023-01-14 07:36:20 | INFO | train_inner | epoch 055:   1904 / 1978 loss=3.157, nll_loss=1.015, word_ins=2.833, length=3.235, ppl=8.92, wps=46123.1, ups=0.77, wpb=59628.9, bsz=2086.8, num_updates=108700, lr=0.000303309, gnorm=1.079, loss_scale=16384, train_wall=129, wall=143335
2023-01-14 07:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 07:38:09 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 4.495 | nll_loss 1.993 | word_ins 3.761 | length 7.339 | ppl 22.56 | wps 136734 | wpb 40242.5 | bsz 1500 | num_updates 108774 | best_loss 4.422
2023-01-14 07:38:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 07:38:37 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint55.pt (epoch 55 @ 108774 updates, score 4.495) (writing took 28.112640542909503 seconds)
2023-01-14 07:38:37 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-01-14 07:38:37 | INFO | train | epoch 055 | loss 3.175 | nll_loss 1.032 | word_ins 2.849 | length 3.26 | ppl 9.03 | wps 45406 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 108774 | lr 0.000303206 | gnorm 1.053 | loss_scale 16384 | train_wall 2523 | wall 143471
2023-01-14 07:38:37 | INFO | fairseq.trainer | begin training epoch 56
2023-01-14 07:39:22 | INFO | train_inner | epoch 056:     26 / 1978 loss=3.2, nll_loss=1.052, word_ins=2.868, length=3.321, ppl=9.19, wps=32492.3, ups=0.55, wpb=59109.7, bsz=1903.4, num_updates=108800, lr=0.00030317, gnorm=1.072, loss_scale=16384, train_wall=126, wall=143516
2023-01-14 07:41:30 | INFO | train_inner | epoch 056:    126 / 1978 loss=3.172, nll_loss=1.033, word_ins=2.85, length=3.216, ppl=9.01, wps=46700.3, ups=0.78, wpb=59546.2, bsz=1989.1, num_updates=108900, lr=0.00030303, gnorm=1.056, loss_scale=16384, train_wall=127, wall=143644
2023-01-14 07:43:38 | INFO | train_inner | epoch 056:    226 / 1978 loss=3.148, nll_loss=1.01, word_ins=2.829, length=3.188, ppl=8.86, wps=46493.6, ups=0.78, wpb=59586.1, bsz=2034.1, num_updates=109000, lr=0.000302891, gnorm=1.069, loss_scale=16384, train_wall=128, wall=143772
2023-01-14 07:45:46 | INFO | train_inner | epoch 056:    326 / 1978 loss=3.148, nll_loss=1.008, word_ins=2.827, length=3.213, ppl=8.87, wps=46519, ups=0.78, wpb=59638, bsz=2036.9, num_updates=109100, lr=0.000302752, gnorm=1.066, loss_scale=16384, train_wall=128, wall=143900
2023-01-14 07:47:54 | INFO | train_inner | epoch 056:    426 / 1978 loss=3.159, nll_loss=1.016, word_ins=2.835, length=3.233, ppl=8.93, wps=46136.8, ups=0.79, wpb=58754.7, bsz=2006.2, num_updates=109200, lr=0.000302614, gnorm=1.024, loss_scale=16384, train_wall=127, wall=144028
2023-01-14 07:50:01 | INFO | train_inner | epoch 056:    526 / 1978 loss=3.194, nll_loss=1.047, word_ins=2.863, length=3.306, ppl=9.15, wps=46445.7, ups=0.78, wpb=59183.9, bsz=1960.6, num_updates=109300, lr=0.000302475, gnorm=1.066, loss_scale=16384, train_wall=127, wall=144155
2023-01-14 07:52:09 | INFO | train_inner | epoch 056:    626 / 1978 loss=3.159, nll_loss=1.021, word_ins=2.839, length=3.198, ppl=8.93, wps=46587.2, ups=0.78, wpb=59716.6, bsz=2057.9, num_updates=109400, lr=0.000302337, gnorm=1.053, loss_scale=16384, train_wall=128, wall=144283
2023-01-14 07:54:16 | INFO | train_inner | epoch 056:    726 / 1978 loss=3.175, nll_loss=1.024, word_ins=2.843, length=3.316, ppl=9.03, wps=46166.2, ups=0.79, wpb=58606.6, bsz=1948.2, num_updates=109500, lr=0.000302199, gnorm=1.071, loss_scale=16384, train_wall=127, wall=144410
2023-01-14 07:56:25 | INFO | train_inner | epoch 056:    826 / 1978 loss=3.18, nll_loss=1.036, word_ins=2.852, length=3.281, ppl=9.07, wps=46294.4, ups=0.78, wpb=59393.9, bsz=2037.8, num_updates=109600, lr=0.000302061, gnorm=1.101, loss_scale=16384, train_wall=128, wall=144539
2023-01-14 07:58:33 | INFO | train_inner | epoch 056:    926 / 1978 loss=3.155, nll_loss=1.011, word_ins=2.83, length=3.243, ppl=8.91, wps=46491.6, ups=0.78, wpb=59811.7, bsz=2017.9, num_updates=109700, lr=0.000301923, gnorm=1.073, loss_scale=16384, train_wall=128, wall=144667
2023-01-14 08:00:40 | INFO | train_inner | epoch 056:   1026 / 1978 loss=3.182, nll_loss=1.043, word_ins=2.859, length=3.225, ppl=9.07, wps=46722.5, ups=0.79, wpb=59403.2, bsz=1951.2, num_updates=109800, lr=0.000301786, gnorm=1.111, loss_scale=16384, train_wall=127, wall=144794
2023-01-14 08:02:49 | INFO | train_inner | epoch 056:   1126 / 1978 loss=3.188, nll_loss=1.047, word_ins=2.863, length=3.251, ppl=9.11, wps=45503.3, ups=0.78, wpb=58568.8, bsz=2099.8, num_updates=109900, lr=0.000301648, gnorm=1.064, loss_scale=16384, train_wall=128, wall=144923
2023-01-14 08:04:58 | INFO | train_inner | epoch 056:   1226 / 1978 loss=3.172, nll_loss=1.027, word_ins=2.846, length=3.262, ppl=9.01, wps=45794.9, ups=0.78, wpb=58986.6, bsz=1996.6, num_updates=110000, lr=0.000301511, gnorm=1.053, loss_scale=16384, train_wall=129, wall=145052
2023-01-14 08:07:06 | INFO | train_inner | epoch 056:   1326 / 1978 loss=3.167, nll_loss=1.024, word_ins=2.842, length=3.252, ppl=8.98, wps=46617.3, ups=0.78, wpb=59672.6, bsz=1964.6, num_updates=110100, lr=0.000301374, gnorm=1.08, loss_scale=16384, train_wall=128, wall=145180
2023-01-14 08:09:13 | INFO | train_inner | epoch 056:   1426 / 1978 loss=3.154, nll_loss=1.013, word_ins=2.832, length=3.226, ppl=8.9, wps=47056.3, ups=0.78, wpb=59981.7, bsz=2030.7, num_updates=110200, lr=0.000301238, gnorm=1.095, loss_scale=16384, train_wall=127, wall=145307
2023-01-14 08:09:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 08:11:23 | INFO | train_inner | epoch 056:   1527 / 1978 loss=3.171, nll_loss=1.027, word_ins=2.845, length=3.261, ppl=9.01, wps=45718.8, ups=0.77, wpb=59136.6, bsz=2015.4, num_updates=110300, lr=0.000301101, gnorm=1.08, loss_scale=16384, train_wall=129, wall=145437
2023-01-14 08:13:30 | INFO | train_inner | epoch 056:   1627 / 1978 loss=3.18, nll_loss=1.036, word_ins=2.852, length=3.281, ppl=9.06, wps=46248.1, ups=0.79, wpb=58846.9, bsz=1960.4, num_updates=110400, lr=0.000300965, gnorm=1.084, loss_scale=16384, train_wall=127, wall=145564
2023-01-14 08:15:37 | INFO | train_inner | epoch 056:   1727 / 1978 loss=3.173, nll_loss=1.03, word_ins=2.847, length=3.258, ppl=9.02, wps=46493.9, ups=0.78, wpb=59248.9, bsz=2005.9, num_updates=110500, lr=0.000300828, gnorm=1.061, loss_scale=16384, train_wall=127, wall=145691
2023-01-14 08:17:46 | INFO | train_inner | epoch 056:   1827 / 1978 loss=3.159, nll_loss=1.015, word_ins=2.834, length=3.257, ppl=8.93, wps=46299.2, ups=0.78, wpb=59368.4, bsz=2030.1, num_updates=110600, lr=0.000300692, gnorm=1.082, loss_scale=16384, train_wall=128, wall=145820
2023-01-14 08:19:53 | INFO | train_inner | epoch 056:   1927 / 1978 loss=3.192, nll_loss=1.047, word_ins=2.863, length=3.288, ppl=9.14, wps=46262.4, ups=0.78, wpb=59085.6, bsz=1950.4, num_updates=110700, lr=0.000300557, gnorm=1.066, loss_scale=16384, train_wall=127, wall=145947
2023-01-14 08:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 08:21:12 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 4.606 | nll_loss 2.019 | word_ins 3.785 | length 8.206 | ppl 24.35 | wps 167104 | wpb 40242.5 | bsz 1500 | num_updates 110751 | best_loss 4.422
2023-01-14 08:21:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 08:21:40 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint56.pt (epoch 56 @ 110751 updates, score 4.606) (writing took 28.278243214357644 seconds)
2023-01-14 08:21:40 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2023-01-14 08:21:40 | INFO | train | epoch 056 | loss 3.171 | nll_loss 1.028 | word_ins 2.846 | length 3.253 | ppl 9.01 | wps 45369.7 | ups 0.77 | wpb 59284.6 | bsz 2002.5 | num_updates 110751 | lr 0.000300487 | gnorm 1.071 | loss_scale 16384 | train_wall 2524 | wall 146054
2023-01-14 08:21:40 | INFO | fairseq.trainer | begin training epoch 57
2023-01-14 08:22:56 | INFO | train_inner | epoch 057:     49 / 1978 loss=3.169, nll_loss=1.026, word_ins=2.843, length=3.257, ppl=8.99, wps=32622.2, ups=0.55, wpb=59600.7, bsz=1990, num_updates=110800, lr=0.000300421, gnorm=1.083, loss_scale=16384, train_wall=128, wall=146130
2023-01-14 08:25:04 | INFO | train_inner | epoch 057:    149 / 1978 loss=3.153, nll_loss=1.009, word_ins=2.829, length=3.24, ppl=8.89, wps=46231, ups=0.78, wpb=59032.5, bsz=2022.6, num_updates=110900, lr=0.000300285, gnorm=1.073, loss_scale=16384, train_wall=127, wall=146258
2023-01-14 08:27:13 | INFO | train_inner | epoch 057:    249 / 1978 loss=3.14, nll_loss=1.003, word_ins=2.823, length=3.172, ppl=8.82, wps=46267.3, ups=0.78, wpb=59676, bsz=2105.4, num_updates=111000, lr=0.00030015, gnorm=1.066, loss_scale=16384, train_wall=129, wall=146387
2023-01-14 08:29:20 | INFO | train_inner | epoch 057:    349 / 1978 loss=3.137, nll_loss=0.996, word_ins=2.817, length=3.203, ppl=8.8, wps=46574.3, ups=0.78, wpb=59336.7, bsz=2072.2, num_updates=111100, lr=0.000300015, gnorm=1.091, loss_scale=16384, train_wall=127, wall=146514
2023-01-14 08:31:28 | INFO | train_inner | epoch 057:    449 / 1978 loss=3.188, nll_loss=1.047, word_ins=2.864, length=3.247, ppl=9.12, wps=46085.4, ups=0.79, wpb=58699.8, bsz=1969, num_updates=111200, lr=0.00029988, gnorm=1.075, loss_scale=16384, train_wall=127, wall=146642
2023-01-14 08:33:34 | INFO | train_inner | epoch 057:    549 / 1978 loss=3.158, nll_loss=1.015, word_ins=2.833, length=3.248, ppl=8.93, wps=46719, ups=0.79, wpb=59151.8, bsz=1958.8, num_updates=111300, lr=0.000299745, gnorm=1.07, loss_scale=16384, train_wall=126, wall=146768
2023-01-14 08:35:42 | INFO | train_inner | epoch 057:    649 / 1978 loss=3.167, nll_loss=1.02, word_ins=2.838, length=3.291, ppl=8.98, wps=46548.9, ups=0.78, wpb=59470.1, bsz=1953.6, num_updates=111400, lr=0.000299611, gnorm=1.099, loss_scale=16384, train_wall=128, wall=146896
2023-01-14 08:37:50 | INFO | train_inner | epoch 057:    749 / 1978 loss=3.126, nll_loss=0.993, word_ins=2.813, length=3.133, ppl=8.73, wps=46509, ups=0.78, wpb=59717.2, bsz=2054.8, num_updates=111500, lr=0.000299476, gnorm=1.061, loss_scale=16384, train_wall=128, wall=147024
2023-01-14 08:39:59 | INFO | train_inner | epoch 057:    849 / 1978 loss=3.14, nll_loss=1.006, word_ins=2.826, length=3.146, ppl=8.82, wps=46120.3, ups=0.78, wpb=59347.8, bsz=2110.1, num_updates=111600, lr=0.000299342, gnorm=1.042, loss_scale=16384, train_wall=128, wall=147153
2023-01-14 08:42:07 | INFO | train_inner | epoch 057:    949 / 1978 loss=3.174, nll_loss=1.029, word_ins=2.846, length=3.28, ppl=9.02, wps=46589.8, ups=0.78, wpb=59424.5, bsz=1965, num_updates=111700, lr=0.000299208, gnorm=1.106, loss_scale=16384, train_wall=127, wall=147281
2023-01-14 08:44:16 | INFO | train_inner | epoch 057:   1049 / 1978 loss=3.139, nll_loss=0.997, word_ins=2.816, length=3.228, ppl=8.81, wps=46144.3, ups=0.77, wpb=59614.7, bsz=2096.4, num_updates=111800, lr=0.000299074, gnorm=1.057, loss_scale=16384, train_wall=129, wall=147410
2023-01-14 08:46:24 | INFO | train_inner | epoch 057:   1149 / 1978 loss=3.175, nll_loss=1.036, word_ins=2.852, length=3.233, ppl=9.03, wps=46686.9, ups=0.78, wpb=59684.7, bsz=1979.4, num_updates=111900, lr=0.000298941, gnorm=1.109, loss_scale=16384, train_wall=128, wall=147538
2023-01-14 08:48:32 | INFO | train_inner | epoch 057:   1249 / 1978 loss=3.194, nll_loss=1.048, word_ins=2.864, length=3.304, ppl=9.15, wps=45953.6, ups=0.78, wpb=58969.4, bsz=1966.8, num_updates=112000, lr=0.000298807, gnorm=1.108, loss_scale=16384, train_wall=128, wall=147666
2023-01-14 08:50:39 | INFO | train_inner | epoch 057:   1349 / 1978 loss=3.228, nll_loss=1.075, word_ins=2.888, length=3.402, ppl=9.37, wps=46411.2, ups=0.79, wpb=58816.8, bsz=1902, num_updates=112100, lr=0.000298674, gnorm=1.116, loss_scale=16384, train_wall=126, wall=147793
2023-01-14 08:52:46 | INFO | train_inner | epoch 057:   1449 / 1978 loss=3.163, nll_loss=1.016, word_ins=2.835, length=3.284, ppl=8.96, wps=46769.6, ups=0.78, wpb=59756, bsz=2019.4, num_updates=112200, lr=0.000298541, gnorm=1.117, loss_scale=16384, train_wall=127, wall=147921
2023-01-14 08:54:55 | INFO | train_inner | epoch 057:   1549 / 1978 loss=3.179, nll_loss=1.042, word_ins=2.858, length=3.209, ppl=9.06, wps=45924.2, ups=0.78, wpb=58961, bsz=2052.6, num_updates=112300, lr=0.000298408, gnorm=1.094, loss_scale=16384, train_wall=128, wall=148049
2023-01-14 08:57:01 | INFO | train_inner | epoch 057:   1649 / 1978 loss=3.213, nll_loss=1.056, word_ins=2.871, length=3.419, ppl=9.27, wps=46382.1, ups=0.79, wpb=58675.5, bsz=1847.3, num_updates=112400, lr=0.000298275, gnorm=1.103, loss_scale=16384, train_wall=126, wall=148175
2023-01-14 08:59:10 | INFO | train_inner | epoch 057:   1749 / 1978 loss=3.168, nll_loss=1.025, word_ins=2.842, length=3.257, ppl=8.99, wps=46215.2, ups=0.78, wpb=59491.5, bsz=2026.4, num_updates=112500, lr=0.000298142, gnorm=1.091, loss_scale=16384, train_wall=128, wall=148304
2023-01-14 09:01:19 | INFO | train_inner | epoch 057:   1849 / 1978 loss=3.155, nll_loss=1.012, word_ins=2.831, length=3.24, ppl=8.91, wps=45676.8, ups=0.77, wpb=59034.8, bsz=2065.7, num_updates=112600, lr=0.00029801, gnorm=1.074, loss_scale=16384, train_wall=129, wall=148433
2023-01-14 09:03:26 | INFO | train_inner | epoch 057:   1949 / 1978 loss=3.187, nll_loss=1.041, word_ins=2.857, length=3.3, ppl=9.11, wps=46760.7, ups=0.79, wpb=59339.3, bsz=1903.5, num_updates=112700, lr=0.000297878, gnorm=1.087, loss_scale=16384, train_wall=127, wall=148560
2023-01-14 09:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 09:04:18 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 4.68 | nll_loss 2.017 | word_ins 3.785 | length 8.942 | ppl 25.63 | wps 109566 | wpb 40242.5 | bsz 1500 | num_updates 112729 | best_loss 4.422
2023-01-14 09:04:18 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 09:04:46 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint57.pt (epoch 57 @ 112729 updates, score 4.68) (writing took 28.40267557837069 seconds)
2023-01-14 09:04:46 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2023-01-14 09:04:46 | INFO | train | epoch 057 | loss 3.167 | nll_loss 1.024 | word_ins 2.842 | length 3.254 | ppl 8.98 | wps 45341.6 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 112729 | lr 0.000297839 | gnorm 1.087 | loss_scale 16384 | train_wall 2524 | wall 148640
2023-01-14 09:04:46 | INFO | fairseq.trainer | begin training epoch 58
2023-01-14 09:06:30 | INFO | train_inner | epoch 058:     71 / 1978 loss=3.157, nll_loss=1.016, word_ins=2.835, length=3.224, ppl=8.92, wps=32227.4, ups=0.55, wpb=59119.6, bsz=1975.8, num_updates=112800, lr=0.000297746, gnorm=1.076, loss_scale=16384, train_wall=127, wall=148744
2023-01-14 09:08:38 | INFO | train_inner | epoch 058:    171 / 1978 loss=3.161, nll_loss=1.024, word_ins=2.842, length=3.19, ppl=8.94, wps=46545.6, ups=0.78, wpb=59534.8, bsz=1984.7, num_updates=112900, lr=0.000297614, gnorm=1.102, loss_scale=16384, train_wall=128, wall=148872
2023-01-14 09:10:46 | INFO | train_inner | epoch 058:    271 / 1978 loss=3.171, nll_loss=1.025, word_ins=2.843, length=3.28, ppl=9.01, wps=45986.9, ups=0.78, wpb=59251, bsz=1974.2, num_updates=113000, lr=0.000297482, gnorm=1.109, loss_scale=16384, train_wall=129, wall=149001
2023-01-14 09:12:55 | INFO | train_inner | epoch 058:    371 / 1978 loss=3.162, nll_loss=1.02, word_ins=2.838, length=3.238, ppl=8.95, wps=46684.9, ups=0.78, wpb=59833.2, bsz=2000.1, num_updates=113100, lr=0.000297351, gnorm=1.118, loss_scale=16384, train_wall=128, wall=149129
2023-01-14 09:15:03 | INFO | train_inner | epoch 058:    471 / 1978 loss=3.143, nll_loss=1.003, word_ins=2.822, length=3.205, ppl=8.83, wps=46422.8, ups=0.78, wpb=59449.4, bsz=2008.4, num_updates=113200, lr=0.000297219, gnorm=1.104, loss_scale=16384, train_wall=128, wall=149257
2023-01-14 09:17:11 | INFO | train_inner | epoch 058:    571 / 1978 loss=3.151, nll_loss=1.006, word_ins=2.826, length=3.254, ppl=8.88, wps=46466, ups=0.78, wpb=59651.7, bsz=1978.6, num_updates=113300, lr=0.000297088, gnorm=1.114, loss_scale=16384, train_wall=128, wall=149385
2023-01-14 09:19:19 | INFO | train_inner | epoch 058:    671 / 1978 loss=3.185, nll_loss=1.047, word_ins=2.863, length=3.221, ppl=9.1, wps=46354.5, ups=0.78, wpb=59366.8, bsz=1983.2, num_updates=113400, lr=0.000296957, gnorm=1.092, loss_scale=16384, train_wall=128, wall=149513
2023-01-14 09:21:27 | INFO | train_inner | epoch 058:    771 / 1978 loss=3.179, nll_loss=1.033, word_ins=2.849, length=3.298, ppl=9.06, wps=46237.1, ups=0.78, wpb=59260.8, bsz=2010.2, num_updates=113500, lr=0.000296826, gnorm=1.116, loss_scale=16384, train_wall=128, wall=149641
2023-01-14 09:23:36 | INFO | train_inner | epoch 058:    871 / 1978 loss=3.148, nll_loss=1.008, word_ins=2.827, length=3.207, ppl=8.86, wps=45943.9, ups=0.77, wpb=59315.7, bsz=2059, num_updates=113600, lr=0.000296695, gnorm=1.115, loss_scale=16384, train_wall=129, wall=149771
2023-01-14 09:25:45 | INFO | train_inner | epoch 058:    971 / 1978 loss=3.137, nll_loss=0.994, word_ins=2.815, length=3.227, ppl=8.8, wps=46193.7, ups=0.78, wpb=59168.4, bsz=2026, num_updates=113700, lr=0.000296565, gnorm=1.085, loss_scale=16384, train_wall=128, wall=149899
2023-01-14 09:27:52 | INFO | train_inner | epoch 058:   1071 / 1978 loss=3.171, nll_loss=1.028, word_ins=2.845, length=3.259, ppl=9.01, wps=46193.3, ups=0.78, wpb=58953.8, bsz=1998.3, num_updates=113800, lr=0.000296435, gnorm=1.12, loss_scale=16384, train_wall=127, wall=150026
2023-01-14 09:30:00 | INFO | train_inner | epoch 058:   1171 / 1978 loss=3.147, nll_loss=1.005, word_ins=2.824, length=3.229, ppl=8.86, wps=46359.3, ups=0.78, wpb=59207.8, bsz=2050.3, num_updates=113900, lr=0.000296304, gnorm=1.062, loss_scale=16384, train_wall=127, wall=150154
2023-01-14 09:32:08 | INFO | train_inner | epoch 058:   1271 / 1978 loss=3.133, nll_loss=0.991, word_ins=2.811, length=3.22, ppl=8.77, wps=46333.1, ups=0.78, wpb=59449.8, bsz=2086.6, num_updates=114000, lr=0.000296174, gnorm=1.143, loss_scale=16384, train_wall=128, wall=150282
2023-01-14 09:34:16 | INFO | train_inner | epoch 058:   1371 / 1978 loss=3.153, nll_loss=1.006, word_ins=2.825, length=3.284, ppl=8.9, wps=46194.6, ups=0.78, wpb=59137.1, bsz=2042.2, num_updates=114100, lr=0.000296045, gnorm=1.117, loss_scale=16384, train_wall=128, wall=150410
2023-01-14 09:36:23 | INFO | train_inner | epoch 058:   1471 / 1978 loss=3.183, nll_loss=1.036, word_ins=2.852, length=3.307, ppl=9.08, wps=46713.7, ups=0.79, wpb=59348.9, bsz=1931.4, num_updates=114200, lr=0.000295915, gnorm=1.11, loss_scale=16384, train_wall=127, wall=150537
2023-01-14 09:38:29 | INFO | train_inner | epoch 058:   1571 / 1978 loss=3.175, nll_loss=1.033, word_ins=2.849, length=3.252, ppl=9.03, wps=46656, ups=0.79, wpb=58866.9, bsz=1904.6, num_updates=114300, lr=0.000295786, gnorm=1.119, loss_scale=16384, train_wall=126, wall=150664
2023-01-14 09:39:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 09:40:39 | INFO | train_inner | epoch 058:   1672 / 1978 loss=3.162, nll_loss=1.018, word_ins=2.836, length=3.256, ppl=8.95, wps=45605.2, ups=0.77, wpb=58986, bsz=2049.4, num_updates=114400, lr=0.000295656, gnorm=1.087, loss_scale=16384, train_wall=129, wall=150793
2023-01-14 09:42:46 | INFO | train_inner | epoch 058:   1772 / 1978 loss=3.147, nll_loss=1.002, word_ins=2.821, length=3.259, ppl=8.86, wps=46671.5, ups=0.78, wpb=59507.2, bsz=2024.5, num_updates=114500, lr=0.000295527, gnorm=1.105, loss_scale=16384, train_wall=127, wall=150920
2023-01-14 09:44:54 | INFO | train_inner | epoch 058:   1872 / 1978 loss=3.186, nll_loss=1.033, word_ins=2.851, length=3.35, ppl=9.1, wps=46684.2, ups=0.79, wpb=59414.3, bsz=1934.6, num_updates=114600, lr=0.000295398, gnorm=1.115, loss_scale=16384, train_wall=127, wall=151048
2023-01-14 09:47:01 | INFO | train_inner | epoch 058:   1972 / 1978 loss=3.176, nll_loss=1.033, word_ins=2.85, length=3.255, ppl=9.03, wps=46086.5, ups=0.79, wpb=58694.4, bsz=1998.9, num_updates=114700, lr=0.000295269, gnorm=1.079, loss_scale=16384, train_wall=127, wall=151175
2023-01-14 09:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 09:47:22 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 4.513 | nll_loss 1.981 | word_ins 3.753 | length 7.601 | ppl 22.83 | wps 142534 | wpb 40242.5 | bsz 1500 | num_updates 114706 | best_loss 4.422
2023-01-14 09:47:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 09:47:50 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint58.pt (epoch 58 @ 114706 updates, score 4.513) (writing took 28.60629355534911 seconds)
2023-01-14 09:47:50 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2023-01-14 09:47:50 | INFO | train | epoch 058 | loss 3.161 | nll_loss 1.018 | word_ins 2.836 | length 3.248 | ppl 8.94 | wps 45353 | ups 0.77 | wpb 59281.9 | bsz 2002.6 | num_updates 114706 | lr 0.000295262 | gnorm 1.105 | loss_scale 16384 | train_wall 2525 | wall 151224
2023-01-14 09:47:50 | INFO | fairseq.trainer | begin training epoch 59
2023-01-14 09:50:02 | INFO | train_inner | epoch 059:     94 / 1978 loss=3.166, nll_loss=1.02, word_ins=2.839, length=3.269, ppl=8.97, wps=32891.5, ups=0.55, wpb=59531.4, bsz=1900.1, num_updates=114800, lr=0.000295141, gnorm=1.147, loss_scale=16384, train_wall=127, wall=151356
2023-01-14 09:52:10 | INFO | train_inner | epoch 059:    194 / 1978 loss=3.156, nll_loss=1.02, word_ins=2.838, length=3.188, ppl=8.92, wps=46585, ups=0.78, wpb=59599.9, bsz=1997.4, num_updates=114900, lr=0.000295012, gnorm=1.085, loss_scale=16384, train_wall=128, wall=151484
2023-01-14 09:54:19 | INFO | train_inner | epoch 059:    294 / 1978 loss=3.144, nll_loss=1.007, word_ins=2.826, length=3.178, ppl=8.84, wps=46084.2, ups=0.78, wpb=59336.1, bsz=2031.4, num_updates=115000, lr=0.000294884, gnorm=1.116, loss_scale=16384, train_wall=129, wall=151613
2023-01-14 09:56:27 | INFO | train_inner | epoch 059:    394 / 1978 loss=3.138, nll_loss=0.996, word_ins=2.816, length=3.219, ppl=8.8, wps=46487.8, ups=0.78, wpb=59511.7, bsz=2007.1, num_updates=115100, lr=0.000294756, gnorm=1.095, loss_scale=16384, train_wall=128, wall=151741
2023-01-14 09:58:34 | INFO | train_inner | epoch 059:    494 / 1978 loss=3.171, nll_loss=1.02, word_ins=2.838, length=3.33, ppl=9.01, wps=46264.9, ups=0.78, wpb=59108.5, bsz=1965, num_updates=115200, lr=0.000294628, gnorm=1.07, loss_scale=16384, train_wall=127, wall=151869
2023-01-14 10:00:43 | INFO | train_inner | epoch 059:    594 / 1978 loss=3.142, nll_loss=1.001, word_ins=2.821, length=3.214, ppl=8.83, wps=46286.8, ups=0.78, wpb=59336.7, bsz=2041.9, num_updates=115300, lr=0.0002945, gnorm=1.108, loss_scale=16384, train_wall=128, wall=151997
2023-01-14 10:02:51 | INFO | train_inner | epoch 059:    694 / 1978 loss=3.141, nll_loss=0.999, word_ins=2.819, length=3.222, ppl=8.82, wps=46223.6, ups=0.78, wpb=59290, bsz=2009.2, num_updates=115400, lr=0.000294372, gnorm=1.142, loss_scale=16384, train_wall=128, wall=152125
2023-01-14 10:04:58 | INFO | train_inner | epoch 059:    794 / 1978 loss=3.164, nll_loss=1.018, word_ins=2.836, length=3.278, ppl=8.96, wps=46414.1, ups=0.78, wpb=59148.5, bsz=2000.4, num_updates=115500, lr=0.000294245, gnorm=1.116, loss_scale=16384, train_wall=127, wall=152253
2023-01-14 10:07:07 | INFO | train_inner | epoch 059:    894 / 1978 loss=3.156, nll_loss=1.02, word_ins=2.838, length=3.184, ppl=8.91, wps=45918.9, ups=0.78, wpb=59003.5, bsz=2042.3, num_updates=115600, lr=0.000294118, gnorm=1.109, loss_scale=16384, train_wall=128, wall=152381
2023-01-14 10:09:15 | INFO | train_inner | epoch 059:    994 / 1978 loss=3.157, nll_loss=1.012, word_ins=2.831, length=3.261, ppl=8.92, wps=46167, ups=0.78, wpb=58958.2, bsz=1986.7, num_updates=115700, lr=0.000293991, gnorm=1.11, loss_scale=16384, train_wall=127, wall=152509
2023-01-14 10:11:22 | INFO | train_inner | epoch 059:   1094 / 1978 loss=3.161, nll_loss=1.016, word_ins=2.833, length=3.274, ppl=8.94, wps=46488.3, ups=0.78, wpb=59425.2, bsz=1990.9, num_updates=115800, lr=0.000293864, gnorm=1.151, loss_scale=16384, train_wall=128, wall=152637
2023-01-14 10:13:30 | INFO | train_inner | epoch 059:   1194 / 1978 loss=3.193, nll_loss=1.05, word_ins=2.865, length=3.276, ppl=9.14, wps=46136.1, ups=0.78, wpb=58910.3, bsz=1959.5, num_updates=115900, lr=0.000293737, gnorm=1.134, loss_scale=16384, train_wall=127, wall=152764
2023-01-14 10:15:38 | INFO | train_inner | epoch 059:   1294 / 1978 loss=3.161, nll_loss=1.019, word_ins=2.837, length=3.238, ppl=8.94, wps=46186.4, ups=0.78, wpb=59098.1, bsz=2013, num_updates=116000, lr=0.00029361, gnorm=1.101, loss_scale=16384, train_wall=128, wall=152892
2023-01-14 10:17:46 | INFO | train_inner | epoch 059:   1394 / 1978 loss=3.149, nll_loss=1.005, word_ins=2.825, length=3.24, ppl=8.87, wps=46107.7, ups=0.78, wpb=58956.1, bsz=2028, num_updates=116100, lr=0.000293484, gnorm=1.162, loss_scale=16384, train_wall=128, wall=153020
2023-01-14 10:19:54 | INFO | train_inner | epoch 059:   1494 / 1978 loss=3.154, nll_loss=1.014, word_ins=2.832, length=3.22, ppl=8.9, wps=46740.4, ups=0.78, wpb=59664.6, bsz=2049.4, num_updates=116200, lr=0.000293357, gnorm=1.101, loss_scale=16384, train_wall=127, wall=153148
2023-01-14 10:22:02 | INFO | train_inner | epoch 059:   1594 / 1978 loss=3.165, nll_loss=1.023, word_ins=2.841, length=3.239, ppl=8.97, wps=46172, ups=0.78, wpb=59037.4, bsz=2001.7, num_updates=116300, lr=0.000293231, gnorm=1.114, loss_scale=16384, train_wall=128, wall=153276
2023-01-14 10:24:10 | INFO | train_inner | epoch 059:   1694 / 1978 loss=3.155, nll_loss=1.011, word_ins=2.829, length=3.258, ppl=8.91, wps=46549.1, ups=0.78, wpb=59574.3, bsz=2048.7, num_updates=116400, lr=0.000293105, gnorm=1.137, loss_scale=16384, train_wall=128, wall=153404
2023-01-14 10:26:16 | INFO | train_inner | epoch 059:   1794 / 1978 loss=3.169, nll_loss=1.023, word_ins=2.841, length=3.275, ppl=8.99, wps=46745.1, ups=0.79, wpb=59315.2, bsz=1981.1, num_updates=116500, lr=0.000292979, gnorm=1.139, loss_scale=16384, train_wall=127, wall=153530
2023-01-14 10:28:24 | INFO | train_inner | epoch 059:   1894 / 1978 loss=3.142, nll_loss=1.001, word_ins=2.82, length=3.213, ppl=8.82, wps=46885.8, ups=0.78, wpb=59749.3, bsz=2008.6, num_updates=116600, lr=0.000292854, gnorm=1.124, loss_scale=16384, train_wall=127, wall=153658
2023-01-14 10:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 10:30:23 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 4.547 | nll_loss 2.002 | word_ins 3.768 | length 7.784 | ppl 23.37 | wps 139084 | wpb 40242.5 | bsz 1500 | num_updates 116684 | best_loss 4.422
2023-01-14 10:30:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 10:30:50 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint59.pt (epoch 59 @ 116684 updates, score 4.547) (writing took 27.57123190490529 seconds)
2023-01-14 10:30:50 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2023-01-14 10:30:50 | INFO | train | epoch 059 | loss 3.157 | nll_loss 1.014 | word_ins 2.832 | length 3.242 | ppl 8.92 | wps 45452 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 116684 | lr 0.000292748 | gnorm 1.119 | loss_scale 16384 | train_wall 2523 | wall 153804
2023-01-14 10:30:50 | INFO | fairseq.trainer | begin training epoch 60
2023-01-14 10:31:22 | INFO | train_inner | epoch 060:     16 / 1978 loss=3.143, nll_loss=0.998, word_ins=2.818, length=3.254, ppl=8.84, wps=33041.5, ups=0.56, wpb=59014.4, bsz=2008.6, num_updates=116700, lr=0.000292728, gnorm=1.128, loss_scale=16384, train_wall=127, wall=153837
2023-01-14 10:33:31 | INFO | train_inner | epoch 060:    116 / 1978 loss=3.124, nll_loss=0.989, word_ins=2.81, length=3.139, ppl=8.72, wps=46402.2, ups=0.78, wpb=59650.8, bsz=2122.2, num_updates=116800, lr=0.000292603, gnorm=1.106, loss_scale=16384, train_wall=128, wall=153965
2023-01-14 10:35:38 | INFO | train_inner | epoch 060:    216 / 1978 loss=3.153, nll_loss=1.014, word_ins=2.833, length=3.202, ppl=8.9, wps=46279.4, ups=0.78, wpb=58969.4, bsz=1974.9, num_updates=116900, lr=0.000292478, gnorm=1.131, loss_scale=16384, train_wall=127, wall=154093
2023-01-14 10:37:46 | INFO | train_inner | epoch 060:    316 / 1978 loss=3.157, nll_loss=1.015, word_ins=2.833, length=3.241, ppl=8.92, wps=46456.1, ups=0.78, wpb=59445.9, bsz=1973.8, num_updates=117000, lr=0.000292353, gnorm=1.134, loss_scale=16384, train_wall=128, wall=154220
2023-01-14 10:39:54 | INFO | train_inner | epoch 060:    416 / 1978 loss=3.16, nll_loss=1.015, word_ins=2.833, length=3.271, ppl=8.94, wps=46355, ups=0.78, wpb=59071.9, bsz=1955.9, num_updates=117100, lr=0.000292228, gnorm=1.13, loss_scale=16384, train_wall=127, wall=154348
2023-01-14 10:42:02 | INFO | train_inner | epoch 060:    516 / 1978 loss=3.144, nll_loss=1.001, word_ins=2.821, length=3.236, ppl=8.84, wps=46394.1, ups=0.78, wpb=59260.8, bsz=2049.9, num_updates=117200, lr=0.000292103, gnorm=1.132, loss_scale=16384, train_wall=128, wall=154476
2023-01-14 10:44:08 | INFO | train_inner | epoch 060:    616 / 1978 loss=3.171, nll_loss=1.025, word_ins=2.842, length=3.282, ppl=9, wps=46513, ups=0.79, wpb=58942.7, bsz=1862.8, num_updates=117300, lr=0.000291979, gnorm=1.161, loss_scale=16384, train_wall=126, wall=154602
2023-01-14 10:46:16 | INFO | train_inner | epoch 060:    716 / 1978 loss=3.163, nll_loss=1.017, word_ins=2.835, length=3.279, ppl=8.95, wps=46227.5, ups=0.78, wpb=59220.4, bsz=2063.8, num_updates=117400, lr=0.000291854, gnorm=1.159, loss_scale=16384, train_wall=128, wall=154731
2023-01-14 10:48:23 | INFO | train_inner | epoch 060:    816 / 1978 loss=3.173, nll_loss=1.024, word_ins=2.841, length=3.317, ppl=9.02, wps=46786.2, ups=0.79, wpb=59324.1, bsz=1919.6, num_updates=117500, lr=0.00029173, gnorm=1.135, loss_scale=16384, train_wall=127, wall=154857
2023-01-14 10:50:32 | INFO | train_inner | epoch 060:    916 / 1978 loss=3.134, nll_loss=0.996, word_ins=2.816, length=3.189, ppl=8.78, wps=46144.8, ups=0.78, wpb=59237.3, bsz=2048.9, num_updates=117600, lr=0.000291606, gnorm=1.138, loss_scale=16384, train_wall=128, wall=154986
2023-01-14 10:52:39 | INFO | train_inner | epoch 060:   1016 / 1978 loss=3.155, nll_loss=1.012, word_ins=2.83, length=3.249, ppl=8.91, wps=46257.6, ups=0.78, wpb=59052, bsz=2015.6, num_updates=117700, lr=0.000291482, gnorm=1.14, loss_scale=16384, train_wall=127, wall=155113
2023-01-14 10:54:47 | INFO | train_inner | epoch 060:   1116 / 1978 loss=3.17, nll_loss=1.027, word_ins=2.845, length=3.25, ppl=9, wps=46405.3, ups=0.78, wpb=59259, bsz=2077.3, num_updates=117800, lr=0.000291358, gnorm=1.154, loss_scale=16384, train_wall=127, wall=155241
2023-01-14 10:56:55 | INFO | train_inner | epoch 060:   1216 / 1978 loss=3.151, nll_loss=1.008, word_ins=2.826, length=3.247, ppl=8.88, wps=46308.2, ups=0.78, wpb=59469.2, bsz=2061, num_updates=117900, lr=0.000291235, gnorm=1.128, loss_scale=16384, train_wall=128, wall=155369
2023-01-14 10:59:03 | INFO | train_inner | epoch 060:   1316 / 1978 loss=3.16, nll_loss=1.014, word_ins=2.832, length=3.278, ppl=8.94, wps=46463.1, ups=0.78, wpb=59347.3, bsz=1970.1, num_updates=118000, lr=0.000291111, gnorm=1.112, loss_scale=16384, train_wall=127, wall=155497
2023-01-14 11:01:12 | INFO | train_inner | epoch 060:   1416 / 1978 loss=3.153, nll_loss=1.01, word_ins=2.828, length=3.246, ppl=8.9, wps=45938.8, ups=0.78, wpb=59103.9, bsz=2060.3, num_updates=118100, lr=0.000290988, gnorm=1.14, loss_scale=16384, train_wall=128, wall=155626
2023-01-14 11:03:20 | INFO | train_inner | epoch 060:   1516 / 1978 loss=3.147, nll_loss=1.003, word_ins=2.822, length=3.244, ppl=8.86, wps=46392.9, ups=0.78, wpb=59507.4, bsz=1995.3, num_updates=118200, lr=0.000290865, gnorm=1.129, loss_scale=16384, train_wall=128, wall=155754
2023-01-14 11:05:28 | INFO | train_inner | epoch 060:   1616 / 1978 loss=3.155, nll_loss=1.011, word_ins=2.829, length=3.261, ppl=8.91, wps=46592.7, ups=0.78, wpb=59599.8, bsz=1972.3, num_updates=118300, lr=0.000290742, gnorm=1.134, loss_scale=16384, train_wall=128, wall=155882
2023-01-14 11:07:35 | INFO | train_inner | epoch 060:   1716 / 1978 loss=3.165, nll_loss=1.024, word_ins=2.842, length=3.227, ppl=8.97, wps=46393.7, ups=0.79, wpb=58949.5, bsz=1964.2, num_updates=118400, lr=0.000290619, gnorm=1.111, loss_scale=16384, train_wall=127, wall=156009
2023-01-14 11:08:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 11:09:44 | INFO | train_inner | epoch 060:   1817 / 1978 loss=3.147, nll_loss=1.008, word_ins=2.826, length=3.205, ppl=8.86, wps=45960.3, ups=0.77, wpb=59477.6, bsz=2002.5, num_updates=118500, lr=0.000290496, gnorm=1.15, loss_scale=16384, train_wall=129, wall=156139
2023-01-14 11:11:52 | INFO | train_inner | epoch 060:   1917 / 1978 loss=3.156, nll_loss=1.011, word_ins=2.83, length=3.26, ppl=8.91, wps=46446.2, ups=0.78, wpb=59430.7, bsz=1961.8, num_updates=118600, lr=0.000290374, gnorm=1.164, loss_scale=16384, train_wall=127, wall=156267
2023-01-14 11:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 11:13:23 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 4.6 | nll_loss 1.984 | word_ins 3.754 | length 8.458 | ppl 24.25 | wps 108556 | wpb 40242.5 | bsz 1500 | num_updates 118661 | best_loss 4.422
2023-01-14 11:13:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 11:13:52 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint60.pt (epoch 60 @ 118661 updates, score 4.6) (writing took 29.264655190054327 seconds)
2023-01-14 11:13:52 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2023-01-14 11:13:52 | INFO | train | epoch 060 | loss 3.154 | nll_loss 1.011 | word_ins 2.83 | length 3.242 | ppl 8.9 | wps 45404.5 | ups 0.77 | wpb 59287.7 | bsz 2003.1 | num_updates 118661 | lr 0.000290299 | gnorm 1.138 | loss_scale 16384 | train_wall 2523 | wall 156386
2023-01-14 11:13:52 | INFO | fairseq.trainer | begin training epoch 61
2023-01-14 11:14:54 | INFO | train_inner | epoch 061:     39 / 1978 loss=3.142, nll_loss=1.004, word_ins=2.822, length=3.193, ppl=8.83, wps=32900.4, ups=0.55, wpb=59763.7, bsz=1963, num_updates=118700, lr=0.000290252, gnorm=1.187, loss_scale=16384, train_wall=128, wall=156448
2023-01-14 11:17:03 | INFO | train_inner | epoch 061:    139 / 1978 loss=3.112, nll_loss=0.971, word_ins=2.793, length=3.185, ppl=8.65, wps=45912.5, ups=0.77, wpb=59337.1, bsz=2107.4, num_updates=118800, lr=0.000290129, gnorm=1.123, loss_scale=16384, train_wall=129, wall=156577
2023-01-14 11:19:10 | INFO | train_inner | epoch 061:    239 / 1978 loss=3.146, nll_loss=1.006, word_ins=2.825, length=3.205, ppl=8.85, wps=46244.3, ups=0.79, wpb=58771.5, bsz=1934.3, num_updates=118900, lr=0.000290007, gnorm=1.135, loss_scale=16384, train_wall=127, wall=156704
2023-01-14 11:21:19 | INFO | train_inner | epoch 061:    339 / 1978 loss=3.145, nll_loss=1.003, word_ins=2.822, length=3.232, ppl=8.85, wps=46146, ups=0.78, wpb=59154.5, bsz=1951, num_updates=119000, lr=0.000289886, gnorm=1.128, loss_scale=16384, train_wall=128, wall=156833
2023-01-14 11:23:26 | INFO | train_inner | epoch 061:    439 / 1978 loss=3.151, nll_loss=1.008, word_ins=2.827, length=3.234, ppl=8.88, wps=46515.6, ups=0.78, wpb=59461, bsz=2003.8, num_updates=119100, lr=0.000289764, gnorm=1.154, loss_scale=16384, train_wall=127, wall=156961
2023-01-14 11:25:33 | INFO | train_inner | epoch 061:    539 / 1978 loss=3.147, nll_loss=1.005, word_ins=2.824, length=3.228, ppl=8.86, wps=47071, ups=0.79, wpb=59593.3, bsz=1939.7, num_updates=119200, lr=0.000289642, gnorm=1.152, loss_scale=16384, train_wall=126, wall=157087
2023-01-14 11:27:42 | INFO | train_inner | epoch 061:    639 / 1978 loss=3.15, nll_loss=1.007, word_ins=2.825, length=3.255, ppl=8.88, wps=46408.4, ups=0.78, wpb=59655, bsz=1950, num_updates=119300, lr=0.000289521, gnorm=1.157, loss_scale=16384, train_wall=127, wall=157216
2023-01-14 11:29:51 | INFO | train_inner | epoch 061:    739 / 1978 loss=3.13, nll_loss=0.993, word_ins=2.813, length=3.172, ppl=8.76, wps=45617.4, ups=0.77, wpb=59131.8, bsz=2101.8, num_updates=119400, lr=0.0002894, gnorm=1.118, loss_scale=16384, train_wall=129, wall=157345
2023-01-14 11:31:59 | INFO | train_inner | epoch 061:    839 / 1978 loss=3.166, nll_loss=1.022, word_ins=2.84, length=3.258, ppl=8.97, wps=46331.3, ups=0.78, wpb=59101.5, bsz=2015.7, num_updates=119500, lr=0.000289278, gnorm=1.13, loss_scale=16384, train_wall=127, wall=157473
2023-01-14 11:34:07 | INFO | train_inner | epoch 061:    939 / 1978 loss=3.181, nll_loss=1.032, word_ins=2.849, length=3.323, ppl=9.07, wps=46024, ups=0.78, wpb=59140, bsz=2018.8, num_updates=119600, lr=0.000289157, gnorm=1.177, loss_scale=16384, train_wall=128, wall=157601
2023-01-14 11:36:15 | INFO | train_inner | epoch 061:   1039 / 1978 loss=3.139, nll_loss=0.999, word_ins=2.818, length=3.21, ppl=8.81, wps=46100.9, ups=0.78, wpb=59003.3, bsz=1981.8, num_updates=119700, lr=0.000289037, gnorm=1.13, loss_scale=16384, train_wall=128, wall=157729
2023-01-14 11:38:22 | INFO | train_inner | epoch 061:   1139 / 1978 loss=3.157, nll_loss=1.009, word_ins=2.828, length=3.294, ppl=8.92, wps=46370.9, ups=0.79, wpb=58787.7, bsz=1960.4, num_updates=119800, lr=0.000288916, gnorm=1.138, loss_scale=16384, train_wall=127, wall=157856
2023-01-14 11:40:30 | INFO | train_inner | epoch 061:   1239 / 1978 loss=3.131, nll_loss=0.988, word_ins=2.808, length=3.23, ppl=8.76, wps=46134, ups=0.78, wpb=59245.8, bsz=2027.3, num_updates=119900, lr=0.000288795, gnorm=1.155, loss_scale=16384, train_wall=128, wall=157985
2023-01-14 11:42:38 | INFO | train_inner | epoch 061:   1339 / 1978 loss=3.15, nll_loss=1.005, word_ins=2.824, length=3.264, ppl=8.88, wps=46566.4, ups=0.79, wpb=59271.2, bsz=1927.9, num_updates=120000, lr=0.000288675, gnorm=1.18, loss_scale=16384, train_wall=127, wall=158112
2023-01-14 11:44:46 | INFO | train_inner | epoch 061:   1439 / 1978 loss=3.148, nll_loss=1.009, word_ins=2.827, length=3.212, ppl=8.87, wps=46240.3, ups=0.78, wpb=59095.9, bsz=2026.1, num_updates=120100, lr=0.000288555, gnorm=1.152, loss_scale=16384, train_wall=128, wall=158240
2023-01-14 11:46:54 | INFO | train_inner | epoch 061:   1539 / 1978 loss=3.134, nll_loss=0.994, word_ins=2.814, length=3.202, ppl=8.78, wps=46021.4, ups=0.78, wpb=59308.4, bsz=2118.1, num_updates=120200, lr=0.000288435, gnorm=1.154, loss_scale=16384, train_wall=129, wall=158369
2023-01-14 11:49:03 | INFO | train_inner | epoch 061:   1639 / 1978 loss=3.158, nll_loss=1.018, word_ins=2.836, length=3.22, ppl=8.92, wps=46157.4, ups=0.78, wpb=59212.1, bsz=2028.4, num_updates=120300, lr=0.000288315, gnorm=1.165, loss_scale=16384, train_wall=128, wall=158497
2023-01-14 11:51:12 | INFO | train_inner | epoch 061:   1739 / 1978 loss=3.149, nll_loss=1.011, word_ins=2.829, length=3.198, ppl=8.87, wps=46309, ups=0.78, wpb=59647, bsz=2040.2, num_updates=120400, lr=0.000288195, gnorm=1.15, loss_scale=16384, train_wall=128, wall=158626
2023-01-14 11:53:21 | INFO | train_inner | epoch 061:   1839 / 1978 loss=3.157, nll_loss=1.012, word_ins=2.83, length=3.266, ppl=8.92, wps=46375, ups=0.77, wpb=59896.2, bsz=2014.4, num_updates=120500, lr=0.000288076, gnorm=1.155, loss_scale=16384, train_wall=129, wall=158755
2023-01-14 11:55:27 | INFO | train_inner | epoch 061:   1939 / 1978 loss=3.162, nll_loss=1.016, word_ins=2.834, length=3.28, ppl=8.95, wps=46665.9, ups=0.79, wpb=59019.5, bsz=1932.5, num_updates=120600, lr=0.000287956, gnorm=1.172, loss_scale=16384, train_wall=126, wall=158881
2023-01-14 11:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 11:56:29 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 4.563 | nll_loss 1.989 | word_ins 3.755 | length 8.078 | ppl 23.63 | wps 116896 | wpb 40242.5 | bsz 1500 | num_updates 120639 | best_loss 4.422
2023-01-14 11:56:29 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 11:56:57 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint61.pt (epoch 61 @ 120639 updates, score 4.563) (writing took 28.065188596956432 seconds)
2023-01-14 11:56:57 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2023-01-14 11:56:57 | INFO | train | epoch 061 | loss 3.148 | nll_loss 1.006 | word_ins 2.825 | length 3.233 | ppl 8.87 | wps 45363.2 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 120639 | lr 0.00028791 | gnorm 1.149 | loss_scale 16384 | train_wall 2527 | wall 158971
2023-01-14 11:56:57 | INFO | fairseq.trainer | begin training epoch 62
2023-01-14 11:58:27 | INFO | train_inner | epoch 062:     61 / 1978 loss=3.139, nll_loss=0.999, word_ins=2.818, length=3.204, ppl=8.81, wps=33174.8, ups=0.56, wpb=59675.1, bsz=2016.4, num_updates=120700, lr=0.000287837, gnorm=1.193, loss_scale=16384, train_wall=128, wall=159061
2023-01-14 12:00:36 | INFO | train_inner | epoch 062:    161 / 1978 loss=3.145, nll_loss=1.004, word_ins=2.823, length=3.224, ppl=8.85, wps=45977.2, ups=0.78, wpb=59280.4, bsz=1997.7, num_updates=120800, lr=0.000287718, gnorm=1.168, loss_scale=16384, train_wall=129, wall=159190
2023-01-14 12:02:45 | INFO | train_inner | epoch 062:    261 / 1978 loss=3.119, nll_loss=0.973, word_ins=2.795, length=3.238, ppl=8.69, wps=46080.7, ups=0.77, wpb=59485.8, bsz=2048.8, num_updates=120900, lr=0.000287599, gnorm=1.192, loss_scale=16384, train_wall=129, wall=159319
2023-01-14 12:04:53 | INFO | train_inner | epoch 062:    361 / 1978 loss=3.139, nll_loss=1.001, word_ins=2.82, length=3.19, ppl=8.81, wps=46397, ups=0.78, wpb=59215.6, bsz=2007.5, num_updates=121000, lr=0.00028748, gnorm=1.154, loss_scale=16384, train_wall=127, wall=159447
2023-01-14 12:07:00 | INFO | train_inner | epoch 062:    461 / 1978 loss=3.15, nll_loss=1.008, word_ins=2.827, length=3.236, ppl=8.88, wps=46483.9, ups=0.78, wpb=59257.4, bsz=1962.3, num_updates=121100, lr=0.000287361, gnorm=1.159, loss_scale=16384, train_wall=127, wall=159574
2023-01-14 12:09:07 | INFO | train_inner | epoch 062:    561 / 1978 loss=3.132, nll_loss=0.989, word_ins=2.81, length=3.222, ppl=8.77, wps=46547.9, ups=0.79, wpb=59150.7, bsz=2036.9, num_updates=121200, lr=0.000287242, gnorm=1.135, loss_scale=16384, train_wall=127, wall=159701
2023-01-14 12:11:14 | INFO | train_inner | epoch 062:    661 / 1978 loss=3.143, nll_loss=0.997, word_ins=2.816, length=3.265, ppl=8.83, wps=46596.3, ups=0.79, wpb=59179, bsz=1972.6, num_updates=121300, lr=0.000287124, gnorm=1.169, loss_scale=16384, train_wall=127, wall=159828
2023-01-14 12:13:20 | INFO | train_inner | epoch 062:    761 / 1978 loss=3.172, nll_loss=1.026, word_ins=2.843, length=3.288, ppl=9.01, wps=46603.4, ups=0.79, wpb=58734.3, bsz=1872.9, num_updates=121400, lr=0.000287006, gnorm=1.156, loss_scale=16384, train_wall=126, wall=159954
2023-01-14 12:15:29 | INFO | train_inner | epoch 062:    861 / 1978 loss=3.126, nll_loss=0.984, word_ins=2.804, length=3.214, ppl=8.73, wps=46592.6, ups=0.78, wpb=59899.1, bsz=2098.9, num_updates=121500, lr=0.000286888, gnorm=1.195, loss_scale=16384, train_wall=128, wall=160083
2023-01-14 12:17:37 | INFO | train_inner | epoch 062:    961 / 1978 loss=3.134, nll_loss=0.996, word_ins=2.816, length=3.179, ppl=8.78, wps=46239.3, ups=0.78, wpb=59060.5, bsz=2022.6, num_updates=121600, lr=0.00028677, gnorm=1.15, loss_scale=16384, train_wall=128, wall=160211
2023-01-14 12:19:44 | INFO | train_inner | epoch 062:   1061 / 1978 loss=3.123, nll_loss=0.983, word_ins=2.804, length=3.187, ppl=8.71, wps=46189.1, ups=0.78, wpb=58973.2, bsz=2058.3, num_updates=121700, lr=0.000286652, gnorm=1.168, loss_scale=16384, train_wall=127, wall=160338
2023-01-14 12:21:52 | INFO | train_inner | epoch 062:   1161 / 1978 loss=3.142, nll_loss=1.005, word_ins=2.823, length=3.191, ppl=8.83, wps=46884.5, ups=0.78, wpb=59820, bsz=2032.6, num_updates=121800, lr=0.000286534, gnorm=1.163, loss_scale=16384, train_wall=127, wall=160466
2023-01-14 12:23:59 | INFO | train_inner | epoch 062:   1261 / 1978 loss=3.138, nll_loss=0.99, word_ins=2.811, length=3.275, ppl=8.8, wps=46363.4, ups=0.78, wpb=59099.8, bsz=2053, num_updates=121900, lr=0.000286417, gnorm=1.183, loss_scale=16384, train_wall=127, wall=160593
2023-01-14 12:26:07 | INFO | train_inner | epoch 062:   1361 / 1978 loss=3.153, nll_loss=1.012, word_ins=2.83, length=3.224, ppl=8.89, wps=46719.3, ups=0.79, wpb=59472.3, bsz=1988.2, num_updates=122000, lr=0.000286299, gnorm=1.191, loss_scale=16384, train_wall=127, wall=160721
2023-01-14 12:28:14 | INFO | train_inner | epoch 062:   1461 / 1978 loss=3.176, nll_loss=1.032, word_ins=2.848, length=3.276, ppl=9.04, wps=46448.2, ups=0.79, wpb=59052.9, bsz=1940.8, num_updates=122100, lr=0.000286182, gnorm=1.162, loss_scale=16384, train_wall=127, wall=160848
2023-01-14 12:30:22 | INFO | train_inner | epoch 062:   1561 / 1978 loss=3.117, nll_loss=0.979, word_ins=2.8, length=3.171, ppl=8.68, wps=46409.1, ups=0.78, wpb=59551.7, bsz=2082.5, num_updates=122200, lr=0.000286065, gnorm=1.139, loss_scale=16384, train_wall=128, wall=160976
2023-01-14 12:32:30 | INFO | train_inner | epoch 062:   1661 / 1978 loss=3.159, nll_loss=1.011, word_ins=2.829, length=3.296, ppl=8.93, wps=46736.7, ups=0.78, wpb=59722.5, bsz=1917, num_updates=122300, lr=0.000285948, gnorm=1.206, loss_scale=16384, train_wall=128, wall=161104
2023-01-14 12:34:37 | INFO | train_inner | epoch 062:   1761 / 1978 loss=3.164, nll_loss=1.016, word_ins=2.833, length=3.303, ppl=8.96, wps=46302.5, ups=0.79, wpb=58707.8, bsz=1964.3, num_updates=122400, lr=0.000285831, gnorm=1.169, loss_scale=16384, train_wall=127, wall=161231
2023-01-14 12:36:45 | INFO | train_inner | epoch 062:   1861 / 1978 loss=3.168, nll_loss=1.026, word_ins=2.843, length=3.244, ppl=8.99, wps=46387.6, ups=0.78, wpb=59280.9, bsz=1966.6, num_updates=122500, lr=0.000285714, gnorm=1.218, loss_scale=16384, train_wall=128, wall=161359
2023-01-14 12:37:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 12:38:53 | INFO | train_inner | epoch 062:   1962 / 1978 loss=3.153, nll_loss=1.01, word_ins=2.828, length=3.254, ppl=8.9, wps=45994.7, ups=0.78, wpb=59236.6, bsz=1992.3, num_updates=122600, lr=0.000285598, gnorm=1.165, loss_scale=16384, train_wall=129, wall=161487
2023-01-14 12:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 12:39:24 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 4.572 | nll_loss 1.991 | word_ins 3.76 | length 8.123 | ppl 23.78 | wps 124657 | wpb 40242.5 | bsz 1500 | num_updates 122616 | best_loss 4.422
2023-01-14 12:39:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 12:39:53 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint62.pt (epoch 62 @ 122616 updates, score 4.572) (writing took 28.728300720918924 seconds)
2023-01-14 12:39:53 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2023-01-14 12:39:53 | INFO | train | epoch 062 | loss 3.144 | nll_loss 1.001 | word_ins 2.82 | length 3.233 | ppl 8.84 | wps 45498.8 | ups 0.77 | wpb 59283.8 | bsz 2002.2 | num_updates 122616 | lr 0.000285579 | gnorm 1.173 | loss_scale 16384 | train_wall 2521 | wall 161547
2023-01-14 12:39:53 | INFO | fairseq.trainer | begin training epoch 63
2023-01-14 12:41:51 | INFO | train_inner | epoch 063:     84 / 1978 loss=3.126, nll_loss=0.989, word_ins=2.809, length=3.172, ppl=8.73, wps=33373.7, ups=0.56, wpb=59376.2, bsz=2006.2, num_updates=122700, lr=0.000285481, gnorm=1.194, loss_scale=16384, train_wall=128, wall=161665
2023-01-14 12:44:00 | INFO | train_inner | epoch 063:    184 / 1978 loss=3.113, nll_loss=0.976, word_ins=2.798, length=3.152, ppl=8.65, wps=46307.4, ups=0.78, wpb=59471.9, bsz=2095, num_updates=122800, lr=0.000285365, gnorm=1.167, loss_scale=16384, train_wall=128, wall=161794
2023-01-14 12:46:08 | INFO | train_inner | epoch 063:    284 / 1978 loss=3.133, nll_loss=0.996, word_ins=2.816, length=3.173, ppl=8.77, wps=46254.3, ups=0.78, wpb=59137.4, bsz=2065.1, num_updates=122900, lr=0.000285249, gnorm=1.181, loss_scale=16384, train_wall=128, wall=161922
2023-01-14 12:48:15 | INFO | train_inner | epoch 063:    384 / 1978 loss=3.122, nll_loss=0.979, word_ins=2.8, length=3.215, ppl=8.7, wps=46334.3, ups=0.78, wpb=59188.6, bsz=2042.2, num_updates=123000, lr=0.000285133, gnorm=1.203, loss_scale=16384, train_wall=128, wall=162049
2023-01-14 12:50:24 | INFO | train_inner | epoch 063:    484 / 1978 loss=3.109, nll_loss=0.971, word_ins=2.793, length=3.159, ppl=8.63, wps=46335, ups=0.78, wpb=59505, bsz=2127.3, num_updates=123100, lr=0.000285017, gnorm=1.163, loss_scale=16384, train_wall=128, wall=162178
2023-01-14 12:52:32 | INFO | train_inner | epoch 063:    584 / 1978 loss=3.133, nll_loss=0.992, word_ins=2.812, length=3.21, ppl=8.77, wps=46382.4, ups=0.78, wpb=59335.6, bsz=2072.7, num_updates=123200, lr=0.000284901, gnorm=1.142, loss_scale=16384, train_wall=128, wall=162306
2023-01-14 12:54:40 | INFO | train_inner | epoch 063:    684 / 1978 loss=3.156, nll_loss=1.012, word_ins=2.83, length=3.259, ppl=8.91, wps=46458.1, ups=0.78, wpb=59406.1, bsz=1947.9, num_updates=123300, lr=0.000284786, gnorm=1.163, loss_scale=16384, train_wall=128, wall=162434
2023-01-14 12:56:46 | INFO | train_inner | epoch 063:    784 / 1978 loss=3.135, nll_loss=0.99, word_ins=2.81, length=3.247, ppl=8.78, wps=47361.4, ups=0.79, wpb=59990, bsz=1923.6, num_updates=123400, lr=0.00028467, gnorm=1.214, loss_scale=16384, train_wall=126, wall=162560
2023-01-14 12:58:54 | INFO | train_inner | epoch 063:    884 / 1978 loss=3.15, nll_loss=1.007, word_ins=2.826, length=3.239, ppl=8.88, wps=45891.9, ups=0.78, wpb=58718.5, bsz=1996.1, num_updates=123500, lr=0.000284555, gnorm=1.188, loss_scale=16384, train_wall=128, wall=162688
2023-01-14 13:01:01 | INFO | train_inner | epoch 063:    984 / 1978 loss=3.136, nll_loss=0.99, word_ins=2.811, length=3.252, ppl=8.79, wps=46371.8, ups=0.79, wpb=58833.5, bsz=1970.3, num_updates=123600, lr=0.00028444, gnorm=1.172, loss_scale=16384, train_wall=127, wall=162815
2023-01-14 13:03:08 | INFO | train_inner | epoch 063:   1084 / 1978 loss=3.111, nll_loss=0.971, word_ins=2.793, length=3.186, ppl=8.64, wps=46480.2, ups=0.78, wpb=59235.7, bsz=2064.6, num_updates=123700, lr=0.000284325, gnorm=1.176, loss_scale=16384, train_wall=127, wall=162943
2023-01-14 13:05:17 | INFO | train_inner | epoch 063:   1184 / 1978 loss=3.148, nll_loss=1.006, word_ins=2.824, length=3.231, ppl=8.86, wps=46323, ups=0.78, wpb=59313.4, bsz=2022, num_updates=123800, lr=0.00028421, gnorm=1.175, loss_scale=16384, train_wall=128, wall=163071
2023-01-14 13:07:24 | INFO | train_inner | epoch 063:   1284 / 1978 loss=3.18, nll_loss=1.035, word_ins=2.851, length=3.287, ppl=9.06, wps=46375.5, ups=0.79, wpb=58927.4, bsz=1924.6, num_updates=123900, lr=0.000284095, gnorm=1.192, loss_scale=16384, train_wall=127, wall=163198
2023-01-14 13:09:30 | INFO | train_inner | epoch 063:   1384 / 1978 loss=3.168, nll_loss=1.026, word_ins=2.843, length=3.249, ppl=8.99, wps=46719.2, ups=0.79, wpb=59255.8, bsz=1908.5, num_updates=124000, lr=0.000283981, gnorm=1.207, loss_scale=16384, train_wall=127, wall=163325
2023-01-14 13:11:38 | INFO | train_inner | epoch 063:   1484 / 1978 loss=3.132, nll_loss=0.99, word_ins=2.81, length=3.221, ppl=8.77, wps=46746.6, ups=0.79, wpb=59431.8, bsz=2013.2, num_updates=124100, lr=0.000283866, gnorm=1.179, loss_scale=16384, train_wall=127, wall=163452
2023-01-14 13:13:44 | INFO | train_inner | epoch 063:   1584 / 1978 loss=3.135, nll_loss=0.995, word_ins=2.815, length=3.199, ppl=8.78, wps=46727.8, ups=0.79, wpb=58912.5, bsz=1981.7, num_updates=124200, lr=0.000283752, gnorm=1.197, loss_scale=16384, train_wall=126, wall=163578
2023-01-14 13:15:51 | INFO | train_inner | epoch 063:   1684 / 1978 loss=3.151, nll_loss=1.006, word_ins=2.824, length=3.273, ppl=8.89, wps=46887.8, ups=0.79, wpb=59575.8, bsz=1940.9, num_updates=124300, lr=0.000283638, gnorm=1.177, loss_scale=16384, train_wall=127, wall=163705
2023-01-14 13:17:58 | INFO | train_inner | epoch 063:   1784 / 1978 loss=3.142, nll_loss=1.001, word_ins=2.82, length=3.217, ppl=8.83, wps=46970.8, ups=0.79, wpb=59751.4, bsz=1996.2, num_updates=124400, lr=0.000283524, gnorm=1.194, loss_scale=16384, train_wall=127, wall=163832
2023-01-14 13:20:05 | INFO | train_inner | epoch 063:   1884 / 1978 loss=3.144, nll_loss=1.001, word_ins=2.82, length=3.241, ppl=8.84, wps=46630, ups=0.78, wpb=59449.9, bsz=1963.1, num_updates=124500, lr=0.00028341, gnorm=1.221, loss_scale=16384, train_wall=127, wall=163960
2023-01-14 13:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 13:22:17 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 4.626 | nll_loss 1.999 | word_ins 3.769 | length 8.565 | ppl 24.7 | wps 119511 | wpb 40242.5 | bsz 1500 | num_updates 124594 | best_loss 4.422
2023-01-14 13:22:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 13:22:47 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint63.pt (epoch 63 @ 124594 updates, score 4.626) (writing took 29.08885629940778 seconds)
2023-01-14 13:22:47 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2023-01-14 13:22:47 | INFO | train | epoch 063 | loss 3.139 | nll_loss 0.998 | word_ins 2.817 | length 3.225 | ppl 8.81 | wps 45562.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 124594 | lr 0.000283303 | gnorm 1.185 | loss_scale 16384 | train_wall 2518 | wall 164121
2023-01-14 13:22:47 | INFO | fairseq.trainer | begin training epoch 64
2023-01-14 13:23:05 | INFO | train_inner | epoch 064:      6 / 1978 loss=3.161, nll_loss=1.012, word_ins=2.83, length=3.316, ppl=8.95, wps=32734.3, ups=0.56, wpb=58738.5, bsz=1977, num_updates=124600, lr=0.000283296, gnorm=1.188, loss_scale=16384, train_wall=128, wall=164139
2023-01-14 13:25:13 | INFO | train_inner | epoch 064:    106 / 1978 loss=3.125, nll_loss=0.986, word_ins=2.807, length=3.18, ppl=8.72, wps=46537.6, ups=0.78, wpb=59610.8, bsz=2010.5, num_updates=124700, lr=0.000283183, gnorm=1.177, loss_scale=16384, train_wall=128, wall=164267
2023-01-14 13:27:21 | INFO | train_inner | epoch 064:    206 / 1978 loss=3.112, nll_loss=0.971, word_ins=2.792, length=3.196, ppl=8.64, wps=46510.5, ups=0.78, wpb=59327.5, bsz=1982.4, num_updates=124800, lr=0.000283069, gnorm=1.199, loss_scale=16384, train_wall=127, wall=164395
2023-01-14 13:29:29 | INFO | train_inner | epoch 064:    306 / 1978 loss=3.122, nll_loss=0.982, word_ins=2.803, length=3.186, ppl=8.7, wps=46373.7, ups=0.78, wpb=59446.1, bsz=2038.6, num_updates=124900, lr=0.000282956, gnorm=1.245, loss_scale=16384, train_wall=128, wall=164523
2023-01-14 13:31:37 | INFO | train_inner | epoch 064:    406 / 1978 loss=3.138, nll_loss=0.998, word_ins=2.817, length=3.206, ppl=8.8, wps=46392.7, ups=0.78, wpb=59280, bsz=2049.9, num_updates=125000, lr=0.000282843, gnorm=1.2, loss_scale=16384, train_wall=128, wall=164651
2023-01-14 13:33:43 | INFO | train_inner | epoch 064:    506 / 1978 loss=3.131, nll_loss=0.99, word_ins=2.81, length=3.203, ppl=8.76, wps=47065.9, ups=0.79, wpb=59647.9, bsz=1969.1, num_updates=125100, lr=0.00028273, gnorm=1.222, loss_scale=16384, train_wall=127, wall=164777
2023-01-14 13:35:51 | INFO | train_inner | epoch 064:    606 / 1978 loss=3.112, nll_loss=0.975, word_ins=2.796, length=3.164, ppl=8.65, wps=46552.1, ups=0.78, wpb=59564.5, bsz=2083.4, num_updates=125200, lr=0.000282617, gnorm=1.205, loss_scale=16384, train_wall=128, wall=164905
2023-01-14 13:37:59 | INFO | train_inner | epoch 064:    706 / 1978 loss=3.105, nll_loss=0.967, word_ins=2.789, length=3.157, ppl=8.6, wps=46729.8, ups=0.78, wpb=59736.1, bsz=2101.5, num_updates=125300, lr=0.000282504, gnorm=1.165, loss_scale=16384, train_wall=128, wall=165033
2023-01-14 13:40:07 | INFO | train_inner | epoch 064:    806 / 1978 loss=3.129, nll_loss=0.993, word_ins=2.812, length=3.167, ppl=8.75, wps=46506.9, ups=0.78, wpb=59387, bsz=2032.6, num_updates=125400, lr=0.000282391, gnorm=1.186, loss_scale=16384, train_wall=127, wall=165161
2023-01-14 13:42:14 | INFO | train_inner | epoch 064:    906 / 1978 loss=3.124, nll_loss=0.981, word_ins=2.801, length=3.225, ppl=8.72, wps=46787.3, ups=0.78, wpb=59670, bsz=2039, num_updates=125500, lr=0.000282279, gnorm=1.204, loss_scale=16384, train_wall=127, wall=165288
2023-01-14 13:44:21 | INFO | train_inner | epoch 064:   1006 / 1978 loss=3.152, nll_loss=1.004, word_ins=2.823, length=3.29, ppl=8.89, wps=46325.7, ups=0.79, wpb=58707.1, bsz=1955, num_updates=125600, lr=0.000282166, gnorm=1.153, loss_scale=16384, train_wall=127, wall=165415
2023-01-14 13:46:27 | INFO | train_inner | epoch 064:   1106 / 1978 loss=3.152, nll_loss=1.003, word_ins=2.822, length=3.301, ppl=8.89, wps=46936, ups=0.79, wpb=59337.8, bsz=1974.2, num_updates=125700, lr=0.000282054, gnorm=1.196, loss_scale=16384, train_wall=126, wall=165542
2023-01-14 13:48:34 | INFO | train_inner | epoch 064:   1206 / 1978 loss=3.175, nll_loss=1.033, word_ins=2.849, length=3.264, ppl=9.03, wps=46733.2, ups=0.79, wpb=59117.6, bsz=1908.6, num_updates=125800, lr=0.000281942, gnorm=1.224, loss_scale=16384, train_wall=126, wall=165668
2023-01-14 13:50:41 | INFO | train_inner | epoch 064:   1306 / 1978 loss=3.121, nll_loss=0.981, word_ins=2.801, length=3.196, ppl=8.7, wps=46807, ups=0.78, wpb=59633.8, bsz=1974.3, num_updates=125900, lr=0.00028183, gnorm=1.184, loss_scale=16384, train_wall=127, wall=165795
2023-01-14 13:52:48 | INFO | train_inner | epoch 064:   1406 / 1978 loss=3.145, nll_loss=1.002, word_ins=2.821, length=3.241, ppl=8.84, wps=46446.1, ups=0.79, wpb=58998.8, bsz=1993.7, num_updates=126000, lr=0.000281718, gnorm=1.175, loss_scale=16384, train_wall=127, wall=165922
2023-01-14 13:54:56 | INFO | train_inner | epoch 064:   1506 / 1978 loss=3.121, nll_loss=0.982, word_ins=2.803, length=3.182, ppl=8.7, wps=46414.8, ups=0.78, wpb=59275.2, bsz=2054.2, num_updates=126100, lr=0.000281606, gnorm=1.234, loss_scale=16384, train_wall=128, wall=166050
2023-01-14 13:57:03 | INFO | train_inner | epoch 064:   1606 / 1978 loss=3.159, nll_loss=1.016, word_ins=2.833, length=3.257, ppl=8.93, wps=46325.2, ups=0.79, wpb=58877.1, bsz=1966.8, num_updates=126200, lr=0.000281495, gnorm=1.203, loss_scale=16384, train_wall=127, wall=166177
2023-01-14 13:59:10 | INFO | train_inner | epoch 064:   1706 / 1978 loss=3.135, nll_loss=0.993, word_ins=2.813, length=3.224, ppl=8.79, wps=46249.8, ups=0.79, wpb=58834.5, bsz=1980.9, num_updates=126300, lr=0.000281383, gnorm=1.221, loss_scale=16384, train_wall=127, wall=166304
2023-01-14 14:01:19 | INFO | train_inner | epoch 064:   1806 / 1978 loss=3.135, nll_loss=0.994, word_ins=2.813, length=3.218, ppl=8.78, wps=46463.3, ups=0.78, wpb=59567.9, bsz=1988.2, num_updates=126400, lr=0.000281272, gnorm=1.187, loss_scale=16384, train_wall=128, wall=166433
2023-01-14 14:03:27 | INFO | train_inner | epoch 064:   1906 / 1978 loss=3.141, nll_loss=1.004, word_ins=2.822, length=3.184, ppl=8.82, wps=46124.7, ups=0.78, wpb=59142.4, bsz=2024.4, num_updates=126500, lr=0.000281161, gnorm=1.205, loss_scale=16384, train_wall=128, wall=166561
2023-01-14 14:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 14:05:10 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 4.567 | nll_loss 1.993 | word_ins 3.761 | length 8.053 | ppl 23.7 | wps 156059 | wpb 40242.5 | bsz 1500 | num_updates 126572 | best_loss 4.422
2023-01-14 14:05:10 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 14:05:39 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint64.pt (epoch 64 @ 126572 updates, score 4.567) (writing took 28.854645286221057 seconds)
2023-01-14 14:05:39 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2023-01-14 14:05:39 | INFO | train | epoch 064 | loss 3.136 | nll_loss 0.994 | word_ins 2.814 | length 3.218 | ppl 8.79 | wps 45582.3 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 126572 | lr 0.000281081 | gnorm 1.2 | loss_scale 16384 | train_wall 2517 | wall 166693
2023-01-14 14:05:39 | INFO | fairseq.trainer | begin training epoch 65
2023-01-14 14:06:27 | INFO | train_inner | epoch 065:     28 / 1978 loss=3.171, nll_loss=1.023, word_ins=2.84, length=3.317, ppl=9.01, wps=32859.5, ups=0.56, wpb=59035.4, bsz=1922.6, num_updates=126600, lr=0.00028105, gnorm=1.251, loss_scale=16384, train_wall=127, wall=166741
2023-01-14 14:06:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 14:08:35 | INFO | train_inner | epoch 065:    129 / 1978 loss=3.116, nll_loss=0.979, word_ins=2.8, length=3.162, ppl=8.67, wps=46229.3, ups=0.78, wpb=59307, bsz=1996.2, num_updates=126700, lr=0.000280939, gnorm=1.171, loss_scale=16384, train_wall=128, wall=166869
2023-01-14 14:10:43 | INFO | train_inner | epoch 065:    229 / 1978 loss=3.144, nll_loss=1.004, word_ins=2.822, length=3.221, ppl=8.84, wps=46415.3, ups=0.78, wpb=59497, bsz=1957.2, num_updates=126800, lr=0.000280828, gnorm=1.226, loss_scale=16384, train_wall=128, wall=166997
2023-01-14 14:12:51 | INFO | train_inner | epoch 065:    329 / 1978 loss=3.088, nll_loss=0.953, word_ins=2.776, length=3.117, ppl=8.5, wps=46779.1, ups=0.78, wpb=59957.7, bsz=2098.8, num_updates=126900, lr=0.000280717, gnorm=1.191, loss_scale=16384, train_wall=128, wall=167125
2023-01-14 14:14:58 | INFO | train_inner | epoch 065:    429 / 1978 loss=3.148, nll_loss=1.007, word_ins=2.825, length=3.226, ppl=8.86, wps=46412.1, ups=0.79, wpb=58821.1, bsz=1965.2, num_updates=127000, lr=0.000280607, gnorm=1.205, loss_scale=16384, train_wall=127, wall=167252
2023-01-14 14:17:07 | INFO | train_inner | epoch 065:    529 / 1978 loss=3.12, nll_loss=0.984, word_ins=2.805, length=3.143, ppl=8.69, wps=45841.5, ups=0.78, wpb=58950.2, bsz=2075.4, num_updates=127100, lr=0.000280496, gnorm=1.172, loss_scale=16384, train_wall=128, wall=167381
2023-01-14 14:19:13 | INFO | train_inner | epoch 065:    629 / 1978 loss=3.133, nll_loss=0.991, word_ins=2.811, length=3.228, ppl=8.77, wps=47220.2, ups=0.79, wpb=59868.5, bsz=1958.8, num_updates=127200, lr=0.000280386, gnorm=1.237, loss_scale=16384, train_wall=127, wall=167507
2023-01-14 14:21:21 | INFO | train_inner | epoch 065:    729 / 1978 loss=3.152, nll_loss=1.005, word_ins=2.823, length=3.284, ppl=8.89, wps=46285.4, ups=0.79, wpb=58940, bsz=1975, num_updates=127300, lr=0.000280276, gnorm=1.185, loss_scale=16384, train_wall=127, wall=167635
2023-01-14 14:23:28 | INFO | train_inner | epoch 065:    829 / 1978 loss=3.159, nll_loss=1.017, word_ins=2.834, length=3.249, ppl=8.93, wps=46750.8, ups=0.79, wpb=59378.1, bsz=1958.8, num_updates=127400, lr=0.000280166, gnorm=1.234, loss_scale=16384, train_wall=127, wall=167762
2023-01-14 14:25:34 | INFO | train_inner | epoch 065:    929 / 1978 loss=3.127, nll_loss=0.984, word_ins=2.804, length=3.226, ppl=8.74, wps=47132.7, ups=0.79, wpb=59513.1, bsz=1897.4, num_updates=127500, lr=0.000280056, gnorm=1.24, loss_scale=16384, train_wall=126, wall=167888
2023-01-14 14:27:42 | INFO | train_inner | epoch 065:   1029 / 1978 loss=3.124, nll_loss=0.988, word_ins=2.808, length=3.161, ppl=8.72, wps=46170.3, ups=0.78, wpb=59009.2, bsz=2047.4, num_updates=127600, lr=0.000279946, gnorm=1.223, loss_scale=16384, train_wall=128, wall=168016
2023-01-14 14:29:49 | INFO | train_inner | epoch 065:   1129 / 1978 loss=3.146, nll_loss=1.004, word_ins=2.822, length=3.234, ppl=8.85, wps=46875.9, ups=0.79, wpb=59429.1, bsz=1910.5, num_updates=127700, lr=0.000279837, gnorm=1.246, loss_scale=16384, train_wall=127, wall=168143
2023-01-14 14:31:56 | INFO | train_inner | epoch 065:   1229 / 1978 loss=3.121, nll_loss=0.979, word_ins=2.8, length=3.214, ppl=8.7, wps=46844, ups=0.78, wpb=59847.2, bsz=1999.1, num_updates=127800, lr=0.000279727, gnorm=1.217, loss_scale=16384, train_wall=128, wall=168270
2023-01-14 14:34:04 | INFO | train_inner | epoch 065:   1329 / 1978 loss=3.14, nll_loss=1.002, word_ins=2.82, length=3.192, ppl=8.81, wps=46271.2, ups=0.78, wpb=59300.7, bsz=2081.8, num_updates=127900, lr=0.000279618, gnorm=1.204, loss_scale=16384, train_wall=128, wall=168399
2023-01-14 14:36:11 | INFO | train_inner | epoch 065:   1429 / 1978 loss=3.141, nll_loss=0.998, word_ins=2.817, length=3.234, ppl=8.82, wps=46229.6, ups=0.79, wpb=58593.8, bsz=1936.8, num_updates=128000, lr=0.000279508, gnorm=1.223, loss_scale=16384, train_wall=127, wall=168525
2023-01-14 14:38:17 | INFO | train_inner | epoch 065:   1529 / 1978 loss=3.141, nll_loss=0.999, word_ins=2.818, length=3.227, ppl=8.82, wps=47107.6, ups=0.79, wpb=59290.8, bsz=1976.6, num_updates=128100, lr=0.000279399, gnorm=1.188, loss_scale=16384, train_wall=126, wall=168651
2023-01-14 14:40:25 | INFO | train_inner | epoch 065:   1629 / 1978 loss=3.126, nll_loss=0.985, word_ins=2.805, length=3.208, ppl=8.73, wps=46099.8, ups=0.78, wpb=59099.6, bsz=2077.5, num_updates=128200, lr=0.00027929, gnorm=1.162, loss_scale=16384, train_wall=128, wall=168779
2023-01-14 14:42:33 | INFO | train_inner | epoch 065:   1729 / 1978 loss=3.128, nll_loss=0.984, word_ins=2.805, length=3.232, ppl=8.74, wps=45991.1, ups=0.78, wpb=58841.4, bsz=2038.3, num_updates=128300, lr=0.000279182, gnorm=1.191, loss_scale=16384, train_wall=128, wall=168907
2023-01-14 14:44:42 | INFO | train_inner | epoch 065:   1829 / 1978 loss=3.118, nll_loss=0.977, word_ins=2.798, length=3.2, ppl=8.68, wps=46178.5, ups=0.78, wpb=59257.8, bsz=2061.8, num_updates=128400, lr=0.000279073, gnorm=1.179, loss_scale=16384, train_wall=128, wall=169036
2023-01-14 14:46:50 | INFO | train_inner | epoch 065:   1929 / 1978 loss=3.117, nll_loss=0.981, word_ins=2.801, length=3.152, ppl=8.67, wps=46238.5, ups=0.78, wpb=59414.8, bsz=2071.1, num_updates=128500, lr=0.000278964, gnorm=1.232, loss_scale=16384, train_wall=128, wall=169164
2023-01-14 14:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 14:48:04 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 4.543 | nll_loss 1.998 | word_ins 3.764 | length 7.795 | ppl 23.31 | wps 106153 | wpb 40242.5 | bsz 1500 | num_updates 128549 | best_loss 4.422
2023-01-14 14:48:04 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 14:48:32 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint65.pt (epoch 65 @ 128549 updates, score 4.543) (writing took 27.80047788284719 seconds)
2023-01-14 14:48:32 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2023-01-14 14:48:32 | INFO | train | epoch 065 | loss 3.131 | nll_loss 0.99 | word_ins 2.81 | length 3.208 | ppl 8.76 | wps 45561.9 | ups 0.77 | wpb 59283.6 | bsz 2002.8 | num_updates 128549 | lr 0.000278911 | gnorm 1.207 | loss_scale 16384 | train_wall 2518 | wall 169266
2023-01-14 14:48:32 | INFO | fairseq.trainer | begin training epoch 66
2023-01-14 14:49:48 | INFO | train_inner | epoch 066:     51 / 1978 loss=3.124, nll_loss=0.981, word_ins=2.802, length=3.223, ppl=8.72, wps=33098.3, ups=0.56, wpb=58921.8, bsz=1996.6, num_updates=128600, lr=0.000278856, gnorm=1.203, loss_scale=16384, train_wall=127, wall=169342
2023-01-14 14:51:56 | INFO | train_inner | epoch 066:    151 / 1978 loss=3.112, nll_loss=0.975, word_ins=2.796, length=3.155, ppl=8.64, wps=45853.4, ups=0.78, wpb=58836, bsz=2038.9, num_updates=128700, lr=0.000278747, gnorm=1.207, loss_scale=16384, train_wall=128, wall=169470
2023-01-14 14:54:04 | INFO | train_inner | epoch 066:    251 / 1978 loss=3.119, nll_loss=0.972, word_ins=2.794, length=3.248, ppl=8.69, wps=46004, ups=0.78, wpb=58895.9, bsz=2029.8, num_updates=128800, lr=0.000278639, gnorm=1.21, loss_scale=16384, train_wall=128, wall=169599
2023-01-14 14:56:12 | INFO | train_inner | epoch 066:    351 / 1978 loss=3.146, nll_loss=1.004, word_ins=2.822, length=3.236, ppl=8.85, wps=46638.6, ups=0.78, wpb=59509.9, bsz=1938.5, num_updates=128900, lr=0.000278531, gnorm=1.203, loss_scale=16384, train_wall=127, wall=169726
2023-01-14 14:58:20 | INFO | train_inner | epoch 066:    451 / 1978 loss=3.114, nll_loss=0.974, word_ins=2.795, length=3.183, ppl=8.66, wps=46509.2, ups=0.78, wpb=59444.5, bsz=2026.7, num_updates=129000, lr=0.000278423, gnorm=1.179, loss_scale=16384, train_wall=128, wall=169854
2023-01-14 15:00:28 | INFO | train_inner | epoch 066:    551 / 1978 loss=3.092, nll_loss=0.955, word_ins=2.779, length=3.134, ppl=8.53, wps=46400.7, ups=0.78, wpb=59466.4, bsz=2085.9, num_updates=129100, lr=0.000278315, gnorm=1.216, loss_scale=16384, train_wall=128, wall=169982
2023-01-14 15:02:36 | INFO | train_inner | epoch 066:    651 / 1978 loss=3.131, nll_loss=0.992, word_ins=2.812, length=3.189, ppl=8.76, wps=45988.9, ups=0.78, wpb=58902.5, bsz=1990.6, num_updates=129200, lr=0.000278207, gnorm=1.21, loss_scale=16384, train_wall=128, wall=170110
2023-01-14 15:04:44 | INFO | train_inner | epoch 066:    751 / 1978 loss=3.134, nll_loss=0.993, word_ins=2.812, length=3.216, ppl=8.78, wps=46389.9, ups=0.78, wpb=59248.5, bsz=1952.7, num_updates=129300, lr=0.0002781, gnorm=1.24, loss_scale=16384, train_wall=128, wall=170238
2023-01-14 15:06:51 | INFO | train_inner | epoch 066:    851 / 1978 loss=3.144, nll_loss=1.001, word_ins=2.82, length=3.235, ppl=8.84, wps=46692.3, ups=0.79, wpb=59436.2, bsz=1953.6, num_updates=129400, lr=0.000277992, gnorm=1.274, loss_scale=16384, train_wall=127, wall=170365
2023-01-14 15:08:59 | INFO | train_inner | epoch 066:    951 / 1978 loss=3.103, nll_loss=0.966, word_ins=2.787, length=3.158, ppl=8.59, wps=46761, ups=0.78, wpb=59850.6, bsz=2103.9, num_updates=129500, lr=0.000277885, gnorm=1.199, loss_scale=16384, train_wall=128, wall=170493
2023-01-14 15:11:06 | INFO | train_inner | epoch 066:   1051 / 1978 loss=3.128, nll_loss=0.984, word_ins=2.804, length=3.242, ppl=8.74, wps=46455.9, ups=0.79, wpb=59049.5, bsz=1969.2, num_updates=129600, lr=0.000277778, gnorm=1.223, loss_scale=16384, train_wall=127, wall=170620
2023-01-14 15:13:15 | INFO | train_inner | epoch 066:   1151 / 1978 loss=3.101, nll_loss=0.967, word_ins=2.789, length=3.116, ppl=8.58, wps=46244.7, ups=0.78, wpb=59528.8, bsz=2095.4, num_updates=129700, lr=0.000277671, gnorm=1.196, loss_scale=16384, train_wall=129, wall=170749
2023-01-14 15:15:23 | INFO | train_inner | epoch 066:   1251 / 1978 loss=3.125, nll_loss=0.986, word_ins=2.806, length=3.196, ppl=8.72, wps=46684.9, ups=0.78, wpb=59618.9, bsz=1985, num_updates=129800, lr=0.000277564, gnorm=1.25, loss_scale=16384, train_wall=127, wall=170877
2023-01-14 15:17:30 | INFO | train_inner | epoch 066:   1351 / 1978 loss=3.161, nll_loss=1.018, word_ins=2.835, length=3.262, ppl=8.95, wps=46433.2, ups=0.79, wpb=58949.1, bsz=1940.2, num_updates=129900, lr=0.000277457, gnorm=1.262, loss_scale=16384, train_wall=127, wall=171004
2023-01-14 15:19:36 | INFO | train_inner | epoch 066:   1451 / 1978 loss=3.142, nll_loss=0.998, word_ins=2.817, length=3.255, ppl=8.83, wps=46836.9, ups=0.79, wpb=59400.6, bsz=1903.1, num_updates=130000, lr=0.00027735, gnorm=1.23, loss_scale=16384, train_wall=127, wall=171131
2023-01-14 15:21:44 | INFO | train_inner | epoch 066:   1551 / 1978 loss=3.12, nll_loss=0.983, word_ins=2.803, length=3.176, ppl=8.7, wps=46488.7, ups=0.78, wpb=59472.5, bsz=2037, num_updates=130100, lr=0.000277243, gnorm=1.215, loss_scale=16384, train_wall=128, wall=171258
2023-01-14 15:23:52 | INFO | train_inner | epoch 066:   1651 / 1978 loss=3.137, nll_loss=0.997, word_ins=2.817, length=3.206, ppl=8.8, wps=46061.9, ups=0.78, wpb=58965.7, bsz=2058.5, num_updates=130200, lr=0.000277137, gnorm=1.249, loss_scale=16384, train_wall=128, wall=171386
2023-01-14 15:25:59 | INFO | train_inner | epoch 066:   1751 / 1978 loss=3.142, nll_loss=1.004, word_ins=2.823, length=3.194, ppl=8.83, wps=46765.4, ups=0.79, wpb=59355.4, bsz=1945.3, num_updates=130300, lr=0.000277031, gnorm=1.248, loss_scale=16384, train_wall=127, wall=171513
2023-01-14 15:28:06 | INFO | train_inner | epoch 066:   1851 / 1978 loss=3.14, nll_loss=0.994, word_ins=2.813, length=3.264, ppl=8.81, wps=46809.1, ups=0.79, wpb=59284.1, bsz=1937.8, num_updates=130400, lr=0.000276924, gnorm=1.232, loss_scale=16384, train_wall=126, wall=171640
2023-01-14 15:30:13 | INFO | train_inner | epoch 066:   1951 / 1978 loss=3.123, nll_loss=0.975, word_ins=2.796, length=3.271, ppl=8.71, wps=46762, ups=0.79, wpb=59437.5, bsz=2009, num_updates=130500, lr=0.000276818, gnorm=1.245, loss_scale=16384, train_wall=127, wall=171767
2023-01-14 15:30:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 15:30:58 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 4.588 | nll_loss 1.997 | word_ins 3.76 | length 8.281 | ppl 24.05 | wps 170766 | wpb 40242.5 | bsz 1500 | num_updates 130527 | best_loss 4.422
2023-01-14 15:30:58 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 15:31:28 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint66.pt (epoch 66 @ 130527 updates, score 4.588) (writing took 29.163434030022472 seconds)
2023-01-14 15:31:28 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2023-01-14 15:31:28 | INFO | train | epoch 066 | loss 3.127 | nll_loss 0.986 | word_ins 2.806 | length 3.205 | ppl 8.73 | wps 45520.3 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 130527 | lr 0.00027679 | gnorm 1.226 | loss_scale 16384 | train_wall 2521 | wall 171842
2023-01-14 15:31:28 | INFO | fairseq.trainer | begin training epoch 67
2023-01-14 15:33:12 | INFO | train_inner | epoch 067:     73 / 1978 loss=3.107, nll_loss=0.97, word_ins=2.791, length=3.164, ppl=8.62, wps=33252.9, ups=0.56, wpb=59375.6, bsz=2025.6, num_updates=130600, lr=0.000276712, gnorm=1.243, loss_scale=16384, train_wall=128, wall=171946
2023-01-14 15:35:19 | INFO | train_inner | epoch 067:    173 / 1978 loss=3.127, nll_loss=0.985, word_ins=2.806, length=3.217, ppl=8.74, wps=46672, ups=0.79, wpb=59357.5, bsz=1989, num_updates=130700, lr=0.000276606, gnorm=1.209, loss_scale=16384, train_wall=127, wall=172073
2023-01-14 15:35:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-01-14 15:37:28 | INFO | train_inner | epoch 067:    274 / 1978 loss=3.111, nll_loss=0.967, word_ins=2.789, length=3.22, ppl=8.64, wps=46317, ups=0.78, wpb=59674.1, bsz=2004.3, num_updates=130800, lr=0.000276501, gnorm=1.23, loss_scale=16384, train_wall=129, wall=172202
2023-01-14 15:39:34 | INFO | train_inner | epoch 067:    374 / 1978 loss=3.137, nll_loss=0.999, word_ins=2.818, length=3.193, ppl=8.8, wps=46313, ups=0.79, wpb=58586.8, bsz=1968.8, num_updates=130900, lr=0.000276395, gnorm=1.206, loss_scale=16384, train_wall=126, wall=172328
2023-01-14 15:41:42 | INFO | train_inner | epoch 067:    474 / 1978 loss=3.105, nll_loss=0.968, word_ins=2.79, length=3.151, ppl=8.6, wps=46668.3, ups=0.78, wpb=59688.6, bsz=2045.2, num_updates=131000, lr=0.000276289, gnorm=1.211, loss_scale=16384, train_wall=128, wall=172456
2023-01-14 15:43:49 | INFO | train_inner | epoch 067:    574 / 1978 loss=3.12, nll_loss=0.982, word_ins=2.802, length=3.174, ppl=8.69, wps=46608.5, ups=0.79, wpb=59225.7, bsz=1986, num_updates=131100, lr=0.000276184, gnorm=1.258, loss_scale=16384, train_wall=127, wall=172583
2023-01-14 15:45:57 | INFO | train_inner | epoch 067:    674 / 1978 loss=3.147, nll_loss=1.003, word_ins=2.822, length=3.254, ppl=8.86, wps=46134.8, ups=0.78, wpb=58981.3, bsz=1918.3, num_updates=131200, lr=0.000276079, gnorm=1.257, loss_scale=16384, train_wall=128, wall=172711
2023-01-14 15:48:05 | INFO | train_inner | epoch 067:    774 / 1978 loss=3.131, nll_loss=0.986, word_ins=2.806, length=3.249, ppl=8.76, wps=46626.2, ups=0.78, wpb=59594.7, bsz=1998.6, num_updates=131300, lr=0.000275974, gnorm=1.281, loss_scale=16384, train_wall=128, wall=172839
2023-01-14 15:50:13 | INFO | train_inner | epoch 067:    874 / 1978 loss=3.112, nll_loss=0.967, word_ins=2.789, length=3.23, ppl=8.65, wps=46225.2, ups=0.78, wpb=59085.3, bsz=2023.4, num_updates=131400, lr=0.000275869, gnorm=1.202, loss_scale=16384, train_wall=128, wall=172967
2023-01-14 15:52:20 | INFO | train_inner | epoch 067:    974 / 1978 loss=3.1, nll_loss=0.964, word_ins=2.786, length=3.143, ppl=8.58, wps=46622.4, ups=0.79, wpb=59375.6, bsz=2065.9, num_updates=131500, lr=0.000275764, gnorm=1.206, loss_scale=16384, train_wall=127, wall=173094
2023-01-14 15:54:28 | INFO | train_inner | epoch 067:   1074 / 1978 loss=3.148, nll_loss=1.011, word_ins=2.828, length=3.2, ppl=8.87, wps=46160.8, ups=0.78, wpb=59246.7, bsz=1996.2, num_updates=131600, lr=0.000275659, gnorm=1.192, loss_scale=16384, train_wall=128, wall=173222
2023-01-14 15:56:37 | INFO | train_inner | epoch 067:   1174 / 1978 loss=3.095, nll_loss=0.959, word_ins=2.782, length=3.137, ppl=8.55, wps=46143.9, ups=0.78, wpb=59378.5, bsz=2099.1, num_updates=131700, lr=0.000275554, gnorm=1.248, loss_scale=16384, train_wall=128, wall=173351
2023-01-14 15:58:45 | INFO | train_inner | epoch 067:   1274 / 1978 loss=3.115, nll_loss=0.976, word_ins=2.797, length=3.187, ppl=8.67, wps=46870, ups=0.78, wpb=59918.9, bsz=2043.4, num_updates=131800, lr=0.00027545, gnorm=1.24, loss_scale=16384, train_wall=128, wall=173479
2023-01-14 16:00:52 | INFO | train_inner | epoch 067:   1374 / 1978 loss=3.114, nll_loss=0.975, word_ins=2.796, length=3.182, ppl=8.66, wps=46695.8, ups=0.78, wpb=59558.3, bsz=2020.6, num_updates=131900, lr=0.000275345, gnorm=1.244, loss_scale=16384, train_wall=127, wall=173607
2023-01-14 16:02:59 | INFO | train_inner | epoch 067:   1474 / 1978 loss=3.131, nll_loss=0.987, word_ins=2.807, length=3.24, ppl=8.76, wps=46695, ups=0.79, wpb=59143.8, bsz=2008.2, num_updates=132000, lr=0.000275241, gnorm=1.25, loss_scale=16384, train_wall=126, wall=173733
2023-01-14 16:05:07 | INFO | train_inner | epoch 067:   1574 / 1978 loss=3.115, nll_loss=0.975, word_ins=2.796, length=3.192, ppl=8.66, wps=46378.2, ups=0.78, wpb=59301.1, bsz=2017.6, num_updates=132100, lr=0.000275137, gnorm=1.239, loss_scale=16384, train_wall=128, wall=173861
2023-01-14 16:07:13 | INFO | train_inner | epoch 067:   1674 / 1978 loss=3.119, nll_loss=0.979, word_ins=2.799, length=3.195, ppl=8.69, wps=46611.5, ups=0.79, wpb=58926.6, bsz=1922.2, num_updates=132200, lr=0.000275033, gnorm=1.21, loss_scale=16384, train_wall=126, wall=173988
2023-01-14 16:09:21 | INFO | train_inner | epoch 067:   1774 / 1978 loss=3.161, nll_loss=1.016, word_ins=2.833, length=3.277, ppl=8.94, wps=45894.2, ups=0.78, wpb=58544.4, bsz=1963.8, num_updates=132300, lr=0.000274929, gnorm=1.228, loss_scale=16384, train_wall=127, wall=174115
2023-01-14 16:11:28 | INFO | train_inner | epoch 067:   1874 / 1978 loss=3.148, nll_loss=1.008, word_ins=2.826, length=3.222, ppl=8.87, wps=46226.3, ups=0.79, wpb=58873.5, bsz=1976.1, num_updates=132400, lr=0.000274825, gnorm=1.218, loss_scale=16384, train_wall=127, wall=174242
2023-01-14 16:13:37 | INFO | train_inner | epoch 067:   1974 / 1978 loss=3.125, nll_loss=0.986, word_ins=2.805, length=3.197, ppl=8.72, wps=46325.1, ups=0.78, wpb=59720.8, bsz=2032.2, num_updates=132500, lr=0.000274721, gnorm=1.259, loss_scale=16384, train_wall=129, wall=174371
2023-01-14 16:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 16:13:54 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 4.63 | nll_loss 1.994 | word_ins 3.757 | length 8.728 | ppl 24.76 | wps 128178 | wpb 40242.5 | bsz 1500 | num_updates 132504 | best_loss 4.422
2023-01-14 16:13:54 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 16:14:22 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint67.pt (epoch 67 @ 132504 updates, score 4.63) (writing took 27.719298236072063 seconds)
2023-01-14 16:14:22 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2023-01-14 16:14:22 | INFO | train | epoch 067 | loss 3.124 | nll_loss 0.983 | word_ins 2.803 | length 3.203 | ppl 8.72 | wps 45527.5 | ups 0.77 | wpb 59283.8 | bsz 2002.8 | num_updates 132504 | lr 0.000274717 | gnorm 1.232 | loss_scale 16384 | train_wall 2519 | wall 174416
2023-01-14 16:14:22 | INFO | fairseq.trainer | begin training epoch 68
2023-01-14 16:16:37 | INFO | train_inner | epoch 068:     96 / 1978 loss=3.095, nll_loss=0.953, word_ins=2.776, length=3.186, ppl=8.54, wps=33172.5, ups=0.56, wpb=59491.6, bsz=1975.3, num_updates=132600, lr=0.000274618, gnorm=1.229, loss_scale=16384, train_wall=127, wall=174551
2023-01-14 16:18:44 | INFO | train_inner | epoch 068:    196 / 1978 loss=3.109, nll_loss=0.967, word_ins=2.789, length=3.202, ppl=8.63, wps=46531, ups=0.79, wpb=59209.7, bsz=1995.7, num_updates=132700, lr=0.000274514, gnorm=1.231, loss_scale=16384, train_wall=127, wall=174678
2023-01-14 16:20:51 | INFO | train_inner | epoch 068:    296 / 1978 loss=3.113, nll_loss=0.979, word_ins=2.8, length=3.129, ppl=8.65, wps=46052.5, ups=0.79, wpb=58555, bsz=2036.1, num_updates=132800, lr=0.000274411, gnorm=1.19, loss_scale=16384, train_wall=127, wall=174805
2023-01-14 16:22:59 | INFO | train_inner | epoch 068:    396 / 1978 loss=3.157, nll_loss=1.015, word_ins=2.832, length=3.248, ppl=8.92, wps=45952.8, ups=0.78, wpb=58731.1, bsz=1955.7, num_updates=132900, lr=0.000274307, gnorm=1.243, loss_scale=16384, train_wall=128, wall=174933
2023-01-14 16:25:07 | INFO | train_inner | epoch 068:    496 / 1978 loss=3.099, nll_loss=0.96, word_ins=2.782, length=3.166, ppl=8.57, wps=46289, ups=0.78, wpb=59286.5, bsz=2081.4, num_updates=133000, lr=0.000274204, gnorm=1.217, loss_scale=16384, train_wall=128, wall=175061
2023-01-14 16:27:13 | INFO | train_inner | epoch 068:    596 / 1978 loss=3.137, nll_loss=0.993, word_ins=2.812, length=3.247, ppl=8.8, wps=46700.2, ups=0.79, wpb=59064.4, bsz=1905.1, num_updates=133100, lr=0.000274101, gnorm=1.224, loss_scale=16384, train_wall=126, wall=175187
2023-01-14 16:29:21 | INFO | train_inner | epoch 068:    696 / 1978 loss=3.125, nll_loss=0.987, word_ins=2.807, length=3.178, ppl=8.72, wps=46345.6, ups=0.79, wpb=58909.6, bsz=2021.7, num_updates=133200, lr=0.000273998, gnorm=1.222, loss_scale=16384, train_wall=127, wall=175315
2023-01-14 16:29:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-14 16:31:30 | INFO | train_inner | epoch 068:    797 / 1978 loss=3.127, nll_loss=0.986, word_ins=2.806, length=3.207, ppl=8.74, wps=45892.2, ups=0.77, wpb=59259.2, bsz=2006.6, num_updates=133300, lr=0.000273896, gnorm=1.216, loss_scale=8192, train_wall=129, wall=175444
2023-01-14 16:33:38 | INFO | train_inner | epoch 068:    897 / 1978 loss=3.112, nll_loss=0.974, word_ins=2.795, length=3.176, ppl=8.65, wps=46101.5, ups=0.78, wpb=59330.2, bsz=2160.2, num_updates=133400, lr=0.000273793, gnorm=1.24, loss_scale=8192, train_wall=128, wall=175572
2023-01-14 16:35:46 | INFO | train_inner | epoch 068:    997 / 1978 loss=3.102, nll_loss=0.963, word_ins=2.785, length=3.166, ppl=8.58, wps=46289.9, ups=0.78, wpb=59193.5, bsz=2072.6, num_updates=133500, lr=0.00027369, gnorm=1.235, loss_scale=8192, train_wall=128, wall=175700
2023-01-14 16:37:54 | INFO | train_inner | epoch 068:   1097 / 1978 loss=3.139, nll_loss=0.998, word_ins=2.817, length=3.214, ppl=8.81, wps=46213.9, ups=0.78, wpb=59250.5, bsz=1968, num_updates=133600, lr=0.000273588, gnorm=1.249, loss_scale=8192, train_wall=128, wall=175829
2023-01-14 16:40:03 | INFO | train_inner | epoch 068:   1197 / 1978 loss=3.124, nll_loss=0.982, word_ins=2.802, length=3.218, ppl=8.72, wps=46431.5, ups=0.78, wpb=59555.7, bsz=2007.2, num_updates=133700, lr=0.000273485, gnorm=1.27, loss_scale=8192, train_wall=128, wall=175957
2023-01-14 16:42:10 | INFO | train_inner | epoch 068:   1297 / 1978 loss=3.124, nll_loss=0.985, word_ins=2.806, length=3.186, ppl=8.72, wps=46665.1, ups=0.78, wpb=59480.9, bsz=1980.9, num_updates=133800, lr=0.000273383, gnorm=1.266, loss_scale=8192, train_wall=127, wall=176084
2023-01-14 16:44:17 | INFO | train_inner | epoch 068:   1397 / 1978 loss=3.127, nll_loss=0.985, word_ins=2.805, length=3.226, ppl=8.74, wps=46786.6, ups=0.79, wpb=59370.7, bsz=1939.3, num_updates=133900, lr=0.000273281, gnorm=1.264, loss_scale=8192, train_wall=127, wall=176211
2023-01-14 16:46:24 | INFO | train_inner | epoch 068:   1497 / 1978 loss=3.096, nll_loss=0.957, word_ins=2.779, length=3.169, ppl=8.55, wps=46634.4, ups=0.79, wpb=59335.5, bsz=2010.3, num_updates=134000, lr=0.000273179, gnorm=1.223, loss_scale=8192, train_wall=127, wall=176338
2023-01-14 16:48:32 | INFO | train_inner | epoch 068:   1597 / 1978 loss=3.118, nll_loss=0.974, word_ins=2.794, length=3.24, ppl=8.68, wps=46975.4, ups=0.79, wpb=59768.8, bsz=1992.7, num_updates=134100, lr=0.000273077, gnorm=1.272, loss_scale=8192, train_wall=127, wall=176466
2023-01-14 16:50:40 | INFO | train_inner | epoch 068:   1697 / 1978 loss=3.109, nll_loss=0.973, word_ins=2.793, length=3.154, ppl=8.63, wps=46653.3, ups=0.78, wpb=59840.9, bsz=2023.7, num_updates=134200, lr=0.000272976, gnorm=1.245, loss_scale=8192, train_wall=128, wall=176594
2023-01-14 16:52:47 | INFO | train_inner | epoch 068:   1797 / 1978 loss=3.117, nll_loss=0.982, word_ins=2.802, length=3.155, ppl=8.68, wps=46746.7, ups=0.79, wpb=59309.4, bsz=2028.6, num_updates=134300, lr=0.000272874, gnorm=1.211, loss_scale=8192, train_wall=127, wall=176721
2023-01-14 16:54:54 | INFO | train_inner | epoch 068:   1897 / 1978 loss=3.127, nll_loss=0.982, word_ins=2.802, length=3.246, ppl=8.73, wps=46616.2, ups=0.79, wpb=59302.3, bsz=1990, num_updates=134400, lr=0.000272772, gnorm=1.265, loss_scale=8192, train_wall=127, wall=176848
2023-01-14 16:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 16:56:47 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 4.537 | nll_loss 1.987 | word_ins 3.752 | length 7.849 | ppl 23.21 | wps 131849 | wpb 40242.5 | bsz 1500 | num_updates 134481 | best_loss 4.422
2023-01-14 16:56:47 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 16:57:15 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint68.pt (epoch 68 @ 134481 updates, score 4.537) (writing took 27.72119717532769 seconds)
2023-01-14 16:57:15 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2023-01-14 16:57:15 | INFO | train | epoch 068 | loss 3.12 | nll_loss 0.98 | word_ins 2.8 | length 3.199 | ppl 8.69 | wps 45552.4 | ups 0.77 | wpb 59283.6 | bsz 2003 | num_updates 134481 | lr 0.00027269 | gnorm 1.24 | loss_scale 8192 | train_wall 2517 | wall 176989
2023-01-14 16:57:15 | INFO | fairseq.trainer | begin training epoch 69
2023-01-14 16:57:51 | INFO | train_inner | epoch 069:     19 / 1978 loss=3.142, nll_loss=0.998, word_ins=2.817, length=3.25, ppl=8.82, wps=33720.1, ups=0.57, wpb=59540.6, bsz=1903.2, num_updates=134500, lr=0.000272671, gnorm=1.29, loss_scale=8192, train_wall=126, wall=177025
2023-01-14 16:59:58 | INFO | train_inner | epoch 069:    119 / 1978 loss=3.115, nll_loss=0.976, word_ins=2.797, length=3.181, ppl=8.66, wps=46299.8, ups=0.78, wpb=59207.5, bsz=1967.2, num_updates=134600, lr=0.00027257, gnorm=1.253, loss_scale=8192, train_wall=128, wall=177152
2023-01-14 17:02:06 | INFO | train_inner | epoch 069:    219 / 1978 loss=3.112, nll_loss=0.974, word_ins=2.795, length=3.169, ppl=8.65, wps=46572.2, ups=0.78, wpb=59337.1, bsz=1964.9, num_updates=134700, lr=0.000272468, gnorm=1.22, loss_scale=8192, train_wall=127, wall=177280
2023-01-14 17:04:14 | INFO | train_inner | epoch 069:    319 / 1978 loss=3.09, nll_loss=0.954, word_ins=2.777, length=3.138, ppl=8.52, wps=46823.3, ups=0.78, wpb=59822.8, bsz=2033.3, num_updates=134800, lr=0.000272367, gnorm=1.228, loss_scale=8192, train_wall=128, wall=177408
2023-01-14 17:06:21 | INFO | train_inner | epoch 069:    419 / 1978 loss=3.1, nll_loss=0.959, word_ins=2.782, length=3.184, ppl=8.57, wps=46474.8, ups=0.79, wpb=59018.5, bsz=2009.7, num_updates=134900, lr=0.000272266, gnorm=1.279, loss_scale=8192, train_wall=127, wall=177535
2023-01-14 17:08:28 | INFO | train_inner | epoch 069:    519 / 1978 loss=3.127, nll_loss=0.985, word_ins=2.805, length=3.221, ppl=8.74, wps=46282.1, ups=0.79, wpb=58920, bsz=1951.8, num_updates=135000, lr=0.000272166, gnorm=1.243, loss_scale=8192, train_wall=127, wall=177662
2023-01-14 17:10:35 | INFO | train_inner | epoch 069:    619 / 1978 loss=3.12, nll_loss=0.983, word_ins=2.803, length=3.17, ppl=8.69, wps=46552.1, ups=0.78, wpb=59326.6, bsz=1963.8, num_updates=135100, lr=0.000272065, gnorm=1.231, loss_scale=8192, train_wall=127, wall=177789
2023-01-14 17:12:43 | INFO | train_inner | epoch 069:    719 / 1978 loss=3.126, nll_loss=0.988, word_ins=2.808, length=3.188, ppl=8.73, wps=46034.8, ups=0.78, wpb=58915.9, bsz=2014.6, num_updates=135200, lr=0.000271964, gnorm=1.234, loss_scale=8192, train_wall=128, wall=177917
2023-01-14 17:14:52 | INFO | train_inner | epoch 069:    819 / 1978 loss=3.106, nll_loss=0.963, word_ins=2.785, length=3.211, ppl=8.61, wps=46245.3, ups=0.78, wpb=59318.8, bsz=2047.3, num_updates=135300, lr=0.000271864, gnorm=1.276, loss_scale=8192, train_wall=128, wall=178046
2023-01-14 17:16:58 | INFO | train_inner | epoch 069:    919 / 1978 loss=3.132, nll_loss=0.988, word_ins=2.807, length=3.252, ppl=8.77, wps=46570.3, ups=0.79, wpb=59102, bsz=1921, num_updates=135400, lr=0.000271763, gnorm=1.259, loss_scale=8192, train_wall=127, wall=178173
2023-01-14 17:19:06 | INFO | train_inner | epoch 069:   1019 / 1978 loss=3.126, nll_loss=0.989, word_ins=2.808, length=3.176, ppl=8.73, wps=46640.2, ups=0.78, wpb=59677.2, bsz=2011.4, num_updates=135500, lr=0.000271663, gnorm=1.267, loss_scale=8192, train_wall=128, wall=178301
2023-01-14 17:21:15 | INFO | train_inner | epoch 069:   1119 / 1978 loss=3.101, nll_loss=0.967, word_ins=2.789, length=3.124, ppl=8.58, wps=45883.3, ups=0.78, wpb=59125.5, bsz=2120.3, num_updates=135600, lr=0.000271563, gnorm=1.226, loss_scale=8192, train_wall=129, wall=178429
2023-01-14 17:23:23 | INFO | train_inner | epoch 069:   1219 / 1978 loss=3.107, nll_loss=0.967, word_ins=2.788, length=3.193, ppl=8.62, wps=46346.8, ups=0.78, wpb=59096.3, bsz=2074.1, num_updates=135700, lr=0.000271463, gnorm=1.286, loss_scale=8192, train_wall=127, wall=178557
2023-01-14 17:25:31 | INFO | train_inner | epoch 069:   1319 / 1978 loss=3.131, nll_loss=0.991, word_ins=2.81, length=3.206, ppl=8.76, wps=46510.8, ups=0.78, wpb=59416.5, bsz=2008.6, num_updates=135800, lr=0.000271363, gnorm=1.253, loss_scale=8192, train_wall=128, wall=178685
2023-01-14 17:27:39 | INFO | train_inner | epoch 069:   1419 / 1978 loss=3.105, nll_loss=0.968, word_ins=2.789, length=3.159, ppl=8.6, wps=46003.3, ups=0.78, wpb=59031.7, bsz=2057.4, num_updates=135900, lr=0.000271263, gnorm=1.202, loss_scale=8192, train_wall=128, wall=178813
2023-01-14 17:29:46 | INFO | train_inner | epoch 069:   1519 / 1978 loss=3.155, nll_loss=1.009, word_ins=2.826, length=3.292, ppl=8.91, wps=46864.9, ups=0.78, wpb=59720.2, bsz=1910.7, num_updates=136000, lr=0.000271163, gnorm=1.282, loss_scale=8192, train_wall=127, wall=178940
2023-01-14 17:31:55 | INFO | train_inner | epoch 069:   1619 / 1978 loss=3.084, nll_loss=0.947, word_ins=2.77, length=3.142, ppl=8.48, wps=46376.6, ups=0.78, wpb=59569.5, bsz=2139.2, num_updates=136100, lr=0.000271063, gnorm=1.221, loss_scale=8192, train_wall=128, wall=179069
2023-01-14 17:34:01 | INFO | train_inner | epoch 069:   1719 / 1978 loss=3.123, nll_loss=0.981, word_ins=2.801, length=3.22, ppl=8.71, wps=46790.2, ups=0.79, wpb=59227.2, bsz=1957.2, num_updates=136200, lr=0.000270964, gnorm=1.292, loss_scale=8192, train_wall=126, wall=179195
2023-01-14 17:36:09 | INFO | train_inner | epoch 069:   1819 / 1978 loss=3.111, nll_loss=0.972, word_ins=2.793, length=3.182, ppl=8.64, wps=46342, ups=0.79, wpb=58969.4, bsz=2010.2, num_updates=136300, lr=0.000270864, gnorm=1.243, loss_scale=8192, train_wall=127, wall=179323
2023-01-14 17:38:15 | INFO | train_inner | epoch 069:   1919 / 1978 loss=3.134, nll_loss=0.993, word_ins=2.812, length=3.22, ppl=8.78, wps=46889.4, ups=0.79, wpb=59411.6, bsz=1948.2, num_updates=136400, lr=0.000270765, gnorm=1.24, loss_scale=8192, train_wall=126, wall=179449
2023-01-14 17:39:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 17:39:46 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 4.532 | nll_loss 1.997 | word_ins 3.76 | length 7.719 | ppl 23.13 | wps 148333 | wpb 40242.5 | bsz 1500 | num_updates 136459 | best_loss 4.422
2023-01-14 17:39:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 17:40:14 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint69.pt (epoch 69 @ 136459 updates, score 4.532) (writing took 27.801483639981598 seconds)
2023-01-14 17:40:14 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2023-01-14 17:40:14 | INFO | train | epoch 069 | loss 3.117 | nll_loss 0.977 | word_ins 2.798 | length 3.192 | ppl 8.68 | wps 45476.2 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 136459 | lr 0.000270707 | gnorm 1.25 | loss_scale 8192 | train_wall 2519 | wall 179568
2023-01-14 17:40:14 | INFO | fairseq.trainer | begin training epoch 70
2023-01-14 17:41:17 | INFO | train_inner | epoch 070:     41 / 1978 loss=3.138, nll_loss=0.997, word_ins=2.816, length=3.218, ppl=8.8, wps=32679, ups=0.55, wpb=59511.6, bsz=1889.8, num_updates=136500, lr=0.000270666, gnorm=1.29, loss_scale=8192, train_wall=126, wall=179632
2023-01-14 17:43:26 | INFO | train_inner | epoch 070:    141 / 1978 loss=3.092, nll_loss=0.951, word_ins=2.774, length=3.176, ppl=8.53, wps=46249.6, ups=0.78, wpb=59235.7, bsz=2002.5, num_updates=136600, lr=0.000270567, gnorm=1.239, loss_scale=8192, train_wall=128, wall=179760
2023-01-14 17:45:33 | INFO | train_inner | epoch 070:    241 / 1978 loss=3.126, nll_loss=0.979, word_ins=2.8, length=3.265, ppl=8.73, wps=46579, ups=0.78, wpb=59383.6, bsz=1914.1, num_updates=136700, lr=0.000270468, gnorm=1.24, loss_scale=8192, train_wall=127, wall=179887
2023-01-14 17:47:42 | INFO | train_inner | epoch 070:    341 / 1978 loss=3.104, nll_loss=0.972, word_ins=2.793, length=3.11, ppl=8.6, wps=46399, ups=0.78, wpb=59752.8, bsz=2029.8, num_updates=136800, lr=0.000270369, gnorm=1.261, loss_scale=8192, train_wall=129, wall=180016
2023-01-14 17:49:49 | INFO | train_inner | epoch 070:    441 / 1978 loss=3.126, nll_loss=0.979, word_ins=2.8, length=3.268, ppl=8.73, wps=46658, ups=0.79, wpb=59433.6, bsz=1981.3, num_updates=136900, lr=0.00027027, gnorm=1.271, loss_scale=8192, train_wall=127, wall=180143
2023-01-14 17:51:56 | INFO | train_inner | epoch 070:    541 / 1978 loss=3.109, nll_loss=0.968, word_ins=2.789, length=3.201, ppl=8.63, wps=46876.3, ups=0.79, wpb=59300, bsz=1997.8, num_updates=137000, lr=0.000270172, gnorm=1.255, loss_scale=8192, train_wall=126, wall=180270
2023-01-14 17:54:03 | INFO | train_inner | epoch 070:    641 / 1978 loss=3.11, nll_loss=0.972, word_ins=2.793, length=3.164, ppl=8.63, wps=46361.6, ups=0.79, wpb=58890.1, bsz=1974.2, num_updates=137100, lr=0.000270073, gnorm=1.279, loss_scale=8192, train_wall=127, wall=180397
2023-01-14 17:56:11 | INFO | train_inner | epoch 070:    741 / 1978 loss=3.109, nll_loss=0.97, word_ins=2.791, length=3.176, ppl=8.63, wps=46245, ups=0.78, wpb=59157.5, bsz=2008.7, num_updates=137200, lr=0.000269975, gnorm=1.302, loss_scale=8192, train_wall=128, wall=180525
2023-01-14 17:58:18 | INFO | train_inner | epoch 070:    841 / 1978 loss=3.108, nll_loss=0.974, word_ins=2.794, length=3.131, ppl=8.62, wps=46431.5, ups=0.79, wpb=59140.9, bsz=1969.9, num_updates=137300, lr=0.000269876, gnorm=1.261, loss_scale=8192, train_wall=127, wall=180652
2023-01-14 18:00:25 | INFO | train_inner | epoch 070:    941 / 1978 loss=3.128, nll_loss=0.984, word_ins=2.804, length=3.243, ppl=8.74, wps=46657.5, ups=0.78, wpb=59459.6, bsz=1981.1, num_updates=137400, lr=0.000269778, gnorm=1.267, loss_scale=16384, train_wall=127, wall=180780
2023-01-14 18:02:33 | INFO | train_inner | epoch 070:   1041 / 1978 loss=3.124, nll_loss=0.982, word_ins=2.802, length=3.222, ppl=8.72, wps=46426.2, ups=0.79, wpb=59131.7, bsz=2006.4, num_updates=137500, lr=0.00026968, gnorm=1.268, loss_scale=16384, train_wall=127, wall=180907
2023-01-14 18:03:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-14 18:04:42 | INFO | train_inner | epoch 070:   1142 / 1978 loss=3.103, nll_loss=0.965, word_ins=2.787, length=3.163, ppl=8.59, wps=46032.7, ups=0.77, wpb=59463.9, bsz=2004.9, num_updates=137600, lr=0.000269582, gnorm=1.253, loss_scale=8192, train_wall=129, wall=181036
2023-01-14 18:06:51 | INFO | train_inner | epoch 070:   1242 / 1978 loss=3.097, nll_loss=0.962, word_ins=2.784, length=3.133, ppl=8.56, wps=45931.6, ups=0.78, wpb=59051, bsz=2132.3, num_updates=137700, lr=0.000269484, gnorm=1.222, loss_scale=8192, train_wall=128, wall=181165
2023-01-14 18:08:57 | INFO | train_inner | epoch 070:   1342 / 1978 loss=3.144, nll_loss=1.004, word_ins=2.822, length=3.223, ppl=8.84, wps=46688.3, ups=0.79, wpb=59214.2, bsz=1978, num_updates=137800, lr=0.000269386, gnorm=1.269, loss_scale=8192, train_wall=127, wall=181292
2023-01-14 18:11:05 | INFO | train_inner | epoch 070:   1442 / 1978 loss=3.09, nll_loss=0.952, word_ins=2.775, length=3.155, ppl=8.52, wps=46355, ups=0.78, wpb=59155.2, bsz=2080.5, num_updates=137900, lr=0.000269289, gnorm=1.269, loss_scale=8192, train_wall=127, wall=181419
2023-01-14 18:13:14 | INFO | train_inner | epoch 070:   1542 / 1978 loss=3.109, nll_loss=0.973, word_ins=2.793, length=3.156, ppl=8.63, wps=46344.9, ups=0.78, wpb=59542.1, bsz=2079.9, num_updates=138000, lr=0.000269191, gnorm=1.266, loss_scale=8192, train_wall=128, wall=181548
2023-01-14 18:15:21 | INFO | train_inner | epoch 070:   1642 / 1978 loss=3.12, nll_loss=0.975, word_ins=2.796, length=3.237, ppl=8.69, wps=46393.2, ups=0.79, wpb=59055.4, bsz=2004.2, num_updates=138100, lr=0.000269093, gnorm=1.244, loss_scale=8192, train_wall=127, wall=181675
2023-01-14 18:17:28 | INFO | train_inner | epoch 070:   1742 / 1978 loss=3.145, nll_loss=1, word_ins=2.819, length=3.267, ppl=8.85, wps=46350.1, ups=0.79, wpb=58996, bsz=1993.4, num_updates=138200, lr=0.000268996, gnorm=1.261, loss_scale=8192, train_wall=127, wall=181802
2023-01-14 18:19:35 | INFO | train_inner | epoch 070:   1842 / 1978 loss=3.112, nll_loss=0.97, word_ins=2.791, length=3.217, ppl=8.65, wps=46690.5, ups=0.79, wpb=59411.6, bsz=1955.9, num_updates=138300, lr=0.000268899, gnorm=1.255, loss_scale=8192, train_wall=127, wall=181930
2023-01-14 18:21:44 | INFO | train_inner | epoch 070:   1942 / 1978 loss=3.092, nll_loss=0.955, word_ins=2.778, length=3.141, ppl=8.53, wps=46438.4, ups=0.78, wpb=59496, bsz=2012.2, num_updates=138400, lr=0.000268802, gnorm=1.285, loss_scale=8192, train_wall=128, wall=182058
2023-01-14 18:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 18:22:43 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 4.592 | nll_loss 2.001 | word_ins 3.768 | length 8.237 | ppl 24.11 | wps 119542 | wpb 40242.5 | bsz 1500 | num_updates 138436 | best_loss 4.422
2023-01-14 18:22:43 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 18:23:12 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint70.pt (epoch 70 @ 138436 updates, score 4.592) (writing took 29.612273829057813 seconds)
2023-01-14 18:23:12 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2023-01-14 18:23:12 | INFO | train | epoch 070 | loss 3.113 | nll_loss 0.973 | word_ins 2.794 | length 3.192 | ppl 8.65 | wps 45452.2 | ups 0.77 | wpb 59285.2 | bsz 2003 | num_updates 138436 | lr 0.000268767 | gnorm 1.262 | loss_scale 8192 | train_wall 2519 | wall 182146
2023-01-14 18:23:12 | INFO | fairseq.trainer | begin training epoch 71
2023-01-14 18:24:46 | INFO | train_inner | epoch 071:     64 / 1978 loss=3.091, nll_loss=0.956, word_ins=2.778, length=3.128, ppl=8.52, wps=32491.5, ups=0.55, wpb=59326.3, bsz=2040.6, num_updates=138500, lr=0.000268705, gnorm=1.232, loss_scale=8192, train_wall=127, wall=182240
2023-01-14 18:26:54 | INFO | train_inner | epoch 071:    164 / 1978 loss=3.112, nll_loss=0.97, word_ins=2.792, length=3.2, ppl=8.64, wps=46607.6, ups=0.78, wpb=59403.4, bsz=1961, num_updates=138600, lr=0.000268608, gnorm=1.274, loss_scale=8192, train_wall=127, wall=182368
2023-01-14 18:29:01 | INFO | train_inner | epoch 071:    264 / 1978 loss=3.076, nll_loss=0.939, word_ins=2.762, length=3.138, ppl=8.43, wps=46772.5, ups=0.79, wpb=59526.8, bsz=2043.3, num_updates=138700, lr=0.000268511, gnorm=1.247, loss_scale=8192, train_wall=127, wall=182495
2023-01-14 18:31:08 | INFO | train_inner | epoch 071:    364 / 1978 loss=3.104, nll_loss=0.969, word_ins=2.79, length=3.143, ppl=8.6, wps=46593.3, ups=0.78, wpb=59366.8, bsz=1995, num_updates=138800, lr=0.000268414, gnorm=1.271, loss_scale=8192, train_wall=127, wall=182622
2023-01-14 18:33:15 | INFO | train_inner | epoch 071:    464 / 1978 loss=3.129, nll_loss=0.987, word_ins=2.806, length=3.223, ppl=8.75, wps=46710.2, ups=0.79, wpb=59366.3, bsz=1937.2, num_updates=138900, lr=0.000268317, gnorm=1.306, loss_scale=8192, train_wall=127, wall=182750
2023-01-14 18:35:23 | INFO | train_inner | epoch 071:    564 / 1978 loss=3.097, nll_loss=0.958, word_ins=2.78, length=3.17, ppl=8.56, wps=46508.5, ups=0.78, wpb=59557.3, bsz=2036.1, num_updates=139000, lr=0.000268221, gnorm=1.274, loss_scale=8192, train_wall=128, wall=182878
2023-01-14 18:37:32 | INFO | train_inner | epoch 071:    664 / 1978 loss=3.082, nll_loss=0.944, word_ins=2.767, length=3.143, ppl=8.47, wps=46531, ups=0.78, wpb=59603.2, bsz=2065, num_updates=139100, lr=0.000268124, gnorm=1.306, loss_scale=8192, train_wall=128, wall=183006
2023-01-14 18:39:39 | INFO | train_inner | epoch 071:    764 / 1978 loss=3.104, nll_loss=0.962, word_ins=2.783, length=3.212, ppl=8.6, wps=46775.8, ups=0.78, wpb=59727.5, bsz=2049.4, num_updates=139200, lr=0.000268028, gnorm=1.264, loss_scale=8192, train_wall=127, wall=183133
2023-01-14 18:41:48 | INFO | train_inner | epoch 071:    864 / 1978 loss=3.11, nll_loss=0.973, word_ins=2.794, length=3.165, ppl=8.63, wps=45729.2, ups=0.78, wpb=58996.9, bsz=2078.3, num_updates=139300, lr=0.000267932, gnorm=1.234, loss_scale=8192, train_wall=129, wall=183262
2023-01-14 18:43:56 | INFO | train_inner | epoch 071:    964 / 1978 loss=3.102, nll_loss=0.968, word_ins=2.789, length=3.131, ppl=8.59, wps=46123.3, ups=0.78, wpb=59055.3, bsz=2049.4, num_updates=139400, lr=0.000267836, gnorm=1.229, loss_scale=8192, train_wall=128, wall=183390
2023-01-14 18:46:04 | INFO | train_inner | epoch 071:   1064 / 1978 loss=3.113, nll_loss=0.97, word_ins=2.791, length=3.218, ppl=8.65, wps=45970.4, ups=0.78, wpb=58654.9, bsz=2035.4, num_updates=139500, lr=0.00026774, gnorm=1.248, loss_scale=8192, train_wall=127, wall=183518
2023-01-14 18:48:11 | INFO | train_inner | epoch 071:   1164 / 1978 loss=3.123, nll_loss=0.981, word_ins=2.802, length=3.217, ppl=8.71, wps=46334.8, ups=0.79, wpb=58772.1, bsz=1976.1, num_updates=139600, lr=0.000267644, gnorm=1.284, loss_scale=8192, train_wall=127, wall=183645
2023-01-14 18:50:17 | INFO | train_inner | epoch 071:   1264 / 1978 loss=3.143, nll_loss=0.997, word_ins=2.816, length=3.276, ppl=8.84, wps=46609.4, ups=0.79, wpb=58742.1, bsz=1876.4, num_updates=139700, lr=0.000267548, gnorm=1.278, loss_scale=8192, train_wall=126, wall=183771
2023-01-14 18:52:24 | INFO | train_inner | epoch 071:   1364 / 1978 loss=3.108, nll_loss=0.969, word_ins=2.79, length=3.175, ppl=8.62, wps=46756.9, ups=0.79, wpb=59400.7, bsz=2001.3, num_updates=139800, lr=0.000267452, gnorm=1.288, loss_scale=8192, train_wall=127, wall=183898
2023-01-14 18:54:32 | INFO | train_inner | epoch 071:   1464 / 1978 loss=3.077, nll_loss=0.938, word_ins=2.762, length=3.153, ppl=8.44, wps=46240, ups=0.78, wpb=59448.2, bsz=2090.5, num_updates=139900, lr=0.000267357, gnorm=1.2, loss_scale=8192, train_wall=128, wall=184027
2023-01-14 18:56:41 | INFO | train_inner | epoch 071:   1564 / 1978 loss=3.096, nll_loss=0.958, word_ins=2.78, length=3.164, ppl=8.55, wps=46359.7, ups=0.78, wpb=59758.9, bsz=2027.4, num_updates=140000, lr=0.000267261, gnorm=1.288, loss_scale=8192, train_wall=129, wall=184155
2023-01-14 18:58:49 | INFO | train_inner | epoch 071:   1664 / 1978 loss=3.116, nll_loss=0.973, word_ins=2.794, length=3.228, ppl=8.67, wps=46297, ups=0.78, wpb=59227.3, bsz=1978.9, num_updates=140100, lr=0.000267166, gnorm=1.253, loss_scale=8192, train_wall=128, wall=184283
2023-01-14 19:00:56 | INFO | train_inner | epoch 071:   1764 / 1978 loss=3.131, nll_loss=0.991, word_ins=2.81, length=3.216, ppl=8.76, wps=46554, ups=0.79, wpb=59150.8, bsz=1916.6, num_updates=140200, lr=0.000267071, gnorm=1.258, loss_scale=8192, train_wall=127, wall=184410
2023-01-14 19:03:04 | INFO | train_inner | epoch 071:   1864 / 1978 loss=3.136, nll_loss=0.991, word_ins=2.81, length=3.261, ppl=8.79, wps=46085.6, ups=0.78, wpb=58785.9, bsz=1949.3, num_updates=140300, lr=0.000266975, gnorm=1.256, loss_scale=8192, train_wall=127, wall=184538
2023-01-14 19:05:12 | INFO | train_inner | epoch 071:   1964 / 1978 loss=3.134, nll_loss=0.995, word_ins=2.813, length=3.213, ppl=8.78, wps=47026.6, ups=0.78, wpb=60041.7, bsz=1981, num_updates=140400, lr=0.00026688, gnorm=1.298, loss_scale=8192, train_wall=127, wall=184666
2023-01-14 19:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 19:05:41 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 4.552 | nll_loss 1.975 | word_ins 3.741 | length 8.105 | ppl 23.45 | wps 119598 | wpb 40242.5 | bsz 1500 | num_updates 140414 | best_loss 4.422
2023-01-14 19:05:41 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 19:06:09 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint71.pt (epoch 71 @ 140414 updates, score 4.552) (writing took 28.47942667361349 seconds)
2023-01-14 19:06:09 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2023-01-14 19:06:09 | INFO | train | epoch 071 | loss 3.11 | nll_loss 0.97 | word_ins 2.791 | length 3.191 | ppl 8.63 | wps 45501.8 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 140414 | lr 0.000266867 | gnorm 1.265 | loss_scale 8192 | train_wall 2520 | wall 184723
2023-01-14 19:06:09 | INFO | fairseq.trainer | begin training epoch 72
2023-01-14 19:08:13 | INFO | train_inner | epoch 072:     86 / 1978 loss=3.121, nll_loss=0.979, word_ins=2.8, length=3.212, ppl=8.7, wps=32810.2, ups=0.55, wpb=59429.1, bsz=1945, num_updates=140500, lr=0.000266785, gnorm=1.273, loss_scale=8192, train_wall=128, wall=184847
2023-01-14 19:10:19 | INFO | train_inner | epoch 072:    186 / 1978 loss=3.117, nll_loss=0.979, word_ins=2.8, length=3.177, ppl=8.68, wps=46297.9, ups=0.79, wpb=58559.3, bsz=1925.9, num_updates=140600, lr=0.00026669, gnorm=1.273, loss_scale=8192, train_wall=126, wall=184973
2023-01-14 19:12:29 | INFO | train_inner | epoch 072:    286 / 1978 loss=3.073, nll_loss=0.937, word_ins=2.761, length=3.122, ppl=8.42, wps=45916.1, ups=0.77, wpb=59427.9, bsz=2093.8, num_updates=140700, lr=0.000266596, gnorm=1.249, loss_scale=8192, train_wall=129, wall=185103
2023-01-14 19:14:37 | INFO | train_inner | epoch 072:    386 / 1978 loss=3.102, nll_loss=0.963, word_ins=2.785, length=3.171, ppl=8.59, wps=46221.6, ups=0.78, wpb=59290.8, bsz=2014.4, num_updates=140800, lr=0.000266501, gnorm=1.306, loss_scale=8192, train_wall=128, wall=185231
2023-01-14 19:16:43 | INFO | train_inner | epoch 072:    486 / 1978 loss=3.117, nll_loss=0.973, word_ins=2.793, length=3.232, ppl=8.67, wps=47085, ups=0.79, wpb=59424.8, bsz=1901.8, num_updates=140900, lr=0.000266406, gnorm=1.289, loss_scale=8192, train_wall=126, wall=185357
2023-01-14 19:18:51 | INFO | train_inner | epoch 072:    586 / 1978 loss=3.093, nll_loss=0.957, word_ins=2.779, length=3.144, ppl=8.53, wps=46702.4, ups=0.78, wpb=59774.2, bsz=1996.3, num_updates=141000, lr=0.000266312, gnorm=1.302, loss_scale=8192, train_wall=128, wall=185485
2023-01-14 19:20:59 | INFO | train_inner | epoch 072:    686 / 1978 loss=3.107, nll_loss=0.97, word_ins=2.791, length=3.169, ppl=8.62, wps=46463.2, ups=0.78, wpb=59449.7, bsz=1987.4, num_updates=141100, lr=0.000266217, gnorm=1.317, loss_scale=8192, train_wall=128, wall=185613
2023-01-14 19:23:08 | INFO | train_inner | epoch 072:    786 / 1978 loss=3.124, nll_loss=0.987, word_ins=2.806, length=3.179, ppl=8.72, wps=45957.8, ups=0.78, wpb=59095, bsz=1978.2, num_updates=141200, lr=0.000266123, gnorm=1.297, loss_scale=8192, train_wall=128, wall=185742
2023-01-14 19:25:16 | INFO | train_inner | epoch 072:    886 / 1978 loss=3.093, nll_loss=0.953, word_ins=2.775, length=3.177, ppl=8.53, wps=46186.2, ups=0.78, wpb=59159.2, bsz=2046.8, num_updates=141300, lr=0.000266029, gnorm=1.274, loss_scale=8192, train_wall=128, wall=185870
2023-01-14 19:27:24 | INFO | train_inner | epoch 072:    986 / 1978 loss=3.099, nll_loss=0.96, word_ins=2.782, length=3.175, ppl=8.57, wps=46148.4, ups=0.78, wpb=59213.9, bsz=2056.6, num_updates=141400, lr=0.000265935, gnorm=1.232, loss_scale=8192, train_wall=128, wall=185998
2023-01-14 19:29:31 | INFO | train_inner | epoch 072:   1086 / 1978 loss=3.123, nll_loss=0.982, word_ins=2.803, length=3.2, ppl=8.71, wps=46385.9, ups=0.79, wpb=59068.9, bsz=1962.8, num_updates=141500, lr=0.000265841, gnorm=1.26, loss_scale=8192, train_wall=127, wall=186126
2023-01-14 19:31:40 | INFO | train_inner | epoch 072:   1186 / 1978 loss=3.133, nll_loss=0.99, word_ins=2.809, length=3.242, ppl=8.77, wps=45960.7, ups=0.78, wpb=58853.4, bsz=1967.7, num_updates=141600, lr=0.000265747, gnorm=1.281, loss_scale=8192, train_wall=128, wall=186254
2023-01-14 19:33:48 | INFO | train_inner | epoch 072:   1286 / 1978 loss=3.099, nll_loss=0.963, word_ins=2.785, length=3.144, ppl=8.57, wps=46206.2, ups=0.78, wpb=59354.4, bsz=2082.6, num_updates=141700, lr=0.000265653, gnorm=1.251, loss_scale=16384, train_wall=128, wall=186382
2023-01-14 19:35:56 | INFO | train_inner | epoch 072:   1386 / 1978 loss=3.086, nll_loss=0.946, word_ins=2.768, length=3.179, ppl=8.49, wps=46302.9, ups=0.78, wpb=59425.6, bsz=2067.1, num_updates=141800, lr=0.00026556, gnorm=1.271, loss_scale=16384, train_wall=128, wall=186510
2023-01-14 19:36:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-14 19:38:05 | INFO | train_inner | epoch 072:   1487 / 1978 loss=3.141, nll_loss=1.001, word_ins=2.819, length=3.224, ppl=8.82, wps=46281.1, ups=0.78, wpb=59360, bsz=1936.6, num_updates=141900, lr=0.000265466, gnorm=1.308, loss_scale=8192, train_wall=128, wall=186639
2023-01-14 19:40:12 | INFO | train_inner | epoch 072:   1587 / 1978 loss=3.109, nll_loss=0.965, word_ins=2.786, length=3.226, ppl=8.63, wps=46294, ups=0.78, wpb=59074, bsz=2007.9, num_updates=142000, lr=0.000265372, gnorm=1.248, loss_scale=8192, train_wall=127, wall=186766
2023-01-14 19:42:20 | INFO | train_inner | epoch 072:   1687 / 1978 loss=3.113, nll_loss=0.978, word_ins=2.799, length=3.143, ppl=8.65, wps=46725.1, ups=0.78, wpb=59651.1, bsz=1991.4, num_updates=142100, lr=0.000265279, gnorm=1.297, loss_scale=8192, train_wall=127, wall=186894
2023-01-14 19:44:28 | INFO | train_inner | epoch 072:   1787 / 1978 loss=3.1, nll_loss=0.958, word_ins=2.78, length=3.198, ppl=8.58, wps=46289.5, ups=0.78, wpb=59302.4, bsz=2028.6, num_updates=142200, lr=0.000265186, gnorm=1.258, loss_scale=8192, train_wall=128, wall=187022
2023-01-14 19:46:36 | INFO | train_inner | epoch 072:   1887 / 1978 loss=3.112, nll_loss=0.969, word_ins=2.79, length=3.222, ppl=8.65, wps=46071, ups=0.78, wpb=59148.7, bsz=1983.4, num_updates=142300, lr=0.000265093, gnorm=1.279, loss_scale=8192, train_wall=128, wall=187150
2023-01-14 19:48:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 19:48:51 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 4.631 | nll_loss 2.009 | word_ins 3.773 | length 8.575 | ppl 24.77 | wps 92678.1 | wpb 40242.5 | bsz 1500 | num_updates 142391 | best_loss 4.422
2023-01-14 19:48:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 19:49:21 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint72.pt (epoch 72 @ 142391 updates, score 4.631) (writing took 30.294984673149884 seconds)
2023-01-14 19:49:21 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2023-01-14 19:49:21 | INFO | train | epoch 072 | loss 3.106 | nll_loss 0.967 | word_ins 2.788 | length 3.181 | ppl 8.61 | wps 45218.2 | ups 0.76 | wpb 59284.7 | bsz 2002.3 | num_updates 142391 | lr 0.000265008 | gnorm 1.277 | loss_scale 8192 | train_wall 2526 | wall 187315
2023-01-14 19:49:21 | INFO | fairseq.trainer | begin training epoch 73
2023-01-14 19:49:49 | INFO | train_inner | epoch 073:      9 / 1978 loss=3.077, nll_loss=0.942, word_ins=2.765, length=3.122, ppl=8.44, wps=30902.1, ups=0.52, wpb=59527.2, bsz=2040.2, num_updates=142400, lr=0.000264999, gnorm=1.293, loss_scale=8192, train_wall=129, wall=187343
2023-01-14 19:51:58 | INFO | train_inner | epoch 073:    109 / 1978 loss=3.089, nll_loss=0.95, word_ins=2.773, length=3.154, ppl=8.51, wps=46178.6, ups=0.78, wpb=59393, bsz=2036, num_updates=142500, lr=0.000264906, gnorm=1.268, loss_scale=8192, train_wall=128, wall=187472
2023-01-14 19:54:07 | INFO | train_inner | epoch 073:    209 / 1978 loss=3.09, nll_loss=0.955, word_ins=2.777, length=3.127, ppl=8.51, wps=45448.6, ups=0.77, wpb=58981.3, bsz=2064.4, num_updates=142600, lr=0.000264814, gnorm=1.233, loss_scale=8192, train_wall=130, wall=187602
2023-01-14 19:56:15 | INFO | train_inner | epoch 073:    309 / 1978 loss=3.132, nll_loss=0.991, word_ins=2.81, length=3.22, ppl=8.77, wps=46344.5, ups=0.78, wpb=59144.2, bsz=1920, num_updates=142700, lr=0.000264721, gnorm=1.253, loss_scale=8192, train_wall=127, wall=187729
2023-01-14 19:58:22 | INFO | train_inner | epoch 073:    409 / 1978 loss=3.119, nll_loss=0.979, word_ins=2.799, length=3.199, ppl=8.69, wps=46382.4, ups=0.79, wpb=58901, bsz=1926.3, num_updates=142800, lr=0.000264628, gnorm=1.265, loss_scale=8192, train_wall=127, wall=187856
2023-01-14 20:00:30 | INFO | train_inner | epoch 073:    509 / 1978 loss=3.097, nll_loss=0.957, word_ins=2.78, length=3.173, ppl=8.56, wps=46018.9, ups=0.78, wpb=58963.7, bsz=1960.2, num_updates=142900, lr=0.000264535, gnorm=1.256, loss_scale=8192, train_wall=128, wall=187984
2023-01-14 20:02:38 | INFO | train_inner | epoch 073:    609 / 1978 loss=3.112, nll_loss=0.974, word_ins=2.795, length=3.173, ppl=8.65, wps=46610.7, ups=0.78, wpb=59428.3, bsz=2000, num_updates=143000, lr=0.000264443, gnorm=1.288, loss_scale=8192, train_wall=127, wall=188112
2023-01-14 20:04:46 | INFO | train_inner | epoch 073:    709 / 1978 loss=3.073, nll_loss=0.939, word_ins=2.762, length=3.115, ppl=8.42, wps=46965.3, ups=0.78, wpb=60095.9, bsz=2013.2, num_updates=143100, lr=0.000264351, gnorm=1.285, loss_scale=8192, train_wall=128, wall=188240
2023-01-14 20:06:54 | INFO | train_inner | epoch 073:    809 / 1978 loss=3.1, nll_loss=0.96, word_ins=2.782, length=3.177, ppl=8.57, wps=46648.4, ups=0.78, wpb=59900.2, bsz=1984.6, num_updates=143200, lr=0.000264258, gnorm=1.286, loss_scale=8192, train_wall=128, wall=188368
2023-01-14 20:09:02 | INFO | train_inner | epoch 073:    909 / 1978 loss=3.106, nll_loss=0.964, word_ins=2.786, length=3.194, ppl=8.61, wps=46482.7, ups=0.78, wpb=59443, bsz=2021.4, num_updates=143300, lr=0.000264166, gnorm=1.276, loss_scale=8192, train_wall=128, wall=188496
2023-01-14 20:11:11 | INFO | train_inner | epoch 073:   1009 / 1978 loss=3.064, nll_loss=0.929, word_ins=2.754, length=3.103, ppl=8.37, wps=46089.7, ups=0.77, wpb=59559.9, bsz=2122.2, num_updates=143400, lr=0.000264074, gnorm=1.279, loss_scale=8192, train_wall=129, wall=188625
2023-01-14 20:13:20 | INFO | train_inner | epoch 073:   1109 / 1978 loss=3.091, nll_loss=0.96, word_ins=2.781, length=3.099, ppl=8.52, wps=45793.1, ups=0.77, wpb=59133.5, bsz=2104.2, num_updates=143500, lr=0.000263982, gnorm=1.31, loss_scale=8192, train_wall=129, wall=188754
2023-01-14 20:15:27 | INFO | train_inner | epoch 073:   1209 / 1978 loss=3.161, nll_loss=1.016, word_ins=2.834, length=3.275, ppl=8.94, wps=45999.2, ups=0.79, wpb=58131.3, bsz=1843.2, num_updates=143600, lr=0.00026389, gnorm=1.279, loss_scale=8192, train_wall=126, wall=188881
2023-01-14 20:17:34 | INFO | train_inner | epoch 073:   1309 / 1978 loss=3.123, nll_loss=0.974, word_ins=2.795, length=3.283, ppl=8.71, wps=46797.7, ups=0.79, wpb=59357.4, bsz=1883.8, num_updates=143700, lr=0.000263798, gnorm=1.338, loss_scale=8192, train_wall=127, wall=189008
2023-01-14 20:19:41 | INFO | train_inner | epoch 073:   1409 / 1978 loss=3.097, nll_loss=0.957, word_ins=2.779, length=3.181, ppl=8.56, wps=46231.8, ups=0.78, wpb=59052.4, bsz=2024.2, num_updates=143800, lr=0.000263706, gnorm=1.241, loss_scale=8192, train_wall=128, wall=189135
2023-01-14 20:21:49 | INFO | train_inner | epoch 073:   1509 / 1978 loss=3.119, nll_loss=0.978, word_ins=2.798, length=3.208, ppl=8.69, wps=46273.2, ups=0.78, wpb=59041.4, bsz=1937.3, num_updates=143900, lr=0.000263615, gnorm=1.305, loss_scale=8192, train_wall=127, wall=189263
2023-01-14 20:23:57 | INFO | train_inner | epoch 073:   1609 / 1978 loss=3.084, nll_loss=0.947, word_ins=2.769, length=3.155, ppl=8.48, wps=46637.1, ups=0.78, wpb=59706.9, bsz=2050.2, num_updates=144000, lr=0.000263523, gnorm=1.291, loss_scale=8192, train_wall=128, wall=189391
2023-01-14 20:26:05 | INFO | train_inner | epoch 073:   1709 / 1978 loss=3.107, nll_loss=0.965, word_ins=2.786, length=3.212, ppl=8.62, wps=46030.9, ups=0.78, wpb=59056.4, bsz=2069.8, num_updates=144100, lr=0.000263432, gnorm=1.259, loss_scale=8192, train_wall=128, wall=189519
2023-01-14 20:28:14 | INFO | train_inner | epoch 073:   1809 / 1978 loss=3.08, nll_loss=0.945, word_ins=2.767, length=3.131, ppl=8.46, wps=46404, ups=0.78, wpb=59776.8, bsz=2116.9, num_updates=144200, lr=0.00026334, gnorm=1.288, loss_scale=8192, train_wall=129, wall=189648
2023-01-14 20:30:22 | INFO | train_inner | epoch 073:   1909 / 1978 loss=3.121, nll_loss=0.981, word_ins=2.801, length=3.197, ppl=8.7, wps=46384.4, ups=0.78, wpb=59123.6, bsz=1968.1, num_updates=144300, lr=0.000263249, gnorm=1.312, loss_scale=8192, train_wall=127, wall=189776
2023-01-14 20:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 20:32:07 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 4.54 | nll_loss 1.986 | word_ins 3.757 | length 7.834 | ppl 23.27 | wps 106871 | wpb 40242.5 | bsz 1500 | num_updates 144369 | best_loss 4.422
2023-01-14 20:32:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 20:32:35 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint73.pt (epoch 73 @ 144369 updates, score 4.54) (writing took 27.71624875906855 seconds)
2023-01-14 20:32:35 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2023-01-14 20:32:35 | INFO | train | epoch 073 | loss 3.104 | nll_loss 0.964 | word_ins 2.786 | length 3.178 | ppl 8.6 | wps 45214.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 144369 | lr 0.000263186 | gnorm 1.279 | loss_scale 8192 | train_wall 2528 | wall 189909
2023-01-14 20:32:35 | INFO | fairseq.trainer | begin training epoch 74
2023-01-14 20:33:29 | INFO | train_inner | epoch 074:     31 / 1978 loss=3.111, nll_loss=0.971, word_ins=2.792, length=3.186, ppl=8.64, wps=31487.3, ups=0.53, wpb=59138.3, bsz=1982.3, num_updates=144400, lr=0.000263158, gnorm=1.256, loss_scale=8192, train_wall=127, wall=189963
2023-01-14 20:35:37 | INFO | train_inner | epoch 074:    131 / 1978 loss=3.116, nll_loss=0.971, word_ins=2.792, length=3.237, ppl=8.67, wps=46207.2, ups=0.78, wpb=59136.1, bsz=1992.8, num_updates=144500, lr=0.000263067, gnorm=1.298, loss_scale=8192, train_wall=128, wall=190091
2023-01-14 20:37:44 | INFO | train_inner | epoch 074:    231 / 1978 loss=3.114, nll_loss=0.973, word_ins=2.793, length=3.204, ppl=8.66, wps=46415.8, ups=0.79, wpb=58889, bsz=1967.4, num_updates=144600, lr=0.000262976, gnorm=1.262, loss_scale=8192, train_wall=127, wall=190218
2023-01-14 20:39:52 | INFO | train_inner | epoch 074:    331 / 1978 loss=3.072, nll_loss=0.936, word_ins=2.759, length=3.126, ppl=8.41, wps=46783.1, ups=0.78, wpb=59752.3, bsz=2035.4, num_updates=144700, lr=0.000262885, gnorm=1.227, loss_scale=8192, train_wall=127, wall=190346
2023-01-14 20:42:00 | INFO | train_inner | epoch 074:    431 / 1978 loss=3.096, nll_loss=0.953, word_ins=2.776, length=3.202, ppl=8.55, wps=46592.4, ups=0.78, wpb=59433.6, bsz=1985.9, num_updates=144800, lr=0.000262794, gnorm=1.312, loss_scale=8192, train_wall=127, wall=190474
2023-01-14 20:44:07 | INFO | train_inner | epoch 074:    531 / 1978 loss=3.094, nll_loss=0.95, word_ins=2.772, length=3.213, ppl=8.54, wps=47199.1, ups=0.79, wpb=60048.8, bsz=1933.5, num_updates=144900, lr=0.000262703, gnorm=1.275, loss_scale=8192, train_wall=127, wall=190601
2023-01-14 20:46:15 | INFO | train_inner | epoch 074:    631 / 1978 loss=3.099, nll_loss=0.962, word_ins=2.784, length=3.156, ppl=8.57, wps=46086.9, ups=0.78, wpb=59020.5, bsz=2043.9, num_updates=145000, lr=0.000262613, gnorm=1.284, loss_scale=8192, train_wall=128, wall=190729
2023-01-14 20:48:22 | INFO | train_inner | epoch 074:    731 / 1978 loss=3.113, nll_loss=0.974, word_ins=2.795, length=3.184, ppl=8.65, wps=46632, ups=0.78, wpb=59503.9, bsz=1984.7, num_updates=145100, lr=0.000262522, gnorm=1.352, loss_scale=8192, train_wall=127, wall=190857
2023-01-14 20:50:30 | INFO | train_inner | epoch 074:    831 / 1978 loss=3.096, nll_loss=0.958, word_ins=2.78, length=3.165, ppl=8.55, wps=46767.3, ups=0.78, wpb=59609.2, bsz=1980.9, num_updates=145200, lr=0.000262432, gnorm=1.326, loss_scale=8192, train_wall=127, wall=190984
2023-01-14 20:52:38 | INFO | train_inner | epoch 074:    931 / 1978 loss=3.092, nll_loss=0.953, word_ins=2.776, length=3.153, ppl=8.52, wps=46283.2, ups=0.78, wpb=59259.8, bsz=2032.9, num_updates=145300, lr=0.000262342, gnorm=1.287, loss_scale=8192, train_wall=128, wall=191112
2023-01-14 20:54:45 | INFO | train_inner | epoch 074:   1031 / 1978 loss=3.09, nll_loss=0.949, word_ins=2.772, length=3.184, ppl=8.52, wps=46776, ups=0.79, wpb=59463.8, bsz=2008.8, num_updates=145400, lr=0.000262251, gnorm=1.296, loss_scale=8192, train_wall=127, wall=191239
2023-01-14 20:56:52 | INFO | train_inner | epoch 074:   1131 / 1978 loss=3.113, nll_loss=0.973, word_ins=2.794, length=3.194, ppl=8.65, wps=46790.3, ups=0.79, wpb=59379.5, bsz=1922.2, num_updates=145500, lr=0.000262161, gnorm=1.283, loss_scale=8192, train_wall=127, wall=191366
2023-01-14 20:59:00 | INFO | train_inner | epoch 074:   1231 / 1978 loss=3.081, nll_loss=0.947, word_ins=2.77, length=3.112, ppl=8.46, wps=46314.8, ups=0.78, wpb=59214.6, bsz=2056, num_updates=145600, lr=0.000262071, gnorm=1.271, loss_scale=8192, train_wall=128, wall=191494
2023-01-14 21:01:08 | INFO | train_inner | epoch 074:   1331 / 1978 loss=3.101, nll_loss=0.966, word_ins=2.787, length=3.142, ppl=8.58, wps=46529.4, ups=0.78, wpb=59586.8, bsz=2031.8, num_updates=145700, lr=0.000261981, gnorm=1.262, loss_scale=8192, train_wall=128, wall=191622
2023-01-14 21:03:16 | INFO | train_inner | epoch 074:   1431 / 1978 loss=3.123, nll_loss=0.989, word_ins=2.808, length=3.144, ppl=8.71, wps=45902.5, ups=0.78, wpb=58952.7, bsz=2020.4, num_updates=145800, lr=0.000261891, gnorm=1.232, loss_scale=8192, train_wall=128, wall=191750
2023-01-14 21:05:25 | INFO | train_inner | epoch 074:   1531 / 1978 loss=3.097, nll_loss=0.959, word_ins=2.781, length=3.161, ppl=8.56, wps=45683, ups=0.78, wpb=58690.1, bsz=2027.4, num_updates=145900, lr=0.000261802, gnorm=1.309, loss_scale=16384, train_wall=128, wall=191879
2023-01-14 21:05:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-14 21:05:26 | INFO | train_inner | epoch 074:   1532 / 1978 loss=None, nll_loss=None, word_ins=None, length=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, loss_scale=8192, train_wall=1, wall=191880
2023-01-14 21:07:35 | INFO | train_inner | epoch 074:   1632 / 1978 loss=3.073, nll_loss=0.937, word_ins=2.76, length=3.137, ppl=8.42, wps=46241.5, ups=0.77, wpb=59794.3, bsz=2085.5, num_updates=146000, lr=0.000261712, gnorm=1.243, loss_scale=8192, train_wall=129, wall=192010
2023-01-14 21:09:43 | INFO | train_inner | epoch 074:   1732 / 1978 loss=3.111, nll_loss=0.967, word_ins=2.789, length=3.226, ppl=8.64, wps=45922.3, ups=0.78, wpb=58795.6, bsz=1987.7, num_updates=146100, lr=0.000261622, gnorm=1.263, loss_scale=8192, train_wall=128, wall=192138
2023-01-14 21:11:52 | INFO | train_inner | epoch 074:   1832 / 1978 loss=3.088, nll_loss=0.954, word_ins=2.775, length=3.132, ppl=8.5, wps=46242.7, ups=0.78, wpb=59315.9, bsz=2066.8, num_updates=146200, lr=0.000261533, gnorm=1.25, loss_scale=8192, train_wall=128, wall=192266
2023-01-14 21:13:59 | INFO | train_inner | epoch 074:   1932 / 1978 loss=3.123, nll_loss=0.975, word_ins=2.795, length=3.276, ppl=8.71, wps=46190.1, ups=0.78, wpb=58850.4, bsz=1917.6, num_updates=146300, lr=0.000261443, gnorm=1.301, loss_scale=8192, train_wall=127, wall=192393
2023-01-14 21:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 21:15:17 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 4.563 | nll_loss 1.976 | word_ins 3.744 | length 8.188 | ppl 23.64 | wps 145761 | wpb 40242.5 | bsz 1500 | num_updates 146346 | best_loss 4.422
2023-01-14 21:15:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 21:15:45 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint74.pt (epoch 74 @ 146346 updates, score 4.563) (writing took 27.892626219894737 seconds)
2023-01-14 21:15:45 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2023-01-14 21:15:45 | INFO | train | epoch 074 | loss 3.1 | nll_loss 0.961 | word_ins 2.782 | length 3.176 | ppl 8.57 | wps 45255 | ups 0.76 | wpb 59282.7 | bsz 2002.6 | num_updates 146346 | lr 0.000261402 | gnorm 1.279 | loss_scale 8192 | train_wall 2523 | wall 192499
2023-01-14 21:15:45 | INFO | fairseq.trainer | begin training epoch 75
2023-01-14 21:17:09 | INFO | train_inner | epoch 075:     54 / 1978 loss=3.099, nll_loss=0.961, word_ins=2.783, length=3.154, ppl=8.57, wps=31103.5, ups=0.53, wpb=58894.2, bsz=1977, num_updates=146400, lr=0.000261354, gnorm=1.254, loss_scale=8192, train_wall=127, wall=192583
2023-01-14 21:19:18 | INFO | train_inner | epoch 075:    154 / 1978 loss=3.059, nll_loss=0.924, word_ins=2.749, length=3.095, ppl=8.33, wps=46188.5, ups=0.77, wpb=59748.9, bsz=2101, num_updates=146500, lr=0.000261265, gnorm=1.265, loss_scale=8192, train_wall=129, wall=192712
2023-01-14 21:21:27 | INFO | train_inner | epoch 075:    254 / 1978 loss=3.1, nll_loss=0.962, word_ins=2.784, length=3.159, ppl=8.57, wps=45877.5, ups=0.78, wpb=59080.7, bsz=2003.4, num_updates=146600, lr=0.000261176, gnorm=1.298, loss_scale=8192, train_wall=129, wall=192841
2023-01-14 21:23:34 | INFO | train_inner | epoch 075:    354 / 1978 loss=3.085, nll_loss=0.951, word_ins=2.773, length=3.115, ppl=8.48, wps=46666.1, ups=0.79, wpb=59397.1, bsz=2017.9, num_updates=146700, lr=0.000261087, gnorm=1.299, loss_scale=8192, train_wall=127, wall=192968
2023-01-14 21:25:42 | INFO | train_inner | epoch 075:    454 / 1978 loss=3.087, nll_loss=0.951, word_ins=2.774, length=3.127, ppl=8.49, wps=46109, ups=0.78, wpb=59184.6, bsz=2069.2, num_updates=146800, lr=0.000260998, gnorm=1.26, loss_scale=8192, train_wall=128, wall=193096
2023-01-14 21:27:50 | INFO | train_inner | epoch 075:    554 / 1978 loss=3.095, nll_loss=0.959, word_ins=2.781, length=3.138, ppl=8.54, wps=46196.8, ups=0.78, wpb=59072.9, bsz=1983.5, num_updates=146900, lr=0.000260909, gnorm=1.247, loss_scale=8192, train_wall=128, wall=193224
2023-01-14 21:29:57 | INFO | train_inner | epoch 075:    654 / 1978 loss=3.105, nll_loss=0.963, word_ins=2.784, length=3.217, ppl=8.61, wps=47045.4, ups=0.79, wpb=59783.3, bsz=1967, num_updates=147000, lr=0.00026082, gnorm=1.32, loss_scale=8192, train_wall=127, wall=193351
2023-01-14 21:32:05 | INFO | train_inner | epoch 075:    754 / 1978 loss=3.096, nll_loss=0.954, word_ins=2.776, length=3.2, ppl=8.55, wps=46517.2, ups=0.78, wpb=59277.2, bsz=1975.8, num_updates=147100, lr=0.000260732, gnorm=1.304, loss_scale=8192, train_wall=127, wall=193479
2023-01-14 21:34:12 | INFO | train_inner | epoch 075:    854 / 1978 loss=3.083, nll_loss=0.946, word_ins=2.769, length=3.143, ppl=8.47, wps=46174.4, ups=0.79, wpb=58776.5, bsz=2029.8, num_updates=147200, lr=0.000260643, gnorm=1.285, loss_scale=8192, train_wall=127, wall=193606
2023-01-14 21:36:21 | INFO | train_inner | epoch 075:    954 / 1978 loss=3.108, nll_loss=0.971, word_ins=2.792, length=3.163, ppl=8.62, wps=45637.6, ups=0.77, wpb=59028.7, bsz=2066.8, num_updates=147300, lr=0.000260555, gnorm=1.305, loss_scale=8192, train_wall=129, wall=193735
2023-01-14 21:38:30 | INFO | train_inner | epoch 075:   1054 / 1978 loss=3.066, nll_loss=0.93, word_ins=2.754, length=3.117, ppl=8.37, wps=46243.4, ups=0.78, wpb=59479.2, bsz=2093, num_updates=147400, lr=0.000260466, gnorm=1.217, loss_scale=8192, train_wall=128, wall=193864
2023-01-14 21:40:36 | INFO | train_inner | epoch 075:   1154 / 1978 loss=3.111, nll_loss=0.973, word_ins=2.794, length=3.167, ppl=8.64, wps=46535.8, ups=0.79, wpb=58760.1, bsz=1945.2, num_updates=147500, lr=0.000260378, gnorm=1.297, loss_scale=8192, train_wall=126, wall=193990
2023-01-14 21:42:43 | INFO | train_inner | epoch 075:   1254 / 1978 loss=3.12, nll_loss=0.981, word_ins=2.8, length=3.197, ppl=8.69, wps=46621, ups=0.79, wpb=59003.1, bsz=1940.2, num_updates=147600, lr=0.00026029, gnorm=1.268, loss_scale=8192, train_wall=126, wall=194117
2023-01-14 21:44:49 | INFO | train_inner | epoch 075:   1354 / 1978 loss=3.112, nll_loss=0.968, word_ins=2.788, length=3.234, ppl=8.64, wps=46481.9, ups=0.79, wpb=58814, bsz=1931.1, num_updates=147700, lr=0.000260201, gnorm=1.273, loss_scale=8192, train_wall=126, wall=194243
2023-01-14 21:46:57 | INFO | train_inner | epoch 075:   1454 / 1978 loss=3.096, nll_loss=0.957, word_ins=2.778, length=3.177, ppl=8.55, wps=47104.2, ups=0.79, wpb=59918.3, bsz=2022.1, num_updates=147800, lr=0.000260113, gnorm=1.279, loss_scale=8192, train_wall=127, wall=194371
2023-01-14 21:49:03 | INFO | train_inner | epoch 075:   1554 / 1978 loss=3.106, nll_loss=0.963, word_ins=2.785, length=3.209, ppl=8.61, wps=46818.5, ups=0.79, wpb=59185.2, bsz=1949.2, num_updates=147900, lr=0.000260025, gnorm=1.304, loss_scale=8192, train_wall=126, wall=194497
2023-01-14 21:51:10 | INFO | train_inner | epoch 075:   1654 / 1978 loss=3.111, nll_loss=0.975, word_ins=2.796, length=3.154, ppl=8.64, wps=47074.9, ups=0.79, wpb=59764.1, bsz=1941.3, num_updates=148000, lr=0.000259938, gnorm=1.293, loss_scale=8192, train_wall=127, wall=194624
2023-01-14 21:53:17 | INFO | train_inner | epoch 075:   1754 / 1978 loss=3.09, nll_loss=0.953, word_ins=2.775, length=3.157, ppl=8.52, wps=46347.9, ups=0.78, wpb=59101.6, bsz=2023.4, num_updates=148100, lr=0.00025985, gnorm=1.312, loss_scale=8192, train_wall=127, wall=194752
2023-01-14 21:55:25 | INFO | train_inner | epoch 075:   1854 / 1978 loss=3.101, nll_loss=0.96, word_ins=2.781, length=3.194, ppl=8.58, wps=47122.5, ups=0.79, wpb=59860.2, bsz=1993.8, num_updates=148200, lr=0.000259762, gnorm=1.304, loss_scale=8192, train_wall=127, wall=194879
2023-01-14 21:57:32 | INFO | train_inner | epoch 075:   1954 / 1978 loss=3.094, nll_loss=0.955, word_ins=2.777, length=3.169, ppl=8.54, wps=46695.3, ups=0.78, wpb=59582.8, bsz=2029.8, num_updates=148300, lr=0.000259675, gnorm=1.295, loss_scale=8192, train_wall=127, wall=195006
2023-01-14 21:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 21:58:15 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 4.571 | nll_loss 1.979 | word_ins 3.742 | length 8.295 | ppl 23.77 | wps 142488 | wpb 40242.5 | bsz 1500 | num_updates 148324 | best_loss 4.422
2023-01-14 21:58:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 21:58:42 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint75.pt (epoch 75 @ 148324 updates, score 4.571) (writing took 27.610377476084977 seconds)
2023-01-14 21:58:42 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2023-01-14 21:58:42 | INFO | train | epoch 075 | loss 3.096 | nll_loss 0.958 | word_ins 2.78 | length 3.165 | ppl 8.55 | wps 45491.4 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 148324 | lr 0.000259654 | gnorm 1.285 | loss_scale 8192 | train_wall 2519 | wall 195077
2023-01-14 21:58:42 | INFO | fairseq.trainer | begin training epoch 76
2023-01-14 22:00:32 | INFO | train_inner | epoch 076:     76 / 1978 loss=3.113, nll_loss=0.976, word_ins=2.796, length=3.171, ppl=8.65, wps=32804, ups=0.56, wpb=59077.1, bsz=1916.6, num_updates=148400, lr=0.000259587, gnorm=1.286, loss_scale=8192, train_wall=126, wall=195186
2023-01-14 22:02:40 | INFO | train_inner | epoch 076:    176 / 1978 loss=3.09, nll_loss=0.95, word_ins=2.773, length=3.17, ppl=8.52, wps=46425.7, ups=0.78, wpb=59390.8, bsz=1989.6, num_updates=148500, lr=0.0002595, gnorm=1.288, loss_scale=8192, train_wall=128, wall=195314
2023-01-14 22:04:49 | INFO | train_inner | epoch 076:    276 / 1978 loss=3.08, nll_loss=0.944, word_ins=2.767, length=3.132, ppl=8.46, wps=46216.1, ups=0.78, wpb=59333.3, bsz=2043.6, num_updates=148600, lr=0.000259412, gnorm=1.242, loss_scale=8192, train_wall=128, wall=195443
2023-01-14 22:06:56 | INFO | train_inner | epoch 076:    376 / 1978 loss=3.092, nll_loss=0.953, word_ins=2.776, length=3.162, ppl=8.53, wps=46522.8, ups=0.79, wpb=59128.4, bsz=1940.3, num_updates=148700, lr=0.000259325, gnorm=1.311, loss_scale=8192, train_wall=127, wall=195570
2023-01-14 22:09:03 | INFO | train_inner | epoch 076:    476 / 1978 loss=3.084, nll_loss=0.947, word_ins=2.77, length=3.14, ppl=8.48, wps=46324, ups=0.78, wpb=59168.7, bsz=2017.5, num_updates=148800, lr=0.000259238, gnorm=1.248, loss_scale=8192, train_wall=128, wall=195697
2023-01-14 22:11:12 | INFO | train_inner | epoch 076:    576 / 1978 loss=3.072, nll_loss=0.938, word_ins=2.762, length=3.099, ppl=8.41, wps=46253.5, ups=0.78, wpb=59313.3, bsz=2070.8, num_updates=148900, lr=0.000259151, gnorm=1.239, loss_scale=8192, train_wall=128, wall=195826
2023-01-14 22:13:19 | INFO | train_inner | epoch 076:    676 / 1978 loss=3.098, nll_loss=0.958, word_ins=2.779, length=3.182, ppl=8.56, wps=46651.3, ups=0.78, wpb=59583.1, bsz=1925.7, num_updates=149000, lr=0.000259064, gnorm=1.301, loss_scale=8192, train_wall=127, wall=195953
2023-01-14 22:15:28 | INFO | train_inner | epoch 076:    776 / 1978 loss=3.099, nll_loss=0.963, word_ins=2.784, length=3.152, ppl=8.57, wps=46024.9, ups=0.78, wpb=58992.3, bsz=2039.3, num_updates=149100, lr=0.000258977, gnorm=1.258, loss_scale=8192, train_wall=128, wall=196082
2023-01-14 22:17:36 | INFO | train_inner | epoch 076:    876 / 1978 loss=3.079, nll_loss=0.939, word_ins=2.763, length=3.155, ppl=8.45, wps=46242.2, ups=0.78, wpb=59254.3, bsz=2074.8, num_updates=149200, lr=0.00025889, gnorm=1.278, loss_scale=8192, train_wall=128, wall=196210
2023-01-14 22:19:44 | INFO | train_inner | epoch 076:    976 / 1978 loss=3.092, nll_loss=0.959, word_ins=2.78, length=3.121, ppl=8.53, wps=46420.9, ups=0.78, wpb=59385, bsz=2031.2, num_updates=149300, lr=0.000258803, gnorm=1.32, loss_scale=8192, train_wall=128, wall=196338
2023-01-14 22:21:50 | INFO | train_inner | epoch 076:   1076 / 1978 loss=3.123, nll_loss=0.979, word_ins=2.799, length=3.236, ppl=8.71, wps=46498, ups=0.79, wpb=58893, bsz=1898.3, num_updates=149400, lr=0.000258717, gnorm=1.353, loss_scale=8192, train_wall=126, wall=196464
2023-01-14 22:23:58 | INFO | train_inner | epoch 076:   1176 / 1978 loss=3.09, nll_loss=0.952, word_ins=2.774, length=3.159, ppl=8.52, wps=46383.9, ups=0.78, wpb=59138.8, bsz=2070, num_updates=149500, lr=0.00025863, gnorm=1.259, loss_scale=8192, train_wall=127, wall=196592
2023-01-14 22:26:05 | INFO | train_inner | epoch 076:   1276 / 1978 loss=3.098, nll_loss=0.956, word_ins=2.778, length=3.202, ppl=8.56, wps=46547.6, ups=0.78, wpb=59407.2, bsz=1994.9, num_updates=149600, lr=0.000258544, gnorm=1.272, loss_scale=8192, train_wall=127, wall=196720
2023-01-14 22:28:14 | INFO | train_inner | epoch 076:   1376 / 1978 loss=3.094, nll_loss=0.957, word_ins=2.778, length=3.158, ppl=8.54, wps=46069.1, ups=0.78, wpb=59250.3, bsz=2029.1, num_updates=149700, lr=0.000258457, gnorm=1.296, loss_scale=8192, train_wall=128, wall=196848
2023-01-14 22:30:21 | INFO | train_inner | epoch 076:   1476 / 1978 loss=3.094, nll_loss=0.949, word_ins=2.771, length=3.226, ppl=8.54, wps=46603.5, ups=0.79, wpb=59186.7, bsz=1967.2, num_updates=149800, lr=0.000258371, gnorm=1.32, loss_scale=8192, train_wall=126, wall=196975
2023-01-14 22:32:30 | INFO | train_inner | epoch 076:   1576 / 1978 loss=3.109, nll_loss=0.969, word_ins=2.789, length=3.199, ppl=8.63, wps=45964.2, ups=0.78, wpb=59061.7, bsz=1986.2, num_updates=149900, lr=0.000258285, gnorm=1.277, loss_scale=8192, train_wall=128, wall=197104
2023-01-14 22:34:38 | INFO | train_inner | epoch 076:   1676 / 1978 loss=3.091, nll_loss=0.952, word_ins=2.774, length=3.171, ppl=8.52, wps=46661.5, ups=0.78, wpb=59835.4, bsz=1990.7, num_updates=150000, lr=0.000258199, gnorm=1.287, loss_scale=16384, train_wall=128, wall=197232
2023-01-14 22:36:47 | INFO | train_inner | epoch 076:   1776 / 1978 loss=3.104, nll_loss=0.967, word_ins=2.788, length=3.162, ppl=8.6, wps=45820.2, ups=0.77, wpb=59220.1, bsz=2038, num_updates=150100, lr=0.000258113, gnorm=1.283, loss_scale=16384, train_wall=129, wall=197361
2023-01-14 22:36:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-14 22:38:57 | INFO | train_inner | epoch 076:   1877 / 1978 loss=3.07, nll_loss=0.941, word_ins=2.764, length=3.066, ppl=8.4, wps=46112.6, ups=0.77, wpb=59790, bsz=2036, num_updates=150200, lr=0.000258027, gnorm=1.284, loss_scale=8192, train_wall=129, wall=197491
2023-01-14 22:41:05 | INFO | train_inner | epoch 076:   1977 / 1978 loss=3.098, nll_loss=0.959, word_ins=2.78, length=3.178, ppl=8.56, wps=46323.2, ups=0.78, wpb=59256.8, bsz=1968.6, num_updates=150300, lr=0.000257941, gnorm=1.254, loss_scale=8192, train_wall=128, wall=197619
2023-01-14 22:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 22:41:22 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 4.565 | nll_loss 1.975 | word_ins 3.741 | length 8.245 | ppl 23.67 | wps 92951.3 | wpb 40242.5 | bsz 1500 | num_updates 150301 | best_loss 4.422
2023-01-14 22:41:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 22:41:50 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint76.pt (epoch 76 @ 150301 updates, score 4.565) (writing took 28.439549170900136 seconds)
2023-01-14 22:41:50 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2023-01-14 22:41:50 | INFO | train | epoch 076 | loss 3.093 | nll_loss 0.955 | word_ins 2.777 | length 3.161 | ppl 8.53 | wps 45296.2 | ups 0.76 | wpb 59285.1 | bsz 2002.5 | num_updates 150301 | lr 0.00025794 | gnorm 1.283 | loss_scale 8192 | train_wall 2524 | wall 197664
2023-01-14 22:41:50 | INFO | fairseq.trainer | begin training epoch 77
2023-01-14 22:44:12 | INFO | train_inner | epoch 077:     99 / 1978 loss=3.076, nll_loss=0.941, word_ins=2.765, length=3.116, ppl=8.44, wps=31493.8, ups=0.53, wpb=59100.6, bsz=2050.9, num_updates=150400, lr=0.000257855, gnorm=1.279, loss_scale=8192, train_wall=128, wall=197806
2023-01-14 22:46:21 | INFO | train_inner | epoch 077:    199 / 1978 loss=3.058, nll_loss=0.924, word_ins=2.749, length=3.096, ppl=8.33, wps=46061.2, ups=0.78, wpb=59083.1, bsz=2039.7, num_updates=150500, lr=0.00025777, gnorm=1.223, loss_scale=8192, train_wall=128, wall=197935
2023-01-14 22:48:29 | INFO | train_inner | epoch 077:    299 / 1978 loss=3.093, nll_loss=0.956, word_ins=2.778, length=3.153, ppl=8.53, wps=46688.7, ups=0.78, wpb=59718.2, bsz=1962.4, num_updates=150600, lr=0.000257684, gnorm=1.287, loss_scale=8192, train_wall=128, wall=198063
2023-01-14 22:50:35 | INFO | train_inner | epoch 077:    399 / 1978 loss=3.095, nll_loss=0.958, word_ins=2.779, length=3.157, ppl=8.54, wps=46673.7, ups=0.79, wpb=59224.3, bsz=1943.2, num_updates=150700, lr=0.000257599, gnorm=1.252, loss_scale=8192, train_wall=127, wall=198190
2023-01-14 22:52:44 | INFO | train_inner | epoch 077:    499 / 1978 loss=3.087, nll_loss=0.954, word_ins=2.776, length=3.108, ppl=8.5, wps=46436.5, ups=0.78, wpb=59599.7, bsz=2050.3, num_updates=150800, lr=0.000257513, gnorm=1.275, loss_scale=8192, train_wall=128, wall=198318
2023-01-14 22:54:51 | INFO | train_inner | epoch 077:    599 / 1978 loss=3.106, nll_loss=0.966, word_ins=2.787, length=3.188, ppl=8.61, wps=45941, ups=0.78, wpb=58626.6, bsz=2033.7, num_updates=150900, lr=0.000257428, gnorm=1.277, loss_scale=8192, train_wall=127, wall=198445
2023-01-14 22:57:01 | INFO | train_inner | epoch 077:    699 / 1978 loss=3.085, nll_loss=0.948, word_ins=2.77, length=3.15, ppl=8.49, wps=45791.1, ups=0.77, wpb=59432.8, bsz=2087.9, num_updates=151000, lr=0.000257343, gnorm=1.283, loss_scale=8192, train_wall=130, wall=198575
2023-01-14 22:59:10 | INFO | train_inner | epoch 077:    799 / 1978 loss=3.073, nll_loss=0.937, word_ins=2.761, length=3.121, ppl=8.41, wps=46188.8, ups=0.78, wpb=59580.7, bsz=2053.1, num_updates=151100, lr=0.000257257, gnorm=1.25, loss_scale=8192, train_wall=129, wall=198704
2023-01-14 23:01:18 | INFO | train_inner | epoch 077:    899 / 1978 loss=3.106, nll_loss=0.969, word_ins=2.79, length=3.166, ppl=8.61, wps=46545, ups=0.78, wpb=59329.7, bsz=1959.6, num_updates=151200, lr=0.000257172, gnorm=1.288, loss_scale=8192, train_wall=127, wall=198832
2023-01-14 23:03:27 | INFO | train_inner | epoch 077:    999 / 1978 loss=3.08, nll_loss=0.944, word_ins=2.767, length=3.133, ppl=8.46, wps=45915.7, ups=0.77, wpb=59433.8, bsz=2085.4, num_updates=151300, lr=0.000257087, gnorm=1.282, loss_scale=8192, train_wall=129, wall=198961
2023-01-14 23:05:35 | INFO | train_inner | epoch 077:   1099 / 1978 loss=3.084, nll_loss=0.949, word_ins=2.771, length=3.123, ppl=8.48, wps=46639.3, ups=0.78, wpb=59521.3, bsz=2015.3, num_updates=151400, lr=0.000257002, gnorm=1.272, loss_scale=8192, train_wall=127, wall=199089
2023-01-14 23:07:42 | INFO | train_inner | epoch 077:   1199 / 1978 loss=3.105, nll_loss=0.963, word_ins=2.784, length=3.203, ppl=8.6, wps=46236.5, ups=0.78, wpb=58989.7, bsz=1970, num_updates=151500, lr=0.000256917, gnorm=1.302, loss_scale=8192, train_wall=127, wall=199216
2023-01-14 23:09:50 | INFO | train_inner | epoch 077:   1299 / 1978 loss=3.104, nll_loss=0.964, word_ins=2.785, length=3.188, ppl=8.6, wps=46570.5, ups=0.78, wpb=59584.8, bsz=1988.6, num_updates=151600, lr=0.000256833, gnorm=1.28, loss_scale=8192, train_wall=128, wall=199344
2023-01-14 23:11:57 | INFO | train_inner | epoch 077:   1399 / 1978 loss=3.105, nll_loss=0.964, word_ins=2.785, length=3.201, ppl=8.61, wps=46636.1, ups=0.79, wpb=59208.1, bsz=1909.9, num_updates=151700, lr=0.000256748, gnorm=1.292, loss_scale=8192, train_wall=127, wall=199471
2023-01-14 23:14:04 | INFO | train_inner | epoch 077:   1499 / 1978 loss=3.121, nll_loss=0.978, word_ins=2.798, length=3.239, ppl=8.7, wps=46730.5, ups=0.79, wpb=59226, bsz=1875.5, num_updates=151800, lr=0.000256664, gnorm=1.383, loss_scale=8192, train_wall=127, wall=199598
2023-01-14 23:16:11 | INFO | train_inner | epoch 077:   1599 / 1978 loss=3.096, nll_loss=0.953, word_ins=2.775, length=3.206, ppl=8.55, wps=46676.3, ups=0.78, wpb=59473.7, bsz=1955.8, num_updates=151900, lr=0.000256579, gnorm=1.265, loss_scale=8192, train_wall=127, wall=199725
2023-01-14 23:18:19 | INFO | train_inner | epoch 077:   1699 / 1978 loss=3.071, nll_loss=0.932, word_ins=2.755, length=3.152, ppl=8.4, wps=46046.2, ups=0.78, wpb=58854.6, bsz=2054, num_updates=152000, lr=0.000256495, gnorm=1.277, loss_scale=8192, train_wall=128, wall=199853
2023-01-14 23:20:27 | INFO | train_inner | epoch 077:   1799 / 1978 loss=3.085, nll_loss=0.946, word_ins=2.769, length=3.159, ppl=8.48, wps=46177.8, ups=0.78, wpb=59111, bsz=2004.6, num_updates=152100, lr=0.00025641, gnorm=1.289, loss_scale=8192, train_wall=128, wall=199981
2023-01-14 23:22:35 | INFO | train_inner | epoch 077:   1899 / 1978 loss=3.086, nll_loss=0.944, word_ins=2.766, length=3.195, ppl=8.49, wps=46155.3, ups=0.78, wpb=59152.6, bsz=2030.2, num_updates=152200, lr=0.000256326, gnorm=1.283, loss_scale=8192, train_wall=128, wall=200109
2023-01-14 23:24:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-14 23:24:38 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 4.574 | nll_loss 1.981 | word_ins 3.748 | length 8.257 | ppl 23.81 | wps 96683 | wpb 40242.5 | bsz 1500 | num_updates 152279 | best_loss 4.422
2023-01-14 23:24:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-14 23:25:06 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint77.pt (epoch 77 @ 152279 updates, score 4.574) (writing took 27.798540401272476 seconds)
2023-01-14 23:25:06 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2023-01-14 23:25:06 | INFO | train | epoch 077 | loss 3.091 | nll_loss 0.953 | word_ins 2.775 | length 3.161 | ppl 8.52 | wps 45178.2 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 152279 | lr 0.00025626 | gnorm 1.281 | loss_scale 8192 | train_wall 2525 | wall 200260
2023-01-14 23:25:06 | INFO | fairseq.trainer | begin training epoch 78
2023-01-14 23:25:48 | INFO | train_inner | epoch 078:     21 / 1978 loss=3.1, nll_loss=0.961, word_ins=2.782, length=3.178, ppl=8.57, wps=30757.5, ups=0.52, wpb=59121.3, bsz=1971.2, num_updates=152300, lr=0.000256242, gnorm=1.285, loss_scale=8192, train_wall=127, wall=200302
2023-01-14 23:27:55 | INFO | train_inner | epoch 078:    121 / 1978 loss=3.058, nll_loss=0.923, word_ins=2.748, length=3.1, ppl=8.33, wps=46999.4, ups=0.79, wpb=59795.7, bsz=1981.5, num_updates=152400, lr=0.000256158, gnorm=1.317, loss_scale=8192, train_wall=127, wall=200429
2023-01-14 23:30:06 | INFO | train_inner | epoch 078:    221 / 1978 loss=3.076, nll_loss=0.934, word_ins=2.758, length=3.183, ppl=8.43, wps=45570.3, ups=0.76, wpb=59639.3, bsz=2015.2, num_updates=152500, lr=0.000256074, gnorm=1.268, loss_scale=8192, train_wall=131, wall=200560
2023-01-14 23:32:15 | INFO | train_inner | epoch 078:    321 / 1978 loss=3.093, nll_loss=0.96, word_ins=2.781, length=3.119, ppl=8.53, wps=46034.7, ups=0.77, wpb=59459.4, bsz=2009.9, num_updates=152600, lr=0.00025599, gnorm=1.301, loss_scale=8192, train_wall=129, wall=200689
2023-01-14 23:34:22 | INFO | train_inner | epoch 078:    421 / 1978 loss=3.095, nll_loss=0.955, word_ins=2.777, length=3.183, ppl=8.55, wps=46905, ups=0.79, wpb=59415.6, bsz=1933, num_updates=152700, lr=0.000255906, gnorm=1.313, loss_scale=8192, train_wall=126, wall=200816
2023-01-14 23:36:30 | INFO | train_inner | epoch 078:    521 / 1978 loss=3.087, nll_loss=0.948, word_ins=2.77, length=3.167, ppl=8.5, wps=46135.7, ups=0.78, wpb=59229.9, bsz=1995.8, num_updates=152800, lr=0.000255822, gnorm=1.246, loss_scale=8192, train_wall=128, wall=200944
2023-01-14 23:38:39 | INFO | train_inner | epoch 078:    621 / 1978 loss=3.102, nll_loss=0.964, word_ins=2.785, length=3.168, ppl=8.58, wps=45700.3, ups=0.78, wpb=58887.2, bsz=2027.2, num_updates=152900, lr=0.000255739, gnorm=1.252, loss_scale=8192, train_wall=129, wall=201073
2023-01-14 23:40:46 | INFO | train_inner | epoch 078:    721 / 1978 loss=3.095, nll_loss=0.955, word_ins=2.777, length=3.177, ppl=8.54, wps=46662.9, ups=0.79, wpb=59298.8, bsz=1918, num_updates=153000, lr=0.000255655, gnorm=1.307, loss_scale=8192, train_wall=127, wall=201200
2023-01-14 23:42:54 | INFO | train_inner | epoch 078:    821 / 1978 loss=3.068, nll_loss=0.935, word_ins=2.759, length=3.096, ppl=8.39, wps=46340.4, ups=0.78, wpb=59439.2, bsz=2060.2, num_updates=153100, lr=0.000255571, gnorm=1.267, loss_scale=8192, train_wall=128, wall=201328
2023-01-14 23:45:03 | INFO | train_inner | epoch 078:    921 / 1978 loss=3.098, nll_loss=0.958, word_ins=2.78, length=3.18, ppl=8.56, wps=46253.7, ups=0.78, wpb=59502.2, bsz=1959.4, num_updates=153200, lr=0.000255488, gnorm=1.294, loss_scale=8192, train_wall=128, wall=201457
2023-01-14 23:47:12 | INFO | train_inner | epoch 078:   1021 / 1978 loss=3.06, nll_loss=0.927, word_ins=2.751, length=3.085, ppl=8.34, wps=46028.1, ups=0.77, wpb=59403, bsz=2096.2, num_updates=153300, lr=0.000255405, gnorm=1.213, loss_scale=8192, train_wall=129, wall=201586
2023-01-14 23:49:20 | INFO | train_inner | epoch 078:   1121 / 1978 loss=3.074, nll_loss=0.936, word_ins=2.76, length=3.146, ppl=8.42, wps=45995.4, ups=0.78, wpb=58901.3, bsz=2025.2, num_updates=153400, lr=0.000255321, gnorm=1.289, loss_scale=8192, train_wall=128, wall=201714
2023-01-14 23:51:27 | INFO | train_inner | epoch 078:   1221 / 1978 loss=3.121, nll_loss=0.977, word_ins=2.797, length=3.24, ppl=8.7, wps=46293.2, ups=0.79, wpb=58844.8, bsz=1858.1, num_updates=153500, lr=0.000255238, gnorm=1.337, loss_scale=8192, train_wall=127, wall=201841
2023-01-14 23:53:36 | INFO | train_inner | epoch 078:   1321 / 1978 loss=3.074, nll_loss=0.937, word_ins=2.76, length=3.137, ppl=8.42, wps=46388.9, ups=0.77, wpb=59859.4, bsz=2091.8, num_updates=153600, lr=0.000255155, gnorm=1.274, loss_scale=8192, train_wall=129, wall=201970
2023-01-14 23:55:44 | INFO | train_inner | epoch 078:   1421 / 1978 loss=3.087, nll_loss=0.947, word_ins=2.769, length=3.176, ppl=8.5, wps=46326.5, ups=0.78, wpb=59289.7, bsz=2002, num_updates=153700, lr=0.000255072, gnorm=1.276, loss_scale=8192, train_wall=128, wall=202098
2023-01-14 23:57:52 | INFO | train_inner | epoch 078:   1521 / 1978 loss=3.088, nll_loss=0.95, word_ins=2.772, length=3.157, ppl=8.5, wps=46754.2, ups=0.78, wpb=59718.4, bsz=1965.8, num_updates=153800, lr=0.000254989, gnorm=1.342, loss_scale=8192, train_wall=127, wall=202226
2023-01-15 00:00:01 | INFO | train_inner | epoch 078:   1621 / 1978 loss=3.108, nll_loss=0.971, word_ins=2.791, length=3.174, ppl=8.62, wps=45861.6, ups=0.78, wpb=58982.6, bsz=2012.1, num_updates=153900, lr=0.000254906, gnorm=1.267, loss_scale=8192, train_wall=128, wall=202355
2023-01-15 00:02:09 | INFO | train_inner | epoch 078:   1721 / 1978 loss=3.109, nll_loss=0.968, word_ins=2.788, length=3.212, ppl=8.63, wps=45614, ups=0.78, wpb=58746, bsz=2022.8, num_updates=154000, lr=0.000254824, gnorm=1.255, loss_scale=8192, train_wall=129, wall=202483
2023-01-15 00:04:17 | INFO | train_inner | epoch 078:   1821 / 1978 loss=3.101, nll_loss=0.964, word_ins=2.785, length=3.164, ppl=8.58, wps=46100.2, ups=0.78, wpb=58782.5, bsz=2017.4, num_updates=154100, lr=0.000254741, gnorm=1.233, loss_scale=8192, train_wall=127, wall=202611
2023-01-15 00:06:26 | INFO | train_inner | epoch 078:   1921 / 1978 loss=3.089, nll_loss=0.953, word_ins=2.775, length=3.14, ppl=8.51, wps=46032.4, ups=0.78, wpb=59244.3, bsz=2027, num_updates=154200, lr=0.000254658, gnorm=1.268, loss_scale=16384, train_wall=128, wall=202740
2023-01-15 00:07:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 00:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 00:07:58 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 4.642 | nll_loss 2 | word_ins 3.768 | length 8.744 | ppl 24.97 | wps 103881 | wpb 40242.5 | bsz 1500 | num_updates 154256 | best_loss 4.422
2023-01-15 00:07:58 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 00:08:26 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint78.pt (epoch 78 @ 154256 updates, score 4.642) (writing took 27.39926787884906 seconds)
2023-01-15 00:08:26 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2023-01-15 00:08:26 | INFO | train | epoch 078 | loss 3.088 | nll_loss 0.951 | word_ins 2.773 | length 3.158 | ppl 8.51 | wps 45075.6 | ups 0.76 | wpb 59283 | bsz 2002.5 | num_updates 154256 | lr 0.000254612 | gnorm 1.28 | loss_scale 8192 | train_wall 2532 | wall 202860
2023-01-15 00:08:26 | INFO | fairseq.trainer | begin training epoch 79
2023-01-15 00:09:36 | INFO | train_inner | epoch 079:     44 / 1978 loss=3.111, nll_loss=0.968, word_ins=2.788, length=3.227, ppl=8.64, wps=31080, ups=0.53, wpb=59108.7, bsz=1934.5, num_updates=154300, lr=0.000254576, gnorm=1.312, loss_scale=8192, train_wall=128, wall=202930
2023-01-15 00:11:44 | INFO | train_inner | epoch 079:    144 / 1978 loss=3.079, nll_loss=0.946, word_ins=2.769, length=3.095, ppl=8.45, wps=46183.4, ups=0.78, wpb=59115.4, bsz=2043, num_updates=154400, lr=0.000254493, gnorm=1.273, loss_scale=8192, train_wall=128, wall=203058
2023-01-15 00:13:52 | INFO | train_inner | epoch 079:    244 / 1978 loss=3.079, nll_loss=0.943, word_ins=2.766, length=3.123, ppl=8.45, wps=46606.9, ups=0.78, wpb=59887.9, bsz=2013, num_updates=154500, lr=0.000254411, gnorm=1.271, loss_scale=8192, train_wall=128, wall=203186
2023-01-15 00:16:01 | INFO | train_inner | epoch 079:    344 / 1978 loss=3.073, nll_loss=0.94, word_ins=2.764, length=3.088, ppl=8.41, wps=45628.2, ups=0.78, wpb=58873.6, bsz=2097.8, num_updates=154600, lr=0.000254329, gnorm=1.249, loss_scale=8192, train_wall=129, wall=203315
2023-01-15 00:18:09 | INFO | train_inner | epoch 079:    444 / 1978 loss=3.082, nll_loss=0.945, word_ins=2.768, length=3.144, ppl=8.47, wps=46311.3, ups=0.78, wpb=59098.2, bsz=2003.5, num_updates=154700, lr=0.000254246, gnorm=1.293, loss_scale=8192, train_wall=127, wall=203443
2023-01-15 00:20:16 | INFO | train_inner | epoch 079:    544 / 1978 loss=3.088, nll_loss=0.951, word_ins=2.773, length=3.149, ppl=8.51, wps=46541.6, ups=0.79, wpb=59095.9, bsz=1941.7, num_updates=154800, lr=0.000254164, gnorm=1.296, loss_scale=8192, train_wall=127, wall=203570
2023-01-15 00:22:24 | INFO | train_inner | epoch 079:    644 / 1978 loss=3.071, nll_loss=0.935, word_ins=2.759, length=3.118, ppl=8.4, wps=46285.8, ups=0.78, wpb=59202.6, bsz=2033.3, num_updates=154900, lr=0.000254082, gnorm=1.242, loss_scale=8192, train_wall=128, wall=203698
2023-01-15 00:24:32 | INFO | train_inner | epoch 079:    744 / 1978 loss=3.092, nll_loss=0.954, word_ins=2.776, length=3.153, ppl=8.52, wps=46312.1, ups=0.78, wpb=59318.2, bsz=2031.2, num_updates=155000, lr=0.000254, gnorm=1.29, loss_scale=8192, train_wall=128, wall=203826
2023-01-15 00:26:39 | INFO | train_inner | epoch 079:    844 / 1978 loss=3.095, nll_loss=0.953, word_ins=2.775, length=3.201, ppl=8.54, wps=46679.8, ups=0.79, wpb=59346.2, bsz=2018.5, num_updates=155100, lr=0.000253918, gnorm=1.342, loss_scale=8192, train_wall=127, wall=203953
2023-01-15 00:28:47 | INFO | train_inner | epoch 079:    944 / 1978 loss=3.084, nll_loss=0.946, word_ins=2.768, length=3.154, ppl=8.48, wps=46348.3, ups=0.78, wpb=59259.7, bsz=1966.2, num_updates=155200, lr=0.000253837, gnorm=1.292, loss_scale=8192, train_wall=128, wall=204081
2023-01-15 00:30:55 | INFO | train_inner | epoch 079:   1044 / 1978 loss=3.071, nll_loss=0.933, word_ins=2.756, length=3.146, ppl=8.4, wps=46264.7, ups=0.78, wpb=59494.9, bsz=2008.2, num_updates=155300, lr=0.000253755, gnorm=1.194, loss_scale=8192, train_wall=128, wall=204210
2023-01-15 00:33:05 | INFO | train_inner | epoch 079:   1144 / 1978 loss=3.085, nll_loss=0.949, word_ins=2.771, length=3.142, ppl=8.48, wps=46408, ups=0.77, wpb=60050.7, bsz=2030.9, num_updates=155400, lr=0.000253673, gnorm=1.289, loss_scale=8192, train_wall=129, wall=204339
2023-01-15 00:35:13 | INFO | train_inner | epoch 079:   1244 / 1978 loss=3.076, nll_loss=0.938, word_ins=2.761, length=3.15, ppl=8.43, wps=46195, ups=0.78, wpb=59185.1, bsz=2019.8, num_updates=155500, lr=0.000253592, gnorm=1.276, loss_scale=8192, train_wall=128, wall=204467
2023-01-15 00:37:21 | INFO | train_inner | epoch 079:   1344 / 1978 loss=3.095, nll_loss=0.953, word_ins=2.775, length=3.198, ppl=8.55, wps=46212.5, ups=0.78, wpb=59161.5, bsz=1955.8, num_updates=155600, lr=0.00025351, gnorm=1.273, loss_scale=8192, train_wall=128, wall=204595
2023-01-15 00:39:29 | INFO | train_inner | epoch 079:   1444 / 1978 loss=3.073, nll_loss=0.936, word_ins=2.759, length=3.138, ppl=8.42, wps=46553.4, ups=0.78, wpb=59588.1, bsz=2047.4, num_updates=155700, lr=0.000253429, gnorm=1.273, loss_scale=8192, train_wall=128, wall=204723
2023-01-15 00:41:36 | INFO | train_inner | epoch 079:   1544 / 1978 loss=3.077, nll_loss=0.939, word_ins=2.762, length=3.154, ppl=8.44, wps=46833.9, ups=0.79, wpb=59609.4, bsz=1969.4, num_updates=155800, lr=0.000253347, gnorm=1.287, loss_scale=8192, train_wall=127, wall=204850
2023-01-15 00:43:44 | INFO | train_inner | epoch 079:   1644 / 1978 loss=3.082, nll_loss=0.946, word_ins=2.768, length=3.139, ppl=8.47, wps=46245.3, ups=0.78, wpb=59238.8, bsz=2034.9, num_updates=155900, lr=0.000253266, gnorm=1.26, loss_scale=8192, train_wall=128, wall=204979
2023-01-15 00:45:52 | INFO | train_inner | epoch 079:   1744 / 1978 loss=3.089, nll_loss=0.95, word_ins=2.772, length=3.172, ppl=8.51, wps=46002.2, ups=0.78, wpb=58864.9, bsz=1981.5, num_updates=156000, lr=0.000253185, gnorm=1.27, loss_scale=8192, train_wall=128, wall=205107
2023-01-15 00:48:00 | INFO | train_inner | epoch 079:   1844 / 1978 loss=3.1, nll_loss=0.961, word_ins=2.782, length=3.185, ppl=8.57, wps=46341.6, ups=0.78, wpb=59186.7, bsz=1947.6, num_updates=156100, lr=0.000253104, gnorm=1.283, loss_scale=8192, train_wall=127, wall=205234
2023-01-15 00:50:08 | INFO | train_inner | epoch 079:   1944 / 1978 loss=3.089, nll_loss=0.951, word_ins=2.773, length=3.157, ppl=8.51, wps=46425.9, ups=0.78, wpb=59349, bsz=1989.1, num_updates=156200, lr=0.000253023, gnorm=1.291, loss_scale=8192, train_wall=127, wall=205362
2023-01-15 00:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 00:51:11 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 4.589 | nll_loss 1.985 | word_ins 3.751 | length 8.382 | ppl 24.07 | wps 140424 | wpb 40242.5 | bsz 1500 | num_updates 156234 | best_loss 4.422
2023-01-15 00:51:11 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 00:51:39 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint79.pt (epoch 79 @ 156234 updates, score 4.589) (writing took 27.975851031951606 seconds)
2023-01-15 00:51:39 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2023-01-15 00:51:39 | INFO | train | epoch 079 | loss 3.084 | nll_loss 0.947 | word_ins 2.769 | length 3.151 | ppl 8.48 | wps 45217.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 156234 | lr 0.000252995 | gnorm 1.278 | loss_scale 8192 | train_wall 2526 | wall 205453
2023-01-15 00:51:39 | INFO | fairseq.trainer | begin training epoch 80
2023-01-15 00:53:18 | INFO | train_inner | epoch 080:     66 / 1978 loss=3.09, nll_loss=0.954, word_ins=2.776, length=3.147, ppl=8.52, wps=30891, ups=0.53, wpb=58709.4, bsz=2019.9, num_updates=156300, lr=0.000252942, gnorm=1.255, loss_scale=8192, train_wall=127, wall=205552
2023-01-15 00:55:27 | INFO | train_inner | epoch 080:    166 / 1978 loss=3.06, nll_loss=0.925, word_ins=2.749, length=3.103, ppl=8.34, wps=46331.1, ups=0.78, wpb=59549, bsz=2001, num_updates=156400, lr=0.000252861, gnorm=1.275, loss_scale=8192, train_wall=128, wall=205681
2023-01-15 00:57:34 | INFO | train_inner | epoch 080:    266 / 1978 loss=3.084, nll_loss=0.947, word_ins=2.77, length=3.14, ppl=8.48, wps=46615.6, ups=0.79, wpb=59316.6, bsz=1945.8, num_updates=156500, lr=0.00025278, gnorm=1.286, loss_scale=8192, train_wall=127, wall=205808
2023-01-15 00:59:43 | INFO | train_inner | epoch 080:    366 / 1978 loss=3.079, nll_loss=0.945, word_ins=2.768, length=3.115, ppl=8.45, wps=46369.9, ups=0.78, wpb=59742.9, bsz=1994.9, num_updates=156600, lr=0.000252699, gnorm=1.288, loss_scale=8192, train_wall=129, wall=205937
2023-01-15 01:01:50 | INFO | train_inner | epoch 080:    466 / 1978 loss=3.091, nll_loss=0.948, word_ins=2.771, length=3.196, ppl=8.52, wps=46460.7, ups=0.79, wpb=59021.8, bsz=1928.5, num_updates=156700, lr=0.000252619, gnorm=1.317, loss_scale=8192, train_wall=127, wall=206064
2023-01-15 01:03:58 | INFO | train_inner | epoch 080:    566 / 1978 loss=3.065, nll_loss=0.925, word_ins=2.749, length=3.154, ppl=8.37, wps=46364.9, ups=0.78, wpb=59657.3, bsz=2057.9, num_updates=156800, lr=0.000252538, gnorm=1.288, loss_scale=8192, train_wall=128, wall=206192
2023-01-15 01:06:06 | INFO | train_inner | epoch 080:    666 / 1978 loss=3.077, nll_loss=0.941, word_ins=2.763, length=3.134, ppl=8.44, wps=46621.3, ups=0.78, wpb=59566, bsz=1967.6, num_updates=156900, lr=0.000252458, gnorm=1.268, loss_scale=8192, train_wall=127, wall=206320
2023-01-15 01:08:14 | INFO | train_inner | epoch 080:    766 / 1978 loss=3.101, nll_loss=0.96, word_ins=2.782, length=3.192, ppl=8.58, wps=45688.4, ups=0.78, wpb=58280.2, bsz=1981.5, num_updates=157000, lr=0.000252377, gnorm=1.215, loss_scale=8192, train_wall=127, wall=206448
2023-01-15 01:10:21 | INFO | train_inner | epoch 080:    866 / 1978 loss=3.088, nll_loss=0.952, word_ins=2.774, length=3.135, ppl=8.5, wps=46613, ups=0.78, wpb=59426.6, bsz=1979.4, num_updates=157100, lr=0.000252297, gnorm=1.28, loss_scale=8192, train_wall=127, wall=206575
2023-01-15 01:12:30 | INFO | train_inner | epoch 080:    966 / 1978 loss=3.075, nll_loss=0.932, word_ins=2.756, length=3.194, ppl=8.43, wps=46044, ups=0.78, wpb=59095.3, bsz=2007.5, num_updates=157200, lr=0.000252217, gnorm=1.261, loss_scale=8192, train_wall=128, wall=206704
2023-01-15 01:14:38 | INFO | train_inner | epoch 080:   1066 / 1978 loss=3.066, nll_loss=0.934, word_ins=2.757, length=3.089, ppl=8.38, wps=46217.7, ups=0.78, wpb=59526.4, bsz=2075.6, num_updates=157300, lr=0.000252136, gnorm=1.267, loss_scale=8192, train_wall=128, wall=206832
2023-01-15 01:16:46 | INFO | train_inner | epoch 080:   1166 / 1978 loss=3.078, nll_loss=0.948, word_ins=2.769, length=3.085, ppl=8.44, wps=46390.8, ups=0.78, wpb=59262.7, bsz=2010.8, num_updates=157400, lr=0.000252056, gnorm=1.334, loss_scale=8192, train_wall=127, wall=206960
2023-01-15 01:18:55 | INFO | train_inner | epoch 080:   1266 / 1978 loss=3.099, nll_loss=0.961, word_ins=2.782, length=3.167, ppl=8.57, wps=45821.9, ups=0.78, wpb=59013.2, bsz=2020.5, num_updates=157500, lr=0.000251976, gnorm=1.282, loss_scale=8192, train_wall=129, wall=207089
2023-01-15 01:21:02 | INFO | train_inner | epoch 080:   1366 / 1978 loss=3.122, nll_loss=0.98, word_ins=2.799, length=3.227, ppl=8.71, wps=46225.8, ups=0.79, wpb=58835.5, bsz=1904.2, num_updates=157600, lr=0.000251896, gnorm=1.288, loss_scale=8192, train_wall=127, wall=207216
2023-01-15 01:23:10 | INFO | train_inner | epoch 080:   1466 / 1978 loss=3.085, nll_loss=0.948, word_ins=2.77, length=3.145, ppl=8.48, wps=46562.6, ups=0.78, wpb=59379.2, bsz=2014.3, num_updates=157700, lr=0.000251816, gnorm=1.237, loss_scale=8192, train_wall=127, wall=207344
2023-01-15 01:25:18 | INFO | train_inner | epoch 080:   1566 / 1978 loss=3.06, nll_loss=0.924, word_ins=2.748, length=3.114, ppl=8.34, wps=46354.3, ups=0.78, wpb=59357.8, bsz=2019.3, num_updates=157800, lr=0.000251737, gnorm=1.275, loss_scale=8192, train_wall=128, wall=207472
2023-01-15 01:27:27 | INFO | train_inner | epoch 080:   1666 / 1978 loss=3.071, nll_loss=0.935, word_ins=2.758, length=3.126, ppl=8.4, wps=46040.7, ups=0.78, wpb=59275.3, bsz=2075, num_updates=157900, lr=0.000251657, gnorm=1.251, loss_scale=8192, train_wall=129, wall=207601
2023-01-15 01:29:35 | INFO | train_inner | epoch 080:   1766 / 1978 loss=3.08, nll_loss=0.945, word_ins=2.767, length=3.129, ppl=8.46, wps=46170.5, ups=0.78, wpb=59409.4, bsz=2033.5, num_updates=158000, lr=0.000251577, gnorm=1.289, loss_scale=8192, train_wall=128, wall=207729
2023-01-15 01:31:44 | INFO | train_inner | epoch 080:   1866 / 1978 loss=3.083, nll_loss=0.941, word_ins=2.763, length=3.193, ppl=8.47, wps=46051.1, ups=0.78, wpb=59196.2, bsz=1996.3, num_updates=158100, lr=0.000251498, gnorm=1.302, loss_scale=8192, train_wall=128, wall=207858
2023-01-15 01:33:52 | INFO | train_inner | epoch 080:   1966 / 1978 loss=3.065, nll_loss=0.927, word_ins=2.751, length=3.14, ppl=8.37, wps=46813.4, ups=0.78, wpb=60033, bsz=2034.8, num_updates=158200, lr=0.000251418, gnorm=1.292, loss_scale=8192, train_wall=128, wall=207986
2023-01-15 01:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 01:34:24 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 4.586 | nll_loss 1.997 | word_ins 3.76 | length 8.266 | ppl 24.02 | wps 118960 | wpb 40242.5 | bsz 1500 | num_updates 158212 | best_loss 4.422
2023-01-15 01:34:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 01:34:51 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint80.pt (epoch 80 @ 158212 updates, score 4.586) (writing took 27.625998625997454 seconds)
2023-01-15 01:34:51 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2023-01-15 01:34:51 | INFO | train | epoch 080 | loss 3.081 | nll_loss 0.944 | word_ins 2.766 | length 3.147 | ppl 8.46 | wps 45232.8 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 158212 | lr 0.000251409 | gnorm 1.277 | loss_scale 8192 | train_wall 2527 | wall 208046
2023-01-15 01:34:52 | INFO | fairseq.trainer | begin training epoch 81
2023-01-15 01:36:59 | INFO | train_inner | epoch 081:     88 / 1978 loss=3.073, nll_loss=0.937, word_ins=2.76, length=3.133, ppl=8.42, wps=31551.9, ups=0.53, wpb=59038.1, bsz=1993.8, num_updates=158300, lr=0.000251339, gnorm=1.246, loss_scale=8192, train_wall=128, wall=208173
2023-01-15 01:38:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 01:39:08 | INFO | train_inner | epoch 081:    189 / 1978 loss=3.064, nll_loss=0.927, word_ins=2.751, length=3.127, ppl=8.36, wps=45609, ups=0.77, wpb=58906.9, bsz=2032.3, num_updates=158400, lr=0.000251259, gnorm=1.247, loss_scale=8192, train_wall=129, wall=208302
2023-01-15 01:41:17 | INFO | train_inner | epoch 081:    289 / 1978 loss=3.064, nll_loss=0.932, word_ins=2.755, length=3.087, ppl=8.36, wps=46438, ups=0.78, wpb=59789.5, bsz=2045.2, num_updates=158500, lr=0.00025118, gnorm=1.295, loss_scale=8192, train_wall=128, wall=208431
2023-01-15 01:43:25 | INFO | train_inner | epoch 081:    389 / 1978 loss=3.058, nll_loss=0.925, word_ins=2.749, length=3.089, ppl=8.33, wps=46540.5, ups=0.78, wpb=59437, bsz=2052.6, num_updates=158600, lr=0.000251101, gnorm=1.241, loss_scale=8192, train_wall=127, wall=208559
2023-01-15 01:45:33 | INFO | train_inner | epoch 081:    489 / 1978 loss=3.07, nll_loss=0.937, word_ins=2.761, length=3.091, ppl=8.4, wps=45812.9, ups=0.78, wpb=58941.3, bsz=2060.3, num_updates=158700, lr=0.000251022, gnorm=1.262, loss_scale=8192, train_wall=128, wall=208688
2023-01-15 01:47:40 | INFO | train_inner | epoch 081:    589 / 1978 loss=3.112, nll_loss=0.971, word_ins=2.792, length=3.199, ppl=8.64, wps=46747, ups=0.79, wpb=59281.3, bsz=1889.8, num_updates=158800, lr=0.000250943, gnorm=1.27, loss_scale=8192, train_wall=127, wall=208814
2023-01-15 01:49:47 | INFO | train_inner | epoch 081:    689 / 1978 loss=3.087, nll_loss=0.944, word_ins=2.767, length=3.198, ppl=8.5, wps=46425.4, ups=0.79, wpb=58996.3, bsz=1974.2, num_updates=158900, lr=0.000250864, gnorm=1.294, loss_scale=8192, train_wall=127, wall=208941
2023-01-15 01:51:54 | INFO | train_inner | epoch 081:    789 / 1978 loss=3.058, nll_loss=0.922, word_ins=2.746, length=3.117, ppl=8.33, wps=46937.6, ups=0.79, wpb=59500.7, bsz=2019.3, num_updates=159000, lr=0.000250785, gnorm=1.301, loss_scale=8192, train_wall=127, wall=209068
2023-01-15 01:54:02 | INFO | train_inner | epoch 081:    889 / 1978 loss=3.083, nll_loss=0.942, word_ins=2.765, length=3.178, ppl=8.47, wps=46515.8, ups=0.78, wpb=59375.9, bsz=1972.5, num_updates=159100, lr=0.000250706, gnorm=1.305, loss_scale=8192, train_wall=127, wall=209196
2023-01-15 01:56:10 | INFO | train_inner | epoch 081:    989 / 1978 loss=3.089, nll_loss=0.956, word_ins=2.778, length=3.118, ppl=8.51, wps=46229.1, ups=0.78, wpb=59056.8, bsz=2009.6, num_updates=159200, lr=0.000250627, gnorm=1.247, loss_scale=8192, train_wall=127, wall=209324
2023-01-15 01:58:18 | INFO | train_inner | epoch 081:   1089 / 1978 loss=3.099, nll_loss=0.965, word_ins=2.785, length=3.139, ppl=8.57, wps=46170.7, ups=0.78, wpb=59263.1, bsz=1993.9, num_updates=159300, lr=0.000250549, gnorm=1.272, loss_scale=8192, train_wall=128, wall=209452
2023-01-15 02:00:28 | INFO | train_inner | epoch 081:   1189 / 1978 loss=3.082, nll_loss=0.943, word_ins=2.765, length=3.163, ppl=8.47, wps=45629.3, ups=0.77, wpb=59194, bsz=2056.6, num_updates=159400, lr=0.00025047, gnorm=1.238, loss_scale=8192, train_wall=129, wall=209582
2023-01-15 02:02:35 | INFO | train_inner | epoch 081:   1289 / 1978 loss=3.072, nll_loss=0.936, word_ins=2.759, length=3.131, ppl=8.41, wps=46448.7, ups=0.78, wpb=59317.4, bsz=1953.4, num_updates=159500, lr=0.000250392, gnorm=1.297, loss_scale=8192, train_wall=127, wall=209709
2023-01-15 02:04:43 | INFO | train_inner | epoch 081:   1389 / 1978 loss=3.068, nll_loss=0.931, word_ins=2.754, length=3.138, ppl=8.38, wps=46563.1, ups=0.78, wpb=59430.8, bsz=1997.6, num_updates=159600, lr=0.000250313, gnorm=1.32, loss_scale=8192, train_wall=127, wall=209837
2023-01-15 02:06:51 | INFO | train_inner | epoch 081:   1489 / 1978 loss=3.089, nll_loss=0.95, word_ins=2.772, length=3.168, ppl=8.51, wps=46049.7, ups=0.78, wpb=59112.6, bsz=1983.1, num_updates=159700, lr=0.000250235, gnorm=1.275, loss_scale=8192, train_wall=128, wall=209965
2023-01-15 02:09:00 | INFO | train_inner | epoch 081:   1589 / 1978 loss=3.097, nll_loss=0.962, word_ins=2.783, length=3.143, ppl=8.56, wps=46195, ups=0.78, wpb=59210.3, bsz=1954.5, num_updates=159800, lr=0.000250156, gnorm=1.294, loss_scale=8192, train_wall=128, wall=210094
2023-01-15 02:11:07 | INFO | train_inner | epoch 081:   1689 / 1978 loss=3.096, nll_loss=0.959, word_ins=2.78, length=3.156, ppl=8.55, wps=46650.1, ups=0.79, wpb=59221.2, bsz=1971.8, num_updates=159900, lr=0.000250078, gnorm=1.255, loss_scale=8192, train_wall=127, wall=210221
2023-01-15 02:13:15 | INFO | train_inner | epoch 081:   1789 / 1978 loss=3.071, nll_loss=0.942, word_ins=2.764, length=3.064, ppl=8.4, wps=46290.1, ups=0.78, wpb=59696.3, bsz=2011.8, num_updates=160000, lr=0.00025, gnorm=1.276, loss_scale=8192, train_wall=129, wall=210350
2023-01-15 02:15:24 | INFO | train_inner | epoch 081:   1889 / 1978 loss=3.062, nll_loss=0.929, word_ins=2.752, length=3.103, ppl=8.35, wps=46260.1, ups=0.78, wpb=59572.8, bsz=2071.7, num_updates=160100, lr=0.000249922, gnorm=1.259, loss_scale=8192, train_wall=129, wall=210478
2023-01-15 02:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 02:17:37 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 4.621 | nll_loss 1.991 | word_ins 3.754 | length 8.672 | ppl 24.61 | wps 150940 | wpb 40242.5 | bsz 1500 | num_updates 160189 | best_loss 4.422
2023-01-15 02:17:37 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 02:18:05 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint81.pt (epoch 81 @ 160189 updates, score 4.621) (writing took 27.64483427396044 seconds)
2023-01-15 02:18:05 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2023-01-15 02:18:05 | INFO | train | epoch 081 | loss 3.078 | nll_loss 0.942 | word_ins 2.765 | length 3.135 | ppl 8.45 | wps 45201.3 | ups 0.76 | wpb 59286.8 | bsz 2002.9 | num_updates 160189 | lr 0.000249852 | gnorm 1.271 | loss_scale 8192 | train_wall 2525 | wall 210639
2023-01-15 02:18:05 | INFO | fairseq.trainer | begin training epoch 82
2023-01-15 02:18:35 | INFO | train_inner | epoch 082:     11 / 1978 loss=3.063, nll_loss=0.927, word_ins=2.75, length=3.127, ppl=8.36, wps=31136.1, ups=0.52, wpb=59348.6, bsz=2033.4, num_updates=160200, lr=0.000249844, gnorm=1.222, loss_scale=8192, train_wall=127, wall=210669
2023-01-15 02:20:43 | INFO | train_inner | epoch 082:    111 / 1978 loss=3.077, nll_loss=0.939, word_ins=2.762, length=3.145, ppl=8.44, wps=46088.8, ups=0.78, wpb=59062.1, bsz=1956.8, num_updates=160300, lr=0.000249766, gnorm=1.278, loss_scale=8192, train_wall=128, wall=210797
2023-01-15 02:22:52 | INFO | train_inner | epoch 082:    211 / 1978 loss=3.068, nll_loss=0.938, word_ins=2.761, length=3.061, ppl=8.38, wps=45830.2, ups=0.78, wpb=59016.3, bsz=2010.6, num_updates=160400, lr=0.000249688, gnorm=1.216, loss_scale=8192, train_wall=128, wall=210926
2023-01-15 02:25:01 | INFO | train_inner | epoch 082:    311 / 1978 loss=3.064, nll_loss=0.93, word_ins=2.754, length=3.103, ppl=8.37, wps=46337.3, ups=0.78, wpb=59768.2, bsz=1993.1, num_updates=160500, lr=0.00024961, gnorm=1.266, loss_scale=8192, train_wall=129, wall=211055
2023-01-15 02:27:10 | INFO | train_inner | epoch 082:    411 / 1978 loss=3.07, nll_loss=0.93, word_ins=2.754, length=3.16, ppl=8.4, wps=45878.3, ups=0.78, wpb=59039.1, bsz=2043.8, num_updates=160600, lr=0.000249533, gnorm=1.239, loss_scale=8192, train_wall=128, wall=211184
2023-01-15 02:29:17 | INFO | train_inner | epoch 082:    511 / 1978 loss=3.079, nll_loss=0.94, word_ins=2.763, length=3.158, ppl=8.45, wps=46858.9, ups=0.79, wpb=59517.5, bsz=1931.4, num_updates=160700, lr=0.000249455, gnorm=1.268, loss_scale=8192, train_wall=127, wall=211311
2023-01-15 02:31:24 | INFO | train_inner | epoch 082:    611 / 1978 loss=3.074, nll_loss=0.94, word_ins=2.763, length=3.112, ppl=8.42, wps=46371.1, ups=0.78, wpb=59282, bsz=2045.9, num_updates=160800, lr=0.000249377, gnorm=1.244, loss_scale=8192, train_wall=128, wall=211438
2023-01-15 02:33:33 | INFO | train_inner | epoch 082:    711 / 1978 loss=3.071, nll_loss=0.938, word_ins=2.761, length=3.098, ppl=8.41, wps=46058, ups=0.78, wpb=59089.6, bsz=2062.8, num_updates=160900, lr=0.0002493, gnorm=1.283, loss_scale=8192, train_wall=128, wall=211567
2023-01-15 02:35:41 | INFO | train_inner | epoch 082:    811 / 1978 loss=3.068, nll_loss=0.931, word_ins=2.755, length=3.134, ppl=8.39, wps=46214.5, ups=0.78, wpb=59373.5, bsz=2026.6, num_updates=161000, lr=0.000249222, gnorm=1.264, loss_scale=8192, train_wall=128, wall=211695
2023-01-15 02:37:49 | INFO | train_inner | epoch 082:    911 / 1978 loss=3.081, nll_loss=0.945, word_ins=2.768, length=3.134, ppl=8.46, wps=46302, ups=0.78, wpb=59262.6, bsz=1996.5, num_updates=161100, lr=0.000249145, gnorm=1.244, loss_scale=8192, train_wall=128, wall=211823
2023-01-15 02:39:56 | INFO | train_inner | epoch 082:   1011 / 1978 loss=3.075, nll_loss=0.939, word_ins=2.761, length=3.135, ppl=8.43, wps=46658.8, ups=0.79, wpb=59311.5, bsz=1935.5, num_updates=161200, lr=0.000249068, gnorm=1.313, loss_scale=8192, train_wall=127, wall=211950
2023-01-15 02:42:04 | INFO | train_inner | epoch 082:   1111 / 1978 loss=3.07, nll_loss=0.933, word_ins=2.757, length=3.133, ppl=8.4, wps=46400.2, ups=0.78, wpb=59196.6, bsz=2006, num_updates=161300, lr=0.000248991, gnorm=1.236, loss_scale=8192, train_wall=127, wall=212078
2023-01-15 02:44:11 | INFO | train_inner | epoch 082:   1211 / 1978 loss=3.078, nll_loss=0.941, word_ins=2.764, length=3.142, ppl=8.44, wps=46401, ups=0.79, wpb=58922.5, bsz=2053.3, num_updates=161400, lr=0.000248913, gnorm=1.258, loss_scale=8192, train_wall=127, wall=212205
2023-01-15 02:46:19 | INFO | train_inner | epoch 082:   1311 / 1978 loss=3.066, nll_loss=0.93, word_ins=2.754, length=3.12, ppl=8.37, wps=46410.1, ups=0.78, wpb=59458.1, bsz=1974.8, num_updates=161500, lr=0.000248836, gnorm=1.287, loss_scale=8192, train_wall=128, wall=212333
2023-01-15 02:48:27 | INFO | train_inner | epoch 082:   1411 / 1978 loss=3.068, nll_loss=0.929, word_ins=2.752, length=3.156, ppl=8.39, wps=46677.6, ups=0.78, wpb=59832.3, bsz=1984.2, num_updates=161600, lr=0.000248759, gnorm=1.292, loss_scale=8192, train_wall=128, wall=212461
2023-01-15 02:50:35 | INFO | train_inner | epoch 082:   1511 / 1978 loss=3.077, nll_loss=0.944, word_ins=2.766, length=3.107, ppl=8.44, wps=46107.4, ups=0.78, wpb=59118.4, bsz=2007.7, num_updates=161700, lr=0.000248682, gnorm=1.289, loss_scale=8192, train_wall=128, wall=212590
2023-01-15 02:52:43 | INFO | train_inner | epoch 082:   1611 / 1978 loss=3.096, nll_loss=0.957, word_ins=2.778, length=3.177, ppl=8.55, wps=46429.9, ups=0.78, wpb=59299.1, bsz=1950.2, num_updates=161800, lr=0.000248606, gnorm=1.267, loss_scale=8192, train_wall=127, wall=212717
2023-01-15 02:54:49 | INFO | train_inner | epoch 082:   1711 / 1978 loss=3.145, nll_loss=1.004, word_ins=2.821, length=3.24, ppl=8.85, wps=46612.6, ups=0.79, wpb=58872.3, bsz=1857.7, num_updates=161900, lr=0.000248529, gnorm=1.296, loss_scale=8192, train_wall=126, wall=212844
2023-01-15 02:56:59 | INFO | train_inner | epoch 082:   1811 / 1978 loss=3.089, nll_loss=0.95, word_ins=2.772, length=3.175, ppl=8.51, wps=45959.3, ups=0.77, wpb=59362, bsz=2038.2, num_updates=162000, lr=0.000248452, gnorm=1.289, loss_scale=8192, train_wall=129, wall=212973
2023-01-15 02:59:08 | INFO | train_inner | epoch 082:   1911 / 1978 loss=3.063, nll_loss=0.926, word_ins=2.749, length=3.142, ppl=8.36, wps=45875.1, ups=0.78, wpb=59192.1, bsz=2129.4, num_updates=162100, lr=0.000248375, gnorm=1.27, loss_scale=8192, train_wall=129, wall=213102
2023-01-15 03:00:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 03:00:51 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 4.586 | nll_loss 1.984 | word_ins 3.743 | length 8.423 | ppl 24.01 | wps 157306 | wpb 40242.5 | bsz 1500 | num_updates 162167 | best_loss 4.422
2023-01-15 03:00:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 03:01:19 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint82.pt (epoch 82 @ 162167 updates, score 4.586) (writing took 27.551839942578226 seconds)
2023-01-15 03:01:19 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2023-01-15 03:01:19 | INFO | train | epoch 082 | loss 3.077 | nll_loss 0.94 | word_ins 2.763 | length 3.136 | ppl 8.44 | wps 45205.4 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 162167 | lr 0.000248324 | gnorm 1.266 | loss_scale 8192 | train_wall 2527 | wall 213233
2023-01-15 03:01:19 | INFO | fairseq.trainer | begin training epoch 83
2023-01-15 03:02:17 | INFO | train_inner | epoch 083:     33 / 1978 loss=3.059, nll_loss=0.923, word_ins=2.747, length=3.12, ppl=8.33, wps=31268.2, ups=0.53, wpb=59284.7, bsz=2035.8, num_updates=162200, lr=0.000248299, gnorm=1.252, loss_scale=8192, train_wall=128, wall=213291
2023-01-15 03:04:25 | INFO | train_inner | epoch 083:    133 / 1978 loss=3.064, nll_loss=0.93, word_ins=2.753, length=3.106, ppl=8.36, wps=46447.1, ups=0.78, wpb=59468.5, bsz=2004.1, num_updates=162300, lr=0.000248222, gnorm=1.272, loss_scale=8192, train_wall=128, wall=213419
2023-01-15 03:06:33 | INFO | train_inner | epoch 083:    233 / 1978 loss=3.069, nll_loss=0.935, word_ins=2.758, length=3.109, ppl=8.39, wps=46641.5, ups=0.78, wpb=59475, bsz=2003.7, num_updates=162400, lr=0.000248146, gnorm=1.26, loss_scale=8192, train_wall=127, wall=213547
2023-01-15 03:08:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 03:08:43 | INFO | train_inner | epoch 083:    334 / 1978 loss=3.061, nll_loss=0.926, word_ins=2.75, length=3.112, ppl=8.34, wps=45776.3, ups=0.77, wpb=59479.3, bsz=2045, num_updates=162500, lr=0.000248069, gnorm=1.253, loss_scale=8192, train_wall=130, wall=213677
2023-01-15 03:10:50 | INFO | train_inner | epoch 083:    434 / 1978 loss=3.093, nll_loss=0.953, word_ins=2.775, length=3.186, ppl=8.54, wps=46566, ups=0.79, wpb=59147.3, bsz=1947.1, num_updates=162600, lr=0.000247993, gnorm=1.27, loss_scale=8192, train_wall=127, wall=213804
2023-01-15 03:12:58 | INFO | train_inner | epoch 083:    534 / 1978 loss=3.073, nll_loss=0.933, word_ins=2.756, length=3.16, ppl=8.41, wps=46487.4, ups=0.78, wpb=59658.5, bsz=1984.6, num_updates=162700, lr=0.000247917, gnorm=1.266, loss_scale=8192, train_wall=128, wall=213932
2023-01-15 03:15:07 | INFO | train_inner | epoch 083:    634 / 1978 loss=3.053, nll_loss=0.916, word_ins=2.741, length=3.111, ppl=8.3, wps=45890.2, ups=0.78, wpb=59197.9, bsz=2067, num_updates=162800, lr=0.000247841, gnorm=1.241, loss_scale=8192, train_wall=129, wall=214061
2023-01-15 03:17:15 | INFO | train_inner | epoch 083:    734 / 1978 loss=3.08, nll_loss=0.942, word_ins=2.764, length=3.154, ppl=8.46, wps=46634.6, ups=0.78, wpb=59467.7, bsz=1927.6, num_updates=162900, lr=0.000247765, gnorm=1.237, loss_scale=8192, train_wall=127, wall=214189
2023-01-15 03:19:22 | INFO | train_inner | epoch 083:    834 / 1978 loss=3.081, nll_loss=0.942, word_ins=2.765, length=3.157, ppl=8.46, wps=46271.6, ups=0.78, wpb=59007.2, bsz=1956.3, num_updates=163000, lr=0.000247689, gnorm=1.233, loss_scale=8192, train_wall=127, wall=214316
2023-01-15 03:21:30 | INFO | train_inner | epoch 083:    934 / 1978 loss=3.054, nll_loss=0.921, word_ins=2.746, length=3.083, ppl=8.31, wps=46372.2, ups=0.78, wpb=59331.6, bsz=2029.9, num_updates=163100, lr=0.000247613, gnorm=1.281, loss_scale=8192, train_wall=128, wall=214444
2023-01-15 03:23:39 | INFO | train_inner | epoch 083:   1034 / 1978 loss=3.074, nll_loss=0.943, word_ins=2.765, length=3.081, ppl=8.42, wps=46166.1, ups=0.78, wpb=59432.8, bsz=2053.4, num_updates=163200, lr=0.000247537, gnorm=1.276, loss_scale=8192, train_wall=129, wall=214573
2023-01-15 03:25:47 | INFO | train_inner | epoch 083:   1134 / 1978 loss=3.086, nll_loss=0.949, word_ins=2.771, length=3.152, ppl=8.49, wps=46378.8, ups=0.78, wpb=59200.4, bsz=1960.8, num_updates=163300, lr=0.000247461, gnorm=1.28, loss_scale=8192, train_wall=127, wall=214701
2023-01-15 03:27:54 | INFO | train_inner | epoch 083:   1234 / 1978 loss=3.072, nll_loss=0.938, word_ins=2.761, length=3.107, ppl=8.41, wps=47069.3, ups=0.79, wpb=59729.6, bsz=2001.5, num_updates=163400, lr=0.000247385, gnorm=1.3, loss_scale=8192, train_wall=127, wall=214828
2023-01-15 03:30:01 | INFO | train_inner | epoch 083:   1334 / 1978 loss=3.093, nll_loss=0.956, word_ins=2.777, length=3.162, ppl=8.53, wps=46122.7, ups=0.78, wpb=58844.1, bsz=1964.6, num_updates=163500, lr=0.00024731, gnorm=1.26, loss_scale=8192, train_wall=127, wall=214955
2023-01-15 03:32:10 | INFO | train_inner | epoch 083:   1434 / 1978 loss=3.07, nll_loss=0.934, word_ins=2.757, length=3.131, ppl=8.4, wps=45638.8, ups=0.78, wpb=58808, bsz=2090.6, num_updates=163600, lr=0.000247234, gnorm=1.277, loss_scale=8192, train_wall=129, wall=215084
2023-01-15 03:34:18 | INFO | train_inner | epoch 083:   1534 / 1978 loss=3.054, nll_loss=0.918, word_ins=2.743, length=3.11, ppl=8.3, wps=46342.1, ups=0.78, wpb=59416.1, bsz=2045.6, num_updates=163700, lr=0.000247159, gnorm=1.238, loss_scale=8192, train_wall=128, wall=215212
2023-01-15 03:36:28 | INFO | train_inner | epoch 083:   1634 / 1978 loss=3.048, nll_loss=0.914, word_ins=2.739, length=3.094, ppl=8.27, wps=45846.2, ups=0.77, wpb=59445.7, bsz=2131.4, num_updates=163800, lr=0.000247083, gnorm=1.256, loss_scale=8192, train_wall=129, wall=215342
2023-01-15 03:38:36 | INFO | train_inner | epoch 083:   1734 / 1978 loss=3.086, nll_loss=0.952, word_ins=2.773, length=3.124, ppl=8.49, wps=46744.1, ups=0.78, wpb=59733, bsz=1919.7, num_updates=163900, lr=0.000247008, gnorm=1.281, loss_scale=8192, train_wall=128, wall=215470
2023-01-15 03:40:45 | INFO | train_inner | epoch 083:   1834 / 1978 loss=3.088, nll_loss=0.946, word_ins=2.768, length=3.195, ppl=8.5, wps=45494.2, ups=0.77, wpb=58738.6, bsz=1980.2, num_updates=164000, lr=0.000246932, gnorm=1.265, loss_scale=8192, train_wall=129, wall=215599
2023-01-15 03:42:52 | INFO | train_inner | epoch 083:   1934 / 1978 loss=3.062, nll_loss=0.927, word_ins=2.751, length=3.111, ppl=8.35, wps=46490.8, ups=0.79, wpb=59113.5, bsz=1990, num_updates=164100, lr=0.000246857, gnorm=1.267, loss_scale=8192, train_wall=127, wall=215726
2023-01-15 03:43:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 03:44:07 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 4.583 | nll_loss 1.984 | word_ins 3.749 | length 8.329 | ppl 23.96 | wps 99483 | wpb 40242.5 | bsz 1500 | num_updates 164144 | best_loss 4.422
2023-01-15 03:44:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 03:44:35 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint83.pt (epoch 83 @ 164144 updates, score 4.583) (writing took 28.166038951836526 seconds)
2023-01-15 03:44:35 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2023-01-15 03:44:35 | INFO | train | epoch 083 | loss 3.072 | nll_loss 0.936 | word_ins 2.759 | length 3.13 | ppl 8.41 | wps 45142 | ups 0.76 | wpb 59287 | bsz 2002.8 | num_updates 164144 | lr 0.000246824 | gnorm 1.267 | loss_scale 8192 | train_wall 2528 | wall 215829
2023-01-15 03:44:35 | INFO | fairseq.trainer | begin training epoch 84
2023-01-15 03:46:02 | INFO | train_inner | epoch 084:     56 / 1978 loss=3.129, nll_loss=0.988, word_ins=2.806, length=3.226, ppl=8.75, wps=30953.8, ups=0.53, wpb=58918.9, bsz=1865.8, num_updates=164200, lr=0.000246782, gnorm=1.296, loss_scale=8192, train_wall=127, wall=215916
2023-01-15 03:48:11 | INFO | train_inner | epoch 084:    156 / 1978 loss=3.056, nll_loss=0.923, word_ins=2.747, length=3.092, ppl=8.32, wps=45735.3, ups=0.77, wpb=59094.3, bsz=2026.7, num_updates=164300, lr=0.000246707, gnorm=1.272, loss_scale=8192, train_wall=129, wall=216046
2023-01-15 03:50:21 | INFO | train_inner | epoch 084:    256 / 1978 loss=3.045, nll_loss=0.909, word_ins=2.735, length=3.1, ppl=8.25, wps=45537.4, ups=0.77, wpb=59029.7, bsz=2120.3, num_updates=164400, lr=0.000246632, gnorm=1.2, loss_scale=8192, train_wall=129, wall=216175
2023-01-15 03:52:31 | INFO | train_inner | epoch 084:    356 / 1978 loss=3.045, nll_loss=0.91, word_ins=2.736, length=3.096, ppl=8.26, wps=46099.1, ups=0.77, wpb=59725.2, bsz=2043.8, num_updates=164500, lr=0.000246557, gnorm=1.347, loss_scale=8192, train_wall=129, wall=216305
2023-01-15 03:54:38 | INFO | train_inner | epoch 084:    456 / 1978 loss=3.077, nll_loss=0.937, word_ins=2.76, length=3.172, ppl=8.44, wps=46058.4, ups=0.78, wpb=58805.1, bsz=1941, num_updates=164600, lr=0.000246482, gnorm=1.287, loss_scale=8192, train_wall=127, wall=216432
2023-01-15 03:56:47 | INFO | train_inner | epoch 084:    556 / 1978 loss=3.105, nll_loss=0.971, word_ins=2.791, length=3.144, ppl=8.6, wps=46227.7, ups=0.78, wpb=59371.6, bsz=1927.4, num_updates=164700, lr=0.000246407, gnorm=1.283, loss_scale=8192, train_wall=128, wall=216561
2023-01-15 03:58:55 | INFO | train_inner | epoch 084:    656 / 1978 loss=3.056, nll_loss=0.926, word_ins=2.75, length=3.057, ppl=8.31, wps=46457.3, ups=0.78, wpb=59593.4, bsz=2076.4, num_updates=164800, lr=0.000246332, gnorm=1.267, loss_scale=8192, train_wall=128, wall=216689
2023-01-15 04:01:03 | INFO | train_inner | epoch 084:    756 / 1978 loss=3.057, nll_loss=0.918, word_ins=2.743, length=3.141, ppl=8.32, wps=46241.9, ups=0.78, wpb=59329.1, bsz=2027.4, num_updates=164900, lr=0.000246258, gnorm=1.283, loss_scale=8192, train_wall=128, wall=216818
2023-01-15 04:03:11 | INFO | train_inner | epoch 084:    856 / 1978 loss=3.078, nll_loss=0.942, word_ins=2.764, length=3.139, ppl=8.44, wps=46376.7, ups=0.78, wpb=59108.6, bsz=1987, num_updates=165000, lr=0.000246183, gnorm=1.267, loss_scale=8192, train_wall=127, wall=216945
2023-01-15 04:05:19 | INFO | train_inner | epoch 084:    956 / 1978 loss=3.066, nll_loss=0.933, word_ins=2.757, length=3.096, ppl=8.37, wps=46564.2, ups=0.78, wpb=59760.8, bsz=1978.4, num_updates=165100, lr=0.000246108, gnorm=1.29, loss_scale=8192, train_wall=128, wall=217073
2023-01-15 04:07:27 | INFO | train_inner | epoch 084:   1056 / 1978 loss=3.085, nll_loss=0.952, word_ins=2.773, length=3.121, ppl=8.49, wps=46345, ups=0.78, wpb=59143.7, bsz=1951.5, num_updates=165200, lr=0.000246034, gnorm=1.271, loss_scale=8192, train_wall=127, wall=217201
2023-01-15 04:09:35 | INFO | train_inner | epoch 084:   1156 / 1978 loss=3.055, nll_loss=0.918, word_ins=2.743, length=3.125, ppl=8.31, wps=46624.6, ups=0.78, wpb=59525.4, bsz=1991.4, num_updates=165300, lr=0.000245959, gnorm=1.24, loss_scale=8192, train_wall=127, wall=217329
2023-01-15 04:11:42 | INFO | train_inner | epoch 084:   1256 / 1978 loss=3.071, nll_loss=0.932, word_ins=2.755, length=3.155, ppl=8.4, wps=46109.1, ups=0.78, wpb=58882.6, bsz=1987.6, num_updates=165400, lr=0.000245885, gnorm=1.233, loss_scale=8192, train_wall=127, wall=217456
2023-01-15 04:13:51 | INFO | train_inner | epoch 084:   1356 / 1978 loss=3.068, nll_loss=0.933, word_ins=2.756, length=3.115, ppl=8.39, wps=46302.9, ups=0.78, wpb=59481.8, bsz=2041.4, num_updates=165500, lr=0.000245811, gnorm=1.275, loss_scale=8192, train_wall=128, wall=217585
2023-01-15 04:15:59 | INFO | train_inner | epoch 084:   1456 / 1978 loss=3.056, nll_loss=0.922, word_ins=2.746, length=3.098, ppl=8.32, wps=46309.4, ups=0.78, wpb=59371.3, bsz=2017.4, num_updates=165600, lr=0.000245737, gnorm=1.248, loss_scale=8192, train_wall=128, wall=217713
2023-01-15 04:18:07 | INFO | train_inner | epoch 084:   1556 / 1978 loss=3.059, nll_loss=0.925, word_ins=2.748, length=3.105, ppl=8.33, wps=46509.5, ups=0.78, wpb=59524.6, bsz=2025.9, num_updates=165700, lr=0.000245662, gnorm=1.263, loss_scale=8192, train_wall=128, wall=217841
2023-01-15 04:20:13 | INFO | train_inner | epoch 084:   1656 / 1978 loss=3.064, nll_loss=0.93, word_ins=2.753, length=3.117, ppl=8.37, wps=47259.2, ups=0.79, wpb=59637.2, bsz=1959.2, num_updates=165800, lr=0.000245588, gnorm=1.236, loss_scale=8192, train_wall=126, wall=217967
2023-01-15 04:22:21 | INFO | train_inner | epoch 084:   1756 / 1978 loss=3.092, nll_loss=0.949, word_ins=2.77, length=3.215, ppl=8.53, wps=45903.1, ups=0.78, wpb=58741.4, bsz=2045.4, num_updates=165900, lr=0.000245514, gnorm=1.267, loss_scale=8192, train_wall=128, wall=218095
2023-01-15 04:24:29 | INFO | train_inner | epoch 084:   1856 / 1978 loss=3.063, nll_loss=0.93, word_ins=2.753, length=3.098, ppl=8.36, wps=46241.5, ups=0.78, wpb=59332.7, bsz=2007.6, num_updates=166000, lr=0.00024544, gnorm=1.233, loss_scale=8192, train_wall=128, wall=218224
2023-01-15 04:26:36 | INFO | train_inner | epoch 084:   1956 / 1978 loss=3.085, nll_loss=0.942, word_ins=2.764, length=3.205, ppl=8.48, wps=46651.5, ups=0.79, wpb=59155.8, bsz=1949.3, num_updates=166100, lr=0.000245366, gnorm=1.287, loss_scale=8192, train_wall=127, wall=218350
2023-01-15 04:27:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 04:27:18 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.558 | nll_loss 1.977 | word_ins 3.744 | length 8.136 | ppl 23.55 | wps 119702 | wpb 40242.5 | bsz 1500 | num_updates 166122 | best_loss 4.422
2023-01-15 04:27:18 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 04:27:45 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint84.pt (epoch 84 @ 166122 updates, score 4.558) (writing took 27.063609716948122 seconds)
2023-01-15 04:27:45 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2023-01-15 04:27:45 | INFO | train | epoch 084 | loss 3.069 | nll_loss 0.933 | word_ins 2.756 | length 3.127 | ppl 8.39 | wps 45270.4 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 166122 | lr 0.00024535 | gnorm 1.266 | loss_scale 8192 | train_wall 2528 | wall 218419
2023-01-15 04:27:45 | INFO | fairseq.trainer | begin training epoch 85
2023-01-15 04:29:37 | INFO | train_inner | epoch 085:     78 / 1978 loss=3.065, nll_loss=0.926, word_ins=2.75, length=3.153, ppl=8.37, wps=32661.5, ups=0.55, wpb=58942.4, bsz=1953.4, num_updates=166200, lr=0.000245293, gnorm=1.314, loss_scale=8192, train_wall=127, wall=218531
2023-01-15 04:31:45 | INFO | train_inner | epoch 085:    178 / 1978 loss=3.057, nll_loss=0.925, word_ins=2.75, length=3.071, ppl=8.32, wps=46053.8, ups=0.78, wpb=59115, bsz=2036.9, num_updates=166300, lr=0.000245219, gnorm=1.251, loss_scale=8192, train_wall=128, wall=218659
2023-01-15 04:33:54 | INFO | train_inner | epoch 085:    278 / 1978 loss=3.025, nll_loss=0.894, word_ins=2.72, length=3.054, ppl=8.14, wps=46170.4, ups=0.77, wpb=59737.4, bsz=2093.4, num_updates=166400, lr=0.000245145, gnorm=1.245, loss_scale=8192, train_wall=129, wall=218789
2023-01-15 04:36:02 | INFO | train_inner | epoch 085:    378 / 1978 loss=3.059, nll_loss=0.925, word_ins=2.749, length=3.098, ppl=8.33, wps=46272.6, ups=0.79, wpb=58816.8, bsz=2035.4, num_updates=166500, lr=0.000245072, gnorm=1.238, loss_scale=8192, train_wall=127, wall=218916
2023-01-15 04:38:09 | INFO | train_inner | epoch 085:    478 / 1978 loss=3.086, nll_loss=0.952, word_ins=2.774, length=3.122, ppl=8.49, wps=46119.4, ups=0.78, wpb=58826, bsz=1978.9, num_updates=166600, lr=0.000244998, gnorm=1.271, loss_scale=16384, train_wall=127, wall=219043
2023-01-15 04:38:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 04:40:19 | INFO | train_inner | epoch 085:    579 / 1978 loss=3.06, nll_loss=0.926, word_ins=2.75, length=3.097, ppl=8.34, wps=45835.8, ups=0.77, wpb=59322.1, bsz=2040.4, num_updates=166700, lr=0.000244924, gnorm=1.253, loss_scale=8192, train_wall=129, wall=219173
2023-01-15 04:42:26 | INFO | train_inner | epoch 085:    679 / 1978 loss=3.092, nll_loss=0.953, word_ins=2.774, length=3.182, ppl=8.53, wps=46892.7, ups=0.79, wpb=59570.6, bsz=1951.3, num_updates=166800, lr=0.000244851, gnorm=1.262, loss_scale=8192, train_wall=127, wall=219300
2023-01-15 04:44:33 | INFO | train_inner | epoch 085:    779 / 1978 loss=3.081, nll_loss=0.95, word_ins=2.772, length=3.096, ppl=8.46, wps=46613.6, ups=0.78, wpb=59442.4, bsz=1957.4, num_updates=166900, lr=0.000244778, gnorm=1.303, loss_scale=8192, train_wall=127, wall=219427
2023-01-15 04:46:41 | INFO | train_inner | epoch 085:    879 / 1978 loss=3.069, nll_loss=0.929, word_ins=2.753, length=3.159, ppl=8.39, wps=46100.3, ups=0.78, wpb=59002.6, bsz=2037.2, num_updates=167000, lr=0.000244704, gnorm=1.255, loss_scale=8192, train_wall=128, wall=219555
2023-01-15 04:48:49 | INFO | train_inner | epoch 085:    979 / 1978 loss=3.11, nll_loss=0.974, word_ins=2.793, length=3.164, ppl=8.63, wps=46840.5, ups=0.78, wpb=59681.3, bsz=1894.8, num_updates=167100, lr=0.000244631, gnorm=1.278, loss_scale=8192, train_wall=127, wall=219683
2023-01-15 04:50:57 | INFO | train_inner | epoch 085:   1079 / 1978 loss=3.047, nll_loss=0.909, word_ins=2.735, length=3.118, ppl=8.26, wps=46186.7, ups=0.78, wpb=59203.6, bsz=2024.9, num_updates=167200, lr=0.000244558, gnorm=1.274, loss_scale=8192, train_wall=128, wall=219811
2023-01-15 04:53:05 | INFO | train_inner | epoch 085:   1179 / 1978 loss=3.074, nll_loss=0.937, word_ins=2.76, length=3.14, ppl=8.42, wps=46249.2, ups=0.78, wpb=59105.1, bsz=1990.5, num_updates=167300, lr=0.000244485, gnorm=1.248, loss_scale=8192, train_wall=128, wall=219939
2023-01-15 04:55:13 | INFO | train_inner | epoch 085:   1279 / 1978 loss=3.061, nll_loss=0.928, word_ins=2.751, length=3.1, ppl=8.35, wps=46241.6, ups=0.78, wpb=59328.5, bsz=2067.4, num_updates=167400, lr=0.000244412, gnorm=1.215, loss_scale=8192, train_wall=128, wall=220067
2023-01-15 04:57:21 | INFO | train_inner | epoch 085:   1379 / 1978 loss=3.074, nll_loss=0.935, word_ins=2.758, length=3.156, ppl=8.42, wps=45840.5, ups=0.78, wpb=58735.9, bsz=2055.4, num_updates=167500, lr=0.000244339, gnorm=1.275, loss_scale=8192, train_wall=128, wall=220195
2023-01-15 04:59:29 | INFO | train_inner | epoch 085:   1479 / 1978 loss=3.053, nll_loss=0.92, word_ins=2.744, length=3.09, ppl=8.3, wps=46631.7, ups=0.78, wpb=59783.3, bsz=2015.5, num_updates=167600, lr=0.000244266, gnorm=1.276, loss_scale=8192, train_wall=128, wall=220323
2023-01-15 05:01:37 | INFO | train_inner | epoch 085:   1579 / 1978 loss=3.046, nll_loss=0.912, word_ins=2.737, length=3.089, ppl=8.26, wps=46768.6, ups=0.78, wpb=59635, bsz=2026.5, num_updates=167700, lr=0.000244193, gnorm=1.241, loss_scale=8192, train_wall=127, wall=220451
2023-01-15 05:03:45 | INFO | train_inner | epoch 085:   1679 / 1978 loss=3.048, nll_loss=0.918, word_ins=2.742, length=3.061, ppl=8.27, wps=46663.8, ups=0.78, wpb=59954.6, bsz=2045.8, num_updates=167800, lr=0.00024412, gnorm=1.308, loss_scale=8192, train_wall=128, wall=220579
2023-01-15 05:05:52 | INFO | train_inner | epoch 085:   1779 / 1978 loss=3.09, nll_loss=0.951, word_ins=2.773, length=3.172, ppl=8.51, wps=46609.8, ups=0.79, wpb=59172.2, bsz=1951.1, num_updates=167900, lr=0.000244048, gnorm=1.301, loss_scale=8192, train_wall=127, wall=220706
2023-01-15 05:07:59 | INFO | train_inner | epoch 085:   1879 / 1978 loss=3.087, nll_loss=0.946, word_ins=2.767, length=3.199, ppl=8.5, wps=46846.3, ups=0.79, wpb=59397, bsz=1894.1, num_updates=168000, lr=0.000243975, gnorm=1.31, loss_scale=8192, train_wall=127, wall=220833
2023-01-15 05:10:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 05:10:19 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 4.568 | nll_loss 1.972 | word_ins 3.738 | length 8.293 | ppl 23.72 | wps 108338 | wpb 40242.5 | bsz 1500 | num_updates 168099 | best_loss 4.422
2023-01-15 05:10:19 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 05:10:46 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint85.pt (epoch 85 @ 168099 updates, score 4.568) (writing took 27.240658754948527 seconds)
2023-01-15 05:10:46 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2023-01-15 05:10:46 | INFO | train | epoch 085 | loss 3.068 | nll_loss 0.932 | word_ins 2.756 | length 3.124 | ppl 8.39 | wps 45417.7 | ups 0.77 | wpb 59283.2 | bsz 2002.8 | num_updates 168099 | lr 0.000243903 | gnorm 1.269 | loss_scale 8192 | train_wall 2523 | wall 221000
2023-01-15 05:10:46 | INFO | fairseq.trainer | begin training epoch 86
2023-01-15 05:11:02 | INFO | train_inner | epoch 086:      1 / 1978 loss=3.062, nll_loss=0.927, word_ins=2.75, length=3.117, ppl=8.35, wps=32219.3, ups=0.55, wpb=59061.4, bsz=2033.4, num_updates=168100, lr=0.000243902, gnorm=1.271, loss_scale=8192, train_wall=128, wall=221016
2023-01-15 05:13:09 | INFO | train_inner | epoch 086:    101 / 1978 loss=3.049, nll_loss=0.915, word_ins=2.74, length=3.095, ppl=8.28, wps=46616, ups=0.79, wpb=59169.2, bsz=1978, num_updates=168200, lr=0.00024383, gnorm=1.254, loss_scale=8192, train_wall=127, wall=221143
2023-01-15 05:15:18 | INFO | train_inner | epoch 086:    201 / 1978 loss=3.047, nll_loss=0.915, word_ins=2.74, length=3.072, ppl=8.26, wps=46258.6, ups=0.77, wpb=59732.4, bsz=2074.6, num_updates=168300, lr=0.000243757, gnorm=1.206, loss_scale=8192, train_wall=129, wall=221272
2023-01-15 05:17:27 | INFO | train_inner | epoch 086:    301 / 1978 loss=3.067, nll_loss=0.936, word_ins=2.759, length=3.077, ppl=8.38, wps=45937.7, ups=0.78, wpb=58936.3, bsz=1995.3, num_updates=168400, lr=0.000243685, gnorm=1.243, loss_scale=8192, train_wall=128, wall=221401
2023-01-15 05:19:34 | INFO | train_inner | epoch 086:    401 / 1978 loss=3.058, nll_loss=0.925, word_ins=2.749, length=3.085, ppl=8.33, wps=46301, ups=0.78, wpb=59070.4, bsz=2006.3, num_updates=168500, lr=0.000243613, gnorm=1.256, loss_scale=8192, train_wall=127, wall=221528
2023-01-15 05:21:42 | INFO | train_inner | epoch 086:    501 / 1978 loss=3.054, nll_loss=0.921, word_ins=2.746, length=3.086, ppl=8.31, wps=46625, ups=0.78, wpb=59682.2, bsz=1969.3, num_updates=168600, lr=0.000243541, gnorm=1.29, loss_scale=8192, train_wall=128, wall=221656
2023-01-15 05:23:51 | INFO | train_inner | epoch 086:    601 / 1978 loss=3.067, nll_loss=0.933, word_ins=2.756, length=3.111, ppl=8.38, wps=46400.7, ups=0.78, wpb=59534.1, bsz=2092.4, num_updates=168700, lr=0.000243468, gnorm=1.241, loss_scale=8192, train_wall=128, wall=221785
2023-01-15 05:25:58 | INFO | train_inner | epoch 086:    701 / 1978 loss=3.071, nll_loss=0.932, word_ins=2.755, length=3.152, ppl=8.4, wps=46329.4, ups=0.78, wpb=59202.2, bsz=1993.2, num_updates=168800, lr=0.000243396, gnorm=1.282, loss_scale=8192, train_wall=128, wall=221912
2023-01-15 05:28:06 | INFO | train_inner | epoch 086:    801 / 1978 loss=3.061, nll_loss=0.924, word_ins=2.748, length=3.123, ppl=8.34, wps=46367.3, ups=0.78, wpb=59238.6, bsz=1978.9, num_updates=168900, lr=0.000243324, gnorm=1.262, loss_scale=8192, train_wall=127, wall=222040
2023-01-15 05:30:13 | INFO | train_inner | epoch 086:    901 / 1978 loss=3.063, nll_loss=0.926, word_ins=2.75, length=3.131, ppl=8.36, wps=46451.8, ups=0.79, wpb=59003.7, bsz=1981.6, num_updates=169000, lr=0.000243252, gnorm=1.262, loss_scale=8192, train_wall=127, wall=222167
2023-01-15 05:32:21 | INFO | train_inner | epoch 086:   1001 / 1978 loss=3.052, nll_loss=0.92, word_ins=2.744, length=3.079, ppl=8.29, wps=46424.6, ups=0.78, wpb=59352.8, bsz=2047.5, num_updates=169100, lr=0.00024318, gnorm=1.246, loss_scale=8192, train_wall=128, wall=222295
2023-01-15 05:34:29 | INFO | train_inner | epoch 086:   1101 / 1978 loss=3.085, nll_loss=0.949, word_ins=2.77, length=3.15, ppl=8.48, wps=46207.3, ups=0.78, wpb=59220.2, bsz=1928.4, num_updates=169200, lr=0.000243108, gnorm=1.313, loss_scale=8192, train_wall=128, wall=222423
2023-01-15 05:36:38 | INFO | train_inner | epoch 086:   1201 / 1978 loss=3.052, nll_loss=0.92, word_ins=2.744, length=3.083, ppl=8.29, wps=46079.7, ups=0.77, wpb=59519.8, bsz=2075.6, num_updates=169300, lr=0.000243037, gnorm=1.317, loss_scale=8192, train_wall=129, wall=222552
2023-01-15 05:38:46 | INFO | train_inner | epoch 086:   1301 / 1978 loss=3.068, nll_loss=0.933, word_ins=2.756, length=3.116, ppl=8.39, wps=46491.4, ups=0.78, wpb=59319.1, bsz=2018.7, num_updates=169400, lr=0.000242965, gnorm=1.259, loss_scale=8192, train_wall=127, wall=222680
2023-01-15 05:40:53 | INFO | train_inner | epoch 086:   1401 / 1978 loss=3.105, nll_loss=0.962, word_ins=2.782, length=3.228, ppl=8.61, wps=46389.7, ups=0.79, wpb=58878.6, bsz=1875.4, num_updates=169500, lr=0.000242893, gnorm=1.323, loss_scale=8192, train_wall=127, wall=222807
2023-01-15 05:42:59 | INFO | train_inner | epoch 086:   1501 / 1978 loss=3.069, nll_loss=0.935, word_ins=2.758, length=3.115, ppl=8.39, wps=46567.6, ups=0.79, wpb=58874.5, bsz=2020.5, num_updates=169600, lr=0.000242821, gnorm=1.233, loss_scale=8192, train_wall=126, wall=222933
2023-01-15 05:45:07 | INFO | train_inner | epoch 086:   1601 / 1978 loss=3.076, nll_loss=0.938, word_ins=2.762, length=3.149, ppl=8.44, wps=46252.9, ups=0.78, wpb=58998.7, bsz=1955.5, num_updates=169700, lr=0.00024275, gnorm=1.262, loss_scale=8192, train_wall=127, wall=223061
2023-01-15 05:47:15 | INFO | train_inner | epoch 086:   1701 / 1978 loss=3.06, nll_loss=0.925, word_ins=2.749, length=3.111, ppl=8.34, wps=46519.4, ups=0.78, wpb=59592.3, bsz=2030.6, num_updates=169800, lr=0.000242678, gnorm=1.296, loss_scale=8192, train_wall=128, wall=223189
2023-01-15 05:49:22 | INFO | train_inner | epoch 086:   1801 / 1978 loss=3.068, nll_loss=0.93, word_ins=2.754, length=3.142, ppl=8.38, wps=46698.4, ups=0.79, wpb=59353.8, bsz=1969.8, num_updates=169900, lr=0.000242607, gnorm=1.282, loss_scale=8192, train_wall=127, wall=223316
2023-01-15 05:51:30 | INFO | train_inner | epoch 086:   1901 / 1978 loss=3.047, nll_loss=0.916, word_ins=2.741, length=3.064, ppl=8.26, wps=46656.4, ups=0.78, wpb=59781.7, bsz=2056.6, num_updates=170000, lr=0.000242536, gnorm=1.23, loss_scale=8192, train_wall=128, wall=223444
2023-01-15 05:53:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 05:53:24 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 4.586 | nll_loss 1.972 | word_ins 3.743 | length 8.428 | ppl 24.01 | wps 145504 | wpb 40242.5 | bsz 1500 | num_updates 170077 | best_loss 4.422
2023-01-15 05:53:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 05:53:51 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint86.pt (epoch 86 @ 170077 updates, score 4.586) (writing took 27.748233633115888 seconds)
2023-01-15 05:53:51 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2023-01-15 05:53:51 | INFO | train | epoch 086 | loss 3.064 | nll_loss 0.929 | word_ins 2.752 | length 3.115 | ppl 8.36 | wps 45355.6 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 170077 | lr 0.000242481 | gnorm 1.266 | loss_scale 8192 | train_wall 2522 | wall 223585
2023-01-15 05:53:51 | INFO | fairseq.trainer | begin training epoch 87
2023-01-15 05:54:32 | INFO | train_inner | epoch 087:     23 / 1978 loss=3.06, nll_loss=0.922, word_ins=2.746, length=3.144, ppl=8.34, wps=32375.3, ups=0.55, wpb=58991.2, bsz=1998.6, num_updates=170100, lr=0.000242464, gnorm=1.259, loss_scale=8192, train_wall=128, wall=223626
2023-01-15 05:56:40 | INFO | train_inner | epoch 087:    123 / 1978 loss=3.073, nll_loss=0.936, word_ins=2.759, length=3.138, ppl=8.42, wps=46401.1, ups=0.78, wpb=59283.4, bsz=1969.4, num_updates=170200, lr=0.000242393, gnorm=1.297, loss_scale=8192, train_wall=127, wall=223754
2023-01-15 05:58:48 | INFO | train_inner | epoch 087:    223 / 1978 loss=3.055, nll_loss=0.921, word_ins=2.745, length=3.094, ppl=8.31, wps=46750.5, ups=0.78, wpb=59647.2, bsz=1971.4, num_updates=170300, lr=0.000242322, gnorm=1.268, loss_scale=8192, train_wall=127, wall=223882
2023-01-15 06:00:55 | INFO | train_inner | epoch 087:    323 / 1978 loss=3.044, nll_loss=0.91, word_ins=2.735, length=3.086, ppl=8.25, wps=46900.5, ups=0.78, wpb=59766.4, bsz=1974.4, num_updates=170400, lr=0.000242251, gnorm=1.29, loss_scale=8192, train_wall=127, wall=224009
2023-01-15 06:03:02 | INFO | train_inner | epoch 087:    423 / 1978 loss=3.074, nll_loss=0.939, word_ins=2.762, length=3.12, ppl=8.42, wps=46572.1, ups=0.79, wpb=59286.8, bsz=1943.9, num_updates=170500, lr=0.00024218, gnorm=1.287, loss_scale=8192, train_wall=127, wall=224137
2023-01-15 06:05:09 | INFO | train_inner | epoch 087:    523 / 1978 loss=3.099, nll_loss=0.967, word_ins=2.787, length=3.115, ppl=8.57, wps=46688, ups=0.79, wpb=59308.2, bsz=1888.9, num_updates=170600, lr=0.000242109, gnorm=1.323, loss_scale=8192, train_wall=127, wall=224264
2023-01-15 06:07:18 | INFO | train_inner | epoch 087:    623 / 1978 loss=3.047, nll_loss=0.914, word_ins=2.739, length=3.084, ppl=8.27, wps=46145, ups=0.78, wpb=59492, bsz=2077.2, num_updates=170700, lr=0.000242038, gnorm=1.232, loss_scale=8192, train_wall=129, wall=224393
2023-01-15 06:08:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 06:09:28 | INFO | train_inner | epoch 087:    724 / 1978 loss=3.064, nll_loss=0.93, word_ins=2.753, length=3.11, ppl=8.36, wps=45676.1, ups=0.77, wpb=59205.2, bsz=2016.4, num_updates=170800, lr=0.000241967, gnorm=1.258, loss_scale=8192, train_wall=129, wall=224522
2023-01-15 06:11:36 | INFO | train_inner | epoch 087:    824 / 1978 loss=3.063, nll_loss=0.929, word_ins=2.753, length=3.102, ppl=8.36, wps=46259.5, ups=0.78, wpb=59243.5, bsz=2026.4, num_updates=170900, lr=0.000241896, gnorm=1.296, loss_scale=8192, train_wall=128, wall=224650
2023-01-15 06:13:43 | INFO | train_inner | epoch 087:    924 / 1978 loss=3.055, nll_loss=0.919, word_ins=2.743, length=3.114, ppl=8.31, wps=46853.3, ups=0.79, wpb=59392.8, bsz=1961.2, num_updates=171000, lr=0.000241825, gnorm=1.264, loss_scale=8192, train_wall=127, wall=224777
2023-01-15 06:15:50 | INFO | train_inner | epoch 087:   1024 / 1978 loss=3.056, nll_loss=0.922, word_ins=2.746, length=3.102, ppl=8.32, wps=46707.5, ups=0.79, wpb=59325.1, bsz=2008.6, num_updates=171100, lr=0.000241755, gnorm=1.265, loss_scale=8192, train_wall=127, wall=224904
2023-01-15 06:17:58 | INFO | train_inner | epoch 087:   1124 / 1978 loss=3.074, nll_loss=0.94, word_ins=2.762, length=3.128, ppl=8.42, wps=46532.5, ups=0.78, wpb=59385.9, bsz=1974.9, num_updates=171200, lr=0.000241684, gnorm=1.258, loss_scale=8192, train_wall=127, wall=225032
2023-01-15 06:20:05 | INFO | train_inner | epoch 087:   1224 / 1978 loss=3.045, nll_loss=0.914, word_ins=2.739, length=3.065, ppl=8.25, wps=46163.7, ups=0.78, wpb=58978.1, bsz=2061.4, num_updates=171300, lr=0.000241614, gnorm=1.241, loss_scale=8192, train_wall=127, wall=225159
2023-01-15 06:22:14 | INFO | train_inner | epoch 087:   1324 / 1978 loss=3.06, nll_loss=0.924, word_ins=2.748, length=3.128, ppl=8.34, wps=46319.8, ups=0.78, wpb=59474.3, bsz=2051.4, num_updates=171400, lr=0.000241543, gnorm=1.28, loss_scale=8192, train_wall=128, wall=225288
2023-01-15 06:24:22 | INFO | train_inner | epoch 087:   1424 / 1978 loss=3.049, nll_loss=0.915, word_ins=2.739, length=3.092, ppl=8.27, wps=45798.6, ups=0.78, wpb=58769.9, bsz=2063, num_updates=171500, lr=0.000241473, gnorm=1.243, loss_scale=8192, train_wall=128, wall=225416
2023-01-15 06:26:31 | INFO | train_inner | epoch 087:   1524 / 1978 loss=3.056, nll_loss=0.923, word_ins=2.746, length=3.101, ppl=8.32, wps=46445.3, ups=0.78, wpb=59811, bsz=2084.2, num_updates=171600, lr=0.000241402, gnorm=1.264, loss_scale=8192, train_wall=128, wall=225545
2023-01-15 06:28:39 | INFO | train_inner | epoch 087:   1624 / 1978 loss=3.07, nll_loss=0.93, word_ins=2.753, length=3.166, ppl=8.4, wps=46106.9, ups=0.78, wpb=58961.3, bsz=1995.5, num_updates=171700, lr=0.000241332, gnorm=1.241, loss_scale=8192, train_wall=128, wall=225673
2023-01-15 06:30:48 | INFO | train_inner | epoch 087:   1724 / 1978 loss=3.053, nll_loss=0.92, word_ins=2.744, length=3.092, ppl=8.3, wps=45732.3, ups=0.78, wpb=58951.6, bsz=2069.9, num_updates=171800, lr=0.000241262, gnorm=1.245, loss_scale=8192, train_wall=129, wall=225802
2023-01-15 06:32:54 | INFO | train_inner | epoch 087:   1824 / 1978 loss=3.078, nll_loss=0.939, word_ins=2.762, length=3.155, ppl=8.44, wps=46813.1, ups=0.79, wpb=59381.9, bsz=1987.8, num_updates=171900, lr=0.000241192, gnorm=1.268, loss_scale=8192, train_wall=127, wall=225929
2023-01-15 06:35:02 | INFO | train_inner | epoch 087:   1924 / 1978 loss=3.079, nll_loss=0.941, word_ins=2.763, length=3.154, ppl=8.45, wps=46409.5, ups=0.79, wpb=59008.9, bsz=1963.5, num_updates=172000, lr=0.000241121, gnorm=1.284, loss_scale=8192, train_wall=127, wall=226056
2023-01-15 06:36:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 06:36:25 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 4.626 | nll_loss 1.985 | word_ins 3.747 | length 8.787 | ppl 24.69 | wps 133023 | wpb 40242.5 | bsz 1500 | num_updates 172054 | best_loss 4.422
2023-01-15 06:36:25 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 06:36:52 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint87.pt (epoch 87 @ 172054 updates, score 4.626) (writing took 27.012389692943543 seconds)
2023-01-15 06:36:52 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2023-01-15 06:36:52 | INFO | train | epoch 087 | loss 3.063 | nll_loss 0.928 | word_ins 2.752 | length 3.115 | ppl 8.36 | wps 45424.7 | ups 0.77 | wpb 59284.2 | bsz 2002.8 | num_updates 172054 | lr 0.000241084 | gnorm 1.268 | loss_scale 8192 | train_wall 2522 | wall 226166
2023-01-15 06:36:52 | INFO | fairseq.trainer | begin training epoch 88
2023-01-15 06:38:02 | INFO | train_inner | epoch 088:     46 / 1978 loss=3.081, nll_loss=0.944, word_ins=2.766, length=3.152, ppl=8.46, wps=32691.7, ups=0.56, wpb=58838.3, bsz=1924.7, num_updates=172100, lr=0.000241051, gnorm=1.257, loss_scale=8192, train_wall=127, wall=226236
2023-01-15 06:40:09 | INFO | train_inner | epoch 088:    146 / 1978 loss=3.015, nll_loss=0.885, word_ins=2.713, length=3.02, ppl=8.08, wps=46447.7, ups=0.78, wpb=59283.4, bsz=2107.4, num_updates=172200, lr=0.000240981, gnorm=1.228, loss_scale=8192, train_wall=127, wall=226363
2023-01-15 06:42:17 | INFO | train_inner | epoch 088:    246 / 1978 loss=3.052, nll_loss=0.919, word_ins=2.743, length=3.09, ppl=8.29, wps=46345, ups=0.78, wpb=59138.1, bsz=2036.3, num_updates=172300, lr=0.000240911, gnorm=1.226, loss_scale=8192, train_wall=127, wall=226491
2023-01-15 06:44:25 | INFO | train_inner | epoch 088:    346 / 1978 loss=3.046, nll_loss=0.919, word_ins=2.743, length=3.028, ppl=8.26, wps=46651, ups=0.78, wpb=59794.9, bsz=2015.4, num_updates=172400, lr=0.000240842, gnorm=1.281, loss_scale=8192, train_wall=128, wall=226619
2023-01-15 06:46:32 | INFO | train_inner | epoch 088:    446 / 1978 loss=3.067, nll_loss=0.93, word_ins=2.753, length=3.134, ppl=8.38, wps=46498.8, ups=0.78, wpb=59236.7, bsz=1984.2, num_updates=172500, lr=0.000240772, gnorm=1.253, loss_scale=8192, train_wall=127, wall=226747
2023-01-15 06:48:40 | INFO | train_inner | epoch 088:    546 / 1978 loss=3.051, nll_loss=0.916, word_ins=2.741, length=3.102, ppl=8.29, wps=46403.8, ups=0.78, wpb=59427.2, bsz=2009.4, num_updates=172600, lr=0.000240702, gnorm=1.274, loss_scale=8192, train_wall=128, wall=226875
2023-01-15 06:50:48 | INFO | train_inner | epoch 088:    646 / 1978 loss=3.068, nll_loss=0.933, word_ins=2.756, length=3.124, ppl=8.39, wps=46607.4, ups=0.79, wpb=59198.3, bsz=1944.4, num_updates=172700, lr=0.000240632, gnorm=1.265, loss_scale=8192, train_wall=127, wall=227002
2023-01-15 06:52:56 | INFO | train_inner | epoch 088:    746 / 1978 loss=3.046, nll_loss=0.915, word_ins=2.739, length=3.072, ppl=8.26, wps=46116.6, ups=0.78, wpb=59163.4, bsz=2083.6, num_updates=172800, lr=0.000240563, gnorm=1.251, loss_scale=8192, train_wall=128, wall=227130
2023-01-15 06:55:04 | INFO | train_inner | epoch 088:    846 / 1978 loss=3.022, nll_loss=0.895, word_ins=2.722, length=3.002, ppl=8.12, wps=46423.7, ups=0.78, wpb=59460.3, bsz=2106.9, num_updates=172900, lr=0.000240493, gnorm=1.243, loss_scale=8192, train_wall=128, wall=227258
2023-01-15 06:57:11 | INFO | train_inner | epoch 088:    946 / 1978 loss=3.089, nll_loss=0.952, word_ins=2.773, length=3.155, ppl=8.51, wps=46468.1, ups=0.78, wpb=59262.1, bsz=1906.1, num_updates=173000, lr=0.000240424, gnorm=1.289, loss_scale=8192, train_wall=127, wall=227386
2023-01-15 06:59:18 | INFO | train_inner | epoch 088:   1046 / 1978 loss=3.066, nll_loss=0.935, word_ins=2.758, length=3.082, ppl=8.38, wps=46682.8, ups=0.79, wpb=59228.7, bsz=1946.7, num_updates=173100, lr=0.000240354, gnorm=1.284, loss_scale=8192, train_wall=127, wall=227512
2023-01-15 07:01:27 | INFO | train_inner | epoch 088:   1146 / 1978 loss=3.082, nll_loss=0.941, word_ins=2.763, length=3.187, ppl=8.47, wps=46344.6, ups=0.78, wpb=59701.2, bsz=1991.4, num_updates=173200, lr=0.000240285, gnorm=1.298, loss_scale=8192, train_wall=128, wall=227641
2023-01-15 07:03:36 | INFO | train_inner | epoch 088:   1246 / 1978 loss=3.057, nll_loss=0.919, word_ins=2.744, length=3.132, ppl=8.32, wps=45736.8, ups=0.78, wpb=58817.7, bsz=2022.2, num_updates=173300, lr=0.000240215, gnorm=1.242, loss_scale=8192, train_wall=128, wall=227770
2023-01-15 07:05:43 | INFO | train_inner | epoch 088:   1346 / 1978 loss=3.056, nll_loss=0.918, word_ins=2.742, length=3.144, ppl=8.32, wps=46839.3, ups=0.78, wpb=59768.6, bsz=1959.6, num_updates=173400, lr=0.000240146, gnorm=1.322, loss_scale=8192, train_wall=127, wall=227897
2023-01-15 07:07:51 | INFO | train_inner | epoch 088:   1446 / 1978 loss=3.058, nll_loss=0.924, word_ins=2.748, length=3.102, ppl=8.33, wps=46186.4, ups=0.78, wpb=59075.1, bsz=2030.6, num_updates=173500, lr=0.000240077, gnorm=1.283, loss_scale=8192, train_wall=128, wall=228025
2023-01-15 07:09:58 | INFO | train_inner | epoch 088:   1546 / 1978 loss=3.091, nll_loss=0.953, word_ins=2.774, length=3.165, ppl=8.52, wps=46444.5, ups=0.79, wpb=58900.3, bsz=1910.7, num_updates=173600, lr=0.000240008, gnorm=1.265, loss_scale=8192, train_wall=127, wall=228152
2023-01-15 07:12:06 | INFO | train_inner | epoch 088:   1646 / 1978 loss=3.029, nll_loss=0.898, word_ins=2.724, length=3.051, ppl=8.16, wps=46466.4, ups=0.78, wpb=59619.6, bsz=2079.1, num_updates=173700, lr=0.000239939, gnorm=1.261, loss_scale=8192, train_wall=128, wall=228280
2023-01-15 07:14:14 | INFO | train_inner | epoch 088:   1746 / 1978 loss=3.047, nll_loss=0.914, word_ins=2.738, length=3.086, ppl=8.26, wps=46740.9, ups=0.78, wpb=59753, bsz=2047, num_updates=173800, lr=0.00023987, gnorm=1.261, loss_scale=8192, train_wall=128, wall=228408
2023-01-15 07:16:21 | INFO | train_inner | epoch 088:   1846 / 1978 loss=3.089, nll_loss=0.955, word_ins=2.776, length=3.126, ppl=8.51, wps=46763.2, ups=0.79, wpb=59394.6, bsz=1890.2, num_updates=173900, lr=0.000239801, gnorm=1.288, loss_scale=8192, train_wall=127, wall=228535
2023-01-15 07:18:28 | INFO | train_inner | epoch 088:   1946 / 1978 loss=3.078, nll_loss=0.942, word_ins=2.764, length=3.133, ppl=8.44, wps=46424.3, ups=0.79, wpb=58931.9, bsz=1941.3, num_updates=174000, lr=0.000239732, gnorm=1.277, loss_scale=8192, train_wall=127, wall=228662
2023-01-15 07:19:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 07:19:23 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 4.632 | nll_loss 1.986 | word_ins 3.751 | length 8.82 | ppl 24.8 | wps 94349.6 | wpb 40242.5 | bsz 1500 | num_updates 174032 | best_loss 4.422
2023-01-15 07:19:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 07:19:50 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint88.pt (epoch 88 @ 174032 updates, score 4.632) (writing took 27.25992498686537 seconds)
2023-01-15 07:19:50 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2023-01-15 07:19:50 | INFO | train | epoch 088 | loss 3.058 | nll_loss 0.925 | word_ins 2.748 | length 3.102 | ppl 8.33 | wps 45472.7 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 174032 | lr 0.00023971 | gnorm 1.268 | loss_scale 8192 | train_wall 2520 | wall 228744
2023-01-15 07:19:50 | INFO | fairseq.trainer | begin training epoch 89
2023-01-15 07:21:29 | INFO | train_inner | epoch 089:     68 / 1978 loss=3.042, nll_loss=0.91, word_ins=2.735, length=3.068, ppl=8.24, wps=32530.1, ups=0.55, wpb=58871.7, bsz=2059.4, num_updates=174100, lr=0.000239663, gnorm=1.282, loss_scale=8192, train_wall=128, wall=228843
2023-01-15 07:23:36 | INFO | train_inner | epoch 089:    168 / 1978 loss=3.068, nll_loss=0.934, word_ins=2.757, length=3.11, ppl=8.39, wps=46856.8, ups=0.79, wpb=59553.1, bsz=1923.1, num_updates=174200, lr=0.000239594, gnorm=1.265, loss_scale=8192, train_wall=127, wall=228970
2023-01-15 07:25:43 | INFO | train_inner | epoch 089:    268 / 1978 loss=3.042, nll_loss=0.91, word_ins=2.735, length=3.073, ppl=8.24, wps=46406.2, ups=0.79, wpb=58993.6, bsz=2024.5, num_updates=174300, lr=0.000239525, gnorm=1.213, loss_scale=8192, train_wall=127, wall=229097
2023-01-15 07:27:53 | INFO | train_inner | epoch 089:    368 / 1978 loss=3.056, nll_loss=0.923, word_ins=2.748, length=3.082, ppl=8.32, wps=45542.6, ups=0.77, wpb=59241.5, bsz=1994, num_updates=174400, lr=0.000239457, gnorm=1.345, loss_scale=8192, train_wall=130, wall=229228
2023-01-15 07:30:01 | INFO | train_inner | epoch 089:    468 / 1978 loss=3.065, nll_loss=0.929, word_ins=2.753, length=3.123, ppl=8.37, wps=46771.8, ups=0.79, wpb=59551.7, bsz=1976.1, num_updates=174500, lr=0.000239388, gnorm=1.312, loss_scale=8192, train_wall=127, wall=229355
2023-01-15 07:32:09 | INFO | train_inner | epoch 089:    568 / 1978 loss=3.065, nll_loss=0.928, word_ins=2.752, length=3.129, ppl=8.37, wps=46096.6, ups=0.78, wpb=58936, bsz=1943.4, num_updates=174600, lr=0.000239319, gnorm=1.282, loss_scale=8192, train_wall=128, wall=229483
2023-01-15 07:34:18 | INFO | train_inner | epoch 089:    668 / 1978 loss=3.046, nll_loss=0.912, word_ins=2.737, length=3.088, ppl=8.26, wps=46052.5, ups=0.78, wpb=59351, bsz=2030.6, num_updates=174700, lr=0.000239251, gnorm=1.252, loss_scale=8192, train_wall=129, wall=229612
2023-01-15 07:36:26 | INFO | train_inner | epoch 089:    768 / 1978 loss=3.048, nll_loss=0.918, word_ins=2.741, length=3.071, ppl=8.27, wps=46514.1, ups=0.78, wpb=59788, bsz=2051.8, num_updates=174800, lr=0.000239182, gnorm=1.257, loss_scale=8192, train_wall=128, wall=229740
2023-01-15 07:38:34 | INFO | train_inner | epoch 089:    868 / 1978 loss=3.043, nll_loss=0.914, word_ins=2.739, length=3.041, ppl=8.24, wps=46360.1, ups=0.78, wpb=59403.8, bsz=2081, num_updates=174900, lr=0.000239114, gnorm=1.245, loss_scale=16384, train_wall=128, wall=229868
2023-01-15 07:40:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 07:40:43 | INFO | train_inner | epoch 089:    969 / 1978 loss=3.042, nll_loss=0.908, word_ins=2.733, length=3.09, ppl=8.24, wps=45613.1, ups=0.77, wpb=58908, bsz=2036.8, num_updates=175000, lr=0.000239046, gnorm=1.288, loss_scale=8192, train_wall=129, wall=229997
2023-01-15 07:42:53 | INFO | train_inner | epoch 089:   1069 / 1978 loss=3.045, nll_loss=0.911, word_ins=2.736, length=3.092, ppl=8.25, wps=46179.5, ups=0.77, wpb=59699.6, bsz=2114.3, num_updates=175100, lr=0.000238977, gnorm=1.253, loss_scale=8192, train_wall=129, wall=230127
2023-01-15 07:45:01 | INFO | train_inner | epoch 089:   1169 / 1978 loss=3.049, nll_loss=0.917, word_ins=2.742, length=3.071, ppl=8.27, wps=46096.7, ups=0.78, wpb=59225.6, bsz=2073.4, num_updates=175200, lr=0.000238909, gnorm=1.273, loss_scale=8192, train_wall=128, wall=230255
2023-01-15 07:47:08 | INFO | train_inner | epoch 089:   1269 / 1978 loss=3.088, nll_loss=0.946, word_ins=2.768, length=3.198, ppl=8.5, wps=46124, ups=0.79, wpb=58559.6, bsz=1911.5, num_updates=175300, lr=0.000238841, gnorm=1.279, loss_scale=8192, train_wall=127, wall=230382
2023-01-15 07:49:15 | INFO | train_inner | epoch 089:   1369 / 1978 loss=3.052, nll_loss=0.916, word_ins=2.74, length=3.114, ppl=8.29, wps=46855.9, ups=0.79, wpb=59587.3, bsz=1978.8, num_updates=175400, lr=0.000238773, gnorm=1.295, loss_scale=8192, train_wall=127, wall=230509
2023-01-15 07:51:23 | INFO | train_inner | epoch 089:   1469 / 1978 loss=3.054, nll_loss=0.92, word_ins=2.744, length=3.102, ppl=8.31, wps=46752.3, ups=0.78, wpb=59759.1, bsz=2017.8, num_updates=175500, lr=0.000238705, gnorm=1.223, loss_scale=8192, train_wall=128, wall=230637
2023-01-15 07:53:31 | INFO | train_inner | epoch 089:   1569 / 1978 loss=3.081, nll_loss=0.947, word_ins=2.768, length=3.125, ppl=8.46, wps=46290.3, ups=0.78, wpb=59105.8, bsz=1960.7, num_updates=175600, lr=0.000238637, gnorm=1.266, loss_scale=8192, train_wall=127, wall=230765
2023-01-15 07:55:38 | INFO | train_inner | epoch 089:   1669 / 1978 loss=3.053, nll_loss=0.92, word_ins=2.744, length=3.097, ppl=8.3, wps=46746.5, ups=0.79, wpb=59480, bsz=1980.9, num_updates=175700, lr=0.000238569, gnorm=1.298, loss_scale=8192, train_wall=127, wall=230892
2023-01-15 07:57:45 | INFO | train_inner | epoch 089:   1769 / 1978 loss=3.071, nll_loss=0.934, word_ins=2.757, length=3.138, ppl=8.4, wps=46937.4, ups=0.79, wpb=59577.5, bsz=1950.1, num_updates=175800, lr=0.000238501, gnorm=1.294, loss_scale=8192, train_wall=127, wall=231019
2023-01-15 07:59:53 | INFO | train_inner | epoch 089:   1869 / 1978 loss=3.061, nll_loss=0.926, word_ins=2.749, length=3.12, ppl=8.34, wps=46288.4, ups=0.78, wpb=59338.6, bsz=2050.4, num_updates=175900, lr=0.000238433, gnorm=1.276, loss_scale=8192, train_wall=128, wall=231147
2023-01-15 08:02:00 | INFO | train_inner | epoch 089:   1969 / 1978 loss=3.063, nll_loss=0.927, word_ins=2.75, length=3.124, ppl=8.36, wps=46028.2, ups=0.79, wpb=58581.4, bsz=1981.4, num_updates=176000, lr=0.000238366, gnorm=1.251, loss_scale=8192, train_wall=127, wall=231275
2023-01-15 08:02:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 08:02:26 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 4.541 | nll_loss 1.972 | word_ins 3.736 | length 8.048 | ppl 23.28 | wps 115981 | wpb 40242.5 | bsz 1500 | num_updates 176009 | best_loss 4.422
2023-01-15 08:02:26 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 08:02:54 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint89.pt (epoch 89 @ 176009 updates, score 4.541) (writing took 27.702961856964976 seconds)
2023-01-15 08:02:54 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2023-01-15 08:02:54 | INFO | train | epoch 089 | loss 3.057 | nll_loss 0.923 | word_ins 2.747 | length 3.104 | ppl 8.32 | wps 45368.9 | ups 0.77 | wpb 59281.5 | bsz 2002.7 | num_updates 176009 | lr 0.00023836 | gnorm 1.271 | loss_scale 8192 | train_wall 2525 | wall 231328
2023-01-15 08:02:54 | INFO | fairseq.trainer | begin training epoch 90
2023-01-15 08:05:02 | INFO | train_inner | epoch 090:     91 / 1978 loss=3.06, nll_loss=0.923, word_ins=2.748, length=3.125, ppl=8.34, wps=32468.1, ups=0.55, wpb=59049, bsz=1983, num_updates=176100, lr=0.000238298, gnorm=1.282, loss_scale=8192, train_wall=128, wall=231456
2023-01-15 08:07:11 | INFO | train_inner | epoch 090:    191 / 1978 loss=3.018, nll_loss=0.89, word_ins=2.718, length=3, ppl=8.1, wps=46332.6, ups=0.78, wpb=59492.7, bsz=2128, num_updates=176200, lr=0.00023823, gnorm=1.251, loss_scale=8192, train_wall=128, wall=231585
2023-01-15 08:09:20 | INFO | train_inner | epoch 090:    291 / 1978 loss=3.037, nll_loss=0.907, word_ins=2.732, length=3.045, ppl=8.21, wps=45882.1, ups=0.78, wpb=59114.7, bsz=2090.6, num_updates=176300, lr=0.000238163, gnorm=1.26, loss_scale=8192, train_wall=129, wall=231714
2023-01-15 08:11:28 | INFO | train_inner | epoch 090:    391 / 1978 loss=3.043, nll_loss=0.913, word_ins=2.738, length=3.058, ppl=8.24, wps=46668.6, ups=0.78, wpb=59743.6, bsz=2036.1, num_updates=176400, lr=0.000238095, gnorm=1.291, loss_scale=8192, train_wall=128, wall=231842
2023-01-15 08:13:35 | INFO | train_inner | epoch 090:    491 / 1978 loss=3.07, nll_loss=0.933, word_ins=2.756, length=3.137, ppl=8.4, wps=46438.7, ups=0.79, wpb=58925.9, bsz=1958.5, num_updates=176500, lr=0.000238028, gnorm=1.24, loss_scale=8192, train_wall=127, wall=231969
2023-01-15 08:15:42 | INFO | train_inner | epoch 090:    591 / 1978 loss=3.035, nll_loss=0.899, word_ins=2.725, length=3.101, ppl=8.2, wps=46785.3, ups=0.78, wpb=59724.2, bsz=2033.5, num_updates=176600, lr=0.00023796, gnorm=1.308, loss_scale=8192, train_wall=127, wall=232096
2023-01-15 08:17:50 | INFO | train_inner | epoch 090:    691 / 1978 loss=3.051, nll_loss=0.915, word_ins=2.739, length=3.114, ppl=8.29, wps=46384.8, ups=0.78, wpb=59431.5, bsz=2018.6, num_updates=176700, lr=0.000237893, gnorm=1.303, loss_scale=8192, train_wall=128, wall=232224
2023-01-15 08:19:58 | INFO | train_inner | epoch 090:    791 / 1978 loss=3.05, nll_loss=0.918, word_ins=2.742, length=3.077, ppl=8.28, wps=45879.9, ups=0.78, wpb=58783.5, bsz=2050.2, num_updates=176800, lr=0.000237826, gnorm=1.218, loss_scale=8192, train_wall=128, wall=232353
2023-01-15 08:22:05 | INFO | train_inner | epoch 090:    891 / 1978 loss=3.076, nll_loss=0.939, word_ins=2.762, length=3.146, ppl=8.44, wps=46864.2, ups=0.79, wpb=59417.7, bsz=1938.6, num_updates=176900, lr=0.000237759, gnorm=1.297, loss_scale=8192, train_wall=127, wall=232479
2023-01-15 08:24:14 | INFO | train_inner | epoch 090:    991 / 1978 loss=3.058, nll_loss=0.924, word_ins=2.747, length=3.108, ppl=8.33, wps=46083.5, ups=0.78, wpb=59125.8, bsz=2009, num_updates=177000, lr=0.000237691, gnorm=1.265, loss_scale=8192, train_wall=128, wall=232608
2023-01-15 08:26:21 | INFO | train_inner | epoch 090:   1091 / 1978 loss=3.066, nll_loss=0.93, word_ins=2.753, length=3.121, ppl=8.37, wps=46611.7, ups=0.79, wpb=59204.4, bsz=1907.5, num_updates=177100, lr=0.000237624, gnorm=1.285, loss_scale=8192, train_wall=127, wall=232735
2023-01-15 08:28:28 | INFO | train_inner | epoch 090:   1191 / 1978 loss=3.06, nll_loss=0.923, word_ins=2.746, length=3.132, ppl=8.34, wps=46656.1, ups=0.79, wpb=59256.6, bsz=1948, num_updates=177200, lr=0.000237557, gnorm=1.279, loss_scale=8192, train_wall=127, wall=232862
2023-01-15 08:30:35 | INFO | train_inner | epoch 090:   1291 / 1978 loss=3.085, nll_loss=0.951, word_ins=2.773, length=3.118, ppl=8.48, wps=46090.5, ups=0.79, wpb=58628.6, bsz=1937.3, num_updates=177300, lr=0.00023749, gnorm=1.271, loss_scale=8192, train_wall=127, wall=232989
2023-01-15 08:32:42 | INFO | train_inner | epoch 090:   1391 / 1978 loss=3.078, nll_loss=0.943, word_ins=2.765, length=3.13, ppl=8.44, wps=46538.1, ups=0.78, wpb=59339.8, bsz=1944.5, num_updates=177400, lr=0.000237423, gnorm=1.303, loss_scale=8192, train_wall=127, wall=233116
2023-01-15 08:34:50 | INFO | train_inner | epoch 090:   1491 / 1978 loss=3.072, nll_loss=0.934, word_ins=2.756, length=3.158, ppl=8.41, wps=46347.5, ups=0.78, wpb=59077, bsz=1958.8, num_updates=177500, lr=0.000237356, gnorm=1.308, loss_scale=8192, train_wall=127, wall=233244
2023-01-15 08:36:59 | INFO | train_inner | epoch 090:   1591 / 1978 loss=3.039, nll_loss=0.906, word_ins=2.731, length=3.081, ppl=8.22, wps=45855.6, ups=0.77, wpb=59371.4, bsz=2078.6, num_updates=177600, lr=0.000237289, gnorm=1.244, loss_scale=8192, train_wall=129, wall=233373
2023-01-15 08:39:06 | INFO | train_inner | epoch 090:   1691 / 1978 loss=3.06, nll_loss=0.921, word_ins=2.745, length=3.155, ppl=8.34, wps=46514.4, ups=0.79, wpb=58945.4, bsz=1936.7, num_updates=177700, lr=0.000237223, gnorm=1.295, loss_scale=8192, train_wall=127, wall=233500
2023-01-15 08:41:13 | INFO | train_inner | epoch 090:   1791 / 1978 loss=3.06, nll_loss=0.928, word_ins=2.751, length=3.081, ppl=8.34, wps=47056.9, ups=0.79, wpb=59747.7, bsz=1958.1, num_updates=177800, lr=0.000237156, gnorm=1.306, loss_scale=8192, train_wall=127, wall=233627
2023-01-15 08:43:21 | INFO | train_inner | epoch 090:   1891 / 1978 loss=3.048, nll_loss=0.914, word_ins=2.738, length=3.099, ppl=8.27, wps=46684.7, ups=0.78, wpb=59721.4, bsz=2032.7, num_updates=177900, lr=0.000237089, gnorm=1.254, loss_scale=8192, train_wall=128, wall=233755
2023-01-15 08:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 08:45:26 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 4.626 | nll_loss 1.982 | word_ins 3.75 | length 8.758 | ppl 24.69 | wps 120128 | wpb 40242.5 | bsz 1500 | num_updates 177987 | best_loss 4.422
2023-01-15 08:45:26 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 08:45:53 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint90.pt (epoch 90 @ 177987 updates, score 4.626) (writing took 26.926216814201325 seconds)
2023-01-15 08:45:53 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2023-01-15 08:45:53 | INFO | train | epoch 090 | loss 3.055 | nll_loss 0.921 | word_ins 2.745 | length 3.102 | ppl 8.31 | wps 45469.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 177987 | lr 0.000237031 | gnorm 1.275 | loss_scale 8192 | train_wall 2522 | wall 233907
2023-01-15 08:45:53 | INFO | fairseq.trainer | begin training epoch 91
2023-01-15 08:46:22 | INFO | train_inner | epoch 091:     13 / 1978 loss=3.029, nll_loss=0.9, word_ins=2.725, length=3.045, ppl=8.16, wps=32910.6, ups=0.55, wpb=59479.2, bsz=2118.6, num_updates=178000, lr=0.000237023, gnorm=1.226, loss_scale=8192, train_wall=129, wall=233936
2023-01-15 08:48:29 | INFO | train_inner | epoch 091:    113 / 1978 loss=3.062, nll_loss=0.924, word_ins=2.748, length=3.145, ppl=8.35, wps=46335.8, ups=0.78, wpb=59087.4, bsz=1918.6, num_updates=178100, lr=0.000236956, gnorm=1.305, loss_scale=8192, train_wall=127, wall=234063
2023-01-15 08:50:37 | INFO | train_inner | epoch 091:    213 / 1978 loss=3.052, nll_loss=0.915, word_ins=2.74, length=3.123, ppl=8.29, wps=46383.3, ups=0.78, wpb=59159.8, bsz=1960.1, num_updates=178200, lr=0.00023689, gnorm=1.249, loss_scale=8192, train_wall=127, wall=234191
2023-01-15 08:52:45 | INFO | train_inner | epoch 091:    313 / 1978 loss=3.051, nll_loss=0.918, word_ins=2.743, length=3.082, ppl=8.29, wps=45987.9, ups=0.78, wpb=59203.2, bsz=2018.4, num_updates=178300, lr=0.000236823, gnorm=1.265, loss_scale=8192, train_wall=128, wall=234320
2023-01-15 08:54:54 | INFO | train_inner | epoch 091:    413 / 1978 loss=3.042, nll_loss=0.913, word_ins=2.738, length=3.044, ppl=8.24, wps=46197.1, ups=0.78, wpb=59377.2, bsz=2055.9, num_updates=178400, lr=0.000236757, gnorm=1.294, loss_scale=8192, train_wall=128, wall=234448
2023-01-15 08:57:01 | INFO | train_inner | epoch 091:    513 / 1978 loss=3.046, nll_loss=0.916, word_ins=2.74, length=3.062, ppl=8.26, wps=46608.3, ups=0.79, wpb=59207.7, bsz=1978.6, num_updates=178500, lr=0.000236691, gnorm=1.247, loss_scale=8192, train_wall=127, wall=234575
2023-01-15 08:59:09 | INFO | train_inner | epoch 091:    613 / 1978 loss=3.068, nll_loss=0.933, word_ins=2.756, length=3.118, ppl=8.38, wps=46242.4, ups=0.78, wpb=59082.2, bsz=1980.8, num_updates=178600, lr=0.000236624, gnorm=1.306, loss_scale=8192, train_wall=128, wall=234703
2023-01-15 09:01:17 | INFO | train_inner | epoch 091:    713 / 1978 loss=3.024, nll_loss=0.895, word_ins=2.721, length=3.032, ppl=8.13, wps=46337.6, ups=0.78, wpb=59364.7, bsz=2006.9, num_updates=178700, lr=0.000236558, gnorm=1.261, loss_scale=8192, train_wall=128, wall=234831
2023-01-15 09:03:25 | INFO | train_inner | epoch 091:    813 / 1978 loss=3.048, nll_loss=0.914, word_ins=2.739, length=3.091, ppl=8.27, wps=46056.4, ups=0.78, wpb=59111.1, bsz=2066.7, num_updates=178800, lr=0.000236492, gnorm=1.225, loss_scale=8192, train_wall=128, wall=234959
2023-01-15 09:05:33 | INFO | train_inner | epoch 091:    913 / 1978 loss=3.045, nll_loss=0.908, word_ins=2.733, length=3.12, ppl=8.25, wps=46637.4, ups=0.78, wpb=59528.8, bsz=1973.2, num_updates=178900, lr=0.000236426, gnorm=1.313, loss_scale=8192, train_wall=127, wall=235087
2023-01-15 09:07:39 | INFO | train_inner | epoch 091:   1013 / 1978 loss=3.078, nll_loss=0.941, word_ins=2.763, length=3.157, ppl=8.45, wps=46984.8, ups=0.79, wpb=59384.5, bsz=1898, num_updates=179000, lr=0.00023636, gnorm=1.311, loss_scale=8192, train_wall=126, wall=235213
2023-01-15 09:09:47 | INFO | train_inner | epoch 091:   1113 / 1978 loss=3.046, nll_loss=0.91, word_ins=2.735, length=3.109, ppl=8.26, wps=46854.7, ups=0.79, wpb=59635.2, bsz=1988.6, num_updates=179100, lr=0.000236294, gnorm=1.278, loss_scale=16384, train_wall=127, wall=235341
2023-01-15 09:11:54 | INFO | train_inner | epoch 091:   1213 / 1978 loss=3.048, nll_loss=0.912, word_ins=2.737, length=3.108, ppl=8.27, wps=46310.5, ups=0.78, wpb=59064.5, bsz=1993, num_updates=179200, lr=0.000236228, gnorm=1.27, loss_scale=16384, train_wall=127, wall=235468
2023-01-15 09:14:02 | INFO | train_inner | epoch 091:   1313 / 1978 loss=3.062, nll_loss=0.925, word_ins=2.748, length=3.141, ppl=8.35, wps=46128.9, ups=0.78, wpb=58923.8, bsz=2033.6, num_updates=179300, lr=0.000236162, gnorm=1.229, loss_scale=16384, train_wall=128, wall=235596
2023-01-15 09:16:10 | INFO | train_inner | epoch 091:   1413 / 1978 loss=3.037, nll_loss=0.908, word_ins=2.733, length=3.039, ppl=8.21, wps=46470.8, ups=0.78, wpb=59601.4, bsz=2078.8, num_updates=179400, lr=0.000236096, gnorm=1.272, loss_scale=16384, train_wall=128, wall=235724
2023-01-15 09:18:17 | INFO | train_inner | epoch 091:   1513 / 1978 loss=3.078, nll_loss=0.94, word_ins=2.762, length=3.158, ppl=8.44, wps=46386.3, ups=0.79, wpb=58830.9, bsz=1950.3, num_updates=179500, lr=0.00023603, gnorm=1.232, loss_scale=16384, train_wall=127, wall=235851
2023-01-15 09:20:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 09:20:26 | INFO | train_inner | epoch 091:   1614 / 1978 loss=3.07, nll_loss=0.937, word_ins=2.759, length=3.106, ppl=8.4, wps=46198.9, ups=0.78, wpb=59562.3, bsz=1954.2, num_updates=179600, lr=0.000235965, gnorm=1.294, loss_scale=8192, train_wall=129, wall=235980
2023-01-15 09:22:34 | INFO | train_inner | epoch 091:   1714 / 1978 loss=3.027, nll_loss=0.9, word_ins=2.725, length=3.017, ppl=8.15, wps=46691.2, ups=0.78, wpb=59902, bsz=2096.5, num_updates=179700, lr=0.000235899, gnorm=1.294, loss_scale=8192, train_wall=128, wall=236108
2023-01-15 09:24:43 | INFO | train_inner | epoch 091:   1814 / 1978 loss=3.067, nll_loss=0.936, word_ins=2.758, length=3.093, ppl=8.38, wps=45753.5, ups=0.78, wpb=58778.5, bsz=2013.8, num_updates=179800, lr=0.000235833, gnorm=1.251, loss_scale=8192, train_wall=128, wall=236237
2023-01-15 09:26:52 | INFO | train_inner | epoch 091:   1914 / 1978 loss=3.066, nll_loss=0.929, word_ins=2.751, length=3.15, ppl=8.38, wps=46032.7, ups=0.78, wpb=59352.7, bsz=2038.5, num_updates=179900, lr=0.000235768, gnorm=1.293, loss_scale=8192, train_wall=129, wall=236366
2023-01-15 09:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 09:28:28 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 4.549 | nll_loss 1.984 | word_ins 3.748 | length 8.001 | ppl 23.4 | wps 97315.1 | wpb 40242.5 | bsz 1500 | num_updates 179964 | best_loss 4.422
2023-01-15 09:28:28 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 09:28:56 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint91.pt (epoch 91 @ 179964 updates, score 4.549) (writing took 27.91659261006862 seconds)
2023-01-15 09:28:56 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2023-01-15 09:28:56 | INFO | train | epoch 091 | loss 3.052 | nll_loss 0.919 | word_ins 2.743 | length 3.098 | ppl 8.3 | wps 45367.4 | ups 0.77 | wpb 59283.7 | bsz 2002.7 | num_updates 179964 | lr 0.000235726 | gnorm 1.272 | loss_scale 8192 | train_wall 2524 | wall 236490
2023-01-15 09:28:56 | INFO | fairseq.trainer | begin training epoch 92
2023-01-15 09:29:55 | INFO | train_inner | epoch 092:     36 / 1978 loss=3.033, nll_loss=0.898, word_ins=2.724, length=3.093, ppl=8.19, wps=32360.8, ups=0.55, wpb=59332.5, bsz=2042.9, num_updates=180000, lr=0.000235702, gnorm=1.259, loss_scale=8192, train_wall=128, wall=236549
2023-01-15 09:32:03 | INFO | train_inner | epoch 092:    136 / 1978 loss=3.051, nll_loss=0.92, word_ins=2.744, length=3.069, ppl=8.29, wps=46507.7, ups=0.78, wpb=59492, bsz=1977.1, num_updates=180100, lr=0.000235637, gnorm=1.291, loss_scale=8192, train_wall=128, wall=236677
2023-01-15 09:34:10 | INFO | train_inner | epoch 092:    236 / 1978 loss=3.053, nll_loss=0.919, word_ins=2.743, length=3.096, ppl=8.3, wps=46696.9, ups=0.79, wpb=59258.3, bsz=1935.4, num_updates=180200, lr=0.000235571, gnorm=1.291, loss_scale=8192, train_wall=127, wall=236804
2023-01-15 09:36:18 | INFO | train_inner | epoch 092:    336 / 1978 loss=3.04, nll_loss=0.907, word_ins=2.733, length=3.076, ppl=8.23, wps=46326.5, ups=0.78, wpb=59425.4, bsz=2058.7, num_updates=180300, lr=0.000235506, gnorm=1.234, loss_scale=8192, train_wall=128, wall=236932
2023-01-15 09:38:26 | INFO | train_inner | epoch 092:    436 / 1978 loss=3.041, nll_loss=0.904, word_ins=2.729, length=3.117, ppl=8.23, wps=46346.7, ups=0.78, wpb=59234.5, bsz=1974.3, num_updates=180400, lr=0.000235441, gnorm=1.278, loss_scale=8192, train_wall=128, wall=237060
2023-01-15 09:40:34 | INFO | train_inner | epoch 092:    536 / 1978 loss=3.025, nll_loss=0.895, word_ins=2.721, length=3.048, ppl=8.14, wps=46557.9, ups=0.78, wpb=59456.4, bsz=2045.3, num_updates=180500, lr=0.000235376, gnorm=1.287, loss_scale=8192, train_wall=128, wall=237188
2023-01-15 09:42:41 | INFO | train_inner | epoch 092:    636 / 1978 loss=3.069, nll_loss=0.928, word_ins=2.751, length=3.181, ppl=8.39, wps=46050, ups=0.78, wpb=58790.6, bsz=1993.2, num_updates=180600, lr=0.00023531, gnorm=1.244, loss_scale=8192, train_wall=127, wall=237315
2023-01-15 09:44:50 | INFO | train_inner | epoch 092:    736 / 1978 loss=3.038, nll_loss=0.91, word_ins=2.734, length=3.038, ppl=8.21, wps=46236.3, ups=0.78, wpb=59538.9, bsz=2054.8, num_updates=180700, lr=0.000235245, gnorm=1.255, loss_scale=8192, train_wall=128, wall=237444
2023-01-15 09:46:58 | INFO | train_inner | epoch 092:    836 / 1978 loss=3.043, nll_loss=0.907, word_ins=2.731, length=3.118, ppl=8.24, wps=46352.2, ups=0.78, wpb=59275.8, bsz=2006.6, num_updates=180800, lr=0.00023518, gnorm=1.263, loss_scale=8192, train_wall=128, wall=237572
2023-01-15 09:49:05 | INFO | train_inner | epoch 092:    936 / 1978 loss=3.034, nll_loss=0.9, word_ins=2.726, length=3.079, ppl=8.19, wps=46413.4, ups=0.79, wpb=59026.8, bsz=2022.4, num_updates=180900, lr=0.000235115, gnorm=1.288, loss_scale=8192, train_wall=127, wall=237699
2023-01-15 09:51:13 | INFO | train_inner | epoch 092:   1036 / 1978 loss=3.031, nll_loss=0.897, word_ins=2.723, length=3.084, ppl=8.17, wps=46358.5, ups=0.78, wpb=59229.5, bsz=2040.2, num_updates=181000, lr=0.00023505, gnorm=1.279, loss_scale=8192, train_wall=128, wall=237827
2023-01-15 09:53:22 | INFO | train_inner | epoch 092:   1136 / 1978 loss=3.032, nll_loss=0.902, word_ins=2.727, length=3.05, ppl=8.18, wps=46068.7, ups=0.77, wpb=59537.8, bsz=2122.2, num_updates=181100, lr=0.000234985, gnorm=1.223, loss_scale=8192, train_wall=129, wall=237956
2023-01-15 09:55:31 | INFO | train_inner | epoch 092:   1236 / 1978 loss=3.05, nll_loss=0.916, word_ins=2.74, length=3.106, ppl=8.28, wps=46130.2, ups=0.77, wpb=59627.6, bsz=2072.4, num_updates=181200, lr=0.00023492, gnorm=1.269, loss_scale=8192, train_wall=129, wall=238085
2023-01-15 09:57:38 | INFO | train_inner | epoch 092:   1336 / 1978 loss=3.086, nll_loss=0.951, word_ins=2.772, length=3.139, ppl=8.49, wps=46969.2, ups=0.79, wpb=59508.3, bsz=1904.8, num_updates=181300, lr=0.000234856, gnorm=1.315, loss_scale=8192, train_wall=126, wall=238212
2023-01-15 09:59:46 | INFO | train_inner | epoch 092:   1436 / 1978 loss=3.07, nll_loss=0.932, word_ins=2.755, length=3.152, ppl=8.4, wps=46256.1, ups=0.78, wpb=59001.8, bsz=1959, num_updates=181400, lr=0.000234791, gnorm=1.302, loss_scale=8192, train_wall=127, wall=238340
2023-01-15 10:01:54 | INFO | train_inner | epoch 092:   1536 / 1978 loss=3.046, nll_loss=0.915, word_ins=2.738, length=3.075, ppl=8.26, wps=46299.6, ups=0.78, wpb=59352.8, bsz=2016.6, num_updates=181500, lr=0.000234726, gnorm=1.254, loss_scale=8192, train_wall=128, wall=238468
2023-01-15 10:04:01 | INFO | train_inner | epoch 092:   1636 / 1978 loss=3.04, nll_loss=0.907, word_ins=2.732, length=3.081, ppl=8.22, wps=46880.1, ups=0.79, wpb=59706.2, bsz=1996.9, num_updates=181600, lr=0.000234662, gnorm=1.327, loss_scale=8192, train_wall=127, wall=238595
2023-01-15 10:06:08 | INFO | train_inner | epoch 092:   1736 / 1978 loss=3.078, nll_loss=0.943, word_ins=2.765, length=3.131, ppl=8.45, wps=46687.8, ups=0.79, wpb=58968.2, bsz=1927.9, num_updates=181700, lr=0.000234597, gnorm=1.277, loss_scale=8192, train_wall=126, wall=238722
2023-01-15 10:08:15 | INFO | train_inner | epoch 092:   1836 / 1978 loss=3.074, nll_loss=0.936, word_ins=2.759, length=3.155, ppl=8.42, wps=46011.1, ups=0.79, wpb=58485.3, bsz=1994.1, num_updates=181800, lr=0.000234533, gnorm=1.239, loss_scale=8192, train_wall=127, wall=238849
2023-01-15 10:10:23 | INFO | train_inner | epoch 092:   1936 / 1978 loss=3.047, nll_loss=0.916, word_ins=2.74, length=3.073, ppl=8.27, wps=46492.8, ups=0.78, wpb=59500.7, bsz=1980.5, num_updates=181900, lr=0.000234468, gnorm=1.287, loss_scale=8192, train_wall=128, wall=238977
2023-01-15 10:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 10:11:29 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 4.562 | nll_loss 1.994 | word_ins 3.755 | length 8.063 | ppl 23.61 | wps 115577 | wpb 40242.5 | bsz 1500 | num_updates 181942 | best_loss 4.422
2023-01-15 10:11:29 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 10:11:57 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint92.pt (epoch 92 @ 181942 updates, score 4.562) (writing took 27.79803030192852 seconds)
2023-01-15 10:11:57 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2023-01-15 10:11:57 | INFO | train | epoch 092 | loss 3.051 | nll_loss 0.916 | word_ins 2.741 | length 3.099 | ppl 8.29 | wps 45438.8 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 181942 | lr 0.000234441 | gnorm 1.274 | loss_scale 8192 | train_wall 2523 | wall 239071
2023-01-15 10:11:57 | INFO | fairseq.trainer | begin training epoch 93
2023-01-15 10:13:24 | INFO | train_inner | epoch 093:     58 / 1978 loss=3.058, nll_loss=0.925, word_ins=2.748, length=3.104, ppl=8.33, wps=32671.7, ups=0.55, wpb=59284.1, bsz=1989.7, num_updates=182000, lr=0.000234404, gnorm=1.286, loss_scale=8192, train_wall=128, wall=239158
2023-01-15 10:15:32 | INFO | train_inner | epoch 093:    158 / 1978 loss=3.037, nll_loss=0.905, word_ins=2.73, length=3.073, ppl=8.21, wps=46484.2, ups=0.78, wpb=59237.7, bsz=2004.1, num_updates=182100, lr=0.000234339, gnorm=1.217, loss_scale=8192, train_wall=127, wall=239286
2023-01-15 10:17:39 | INFO | train_inner | epoch 093:    258 / 1978 loss=3.054, nll_loss=0.918, word_ins=2.742, length=3.115, ppl=8.3, wps=46288.7, ups=0.78, wpb=59095.7, bsz=1968, num_updates=182200, lr=0.000234275, gnorm=1.276, loss_scale=8192, train_wall=127, wall=239413
2023-01-15 10:19:47 | INFO | train_inner | epoch 093:    358 / 1978 loss=3.037, nll_loss=0.905, word_ins=2.73, length=3.065, ppl=8.21, wps=46412.5, ups=0.78, wpb=59250.7, bsz=1984, num_updates=182300, lr=0.000234211, gnorm=1.28, loss_scale=8192, train_wall=127, wall=239541
2023-01-15 10:21:53 | INFO | train_inner | epoch 093:    458 / 1978 loss=3.038, nll_loss=0.903, word_ins=2.729, length=3.089, ppl=8.21, wps=46526.1, ups=0.79, wpb=58871.5, bsz=1965.8, num_updates=182400, lr=0.000234146, gnorm=1.229, loss_scale=8192, train_wall=126, wall=239667
2023-01-15 10:24:01 | INFO | train_inner | epoch 093:    558 / 1978 loss=3.048, nll_loss=0.914, word_ins=2.739, length=3.094, ppl=8.27, wps=46053.2, ups=0.78, wpb=58972.6, bsz=2040, num_updates=182500, lr=0.000234082, gnorm=1.305, loss_scale=8192, train_wall=128, wall=239796
2023-01-15 10:26:10 | INFO | train_inner | epoch 093:    658 / 1978 loss=3.036, nll_loss=0.91, word_ins=2.734, length=3.012, ppl=8.2, wps=46690.8, ups=0.78, wpb=59854.5, bsz=2039.2, num_updates=182600, lr=0.000234018, gnorm=1.274, loss_scale=8192, train_wall=128, wall=239924
2023-01-15 10:28:17 | INFO | train_inner | epoch 093:    758 / 1978 loss=3.027, nll_loss=0.896, word_ins=2.722, length=3.047, ppl=8.15, wps=46370.8, ups=0.78, wpb=59253.4, bsz=2030.5, num_updates=182700, lr=0.000233954, gnorm=1.306, loss_scale=8192, train_wall=127, wall=240052
2023-01-15 10:30:25 | INFO | train_inner | epoch 093:    858 / 1978 loss=3.046, nll_loss=0.912, word_ins=2.737, length=3.092, ppl=8.26, wps=46431.3, ups=0.78, wpb=59340.4, bsz=1997.8, num_updates=182800, lr=0.00023389, gnorm=1.289, loss_scale=8192, train_wall=128, wall=240179
2023-01-15 10:32:33 | INFO | train_inner | epoch 093:    958 / 1978 loss=3.063, nll_loss=0.931, word_ins=2.753, length=3.095, ppl=8.36, wps=46605.9, ups=0.78, wpb=59487.8, bsz=1976.9, num_updates=182900, lr=0.000233826, gnorm=1.274, loss_scale=8192, train_wall=127, wall=240307
2023-01-15 10:34:41 | INFO | train_inner | epoch 093:   1058 / 1978 loss=3.036, nll_loss=0.912, word_ins=2.736, length=3.002, ppl=8.2, wps=46201, ups=0.78, wpb=59147.3, bsz=2067, num_updates=183000, lr=0.000233762, gnorm=1.259, loss_scale=8192, train_wall=128, wall=240435
2023-01-15 10:36:50 | INFO | train_inner | epoch 093:   1158 / 1978 loss=3.053, nll_loss=0.918, word_ins=2.742, length=3.115, ppl=8.3, wps=45863.9, ups=0.77, wpb=59257.1, bsz=2014.4, num_updates=183100, lr=0.000233698, gnorm=1.244, loss_scale=8192, train_wall=129, wall=240564
2023-01-15 10:38:59 | INFO | train_inner | epoch 093:   1258 / 1978 loss=3.053, nll_loss=0.925, word_ins=2.749, length=3.047, ppl=8.3, wps=46092, ups=0.78, wpb=59319, bsz=2026.6, num_updates=183200, lr=0.000233635, gnorm=1.289, loss_scale=8192, train_wall=128, wall=240693
2023-01-15 10:41:09 | INFO | train_inner | epoch 093:   1358 / 1978 loss=3.024, nll_loss=0.892, word_ins=2.718, length=3.057, ppl=8.13, wps=46071.7, ups=0.77, wpb=59788.8, bsz=2076.8, num_updates=183300, lr=0.000233571, gnorm=1.279, loss_scale=8192, train_wall=129, wall=240823
2023-01-15 10:43:17 | INFO | train_inner | epoch 093:   1458 / 1978 loss=3.042, nll_loss=0.91, word_ins=2.734, length=3.081, ppl=8.24, wps=46127.6, ups=0.78, wpb=59126.5, bsz=2054.5, num_updates=183400, lr=0.000233507, gnorm=1.232, loss_scale=8192, train_wall=128, wall=240951
2023-01-15 10:45:24 | INFO | train_inner | epoch 093:   1558 / 1978 loss=3.051, nll_loss=0.915, word_ins=2.74, length=3.115, ppl=8.29, wps=46455.5, ups=0.78, wpb=59220.9, bsz=1962.8, num_updates=183500, lr=0.000233444, gnorm=1.283, loss_scale=8192, train_wall=127, wall=241078
2023-01-15 10:47:32 | INFO | train_inner | epoch 093:   1658 / 1978 loss=3.069, nll_loss=0.933, word_ins=2.756, length=3.137, ppl=8.39, wps=46338, ups=0.78, wpb=59190.9, bsz=1990.3, num_updates=183600, lr=0.00023338, gnorm=1.297, loss_scale=8192, train_wall=127, wall=241206
2023-01-15 10:49:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 10:49:39 | INFO | train_inner | epoch 093:   1759 / 1978 loss=3.072, nll_loss=0.93, word_ins=2.753, length=3.19, ppl=8.41, wps=46494.2, ups=0.79, wpb=59195.7, bsz=1875.3, num_updates=183700, lr=0.000233316, gnorm=1.312, loss_scale=8192, train_wall=127, wall=241333
2023-01-15 10:51:48 | INFO | train_inner | epoch 093:   1859 / 1978 loss=3.046, nll_loss=0.913, word_ins=2.737, length=3.097, ppl=8.26, wps=46441.5, ups=0.78, wpb=59677.4, bsz=2055.6, num_updates=183800, lr=0.000233253, gnorm=1.243, loss_scale=8192, train_wall=128, wall=241462
2023-01-15 10:53:55 | INFO | train_inner | epoch 093:   1959 / 1978 loss=3.082, nll_loss=0.939, word_ins=2.762, length=3.204, ppl=8.47, wps=46679.3, ups=0.79, wpb=59227.5, bsz=1899.6, num_updates=183900, lr=0.00023319, gnorm=1.293, loss_scale=8192, train_wall=127, wall=241589
2023-01-15 10:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 10:54:32 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 4.57 | nll_loss 1.993 | word_ins 3.753 | length 8.169 | ppl 23.75 | wps 144754 | wpb 40242.5 | bsz 1500 | num_updates 183919 | best_loss 4.422
2023-01-15 10:54:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 10:55:00 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint93.pt (epoch 93 @ 183919 updates, score 4.57) (writing took 27.704438293818384 seconds)
2023-01-15 10:55:00 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2023-01-15 10:55:00 | INFO | train | epoch 093 | loss 3.048 | nll_loss 0.914 | word_ins 2.739 | length 3.091 | ppl 8.27 | wps 45369.4 | ups 0.77 | wpb 59285.6 | bsz 2002.8 | num_updates 183919 | lr 0.000233178 | gnorm 1.273 | loss_scale 8192 | train_wall 2524 | wall 241654
2023-01-15 10:55:00 | INFO | fairseq.trainer | begin training epoch 94
2023-01-15 10:57:01 | INFO | train_inner | epoch 094:     81 / 1978 loss=3.038, nll_loss=0.91, word_ins=2.735, length=3.034, ppl=8.21, wps=31927.4, ups=0.54, wpb=59472.6, bsz=2015.9, num_updates=184000, lr=0.000233126, gnorm=1.278, loss_scale=8192, train_wall=128, wall=241775
2023-01-15 10:59:10 | INFO | train_inner | epoch 094:    181 / 1978 loss=3.046, nll_loss=0.911, word_ins=2.736, length=3.102, ppl=8.26, wps=45847.3, ups=0.77, wpb=59294.7, bsz=2023.2, num_updates=184100, lr=0.000233063, gnorm=1.307, loss_scale=8192, train_wall=129, wall=241905
2023-01-15 11:01:18 | INFO | train_inner | epoch 094:    281 / 1978 loss=3.022, nll_loss=0.895, word_ins=2.722, length=3.006, ppl=8.12, wps=46434.1, ups=0.78, wpb=59392.1, bsz=2042.2, num_updates=184200, lr=0.000233, gnorm=1.275, loss_scale=8192, train_wall=128, wall=242032
2023-01-15 11:03:26 | INFO | train_inner | epoch 094:    381 / 1978 loss=3.041, nll_loss=0.912, word_ins=2.736, length=3.045, ppl=8.23, wps=46655.7, ups=0.78, wpb=59514.5, bsz=2035, num_updates=184300, lr=0.000232936, gnorm=1.265, loss_scale=8192, train_wall=127, wall=242160
2023-01-15 11:05:35 | INFO | train_inner | epoch 094:    481 / 1978 loss=3.032, nll_loss=0.905, word_ins=2.73, length=3.019, ppl=8.18, wps=46247.8, ups=0.77, wpb=59719.1, bsz=2058.8, num_updates=184400, lr=0.000232873, gnorm=1.268, loss_scale=8192, train_wall=129, wall=242289
2023-01-15 11:07:42 | INFO | train_inner | epoch 094:    581 / 1978 loss=3.099, nll_loss=0.956, word_ins=2.776, length=3.23, ppl=8.57, wps=46584.9, ups=0.79, wpb=59192.3, bsz=1870.2, num_updates=184500, lr=0.00023281, gnorm=1.364, loss_scale=8192, train_wall=127, wall=242416
2023-01-15 11:09:51 | INFO | train_inner | epoch 094:    681 / 1978 loss=3.017, nll_loss=0.888, word_ins=2.715, length=3.013, ppl=8.09, wps=46215.9, ups=0.78, wpb=59451.2, bsz=2073.9, num_updates=184600, lr=0.000232747, gnorm=1.22, loss_scale=8192, train_wall=128, wall=242545
2023-01-15 11:11:58 | INFO | train_inner | epoch 094:    781 / 1978 loss=3.061, nll_loss=0.928, word_ins=2.751, length=3.098, ppl=8.34, wps=46472.5, ups=0.79, wpb=59166.5, bsz=1909.8, num_updates=184700, lr=0.000232684, gnorm=1.297, loss_scale=8192, train_wall=127, wall=242672
2023-01-15 11:14:05 | INFO | train_inner | epoch 094:    881 / 1978 loss=3.051, nll_loss=0.916, word_ins=2.74, length=3.113, ppl=8.29, wps=46792.2, ups=0.79, wpb=59565.6, bsz=1946.6, num_updates=184800, lr=0.000232621, gnorm=1.293, loss_scale=8192, train_wall=127, wall=242799
2023-01-15 11:16:13 | INFO | train_inner | epoch 094:    981 / 1978 loss=3.019, nll_loss=0.884, word_ins=2.711, length=3.078, ppl=8.11, wps=46827.4, ups=0.78, wpb=59945, bsz=2018.9, num_updates=184900, lr=0.000232558, gnorm=1.238, loss_scale=8192, train_wall=128, wall=242927
2023-01-15 11:18:21 | INFO | train_inner | epoch 094:   1081 / 1978 loss=3.06, nll_loss=0.922, word_ins=2.746, length=3.136, ppl=8.34, wps=46234, ups=0.79, wpb=58852.5, bsz=1946.7, num_updates=185000, lr=0.000232495, gnorm=1.245, loss_scale=8192, train_wall=127, wall=243055
2023-01-15 11:20:29 | INFO | train_inner | epoch 094:   1181 / 1978 loss=3.062, nll_loss=0.922, word_ins=2.745, length=3.167, ppl=8.35, wps=46367.1, ups=0.78, wpb=59260.3, bsz=1949.5, num_updates=185100, lr=0.000232432, gnorm=1.28, loss_scale=8192, train_wall=128, wall=243183
2023-01-15 11:22:36 | INFO | train_inner | epoch 094:   1281 / 1978 loss=3.045, nll_loss=0.91, word_ins=2.734, length=3.108, ppl=8.25, wps=46728.8, ups=0.79, wpb=59475.4, bsz=1939.3, num_updates=185200, lr=0.00023237, gnorm=1.308, loss_scale=8192, train_wall=127, wall=243310
2023-01-15 11:24:44 | INFO | train_inner | epoch 094:   1381 / 1978 loss=3.022, nll_loss=0.895, word_ins=2.72, length=3.025, ppl=8.12, wps=46719.8, ups=0.78, wpb=59890.4, bsz=2103.8, num_updates=185300, lr=0.000232307, gnorm=1.302, loss_scale=8192, train_wall=128, wall=243438
2023-01-15 11:26:53 | INFO | train_inner | epoch 094:   1481 / 1978 loss=3.046, nll_loss=0.913, word_ins=2.738, length=3.082, ppl=8.26, wps=45745.2, ups=0.78, wpb=58968.4, bsz=2052.7, num_updates=185400, lr=0.000232244, gnorm=1.286, loss_scale=8192, train_wall=129, wall=243567
2023-01-15 11:29:01 | INFO | train_inner | epoch 094:   1581 / 1978 loss=3.049, nll_loss=0.918, word_ins=2.742, length=3.069, ppl=8.27, wps=45920.5, ups=0.78, wpb=58792.8, bsz=2008.2, num_updates=185500, lr=0.000232182, gnorm=1.241, loss_scale=8192, train_wall=128, wall=243695
2023-01-15 11:31:09 | INFO | train_inner | epoch 094:   1681 / 1978 loss=3.027, nll_loss=0.895, word_ins=2.721, length=3.056, ppl=8.15, wps=46457.6, ups=0.78, wpb=59291.4, bsz=2008.7, num_updates=185600, lr=0.000232119, gnorm=1.283, loss_scale=8192, train_wall=127, wall=243823
2023-01-15 11:33:16 | INFO | train_inner | epoch 094:   1781 / 1978 loss=3.065, nll_loss=0.928, word_ins=2.751, length=3.143, ppl=8.37, wps=46060.9, ups=0.79, wpb=58538.8, bsz=1971.9, num_updates=185700, lr=0.000232057, gnorm=1.252, loss_scale=8192, train_wall=127, wall=243950
2023-01-15 11:35:24 | INFO | train_inner | epoch 094:   1881 / 1978 loss=3.043, nll_loss=0.909, word_ins=2.734, length=3.088, ppl=8.24, wps=45850.7, ups=0.78, wpb=58985.5, bsz=2108.3, num_updates=185800, lr=0.000231994, gnorm=1.268, loss_scale=8192, train_wall=128, wall=244078
2023-01-15 11:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 11:37:48 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 4.628 | nll_loss 1.968 | word_ins 3.733 | length 8.954 | ppl 24.73 | wps 147066 | wpb 40242.5 | bsz 1500 | num_updates 185897 | best_loss 4.422
2023-01-15 11:37:48 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 11:38:15 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint94.pt (epoch 94 @ 185897 updates, score 4.628) (writing took 26.875914397649467 seconds)
2023-01-15 11:38:15 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2023-01-15 11:38:15 | INFO | train | epoch 094 | loss 3.046 | nll_loss 0.912 | word_ins 2.737 | length 3.087 | ppl 8.26 | wps 45189.3 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 185897 | lr 0.000231934 | gnorm 1.279 | loss_scale 8192 | train_wall 2527 | wall 244249
2023-01-15 11:38:15 | INFO | fairseq.trainer | begin training epoch 95
2023-01-15 11:38:32 | INFO | train_inner | epoch 095:      3 / 1978 loss=3.059, nll_loss=0.924, word_ins=2.747, length=3.113, ppl=8.33, wps=31385.4, ups=0.53, wpb=58972.7, bsz=1975.1, num_updates=185900, lr=0.000231932, gnorm=1.31, loss_scale=8192, train_wall=128, wall=244266
2023-01-15 11:40:41 | INFO | train_inner | epoch 095:    103 / 1978 loss=3.028, nll_loss=0.903, word_ins=2.729, length=2.997, ppl=8.16, wps=46500.2, ups=0.78, wpb=59854.1, bsz=2005.3, num_updates=186000, lr=0.000231869, gnorm=1.283, loss_scale=8192, train_wall=128, wall=244395
2023-01-15 11:42:48 | INFO | train_inner | epoch 095:    203 / 1978 loss=3.059, nll_loss=0.922, word_ins=2.746, length=3.13, ppl=8.33, wps=46285.1, ups=0.79, wpb=58689, bsz=1934.2, num_updates=186100, lr=0.000231807, gnorm=1.282, loss_scale=8192, train_wall=126, wall=244522
2023-01-15 11:44:56 | INFO | train_inner | epoch 095:    303 / 1978 loss=3.035, nll_loss=0.903, word_ins=2.729, length=3.062, ppl=8.2, wps=46203.8, ups=0.78, wpb=59185, bsz=2000.5, num_updates=186200, lr=0.000231745, gnorm=1.267, loss_scale=8192, train_wall=128, wall=244650
2023-01-15 11:47:04 | INFO | train_inner | epoch 095:    403 / 1978 loss=3.031, nll_loss=0.897, word_ins=2.723, length=3.076, ppl=8.17, wps=46174.8, ups=0.78, wpb=59188.5, bsz=2002.1, num_updates=186300, lr=0.000231683, gnorm=1.275, loss_scale=8192, train_wall=128, wall=244778
2023-01-15 11:49:12 | INFO | train_inner | epoch 095:    503 / 1978 loss=3.048, nll_loss=0.922, word_ins=2.746, length=3.02, ppl=8.27, wps=46262.6, ups=0.78, wpb=59095.2, bsz=2016.3, num_updates=186400, lr=0.000231621, gnorm=1.239, loss_scale=8192, train_wall=127, wall=244906
2023-01-15 11:51:20 | INFO | train_inner | epoch 095:    603 / 1978 loss=3.035, nll_loss=0.908, word_ins=2.733, length=3.025, ppl=8.2, wps=46428.6, ups=0.78, wpb=59377.5, bsz=2076.2, num_updates=186500, lr=0.000231558, gnorm=1.286, loss_scale=8192, train_wall=128, wall=245034
2023-01-15 11:53:28 | INFO | train_inner | epoch 095:    703 / 1978 loss=3.029, nll_loss=0.894, word_ins=2.72, length=3.089, ppl=8.16, wps=45966.3, ups=0.78, wpb=59029.2, bsz=2060.1, num_updates=186600, lr=0.000231496, gnorm=1.21, loss_scale=8192, train_wall=128, wall=245162
2023-01-15 11:55:36 | INFO | train_inner | epoch 095:    803 / 1978 loss=3.044, nll_loss=0.911, word_ins=2.735, length=3.092, ppl=8.25, wps=46748.2, ups=0.78, wpb=59748.9, bsz=1992.9, num_updates=186700, lr=0.000231434, gnorm=1.305, loss_scale=8192, train_wall=128, wall=245290
2023-01-15 11:57:43 | INFO | train_inner | epoch 095:    903 / 1978 loss=3.019, nll_loss=0.881, word_ins=2.708, length=3.109, ppl=8.11, wps=46758.9, ups=0.78, wpb=59568.9, bsz=1999, num_updates=186800, lr=0.000231372, gnorm=1.26, loss_scale=8192, train_wall=127, wall=245418
2023-01-15 11:59:50 | INFO | train_inner | epoch 095:   1003 / 1978 loss=3.062, nll_loss=0.926, word_ins=2.749, length=3.126, ppl=8.35, wps=46483.9, ups=0.79, wpb=59006.9, bsz=1959.3, num_updates=186900, lr=0.000231311, gnorm=1.214, loss_scale=8192, train_wall=127, wall=245544
2023-01-15 12:01:59 | INFO | train_inner | epoch 095:   1103 / 1978 loss=3.049, nll_loss=0.904, word_ins=2.729, length=3.195, ppl=8.28, wps=46002.4, ups=0.78, wpb=59113, bsz=2065, num_updates=187000, lr=0.000231249, gnorm=1.298, loss_scale=8192, train_wall=128, wall=245673
2023-01-15 12:04:06 | INFO | train_inner | epoch 095:   1203 / 1978 loss=3.055, nll_loss=0.92, word_ins=2.744, length=3.109, ppl=8.31, wps=46807.1, ups=0.79, wpb=59375.5, bsz=1921.8, num_updates=187100, lr=0.000231187, gnorm=1.278, loss_scale=8192, train_wall=127, wall=245800
2023-01-15 12:06:14 | INFO | train_inner | epoch 095:   1303 / 1978 loss=3.052, nll_loss=0.917, word_ins=2.741, length=3.115, ppl=8.3, wps=46161.9, ups=0.78, wpb=59237.1, bsz=2023.4, num_updates=187200, lr=0.000231125, gnorm=1.294, loss_scale=8192, train_wall=128, wall=245928
2023-01-15 12:08:22 | INFO | train_inner | epoch 095:   1403 / 1978 loss=3.056, nll_loss=0.921, word_ins=2.744, length=3.121, ppl=8.32, wps=46677.9, ups=0.78, wpb=59677.3, bsz=1970.5, num_updates=187300, lr=0.000231063, gnorm=1.259, loss_scale=8192, train_wall=128, wall=246056
2023-01-15 12:10:30 | INFO | train_inner | epoch 095:   1503 / 1978 loss=3.043, nll_loss=0.908, word_ins=2.733, length=3.097, ppl=8.24, wps=46228, ups=0.78, wpb=59081.2, bsz=1976.6, num_updates=187400, lr=0.000231002, gnorm=1.291, loss_scale=8192, train_wall=128, wall=246184
2023-01-15 12:12:38 | INFO | train_inner | epoch 095:   1603 / 1978 loss=3.049, nll_loss=0.918, word_ins=2.742, length=3.075, ppl=8.28, wps=45852.5, ups=0.78, wpb=58853.4, bsz=2013.6, num_updates=187500, lr=0.00023094, gnorm=1.321, loss_scale=8192, train_wall=128, wall=246312
2023-01-15 12:14:47 | INFO | train_inner | epoch 095:   1703 / 1978 loss=3.046, nll_loss=0.913, word_ins=2.737, length=3.091, ppl=8.26, wps=45943.8, ups=0.78, wpb=59208.4, bsz=2009.4, num_updates=187600, lr=0.000230879, gnorm=1.286, loss_scale=8192, train_wall=128, wall=246441
2023-01-15 12:16:56 | INFO | train_inner | epoch 095:   1803 / 1978 loss=3.071, nll_loss=0.939, word_ins=2.761, length=3.099, ppl=8.41, wps=45962.7, ups=0.78, wpb=59253.4, bsz=1954.6, num_updates=187700, lr=0.000230817, gnorm=1.284, loss_scale=8192, train_wall=129, wall=246570
2023-01-15 12:19:05 | INFO | train_inner | epoch 095:   1903 / 1978 loss=3.025, nll_loss=0.895, word_ins=2.72, length=3.047, ppl=8.14, wps=46313, ups=0.78, wpb=59735.5, bsz=2082.6, num_updates=187800, lr=0.000230756, gnorm=1.313, loss_scale=16384, train_wall=129, wall=246699
2023-01-15 12:19:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 12:20:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 12:20:58 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 4.519 | nll_loss 1.95 | word_ins 3.719 | length 8 | ppl 22.93 | wps 116489 | wpb 40242.5 | bsz 1500 | num_updates 187874 | best_loss 4.422
2023-01-15 12:20:58 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 12:21:24 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint95.pt (epoch 95 @ 187874 updates, score 4.519) (writing took 26.89544590562582 seconds)
2023-01-15 12:21:24 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2023-01-15 12:21:24 | INFO | train | epoch 095 | loss 3.044 | nll_loss 0.91 | word_ins 2.735 | length 3.09 | ppl 8.24 | wps 45263.7 | ups 0.76 | wpb 59282.4 | bsz 2002.8 | num_updates 187874 | lr 0.00023071 | gnorm 1.275 | loss_scale 8192 | train_wall 2526 | wall 246839
2023-01-15 12:21:24 | INFO | fairseq.trainer | begin training epoch 96
2023-01-15 12:22:14 | INFO | train_inner | epoch 096:     26 / 1978 loss=3.046, nll_loss=0.91, word_ins=2.734, length=3.118, ppl=8.26, wps=31372.9, ups=0.53, wpb=59259.9, bsz=1961.9, num_updates=187900, lr=0.000230694, gnorm=1.24, loss_scale=8192, train_wall=129, wall=246888
2023-01-15 12:24:22 | INFO | train_inner | epoch 096:    126 / 1978 loss=3.032, nll_loss=0.9, word_ins=2.727, length=3.05, ppl=8.18, wps=46056.5, ups=0.78, wpb=58965.5, bsz=1991.7, num_updates=188000, lr=0.000230633, gnorm=1.251, loss_scale=8192, train_wall=128, wall=247016
2023-01-15 12:26:31 | INFO | train_inner | epoch 096:    226 / 1978 loss=3.049, nll_loss=0.918, word_ins=2.742, length=3.071, ppl=8.28, wps=46070.7, ups=0.77, wpb=59588.7, bsz=2017.2, num_updates=188100, lr=0.000230571, gnorm=1.28, loss_scale=8192, train_wall=129, wall=247145
2023-01-15 12:28:38 | INFO | train_inner | epoch 096:    326 / 1978 loss=3.055, nll_loss=0.919, word_ins=2.743, length=3.118, ppl=8.31, wps=46456.3, ups=0.79, wpb=58881.5, bsz=1927.9, num_updates=188200, lr=0.00023051, gnorm=1.302, loss_scale=8192, train_wall=126, wall=247272
2023-01-15 12:30:47 | INFO | train_inner | epoch 096:    426 / 1978 loss=3.014, nll_loss=0.881, word_ins=2.708, length=3.053, ppl=8.08, wps=46008.7, ups=0.77, wpb=59415.7, bsz=2058, num_updates=188300, lr=0.000230449, gnorm=1.318, loss_scale=8192, train_wall=129, wall=247401
2023-01-15 12:32:55 | INFO | train_inner | epoch 096:    526 / 1978 loss=3.043, nll_loss=0.909, word_ins=2.734, length=3.094, ppl=8.24, wps=45807, ups=0.78, wpb=58661.4, bsz=2011.9, num_updates=188400, lr=0.000230388, gnorm=1.241, loss_scale=8192, train_wall=128, wall=247529
2023-01-15 12:35:03 | INFO | train_inner | epoch 096:    626 / 1978 loss=3.048, nll_loss=0.916, word_ins=2.741, length=3.074, ppl=8.27, wps=46384.9, ups=0.78, wpb=59360.4, bsz=2009.7, num_updates=188500, lr=0.000230327, gnorm=1.294, loss_scale=8192, train_wall=128, wall=247657
2023-01-15 12:37:13 | INFO | train_inner | epoch 096:    726 / 1978 loss=3.016, nll_loss=0.883, word_ins=2.71, length=3.061, ppl=8.09, wps=45637.7, ups=0.77, wpb=59097.1, bsz=2130.6, num_updates=188600, lr=0.000230266, gnorm=1.246, loss_scale=8192, train_wall=129, wall=247787
2023-01-15 12:39:20 | INFO | train_inner | epoch 096:    826 / 1978 loss=3.056, nll_loss=0.92, word_ins=2.744, length=3.129, ppl=8.32, wps=47139.2, ups=0.79, wpb=59940, bsz=1905.8, num_updates=188700, lr=0.000230205, gnorm=1.343, loss_scale=8192, train_wall=127, wall=247914
2023-01-15 12:41:29 | INFO | train_inner | epoch 096:    926 / 1978 loss=3.041, nll_loss=0.913, word_ins=2.738, length=3.035, ppl=8.23, wps=45961.2, ups=0.78, wpb=59198.3, bsz=2013, num_updates=188800, lr=0.000230144, gnorm=1.25, loss_scale=8192, train_wall=129, wall=248043
2023-01-15 12:43:38 | INFO | train_inner | epoch 096:   1026 / 1978 loss=3.04, nll_loss=0.905, word_ins=2.73, length=3.106, ppl=8.23, wps=46499, ups=0.77, wpb=60001.7, bsz=1971, num_updates=188900, lr=0.000230083, gnorm=1.28, loss_scale=8192, train_wall=129, wall=248172
2023-01-15 12:45:45 | INFO | train_inner | epoch 096:   1126 / 1978 loss=3.032, nll_loss=0.901, word_ins=2.726, length=3.067, ppl=8.18, wps=47039.2, ups=0.79, wpb=59863.2, bsz=1956.6, num_updates=189000, lr=0.000230022, gnorm=1.263, loss_scale=8192, train_wall=127, wall=248299
2023-01-15 12:47:52 | INFO | train_inner | epoch 096:   1226 / 1978 loss=3.057, nll_loss=0.923, word_ins=2.746, length=3.101, ppl=8.32, wps=46509, ups=0.79, wpb=58985.8, bsz=2005.8, num_updates=189100, lr=0.000229961, gnorm=1.264, loss_scale=8192, train_wall=127, wall=248426
2023-01-15 12:50:00 | INFO | train_inner | epoch 096:   1326 / 1978 loss=3.043, nll_loss=0.915, word_ins=2.739, length=3.034, ppl=8.24, wps=46385.1, ups=0.78, wpb=59265.2, bsz=1996, num_updates=189200, lr=0.0002299, gnorm=1.253, loss_scale=8192, train_wall=128, wall=248554
2023-01-15 12:52:08 | INFO | train_inner | epoch 096:   1426 / 1978 loss=3.037, nll_loss=0.907, word_ins=2.731, length=3.058, ppl=8.21, wps=46370.2, ups=0.78, wpb=59744.2, bsz=2029.1, num_updates=189300, lr=0.00022984, gnorm=1.288, loss_scale=8192, train_wall=129, wall=248682
2023-01-15 12:54:16 | INFO | train_inner | epoch 096:   1526 / 1978 loss=3.033, nll_loss=0.896, word_ins=2.722, length=3.105, ppl=8.18, wps=46311.7, ups=0.78, wpb=59054.5, bsz=1993.8, num_updates=189400, lr=0.000229779, gnorm=1.286, loss_scale=8192, train_wall=127, wall=248810
2023-01-15 12:56:25 | INFO | train_inner | epoch 096:   1626 / 1978 loss=3.04, nll_loss=0.908, word_ins=2.732, length=3.079, ppl=8.22, wps=45854.5, ups=0.78, wpb=59112.3, bsz=2042.9, num_updates=189500, lr=0.000229718, gnorm=1.264, loss_scale=8192, train_wall=129, wall=248939
2023-01-15 12:58:33 | INFO | train_inner | epoch 096:   1726 / 1978 loss=3.047, nll_loss=0.912, word_ins=2.736, length=3.113, ppl=8.27, wps=46291.6, ups=0.78, wpb=59157.2, bsz=1990.6, num_updates=189600, lr=0.000229658, gnorm=1.271, loss_scale=8192, train_wall=128, wall=249067
2023-01-15 13:00:40 | INFO | train_inner | epoch 096:   1826 / 1978 loss=3.057, nll_loss=0.921, word_ins=2.744, length=3.121, ppl=8.32, wps=46240.2, ups=0.78, wpb=59011.1, bsz=1996.9, num_updates=189700, lr=0.000229597, gnorm=1.284, loss_scale=8192, train_wall=127, wall=249194
2023-01-15 13:02:48 | INFO | train_inner | epoch 096:   1926 / 1978 loss=3.037, nll_loss=0.907, word_ins=2.731, length=3.061, ppl=8.21, wps=46595.1, ups=0.79, wpb=59304.6, bsz=2012.3, num_updates=189800, lr=0.000229537, gnorm=1.292, loss_scale=8192, train_wall=127, wall=249322
2023-01-15 13:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 13:04:07 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 4.542 | nll_loss 1.965 | word_ins 3.729 | length 8.131 | ppl 23.3 | wps 99895.5 | wpb 40242.5 | bsz 1500 | num_updates 189852 | best_loss 4.422
2023-01-15 13:04:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 13:04:35 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint96.pt (epoch 96 @ 189852 updates, score 4.542) (writing took 27.194559411145747 seconds)
2023-01-15 13:04:35 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2023-01-15 13:04:35 | INFO | train | epoch 096 | loss 3.042 | nll_loss 0.909 | word_ins 2.734 | length 3.08 | ppl 8.23 | wps 45273.2 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 189852 | lr 0.000229505 | gnorm 1.277 | loss_scale 8192 | train_wall 2528 | wall 249429
2023-01-15 13:04:35 | INFO | fairseq.trainer | begin training epoch 97
2023-01-15 13:05:54 | INFO | train_inner | epoch 097:     48 / 1978 loss=3.03, nll_loss=0.9, word_ins=2.725, length=3.048, ppl=8.17, wps=31699, ups=0.54, wpb=59183.6, bsz=2027, num_updates=189900, lr=0.000229476, gnorm=1.285, loss_scale=8192, train_wall=127, wall=249508
2023-01-15 13:08:03 | INFO | train_inner | epoch 097:    148 / 1978 loss=3.018, nll_loss=0.89, word_ins=2.717, length=3.013, ppl=8.1, wps=45942.2, ups=0.78, wpb=59022.4, bsz=2034.2, num_updates=190000, lr=0.000229416, gnorm=1.225, loss_scale=8192, train_wall=128, wall=249637
2023-01-15 13:10:11 | INFO | train_inner | epoch 097:    248 / 1978 loss=3.022, nll_loss=0.887, word_ins=2.714, length=3.08, ppl=8.12, wps=46247.1, ups=0.78, wpb=59199.3, bsz=2016.8, num_updates=190100, lr=0.000229355, gnorm=1.293, loss_scale=8192, train_wall=128, wall=249765
2023-01-15 13:12:19 | INFO | train_inner | epoch 097:    348 / 1978 loss=3.031, nll_loss=0.896, word_ins=2.722, length=3.097, ppl=8.18, wps=46155.1, ups=0.78, wpb=59155, bsz=2032.6, num_updates=190200, lr=0.000229295, gnorm=1.261, loss_scale=8192, train_wall=128, wall=249893
2023-01-15 13:14:28 | INFO | train_inner | epoch 097:    448 / 1978 loss=3.049, nll_loss=0.922, word_ins=2.745, length=3.039, ppl=8.28, wps=46066.6, ups=0.78, wpb=59248.8, bsz=2017.6, num_updates=190300, lr=0.000229235, gnorm=1.206, loss_scale=8192, train_wall=128, wall=250022
2023-01-15 13:16:36 | INFO | train_inner | epoch 097:    548 / 1978 loss=3.039, nll_loss=0.91, word_ins=2.735, length=3.044, ppl=8.22, wps=46106.2, ups=0.78, wpb=59155, bsz=1989.8, num_updates=190400, lr=0.000229175, gnorm=1.271, loss_scale=8192, train_wall=128, wall=250150
2023-01-15 13:18:44 | INFO | train_inner | epoch 097:    648 / 1978 loss=3.037, nll_loss=0.904, word_ins=2.729, length=3.078, ppl=8.21, wps=46156.1, ups=0.78, wpb=59218.8, bsz=2008.1, num_updates=190500, lr=0.000229114, gnorm=1.265, loss_scale=8192, train_wall=128, wall=250278
2023-01-15 13:20:52 | INFO | train_inner | epoch 097:    748 / 1978 loss=3.026, nll_loss=0.891, word_ins=2.717, length=3.084, ppl=8.14, wps=46035.8, ups=0.78, wpb=58752.5, bsz=2036.1, num_updates=190600, lr=0.000229054, gnorm=1.286, loss_scale=8192, train_wall=127, wall=250406
2023-01-15 13:22:59 | INFO | train_inner | epoch 097:    848 / 1978 loss=3.036, nll_loss=0.905, word_ins=2.73, length=3.061, ppl=8.2, wps=46383.3, ups=0.78, wpb=59128, bsz=1986.6, num_updates=190700, lr=0.000228994, gnorm=1.248, loss_scale=8192, train_wall=127, wall=250533
2023-01-15 13:25:07 | INFO | train_inner | epoch 097:    948 / 1978 loss=3.01, nll_loss=0.883, word_ins=2.71, length=3.007, ppl=8.06, wps=46765.9, ups=0.78, wpb=59759.5, bsz=2060.2, num_updates=190800, lr=0.000228934, gnorm=1.245, loss_scale=8192, train_wall=128, wall=250661
2023-01-15 13:27:14 | INFO | train_inner | epoch 097:   1048 / 1978 loss=3.056, nll_loss=0.924, word_ins=2.747, length=3.087, ppl=8.31, wps=46703.9, ups=0.79, wpb=59309.1, bsz=1981.6, num_updates=190900, lr=0.000228874, gnorm=1.337, loss_scale=8192, train_wall=127, wall=250788
2023-01-15 13:29:22 | INFO | train_inner | epoch 097:   1148 / 1978 loss=3.046, nll_loss=0.91, word_ins=2.734, length=3.119, ppl=8.26, wps=46688.3, ups=0.78, wpb=59570.9, bsz=2032.3, num_updates=191000, lr=0.000228814, gnorm=1.313, loss_scale=8192, train_wall=127, wall=250916
2023-01-15 13:31:29 | INFO | train_inner | epoch 097:   1248 / 1978 loss=3.04, nll_loss=0.912, word_ins=2.736, length=3.036, ppl=8.22, wps=46388, ups=0.78, wpb=59281.1, bsz=2045.4, num_updates=191100, lr=0.000228755, gnorm=1.284, loss_scale=8192, train_wall=128, wall=251044
2023-01-15 13:33:37 | INFO | train_inner | epoch 097:   1348 / 1978 loss=3.042, nll_loss=0.906, word_ins=2.731, length=3.106, ppl=8.24, wps=46712.4, ups=0.79, wpb=59430, bsz=1954.8, num_updates=191200, lr=0.000228695, gnorm=1.273, loss_scale=8192, train_wall=127, wall=251171
2023-01-15 13:35:44 | INFO | train_inner | epoch 097:   1448 / 1978 loss=3.064, nll_loss=0.933, word_ins=2.755, length=3.094, ppl=8.37, wps=46922.8, ups=0.78, wpb=59847.1, bsz=1938.8, num_updates=191300, lr=0.000228635, gnorm=1.343, loss_scale=8192, train_wall=127, wall=251298
2023-01-15 13:37:53 | INFO | train_inner | epoch 097:   1548 / 1978 loss=3.037, nll_loss=0.902, word_ins=2.727, length=3.098, ppl=8.21, wps=46170.9, ups=0.78, wpb=59298.6, bsz=1982.6, num_updates=191400, lr=0.000228575, gnorm=1.271, loss_scale=8192, train_wall=128, wall=251427
2023-01-15 13:40:00 | INFO | train_inner | epoch 097:   1648 / 1978 loss=3.051, nll_loss=0.921, word_ins=2.744, length=3.075, ppl=8.29, wps=46742.3, ups=0.79, wpb=59429.8, bsz=1971, num_updates=191500, lr=0.000228515, gnorm=1.277, loss_scale=8192, train_wall=127, wall=251554
2023-01-15 13:42:06 | INFO | train_inner | epoch 097:   1748 / 1978 loss=3.043, nll_loss=0.906, word_ins=2.731, length=3.123, ppl=8.24, wps=46557.9, ups=0.79, wpb=58891.2, bsz=1965.5, num_updates=191600, lr=0.000228456, gnorm=1.244, loss_scale=8192, train_wall=126, wall=251680
2023-01-15 13:44:14 | INFO | train_inner | epoch 097:   1848 / 1978 loss=3.055, nll_loss=0.919, word_ins=2.742, length=3.125, ppl=8.31, wps=46046.3, ups=0.78, wpb=58696, bsz=1963.2, num_updates=191700, lr=0.000228396, gnorm=1.271, loss_scale=8192, train_wall=127, wall=251808
2023-01-15 13:46:22 | INFO | train_inner | epoch 097:   1948 / 1978 loss=3.04, nll_loss=0.908, word_ins=2.732, length=3.078, ppl=8.23, wps=46791.9, ups=0.78, wpb=59738.7, bsz=1992.6, num_updates=191800, lr=0.000228337, gnorm=1.288, loss_scale=8192, train_wall=127, wall=251936
2023-01-15 13:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 13:47:16 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 4.65 | nll_loss 1.99 | word_ins 3.754 | length 8.965 | ppl 25.11 | wps 108352 | wpb 40242.5 | bsz 1500 | num_updates 191830 | best_loss 4.422
2023-01-15 13:47:16 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 13:47:45 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint97.pt (epoch 97 @ 191830 updates, score 4.65) (writing took 28.567467383109033 seconds)
2023-01-15 13:47:45 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2023-01-15 13:47:45 | INFO | train | epoch 097 | loss 3.038 | nll_loss 0.905 | word_ins 2.73 | length 3.074 | ppl 8.21 | wps 45269.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 191830 | lr 0.000228319 | gnorm 1.273 | loss_scale 8192 | train_wall 2523 | wall 252019
2023-01-15 13:47:45 | INFO | fairseq.trainer | begin training epoch 98
2023-01-15 13:49:27 | INFO | train_inner | epoch 098:     70 / 1978 loss=3.036, nll_loss=0.9, word_ins=2.726, length=3.098, ppl=8.2, wps=32040.8, ups=0.54, wpb=59350.8, bsz=1998.9, num_updates=191900, lr=0.000228277, gnorm=1.238, loss_scale=8192, train_wall=129, wall=252121
2023-01-15 13:51:35 | INFO | train_inner | epoch 098:    170 / 1978 loss=3.002, nll_loss=0.877, word_ins=2.705, length=2.968, ppl=8.01, wps=46672.9, ups=0.78, wpb=59752.6, bsz=2034.7, num_updates=192000, lr=0.000228218, gnorm=1.257, loss_scale=16384, train_wall=128, wall=252249
2023-01-15 13:52:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 13:53:45 | INFO | train_inner | epoch 098:    271 / 1978 loss=3.035, nll_loss=0.903, word_ins=2.729, length=3.06, ppl=8.2, wps=45692, ups=0.77, wpb=59448, bsz=2025.5, num_updates=192100, lr=0.000228158, gnorm=1.302, loss_scale=8192, train_wall=130, wall=252379
2023-01-15 13:55:52 | INFO | train_inner | epoch 098:    371 / 1978 loss=3.052, nll_loss=0.914, word_ins=2.739, length=3.133, ppl=8.29, wps=46647.2, ups=0.79, wpb=59113.5, bsz=1967.3, num_updates=192200, lr=0.000228099, gnorm=1.285, loss_scale=8192, train_wall=126, wall=252506
2023-01-15 13:58:00 | INFO | train_inner | epoch 098:    471 / 1978 loss=3.041, nll_loss=0.908, word_ins=2.733, length=3.076, ppl=8.23, wps=46210.7, ups=0.78, wpb=59143.6, bsz=2015.6, num_updates=192300, lr=0.00022804, gnorm=1.272, loss_scale=8192, train_wall=128, wall=252634
2023-01-15 14:00:09 | INFO | train_inner | epoch 098:    571 / 1978 loss=3.032, nll_loss=0.901, word_ins=2.726, length=3.052, ppl=8.18, wps=46016.5, ups=0.78, wpb=59355.1, bsz=2053.8, num_updates=192400, lr=0.00022798, gnorm=1.291, loss_scale=8192, train_wall=129, wall=252763
2023-01-15 14:02:15 | INFO | train_inner | epoch 098:    671 / 1978 loss=3.037, nll_loss=0.903, word_ins=2.728, length=3.095, ppl=8.21, wps=46861.6, ups=0.79, wpb=59342.9, bsz=1947.1, num_updates=192500, lr=0.000227921, gnorm=1.306, loss_scale=8192, train_wall=126, wall=252889
2023-01-15 14:04:23 | INFO | train_inner | epoch 098:    771 / 1978 loss=3.019, nll_loss=0.886, word_ins=2.712, length=3.067, ppl=8.1, wps=47103.4, ups=0.79, wpb=59966.8, bsz=2040.5, num_updates=192600, lr=0.000227862, gnorm=1.277, loss_scale=8192, train_wall=127, wall=253017
2023-01-15 14:06:29 | INFO | train_inner | epoch 098:    871 / 1978 loss=3.042, nll_loss=0.908, word_ins=2.733, length=3.093, ppl=8.24, wps=46556.4, ups=0.79, wpb=58840.7, bsz=1987.4, num_updates=192700, lr=0.000227803, gnorm=1.28, loss_scale=8192, train_wall=126, wall=253143
2023-01-15 14:08:37 | INFO | train_inner | epoch 098:    971 / 1978 loss=3.052, nll_loss=0.923, word_ins=2.747, length=3.051, ppl=8.3, wps=45712.1, ups=0.78, wpb=58734.1, bsz=2045.3, num_updates=192800, lr=0.000227744, gnorm=1.261, loss_scale=8192, train_wall=128, wall=253272
2023-01-15 14:10:45 | INFO | train_inner | epoch 098:   1071 / 1978 loss=3.022, nll_loss=0.889, word_ins=2.715, length=3.066, ppl=8.12, wps=46609.7, ups=0.78, wpb=59519.6, bsz=2063.3, num_updates=192900, lr=0.000227685, gnorm=1.272, loss_scale=8192, train_wall=127, wall=253399
2023-01-15 14:12:52 | INFO | train_inner | epoch 098:   1171 / 1978 loss=3.033, nll_loss=0.898, word_ins=2.724, length=3.093, ppl=8.18, wps=46406, ups=0.79, wpb=59016.7, bsz=1988.2, num_updates=193000, lr=0.000227626, gnorm=1.248, loss_scale=8192, train_wall=127, wall=253526
2023-01-15 14:15:01 | INFO | train_inner | epoch 098:   1271 / 1978 loss=3.026, nll_loss=0.896, word_ins=2.722, length=3.042, ppl=8.15, wps=46136.4, ups=0.78, wpb=59244, bsz=2017.8, num_updates=193100, lr=0.000227567, gnorm=1.239, loss_scale=8192, train_wall=128, wall=253655
2023-01-15 14:17:09 | INFO | train_inner | epoch 098:   1371 / 1978 loss=3.039, nll_loss=0.906, word_ins=2.73, length=3.09, ppl=8.22, wps=46345.4, ups=0.78, wpb=59248, bsz=1957.9, num_updates=193200, lr=0.000227508, gnorm=1.308, loss_scale=8192, train_wall=128, wall=253783
2023-01-15 14:19:16 | INFO | train_inner | epoch 098:   1471 / 1978 loss=3.056, nll_loss=0.921, word_ins=2.745, length=3.114, ppl=8.32, wps=46090.8, ups=0.78, wpb=58747.5, bsz=1962.7, num_updates=193300, lr=0.000227449, gnorm=1.276, loss_scale=8192, train_wall=127, wall=253910
2023-01-15 14:21:24 | INFO | train_inner | epoch 098:   1571 / 1978 loss=3.033, nll_loss=0.9, word_ins=2.725, length=3.085, ppl=8.19, wps=46903.3, ups=0.78, wpb=59875.3, bsz=2024.3, num_updates=193400, lr=0.00022739, gnorm=1.288, loss_scale=8192, train_wall=127, wall=254038
2023-01-15 14:23:32 | INFO | train_inner | epoch 098:   1671 / 1978 loss=3.007, nll_loss=0.881, word_ins=2.708, length=2.996, ppl=8.04, wps=46422.4, ups=0.78, wpb=59445.1, bsz=2057, num_updates=193500, lr=0.000227331, gnorm=1.26, loss_scale=8192, train_wall=128, wall=254166
2023-01-15 14:25:38 | INFO | train_inner | epoch 098:   1771 / 1978 loss=3.071, nll_loss=0.932, word_ins=2.754, length=3.163, ppl=8.4, wps=46741.9, ups=0.79, wpb=59064.8, bsz=1881.1, num_updates=193600, lr=0.000227273, gnorm=1.333, loss_scale=8192, train_wall=126, wall=254292
2023-01-15 14:27:46 | INFO | train_inner | epoch 098:   1871 / 1978 loss=3.05, nll_loss=0.922, word_ins=2.746, length=3.045, ppl=8.28, wps=46769.9, ups=0.78, wpb=59745.8, bsz=2018.8, num_updates=193700, lr=0.000227214, gnorm=1.275, loss_scale=8192, train_wall=128, wall=254420
2023-01-15 14:29:54 | INFO | train_inner | epoch 098:   1971 / 1978 loss=3.049, nll_loss=0.917, word_ins=2.74, length=3.083, ppl=8.27, wps=46063.2, ups=0.78, wpb=58952.8, bsz=1979.1, num_updates=193800, lr=0.000227155, gnorm=1.243, loss_scale=8192, train_wall=128, wall=254548
2023-01-15 14:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 14:30:16 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 4.575 | nll_loss 1.974 | word_ins 3.738 | length 8.372 | ppl 23.83 | wps 99675.5 | wpb 40242.5 | bsz 1500 | num_updates 193807 | best_loss 4.422
2023-01-15 14:30:16 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 14:30:44 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint98.pt (epoch 98 @ 193807 updates, score 4.575) (writing took 28.78504429431632 seconds)
2023-01-15 14:30:44 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2023-01-15 14:30:44 | INFO | train | epoch 098 | loss 3.037 | nll_loss 0.905 | word_ins 2.73 | length 3.074 | ppl 8.21 | wps 45436.2 | ups 0.77 | wpb 59282.2 | bsz 2002.5 | num_updates 193807 | lr 0.000227151 | gnorm 1.277 | loss_scale 8192 | train_wall 2521 | wall 254598
2023-01-15 14:30:44 | INFO | fairseq.trainer | begin training epoch 99
2023-01-15 14:32:56 | INFO | train_inner | epoch 099:     93 / 1978 loss=3.045, nll_loss=0.914, word_ins=2.738, length=3.069, ppl=8.25, wps=32309.8, ups=0.55, wpb=58993, bsz=1969.5, num_updates=193900, lr=0.000227097, gnorm=1.334, loss_scale=8192, train_wall=127, wall=254731
2023-01-15 14:35:05 | INFO | train_inner | epoch 099:    193 / 1978 loss=2.999, nll_loss=0.873, word_ins=2.701, length=2.986, ppl=8, wps=46356.9, ups=0.78, wpb=59543.6, bsz=2019.5, num_updates=194000, lr=0.000227038, gnorm=1.308, loss_scale=8192, train_wall=128, wall=254859
2023-01-15 14:37:13 | INFO | train_inner | epoch 099:    293 / 1978 loss=3.059, nll_loss=0.924, word_ins=2.748, length=3.116, ppl=8.34, wps=46003.2, ups=0.78, wpb=58810.1, bsz=1918.5, num_updates=194100, lr=0.00022698, gnorm=1.3, loss_scale=8192, train_wall=128, wall=254987
2023-01-15 14:39:21 | INFO | train_inner | epoch 099:    393 / 1978 loss=3.027, nll_loss=0.895, word_ins=2.721, length=3.061, ppl=8.15, wps=45797.8, ups=0.78, wpb=58849.8, bsz=2033.6, num_updates=194200, lr=0.000226921, gnorm=1.279, loss_scale=8192, train_wall=128, wall=255115
2023-01-15 14:41:29 | INFO | train_inner | epoch 099:    493 / 1978 loss=3.042, nll_loss=0.913, word_ins=2.737, length=3.049, ppl=8.23, wps=46693.4, ups=0.78, wpb=59672.1, bsz=2006.6, num_updates=194300, lr=0.000226863, gnorm=1.262, loss_scale=8192, train_wall=128, wall=255243
2023-01-15 14:43:37 | INFO | train_inner | epoch 099:    593 / 1978 loss=3.01, nll_loss=0.882, word_ins=2.709, length=3.009, ppl=8.06, wps=45987.1, ups=0.78, wpb=58924.6, bsz=2067.7, num_updates=194400, lr=0.000226805, gnorm=1.227, loss_scale=8192, train_wall=128, wall=255371
2023-01-15 14:45:45 | INFO | train_inner | epoch 099:    693 / 1978 loss=3.051, nll_loss=0.926, word_ins=2.749, length=3.02, ppl=8.29, wps=46685.5, ups=0.78, wpb=59559.3, bsz=1963.8, num_updates=194500, lr=0.000226746, gnorm=1.261, loss_scale=8192, train_wall=127, wall=255499
2023-01-15 14:47:53 | INFO | train_inner | epoch 099:    793 / 1978 loss=3.046, nll_loss=0.914, word_ins=2.738, length=3.079, ppl=8.26, wps=46175.4, ups=0.78, wpb=59397.7, bsz=2052.1, num_updates=194600, lr=0.000226688, gnorm=1.289, loss_scale=8192, train_wall=128, wall=255627
2023-01-15 14:50:01 | INFO | train_inner | epoch 099:    893 / 1978 loss=3.03, nll_loss=0.897, word_ins=2.723, length=3.079, ppl=8.17, wps=46193.1, ups=0.78, wpb=59120.5, bsz=1932, num_updates=194700, lr=0.00022663, gnorm=1.32, loss_scale=8192, train_wall=128, wall=255755
2023-01-15 14:52:10 | INFO | train_inner | epoch 099:    993 / 1978 loss=3.019, nll_loss=0.888, word_ins=2.715, length=3.043, ppl=8.1, wps=46241.2, ups=0.78, wpb=59612.8, bsz=2052.1, num_updates=194800, lr=0.000226572, gnorm=1.283, loss_scale=8192, train_wall=129, wall=255884
2023-01-15 14:54:21 | INFO | train_inner | epoch 099:   1093 / 1978 loss=3.011, nll_loss=0.882, word_ins=2.708, length=3.024, ppl=8.06, wps=45725, ups=0.77, wpb=59546.4, bsz=2114.7, num_updates=194900, lr=0.000226513, gnorm=1.252, loss_scale=8192, train_wall=130, wall=256015
2023-01-15 14:56:29 | INFO | train_inner | epoch 099:   1193 / 1978 loss=3.024, nll_loss=0.891, word_ins=2.717, length=3.07, ppl=8.13, wps=46006.4, ups=0.78, wpb=59263.1, bsz=2014, num_updates=195000, lr=0.000226455, gnorm=1.272, loss_scale=8192, train_wall=129, wall=256144
2023-01-15 14:58:38 | INFO | train_inner | epoch 099:   1293 / 1978 loss=3.033, nll_loss=0.905, word_ins=2.73, length=3.035, ppl=8.19, wps=46127, ups=0.77, wpb=59527.7, bsz=2003.4, num_updates=195100, lr=0.000226397, gnorm=1.217, loss_scale=8192, train_wall=129, wall=256273
2023-01-15 15:00:46 | INFO | train_inner | epoch 099:   1393 / 1978 loss=3.052, nll_loss=0.913, word_ins=2.738, length=3.14, ppl=8.29, wps=46417.2, ups=0.78, wpb=59198.1, bsz=1922, num_updates=195200, lr=0.000226339, gnorm=1.3, loss_scale=8192, train_wall=127, wall=256400
2023-01-15 15:02:55 | INFO | train_inner | epoch 099:   1493 / 1978 loss=3.035, nll_loss=0.903, word_ins=2.728, length=3.069, ppl=8.2, wps=46103.3, ups=0.78, wpb=59248, bsz=2069.6, num_updates=195300, lr=0.000226281, gnorm=1.273, loss_scale=8192, train_wall=128, wall=256529
2023-01-15 15:05:02 | INFO | train_inner | epoch 099:   1593 / 1978 loss=3.053, nll_loss=0.919, word_ins=2.742, length=3.114, ppl=8.3, wps=46607.7, ups=0.78, wpb=59408.6, bsz=1928.2, num_updates=195400, lr=0.000226224, gnorm=1.335, loss_scale=8192, train_wall=127, wall=256656
2023-01-15 15:07:09 | INFO | train_inner | epoch 099:   1693 / 1978 loss=3.084, nll_loss=0.948, word_ins=2.769, length=3.157, ppl=8.48, wps=46489.4, ups=0.79, wpb=59029.1, bsz=1939.6, num_updates=195500, lr=0.000226166, gnorm=1.295, loss_scale=8192, train_wall=127, wall=256783
2023-01-15 15:09:18 | INFO | train_inner | epoch 099:   1793 / 1978 loss=3.019, nll_loss=0.885, word_ins=2.711, length=3.079, ppl=8.1, wps=46224.2, ups=0.78, wpb=59421.1, bsz=2033.1, num_updates=195600, lr=0.000226108, gnorm=1.25, loss_scale=8192, train_wall=128, wall=256912
2023-01-15 15:11:26 | INFO | train_inner | epoch 099:   1893 / 1978 loss=3.038, nll_loss=0.904, word_ins=2.729, length=3.092, ppl=8.21, wps=46202.5, ups=0.78, wpb=59330.7, bsz=2017.7, num_updates=195700, lr=0.00022605, gnorm=1.256, loss_scale=8192, train_wall=128, wall=257040
2023-01-15 15:13:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 15:13:30 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 4.592 | nll_loss 1.973 | word_ins 3.737 | length 8.538 | ppl 24.11 | wps 135986 | wpb 40242.5 | bsz 1500 | num_updates 195785 | best_loss 4.422
2023-01-15 15:13:30 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 15:13:58 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint99.pt (epoch 99 @ 195785 updates, score 4.592) (writing took 27.636167284101248 seconds)
2023-01-15 15:13:58 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2023-01-15 15:13:58 | INFO | train | epoch 099 | loss 3.036 | nll_loss 0.904 | word_ins 2.729 | length 3.07 | ppl 8.2 | wps 45218.5 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 195785 | lr 0.000226001 | gnorm 1.279 | loss_scale 8192 | train_wall 2531 | wall 257192
2023-01-15 15:13:58 | INFO | fairseq.trainer | begin training epoch 100
2023-01-15 15:14:32 | INFO | train_inner | epoch 100:     15 / 1978 loss=3.035, nll_loss=0.903, word_ins=2.728, length=3.072, ppl=8.2, wps=31835.4, ups=0.54, wpb=59144.1, bsz=1997.9, num_updates=195800, lr=0.000225992, gnorm=1.269, loss_scale=8192, train_wall=127, wall=257226
2023-01-15 15:16:40 | INFO | train_inner | epoch 100:    115 / 1978 loss=2.998, nll_loss=0.873, word_ins=2.701, length=2.974, ppl=7.99, wps=46529.7, ups=0.78, wpb=59562.9, bsz=2015.7, num_updates=195900, lr=0.000225935, gnorm=1.272, loss_scale=8192, train_wall=128, wall=257354
2023-01-15 15:18:48 | INFO | train_inner | epoch 100:    215 / 1978 loss=3.019, nll_loss=0.887, word_ins=2.713, length=3.057, ppl=8.11, wps=46219.1, ups=0.78, wpb=59268.3, bsz=2022.2, num_updates=196000, lr=0.000225877, gnorm=1.272, loss_scale=8192, train_wall=128, wall=257482
2023-01-15 15:20:55 | INFO | train_inner | epoch 100:    315 / 1978 loss=3.044, nll_loss=0.906, word_ins=2.731, length=3.135, ppl=8.25, wps=46549, ups=0.79, wpb=59180.9, bsz=1948.2, num_updates=196100, lr=0.000225819, gnorm=1.247, loss_scale=8192, train_wall=127, wall=257609
2023-01-15 15:23:03 | INFO | train_inner | epoch 100:    415 / 1978 loss=3.033, nll_loss=0.899, word_ins=2.725, length=3.085, ppl=8.19, wps=45704.4, ups=0.78, wpb=58492.1, bsz=1986.8, num_updates=196200, lr=0.000225762, gnorm=1.294, loss_scale=16384, train_wall=128, wall=257737
2023-01-15 15:23:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 15:25:12 | INFO | train_inner | epoch 100:    516 / 1978 loss=3.025, nll_loss=0.889, word_ins=2.716, length=3.097, ppl=8.14, wps=46050.1, ups=0.77, wpb=59509.3, bsz=1978.7, num_updates=196300, lr=0.000225704, gnorm=1.31, loss_scale=8192, train_wall=129, wall=257867
2023-01-15 15:27:22 | INFO | train_inner | epoch 100:    616 / 1978 loss=3.008, nll_loss=0.881, word_ins=2.708, length=3.002, ppl=8.04, wps=46003.1, ups=0.77, wpb=59501, bsz=2114, num_updates=196400, lr=0.000225647, gnorm=1.267, loss_scale=8192, train_wall=129, wall=257996
2023-01-15 15:29:31 | INFO | train_inner | epoch 100:    716 / 1978 loss=3.016, nll_loss=0.886, word_ins=2.713, length=3.037, ppl=8.09, wps=46456.3, ups=0.77, wpb=59987.3, bsz=2043.6, num_updates=196500, lr=0.000225589, gnorm=1.314, loss_scale=8192, train_wall=129, wall=258125
2023-01-15 15:31:40 | INFO | train_inner | epoch 100:    816 / 1978 loss=3.029, nll_loss=0.9, word_ins=2.725, length=3.046, ppl=8.17, wps=45833.4, ups=0.78, wpb=59032, bsz=2045.9, num_updates=196600, lr=0.000225532, gnorm=1.274, loss_scale=8192, train_wall=128, wall=258254
2023-01-15 15:33:47 | INFO | train_inner | epoch 100:    916 / 1978 loss=3.018, nll_loss=0.886, word_ins=2.712, length=3.064, ppl=8.1, wps=46734.8, ups=0.79, wpb=59323.3, bsz=1966.1, num_updates=196700, lr=0.000225475, gnorm=1.282, loss_scale=8192, train_wall=127, wall=258381
2023-01-15 15:35:54 | INFO | train_inner | epoch 100:   1016 / 1978 loss=3.043, nll_loss=0.912, word_ins=2.735, length=3.079, ppl=8.24, wps=46512.6, ups=0.78, wpb=59292.8, bsz=1985.4, num_updates=196800, lr=0.000225417, gnorm=1.256, loss_scale=8192, train_wall=127, wall=258508
2023-01-15 15:38:03 | INFO | train_inner | epoch 100:   1116 / 1978 loss=3.036, nll_loss=0.909, word_ins=2.734, length=3.027, ppl=8.2, wps=45847.1, ups=0.78, wpb=59029.2, bsz=2009.3, num_updates=196900, lr=0.00022536, gnorm=1.287, loss_scale=8192, train_wall=128, wall=258637
2023-01-15 15:40:11 | INFO | train_inner | epoch 100:   1216 / 1978 loss=3.032, nll_loss=0.899, word_ins=2.724, length=3.076, ppl=8.18, wps=46326, ups=0.78, wpb=59287.6, bsz=2037.8, num_updates=197000, lr=0.000225303, gnorm=1.283, loss_scale=8192, train_wall=128, wall=258765
2023-01-15 15:42:20 | INFO | train_inner | epoch 100:   1316 / 1978 loss=3.047, nll_loss=0.919, word_ins=2.743, length=3.046, ppl=8.27, wps=46281.3, ups=0.78, wpb=59601.5, bsz=1968.1, num_updates=197100, lr=0.000225246, gnorm=1.333, loss_scale=8192, train_wall=128, wall=258894
2023-01-15 15:44:28 | INFO | train_inner | epoch 100:   1416 / 1978 loss=3.055, nll_loss=0.92, word_ins=2.743, length=3.123, ppl=8.31, wps=45855.5, ups=0.78, wpb=58846.8, bsz=1967.4, num_updates=197200, lr=0.000225189, gnorm=1.308, loss_scale=8192, train_wall=128, wall=259022
2023-01-15 15:46:37 | INFO | train_inner | epoch 100:   1516 / 1978 loss=3.033, nll_loss=0.905, word_ins=2.729, length=3.042, ppl=8.19, wps=46045.2, ups=0.77, wpb=59548.2, bsz=2040.7, num_updates=197300, lr=0.000225132, gnorm=1.313, loss_scale=8192, train_wall=129, wall=259151
2023-01-15 15:48:46 | INFO | train_inner | epoch 100:   1616 / 1978 loss=3.039, nll_loss=0.907, word_ins=2.731, length=3.081, ppl=8.22, wps=46167.7, ups=0.78, wpb=59544.6, bsz=2023.8, num_updates=197400, lr=0.000225075, gnorm=1.286, loss_scale=8192, train_wall=129, wall=259280
2023-01-15 15:50:54 | INFO | train_inner | epoch 100:   1716 / 1978 loss=3.066, nll_loss=0.932, word_ins=2.755, length=3.11, ppl=8.37, wps=46088.1, ups=0.78, wpb=58787, bsz=1920.2, num_updates=197500, lr=0.000225018, gnorm=1.312, loss_scale=8192, train_wall=127, wall=259408
2023-01-15 15:53:01 | INFO | train_inner | epoch 100:   1816 / 1978 loss=3.052, nll_loss=0.921, word_ins=2.744, length=3.078, ppl=8.29, wps=46634.1, ups=0.79, wpb=59310.5, bsz=1973.4, num_updates=197600, lr=0.000224961, gnorm=1.258, loss_scale=8192, train_wall=127, wall=259535
2023-01-15 15:55:09 | INFO | train_inner | epoch 100:   1916 / 1978 loss=3.035, nll_loss=0.899, word_ins=2.725, length=3.105, ppl=8.2, wps=46113, ups=0.78, wpb=59083.8, bsz=2038.4, num_updates=197700, lr=0.000224904, gnorm=1.239, loss_scale=8192, train_wall=128, wall=259663
2023-01-15 15:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 15:56:44 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 4.644 | nll_loss 1.99 | word_ins 3.755 | length 8.884 | ppl 25 | wps 126997 | wpb 40242.5 | bsz 1500 | num_updates 197762 | best_loss 4.422
2023-01-15 15:56:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 15:57:10 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint100.pt (epoch 100 @ 197762 updates, score 4.644) (writing took 26.329327427316457 seconds)
2023-01-15 15:57:10 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2023-01-15 15:57:10 | INFO | train | epoch 100 | loss 3.033 | nll_loss 0.901 | word_ins 2.726 | length 3.066 | ppl 8.18 | wps 45210.7 | ups 0.76 | wpb 59283 | bsz 2002.5 | num_updates 197762 | lr 0.000224868 | gnorm 1.284 | loss_scale 8192 | train_wall 2529 | wall 259784
2023-01-15 15:57:10 | INFO | fairseq.trainer | begin training epoch 101
2023-01-15 15:58:14 | INFO | train_inner | epoch 101:     38 / 1978 loss=3.013, nll_loss=0.882, word_ins=2.709, length=3.041, ppl=8.07, wps=32093.5, ups=0.54, wpb=59310.5, bsz=2002.3, num_updates=197800, lr=0.000224847, gnorm=1.255, loss_scale=8192, train_wall=127, wall=259848
2023-01-15 16:00:22 | INFO | train_inner | epoch 101:    138 / 1978 loss=3.007, nll_loss=0.873, word_ins=2.701, length=3.057, ppl=8.04, wps=46450.2, ups=0.78, wpb=59228.4, bsz=2031, num_updates=197900, lr=0.00022479, gnorm=1.253, loss_scale=8192, train_wall=127, wall=259976
2023-01-15 16:02:30 | INFO | train_inner | epoch 101:    238 / 1978 loss=3.038, nll_loss=0.906, word_ins=2.731, length=3.068, ppl=8.21, wps=45684.6, ups=0.78, wpb=58844.1, bsz=1960.8, num_updates=198000, lr=0.000224733, gnorm=1.252, loss_scale=8192, train_wall=129, wall=260104
2023-01-15 16:04:39 | INFO | train_inner | epoch 101:    338 / 1978 loss=3.039, nll_loss=0.907, word_ins=2.732, length=3.078, ppl=8.22, wps=46105.8, ups=0.78, wpb=59106.8, bsz=1913, num_updates=198100, lr=0.000224677, gnorm=1.257, loss_scale=8192, train_wall=128, wall=260233
2023-01-15 16:06:47 | INFO | train_inner | epoch 101:    438 / 1978 loss=3.007, nll_loss=0.876, word_ins=2.703, length=3.04, ppl=8.04, wps=46377.3, ups=0.78, wpb=59638.2, bsz=2077.4, num_updates=198200, lr=0.00022462, gnorm=1.281, loss_scale=8192, train_wall=128, wall=260361
2023-01-15 16:08:56 | INFO | train_inner | epoch 101:    538 / 1978 loss=3.022, nll_loss=0.894, word_ins=2.72, length=3.013, ppl=8.12, wps=45741.9, ups=0.77, wpb=59071.8, bsz=2039.4, num_updates=198300, lr=0.000224563, gnorm=1.276, loss_scale=8192, train_wall=129, wall=260490
2023-01-15 16:11:05 | INFO | train_inner | epoch 101:    638 / 1978 loss=3.012, nll_loss=0.884, word_ins=2.711, length=3.01, ppl=8.07, wps=46004.8, ups=0.78, wpb=59354.3, bsz=2037.3, num_updates=198400, lr=0.000224507, gnorm=1.282, loss_scale=8192, train_wall=129, wall=260619
2023-01-15 16:13:14 | INFO | train_inner | epoch 101:    738 / 1978 loss=3.045, nll_loss=0.912, word_ins=2.736, length=3.084, ppl=8.25, wps=46112.8, ups=0.78, wpb=59251.5, bsz=1977.5, num_updates=198500, lr=0.00022445, gnorm=1.297, loss_scale=8192, train_wall=128, wall=260748
2023-01-15 16:15:22 | INFO | train_inner | epoch 101:    838 / 1978 loss=3.045, nll_loss=0.916, word_ins=2.74, length=3.054, ppl=8.25, wps=46426.2, ups=0.78, wpb=59564.4, bsz=2021, num_updates=198600, lr=0.000224394, gnorm=1.311, loss_scale=8192, train_wall=128, wall=260876
2023-01-15 16:17:31 | INFO | train_inner | epoch 101:    938 / 1978 loss=3.012, nll_loss=0.88, word_ins=2.707, length=3.049, ppl=8.07, wps=46476.3, ups=0.78, wpb=59790.4, bsz=2087.1, num_updates=198700, lr=0.000224337, gnorm=1.264, loss_scale=8192, train_wall=128, wall=261005
2023-01-15 16:19:38 | INFO | train_inner | epoch 101:   1038 / 1978 loss=3.033, nll_loss=0.902, word_ins=2.727, length=3.055, ppl=8.18, wps=46796.9, ups=0.78, wpb=59658, bsz=1970.9, num_updates=198800, lr=0.000224281, gnorm=1.295, loss_scale=8192, train_wall=127, wall=261132
2023-01-15 16:21:45 | INFO | train_inner | epoch 101:   1138 / 1978 loss=3.029, nll_loss=0.895, word_ins=2.721, length=3.08, ppl=8.16, wps=46474.9, ups=0.79, wpb=59013, bsz=2032.5, num_updates=198900, lr=0.000224224, gnorm=1.249, loss_scale=8192, train_wall=127, wall=261259
2023-01-15 16:23:53 | INFO | train_inner | epoch 101:   1238 / 1978 loss=3.03, nll_loss=0.899, word_ins=2.724, length=3.061, ppl=8.17, wps=46764.4, ups=0.78, wpb=59604.3, bsz=2004.2, num_updates=199000, lr=0.000224168, gnorm=1.282, loss_scale=8192, train_wall=127, wall=261387
2023-01-15 16:26:00 | INFO | train_inner | epoch 101:   1338 / 1978 loss=3.044, nll_loss=0.903, word_ins=2.729, length=3.154, ppl=8.25, wps=46031.1, ups=0.79, wpb=58385.6, bsz=1912.8, num_updates=199100, lr=0.000224112, gnorm=1.257, loss_scale=8192, train_wall=127, wall=261514
2023-01-15 16:28:09 | INFO | train_inner | epoch 101:   1438 / 1978 loss=3.004, nll_loss=0.879, word_ins=2.706, length=2.979, ppl=8.02, wps=45884, ups=0.77, wpb=59461.4, bsz=2126.6, num_updates=199200, lr=0.000224055, gnorm=1.275, loss_scale=8192, train_wall=129, wall=261643
2023-01-15 16:30:16 | INFO | train_inner | epoch 101:   1538 / 1978 loss=3.06, nll_loss=0.927, word_ins=2.75, length=3.102, ppl=8.34, wps=46434.8, ups=0.79, wpb=58972.6, bsz=1952.2, num_updates=199300, lr=0.000223999, gnorm=1.315, loss_scale=8192, train_wall=127, wall=261770
2023-01-15 16:32:22 | INFO | train_inner | epoch 101:   1638 / 1978 loss=3.074, nll_loss=0.939, word_ins=2.761, length=3.134, ppl=8.42, wps=47240.9, ups=0.8, wpb=59364.8, bsz=1834.5, num_updates=199400, lr=0.000223943, gnorm=1.309, loss_scale=8192, train_wall=125, wall=261896
2023-01-15 16:34:29 | INFO | train_inner | epoch 101:   1738 / 1978 loss=3.027, nll_loss=0.902, word_ins=2.726, length=3.014, ppl=8.15, wps=46667.2, ups=0.78, wpb=59536.8, bsz=2009.8, num_updates=199500, lr=0.000223887, gnorm=1.329, loss_scale=8192, train_wall=127, wall=262024
2023-01-15 16:36:37 | INFO | train_inner | epoch 101:   1838 / 1978 loss=3.048, nll_loss=0.915, word_ins=2.739, length=3.092, ppl=8.27, wps=46697.5, ups=0.79, wpb=59452.8, bsz=1995.1, num_updates=199600, lr=0.000223831, gnorm=1.266, loss_scale=8192, train_wall=127, wall=262151
2023-01-15 16:38:44 | INFO | train_inner | epoch 101:   1938 / 1978 loss=3.012, nll_loss=0.885, word_ins=2.711, length=3.014, ppl=8.07, wps=46681.8, ups=0.79, wpb=59434, bsz=2061.5, num_updates=199700, lr=0.000223775, gnorm=1.276, loss_scale=8192, train_wall=127, wall=262278
2023-01-15 16:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 16:39:49 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 4.55 | nll_loss 1.969 | word_ins 3.733 | length 8.17 | ppl 23.42 | wps 103864 | wpb 40242.5 | bsz 1500 | num_updates 199740 | best_loss 4.422
2023-01-15 16:39:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 16:40:16 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint101.pt (epoch 101 @ 199740 updates, score 4.55) (writing took 27.171480373013765 seconds)
2023-01-15 16:40:16 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2023-01-15 16:40:16 | INFO | train | epoch 101 | loss 3.03 | nll_loss 0.899 | word_ins 2.725 | length 3.059 | ppl 8.17 | wps 45346.3 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 199740 | lr 0.000223752 | gnorm 1.279 | loss_scale 8192 | train_wall 2525 | wall 262370
2023-01-15 16:40:16 | INFO | fairseq.trainer | begin training epoch 102
2023-01-15 16:41:44 | INFO | train_inner | epoch 102:     60 / 1978 loss=3.044, nll_loss=0.912, word_ins=2.736, length=3.081, ppl=8.25, wps=32940.5, ups=0.56, wpb=59093.9, bsz=1912.2, num_updates=199800, lr=0.000223719, gnorm=1.299, loss_scale=8192, train_wall=126, wall=262458
2023-01-15 16:43:51 | INFO | train_inner | epoch 102:    160 / 1978 loss=3.035, nll_loss=0.902, word_ins=2.727, length=3.073, ppl=8.19, wps=46698.9, ups=0.78, wpb=59555.8, bsz=1967.6, num_updates=199900, lr=0.000223663, gnorm=1.302, loss_scale=8192, train_wall=127, wall=262585
2023-01-15 16:46:00 | INFO | train_inner | epoch 102:    260 / 1978 loss=3.005, nll_loss=0.879, word_ins=2.706, length=2.986, ppl=8.03, wps=46073.1, ups=0.78, wpb=59169.7, bsz=2089.5, num_updates=200000, lr=0.000223607, gnorm=1.264, loss_scale=8192, train_wall=128, wall=262714
2023-01-15 16:48:07 | INFO | train_inner | epoch 102:    360 / 1978 loss=3.041, nll_loss=0.915, word_ins=2.739, length=3.017, ppl=8.23, wps=46748.4, ups=0.79, wpb=59534.1, bsz=1983.8, num_updates=200100, lr=0.000223551, gnorm=1.302, loss_scale=8192, train_wall=127, wall=262841
2023-01-15 16:50:14 | INFO | train_inner | epoch 102:    460 / 1978 loss=3.015, nll_loss=0.884, word_ins=2.711, length=3.033, ppl=8.08, wps=46906.5, ups=0.79, wpb=59413.1, bsz=1940.5, num_updates=200200, lr=0.000223495, gnorm=1.279, loss_scale=8192, train_wall=126, wall=262968
2023-01-15 16:52:21 | INFO | train_inner | epoch 102:    560 / 1978 loss=3.026, nll_loss=0.898, word_ins=2.723, length=3.031, ppl=8.15, wps=46058.4, ups=0.78, wpb=58801.8, bsz=2010.2, num_updates=200300, lr=0.000223439, gnorm=1.235, loss_scale=8192, train_wall=127, wall=263095
2023-01-15 16:54:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 16:54:31 | INFO | train_inner | epoch 102:    661 / 1978 loss=3.024, nll_loss=0.893, word_ins=2.719, length=3.052, ppl=8.13, wps=45417.8, ups=0.77, wpb=59172.7, bsz=2043.2, num_updates=200400, lr=0.000223384, gnorm=1.279, loss_scale=8192, train_wall=130, wall=263226
2023-01-15 16:56:39 | INFO | train_inner | epoch 102:    761 / 1978 loss=3.048, nll_loss=0.911, word_ins=2.735, length=3.132, ppl=8.27, wps=46475, ups=0.79, wpb=59122.8, bsz=1927.5, num_updates=200500, lr=0.000223328, gnorm=1.286, loss_scale=8192, train_wall=127, wall=263353
2023-01-15 16:58:46 | INFO | train_inner | epoch 102:    861 / 1978 loss=3.005, nll_loss=0.874, word_ins=2.702, length=3.035, ppl=8.03, wps=46626.3, ups=0.78, wpb=59513, bsz=2019.8, num_updates=200600, lr=0.000223272, gnorm=1.326, loss_scale=8192, train_wall=127, wall=263480
2023-01-15 17:00:53 | INFO | train_inner | epoch 102:    961 / 1978 loss=3.057, nll_loss=0.921, word_ins=2.744, length=3.126, ppl=8.32, wps=46299.1, ups=0.79, wpb=58849.6, bsz=1973.3, num_updates=200700, lr=0.000223217, gnorm=1.295, loss_scale=8192, train_wall=127, wall=263608
2023-01-15 17:03:01 | INFO | train_inner | epoch 102:   1061 / 1978 loss=3.033, nll_loss=0.898, word_ins=2.724, length=3.089, ppl=8.18, wps=46678.2, ups=0.79, wpb=59424.8, bsz=1988.6, num_updates=200800, lr=0.000223161, gnorm=1.29, loss_scale=8192, train_wall=127, wall=263735
2023-01-15 17:05:09 | INFO | train_inner | epoch 102:   1161 / 1978 loss=3.05, nll_loss=0.916, word_ins=2.74, length=3.103, ppl=8.28, wps=46000.2, ups=0.78, wpb=58970.8, bsz=1993.8, num_updates=200900, lr=0.000223105, gnorm=1.377, loss_scale=8192, train_wall=128, wall=263863
2023-01-15 17:07:17 | INFO | train_inner | epoch 102:   1261 / 1978 loss=3.013, nll_loss=0.884, word_ins=2.71, length=3.028, ppl=8.07, wps=46493.5, ups=0.78, wpb=59534, bsz=2097.5, num_updates=201000, lr=0.00022305, gnorm=1.255, loss_scale=8192, train_wall=128, wall=263991
2023-01-15 17:09:24 | INFO | train_inner | epoch 102:   1361 / 1978 loss=3.023, nll_loss=0.896, word_ins=2.721, length=3.02, ppl=8.13, wps=46496, ups=0.79, wpb=59117.7, bsz=2026.7, num_updates=201100, lr=0.000222994, gnorm=1.293, loss_scale=8192, train_wall=127, wall=264118
2023-01-15 17:11:32 | INFO | train_inner | epoch 102:   1461 / 1978 loss=3.017, nll_loss=0.886, word_ins=2.712, length=3.059, ppl=8.1, wps=46823.5, ups=0.78, wpb=59684.1, bsz=2004.6, num_updates=201200, lr=0.000222939, gnorm=1.3, loss_scale=8192, train_wall=127, wall=264246
2023-01-15 17:13:40 | INFO | train_inner | epoch 102:   1561 / 1978 loss=3.037, nll_loss=0.901, word_ins=2.726, length=3.11, ppl=8.21, wps=46172.2, ups=0.78, wpb=59071.9, bsz=1996.6, num_updates=201300, lr=0.000222884, gnorm=1.251, loss_scale=8192, train_wall=128, wall=264374
2023-01-15 17:15:47 | INFO | train_inner | epoch 102:   1661 / 1978 loss=3.044, nll_loss=0.907, word_ins=2.732, length=3.122, ppl=8.25, wps=46055.3, ups=0.79, wpb=58604.1, bsz=1983.7, num_updates=201400, lr=0.000222828, gnorm=1.236, loss_scale=8192, train_wall=127, wall=264501
2023-01-15 17:17:54 | INFO | train_inner | epoch 102:   1761 / 1978 loss=3.017, nll_loss=0.891, word_ins=2.717, length=3, ppl=8.09, wps=46727.6, ups=0.78, wpb=59643.6, bsz=2026.9, num_updates=201500, lr=0.000222773, gnorm=1.268, loss_scale=8192, train_wall=127, wall=264629
2023-01-15 17:20:02 | INFO | train_inner | epoch 102:   1861 / 1978 loss=3.026, nll_loss=0.897, word_ins=2.722, length=3.04, ppl=8.15, wps=46683.7, ups=0.78, wpb=59638.3, bsz=1966.2, num_updates=201600, lr=0.000222718, gnorm=1.284, loss_scale=8192, train_wall=128, wall=264756
2023-01-15 17:22:10 | INFO | train_inner | epoch 102:   1961 / 1978 loss=3.002, nll_loss=0.871, word_ins=2.698, length=3.043, ppl=8.01, wps=46893.2, ups=0.78, wpb=59822.5, bsz=2097.8, num_updates=201700, lr=0.000222662, gnorm=1.28, loss_scale=8192, train_wall=127, wall=264884
2023-01-15 17:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 17:22:45 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 4.571 | nll_loss 1.974 | word_ins 3.741 | length 8.305 | ppl 23.77 | wps 164113 | wpb 40242.5 | bsz 1500 | num_updates 201717 | best_loss 4.422
2023-01-15 17:22:45 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 17:23:12 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint102.pt (epoch 102 @ 201717 updates, score 4.571) (writing took 27.175159608013928 seconds)
2023-01-15 17:23:12 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2023-01-15 17:23:12 | INFO | train | epoch 102 | loss 3.029 | nll_loss 0.897 | word_ins 2.723 | length 3.06 | ppl 8.16 | wps 45494.9 | ups 0.77 | wpb 59285 | bsz 2002.9 | num_updates 201717 | lr 0.000222653 | gnorm 1.286 | loss_scale 8192 | train_wall 2519 | wall 264946
2023-01-15 17:23:12 | INFO | fairseq.trainer | begin training epoch 103
2023-01-15 17:25:10 | INFO | train_inner | epoch 103:     83 / 1978 loss=3.025, nll_loss=0.897, word_ins=2.722, length=3.027, ppl=8.14, wps=32824.2, ups=0.56, wpb=59115.3, bsz=2055.8, num_updates=201800, lr=0.000222607, gnorm=1.304, loss_scale=8192, train_wall=128, wall=265064
2023-01-15 17:27:17 | INFO | train_inner | epoch 103:    183 / 1978 loss=3.017, nll_loss=0.885, word_ins=2.712, length=3.058, ppl=8.1, wps=46720.8, ups=0.79, wpb=59350.9, bsz=1951.7, num_updates=201900, lr=0.000222552, gnorm=1.321, loss_scale=8192, train_wall=127, wall=265191
2023-01-15 17:29:25 | INFO | train_inner | epoch 103:    283 / 1978 loss=2.995, nll_loss=0.868, word_ins=2.696, length=2.989, ppl=7.97, wps=46668.8, ups=0.78, wpb=59648.2, bsz=2014.1, num_updates=202000, lr=0.000222497, gnorm=1.327, loss_scale=8192, train_wall=128, wall=265319
2023-01-15 17:31:32 | INFO | train_inner | epoch 103:    383 / 1978 loss=3.035, nll_loss=0.902, word_ins=2.727, length=3.084, ppl=8.2, wps=46456.5, ups=0.78, wpb=59329.8, bsz=1999.1, num_updates=202100, lr=0.000222442, gnorm=1.287, loss_scale=8192, train_wall=127, wall=265447
2023-01-15 17:33:40 | INFO | train_inner | epoch 103:    483 / 1978 loss=3.051, nll_loss=0.922, word_ins=2.745, length=3.052, ppl=8.29, wps=46294.2, ups=0.78, wpb=59070.6, bsz=1935.4, num_updates=202200, lr=0.000222387, gnorm=1.326, loss_scale=8192, train_wall=127, wall=265574
2023-01-15 17:35:48 | INFO | train_inner | epoch 103:    583 / 1978 loss=3.033, nll_loss=0.899, word_ins=2.724, length=3.084, ppl=8.18, wps=46326.1, ups=0.78, wpb=59097.6, bsz=1943.4, num_updates=202300, lr=0.000222332, gnorm=1.265, loss_scale=8192, train_wall=127, wall=265702
2023-01-15 17:37:55 | INFO | train_inner | epoch 103:    683 / 1978 loss=3.043, nll_loss=0.909, word_ins=2.734, length=3.091, ppl=8.24, wps=45784.3, ups=0.78, wpb=58414, bsz=1985.4, num_updates=202400, lr=0.000222277, gnorm=1.239, loss_scale=8192, train_wall=127, wall=265829
2023-01-15 17:40:04 | INFO | train_inner | epoch 103:    783 / 1978 loss=3.013, nll_loss=0.884, word_ins=2.71, length=3.027, ppl=8.07, wps=45933.8, ups=0.77, wpb=59330.9, bsz=2127.4, num_updates=202500, lr=0.000222222, gnorm=1.284, loss_scale=8192, train_wall=129, wall=265959
2023-01-15 17:42:13 | INFO | train_inner | epoch 103:    883 / 1978 loss=3.018, nll_loss=0.889, word_ins=2.715, length=3.029, ppl=8.1, wps=46552.1, ups=0.78, wpb=59834.5, bsz=2061.5, num_updates=202600, lr=0.000222167, gnorm=1.282, loss_scale=8192, train_wall=128, wall=266087
2023-01-15 17:44:21 | INFO | train_inner | epoch 103:    983 / 1978 loss=3.034, nll_loss=0.905, word_ins=2.729, length=3.054, ppl=8.19, wps=47120.3, ups=0.78, wpb=60103.7, bsz=1965.3, num_updates=202700, lr=0.000222113, gnorm=1.275, loss_scale=8192, train_wall=127, wall=266215
2023-01-15 17:46:28 | INFO | train_inner | epoch 103:   1083 / 1978 loss=3.03, nll_loss=0.897, word_ins=2.722, length=3.08, ppl=8.17, wps=46434.9, ups=0.78, wpb=59374.3, bsz=1946.7, num_updates=202800, lr=0.000222058, gnorm=1.27, loss_scale=8192, train_wall=128, wall=266342
2023-01-15 17:48:37 | INFO | train_inner | epoch 103:   1183 / 1978 loss=3.022, nll_loss=0.897, word_ins=2.722, length=2.993, ppl=8.12, wps=46586.3, ups=0.78, wpb=59694.7, bsz=2051.4, num_updates=202900, lr=0.000222003, gnorm=1.348, loss_scale=8192, train_wall=128, wall=266471
2023-01-15 17:50:44 | INFO | train_inner | epoch 103:   1283 / 1978 loss=3.035, nll_loss=0.9, word_ins=2.725, length=3.098, ppl=8.19, wps=46607.4, ups=0.79, wpb=59293.8, bsz=1953.2, num_updates=203000, lr=0.000221948, gnorm=1.279, loss_scale=8192, train_wall=127, wall=266598
2023-01-15 17:52:51 | INFO | train_inner | epoch 103:   1383 / 1978 loss=3.027, nll_loss=0.892, word_ins=2.718, length=3.09, ppl=8.15, wps=46412.6, ups=0.78, wpb=59147, bsz=2058.6, num_updates=203100, lr=0.000221894, gnorm=1.326, loss_scale=8192, train_wall=127, wall=266725
2023-01-15 17:54:59 | INFO | train_inner | epoch 103:   1483 / 1978 loss=3.025, nll_loss=0.896, word_ins=2.722, length=3.035, ppl=8.14, wps=46227.1, ups=0.78, wpb=59171.3, bsz=2009.2, num_updates=203200, lr=0.000221839, gnorm=1.319, loss_scale=8192, train_wall=128, wall=266853
2023-01-15 17:57:06 | INFO | train_inner | epoch 103:   1583 / 1978 loss=3.044, nll_loss=0.909, word_ins=2.733, length=3.107, ppl=8.24, wps=46851.1, ups=0.79, wpb=59374.9, bsz=1901.2, num_updates=203300, lr=0.000221785, gnorm=1.329, loss_scale=8192, train_wall=127, wall=266980
2023-01-15 17:59:13 | INFO | train_inner | epoch 103:   1683 / 1978 loss=3.034, nll_loss=0.899, word_ins=2.724, length=3.106, ppl=8.19, wps=46877.4, ups=0.79, wpb=59387.2, bsz=1946.6, num_updates=203400, lr=0.00022173, gnorm=1.288, loss_scale=8192, train_wall=126, wall=267107
2023-01-15 18:01:20 | INFO | train_inner | epoch 103:   1783 / 1978 loss=3.033, nll_loss=0.899, word_ins=2.724, length=3.089, ppl=8.18, wps=46293.5, ups=0.79, wpb=58945.6, bsz=1999.3, num_updates=203500, lr=0.000221676, gnorm=1.244, loss_scale=8192, train_wall=127, wall=267234
2023-01-15 18:03:29 | INFO | train_inner | epoch 103:   1883 / 1978 loss=3.003, nll_loss=0.873, word_ins=2.7, length=3.033, ppl=8.02, wps=45888.9, ups=0.78, wpb=59057.7, bsz=2111.3, num_updates=203600, lr=0.000221621, gnorm=1.255, loss_scale=8192, train_wall=128, wall=267363
2023-01-15 18:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 18:05:46 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 4.633 | nll_loss 1.975 | word_ins 3.738 | length 8.943 | ppl 24.81 | wps 132022 | wpb 40242.5 | bsz 1500 | num_updates 203695 | best_loss 4.422
2023-01-15 18:05:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 18:06:13 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint103.pt (epoch 103 @ 203695 updates, score 4.633) (writing took 27.015851405914873 seconds)
2023-01-15 18:06:13 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2023-01-15 18:06:13 | INFO | train | epoch 103 | loss 3.027 | nll_loss 0.896 | word_ins 2.721 | length 3.059 | ppl 8.15 | wps 45436.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 203695 | lr 0.000221569 | gnorm 1.292 | loss_scale 8192 | train_wall 2522 | wall 267527
2023-01-15 18:06:13 | INFO | fairseq.trainer | begin training epoch 104
2023-01-15 18:06:33 | INFO | train_inner | epoch 104:      5 / 1978 loss=3.034, nll_loss=0.9, word_ins=2.725, length=3.094, ppl=8.19, wps=31867.4, ups=0.54, wpb=58660.1, bsz=2022, num_updates=203700, lr=0.000221567, gnorm=1.277, loss_scale=8192, train_wall=128, wall=267547
2023-01-15 18:08:40 | INFO | train_inner | epoch 104:    105 / 1978 loss=3.027, nll_loss=0.896, word_ins=2.721, length=3.056, ppl=8.15, wps=46405.9, ups=0.78, wpb=59168.4, bsz=2030, num_updates=203800, lr=0.000221512, gnorm=1.254, loss_scale=8192, train_wall=127, wall=267674
2023-01-15 18:10:49 | INFO | train_inner | epoch 104:    205 / 1978 loss=3.017, nll_loss=0.889, word_ins=2.716, length=3.013, ppl=8.1, wps=46445.4, ups=0.78, wpb=59580.5, bsz=2023.1, num_updates=203900, lr=0.000221458, gnorm=1.314, loss_scale=8192, train_wall=128, wall=267803
2023-01-15 18:12:55 | INFO | train_inner | epoch 104:    305 / 1978 loss=3.011, nll_loss=0.88, word_ins=2.707, length=3.037, ppl=8.06, wps=46665.3, ups=0.79, wpb=58989.6, bsz=1973, num_updates=204000, lr=0.000221404, gnorm=1.272, loss_scale=8192, train_wall=126, wall=267929
2023-01-15 18:15:04 | INFO | train_inner | epoch 104:    405 / 1978 loss=3.009, nll_loss=0.88, word_ins=2.707, length=3.017, ppl=8.05, wps=46406.7, ups=0.77, wpb=59936.5, bsz=2081.9, num_updates=204100, lr=0.000221349, gnorm=1.273, loss_scale=8192, train_wall=129, wall=268058
2023-01-15 18:17:12 | INFO | train_inner | epoch 104:    505 / 1978 loss=3.039, nll_loss=0.908, word_ins=2.732, length=3.071, ppl=8.22, wps=46046.3, ups=0.78, wpb=58721.4, bsz=1984.4, num_updates=204200, lr=0.000221295, gnorm=1.315, loss_scale=8192, train_wall=127, wall=268186
2023-01-15 18:19:20 | INFO | train_inner | epoch 104:    605 / 1978 loss=2.985, nll_loss=0.859, word_ins=2.688, length=2.977, ppl=7.92, wps=46581, ups=0.78, wpb=59687.5, bsz=2069.4, num_updates=204300, lr=0.000221241, gnorm=1.294, loss_scale=8192, train_wall=128, wall=268314
2023-01-15 18:21:27 | INFO | train_inner | epoch 104:    705 / 1978 loss=3.032, nll_loss=0.903, word_ins=2.727, length=3.043, ppl=8.18, wps=46946.7, ups=0.78, wpb=59836.9, bsz=1960.1, num_updates=204400, lr=0.000221187, gnorm=1.317, loss_scale=8192, train_wall=127, wall=268441
2023-01-15 18:23:35 | INFO | train_inner | epoch 104:    805 / 1978 loss=3.026, nll_loss=0.894, word_ins=2.72, length=3.062, ppl=8.14, wps=46256.5, ups=0.78, wpb=59027.3, bsz=2033.8, num_updates=204500, lr=0.000221133, gnorm=1.277, loss_scale=16384, train_wall=127, wall=268569
2023-01-15 18:23:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 18:25:44 | INFO | train_inner | epoch 104:    906 / 1978 loss=3.033, nll_loss=0.907, word_ins=2.731, length=3.016, ppl=8.18, wps=46118.8, ups=0.77, wpb=59556.6, bsz=1997.3, num_updates=204600, lr=0.000221079, gnorm=1.263, loss_scale=8192, train_wall=129, wall=268698
2023-01-15 18:27:51 | INFO | train_inner | epoch 104:   1006 / 1978 loss=3.023, nll_loss=0.891, word_ins=2.717, length=3.059, ppl=8.13, wps=46460.1, ups=0.79, wpb=59133.8, bsz=2014.9, num_updates=204700, lr=0.000221025, gnorm=1.27, loss_scale=8192, train_wall=127, wall=268825
2023-01-15 18:29:58 | INFO | train_inner | epoch 104:   1106 / 1978 loss=3.048, nll_loss=0.919, word_ins=2.742, length=3.06, ppl=8.27, wps=46649.7, ups=0.79, wpb=59207.2, bsz=1978.6, num_updates=204800, lr=0.000220971, gnorm=1.294, loss_scale=8192, train_wall=127, wall=268952
2023-01-15 18:32:07 | INFO | train_inner | epoch 104:   1206 / 1978 loss=3.039, nll_loss=0.907, word_ins=2.732, length=3.069, ppl=8.22, wps=46443, ups=0.78, wpb=59664.9, bsz=2017.5, num_updates=204900, lr=0.000220917, gnorm=1.28, loss_scale=8192, train_wall=128, wall=269081
2023-01-15 18:34:13 | INFO | train_inner | epoch 104:   1306 / 1978 loss=3.077, nll_loss=0.936, word_ins=2.759, length=3.18, ppl=8.44, wps=46331.4, ups=0.79, wpb=58519.2, bsz=1851.1, num_updates=205000, lr=0.000220863, gnorm=1.295, loss_scale=8192, train_wall=126, wall=269207
2023-01-15 18:36:20 | INFO | train_inner | epoch 104:   1406 / 1978 loss=3.032, nll_loss=0.899, word_ins=2.725, length=3.074, ppl=8.18, wps=46424.1, ups=0.79, wpb=58891.6, bsz=1912.5, num_updates=205100, lr=0.000220809, gnorm=1.31, loss_scale=8192, train_wall=127, wall=269334
2023-01-15 18:38:28 | INFO | train_inner | epoch 104:   1506 / 1978 loss=3.039, nll_loss=0.908, word_ins=2.732, length=3.075, ppl=8.22, wps=46378.4, ups=0.78, wpb=59234, bsz=1961.4, num_updates=205200, lr=0.000220755, gnorm=1.322, loss_scale=8192, train_wall=127, wall=269462
2023-01-15 18:40:37 | INFO | train_inner | epoch 104:   1606 / 1978 loss=3.013, nll_loss=0.883, word_ins=2.709, length=3.033, ppl=8.07, wps=46005.5, ups=0.78, wpb=59361.5, bsz=2057.9, num_updates=205300, lr=0.000220702, gnorm=1.264, loss_scale=8192, train_wall=129, wall=269591
2023-01-15 18:42:45 | INFO | train_inner | epoch 104:   1706 / 1978 loss=3.007, nll_loss=0.878, word_ins=2.705, length=3.028, ppl=8.04, wps=46509.9, ups=0.78, wpb=59572.3, bsz=2040.1, num_updates=205400, lr=0.000220648, gnorm=1.321, loss_scale=8192, train_wall=128, wall=269719
2023-01-15 18:44:55 | INFO | train_inner | epoch 104:   1806 / 1978 loss=3.01, nll_loss=0.88, word_ins=2.707, length=3.031, ppl=8.05, wps=45755.4, ups=0.77, wpb=59608.7, bsz=2083.8, num_updates=205500, lr=0.000220594, gnorm=1.287, loss_scale=8192, train_wall=130, wall=269849
2023-01-15 18:47:02 | INFO | train_inner | epoch 104:   1906 / 1978 loss=3.047, nll_loss=0.912, word_ins=2.736, length=3.102, ppl=8.26, wps=46439.7, ups=0.79, wpb=58949.5, bsz=1885.9, num_updates=205600, lr=0.000220541, gnorm=1.293, loss_scale=8192, train_wall=127, wall=269976
2023-01-15 18:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 18:48:49 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 4.596 | nll_loss 1.965 | word_ins 3.728 | length 8.679 | ppl 24.18 | wps 113638 | wpb 40242.5 | bsz 1500 | num_updates 205672 | best_loss 4.422
2023-01-15 18:48:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 18:49:16 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint104.pt (epoch 104 @ 205672 updates, score 4.596) (writing took 27.48918865667656 seconds)
2023-01-15 18:49:16 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2023-01-15 18:49:16 | INFO | train | epoch 104 | loss 3.026 | nll_loss 0.896 | word_ins 2.721 | length 3.051 | ppl 8.15 | wps 45374.3 | ups 0.77 | wpb 59285 | bsz 2002.8 | num_updates 205672 | lr 0.000220502 | gnorm 1.289 | loss_scale 8192 | train_wall 2524 | wall 270110
2023-01-15 18:49:16 | INFO | fairseq.trainer | begin training epoch 105
2023-01-15 18:50:03 | INFO | train_inner | epoch 105:     28 / 1978 loss=3.017, nll_loss=0.889, word_ins=2.715, length=3.024, ppl=8.1, wps=32565.8, ups=0.55, wpb=58976.2, bsz=2032.9, num_updates=205700, lr=0.000220487, gnorm=1.267, loss_scale=8192, train_wall=128, wall=270157
2023-01-15 18:52:13 | INFO | train_inner | epoch 105:    128 / 1978 loss=3.012, nll_loss=0.881, word_ins=2.708, length=3.042, ppl=8.07, wps=45370.8, ups=0.77, wpb=58703.2, bsz=2110.6, num_updates=205800, lr=0.000220433, gnorm=1.274, loss_scale=8192, train_wall=129, wall=270287
2023-01-15 18:54:22 | INFO | train_inner | epoch 105:    228 / 1978 loss=2.997, nll_loss=0.871, word_ins=2.698, length=2.987, ppl=7.98, wps=46176.3, ups=0.77, wpb=59728, bsz=2119.2, num_updates=205900, lr=0.00022038, gnorm=1.272, loss_scale=8192, train_wall=129, wall=270416
2023-01-15 18:56:30 | INFO | train_inner | epoch 105:    328 / 1978 loss=3.019, nll_loss=0.892, word_ins=2.719, length=3.007, ppl=8.11, wps=46365.7, ups=0.78, wpb=59435.2, bsz=2023.4, num_updates=206000, lr=0.000220326, gnorm=1.311, loss_scale=8192, train_wall=128, wall=270544
2023-01-15 18:58:39 | INFO | train_inner | epoch 105:    428 / 1978 loss=3.043, nll_loss=0.912, word_ins=2.736, length=3.069, ppl=8.24, wps=45890.7, ups=0.77, wpb=59273, bsz=1962.8, num_updates=206100, lr=0.000220273, gnorm=1.314, loss_scale=8192, train_wall=129, wall=270673
2023-01-15 19:00:48 | INFO | train_inner | epoch 105:    528 / 1978 loss=3.003, nll_loss=0.872, word_ins=2.699, length=3.034, ppl=8.01, wps=45925.2, ups=0.78, wpb=59118.4, bsz=2055.9, num_updates=206200, lr=0.000220219, gnorm=1.288, loss_scale=8192, train_wall=128, wall=270802
2023-01-15 19:02:55 | INFO | train_inner | epoch 105:    628 / 1978 loss=3.038, nll_loss=0.907, word_ins=2.731, length=3.066, ppl=8.21, wps=46350.4, ups=0.78, wpb=59068.8, bsz=1895.4, num_updates=206300, lr=0.000220166, gnorm=1.298, loss_scale=8192, train_wall=127, wall=270929
2023-01-15 19:05:04 | INFO | train_inner | epoch 105:    728 / 1978 loss=3.009, nll_loss=0.88, word_ins=2.707, length=3.016, ppl=8.05, wps=46504.9, ups=0.78, wpb=59620.9, bsz=2007.2, num_updates=206400, lr=0.000220113, gnorm=1.25, loss_scale=8192, train_wall=128, wall=271058
2023-01-15 19:07:13 | INFO | train_inner | epoch 105:    828 / 1978 loss=3.013, nll_loss=0.885, word_ins=2.711, length=3.018, ppl=8.07, wps=46121.1, ups=0.77, wpb=59644.8, bsz=2061.8, num_updates=206500, lr=0.000220059, gnorm=1.303, loss_scale=8192, train_wall=129, wall=271187
2023-01-15 19:09:22 | INFO | train_inner | epoch 105:    928 / 1978 loss=3.011, nll_loss=0.878, word_ins=2.705, length=3.06, ppl=8.06, wps=46496.3, ups=0.78, wpb=59858.6, bsz=2004.1, num_updates=206600, lr=0.000220006, gnorm=1.278, loss_scale=8192, train_wall=128, wall=271316
2023-01-15 19:11:29 | INFO | train_inner | epoch 105:   1028 / 1978 loss=3.015, nll_loss=0.884, word_ins=2.711, length=3.043, ppl=8.08, wps=46435.9, ups=0.78, wpb=59222.7, bsz=1985.7, num_updates=206700, lr=0.000219953, gnorm=1.285, loss_scale=8192, train_wall=127, wall=271443
2023-01-15 19:13:37 | INFO | train_inner | epoch 105:   1128 / 1978 loss=3.049, nll_loss=0.913, word_ins=2.737, length=3.126, ppl=8.28, wps=46129.4, ups=0.78, wpb=58940.1, bsz=1902.2, num_updates=206800, lr=0.0002199, gnorm=1.326, loss_scale=8192, train_wall=128, wall=271571
2023-01-15 19:15:45 | INFO | train_inner | epoch 105:   1228 / 1978 loss=3.01, nll_loss=0.877, word_ins=2.704, length=3.06, ppl=8.06, wps=46209.9, ups=0.78, wpb=59346.6, bsz=2004.4, num_updates=206900, lr=0.000219847, gnorm=1.3, loss_scale=8192, train_wall=128, wall=271700
2023-01-15 19:17:54 | INFO | train_inner | epoch 105:   1328 / 1978 loss=3.039, nll_loss=0.908, word_ins=2.731, length=3.078, ppl=8.22, wps=46348.4, ups=0.78, wpb=59443.8, bsz=2010.4, num_updates=207000, lr=0.000219793, gnorm=1.289, loss_scale=8192, train_wall=128, wall=271828
2023-01-15 19:20:01 | INFO | train_inner | epoch 105:   1428 / 1978 loss=3.043, nll_loss=0.909, word_ins=2.733, length=3.095, ppl=8.24, wps=46346, ups=0.78, wpb=59099.8, bsz=1902.2, num_updates=207100, lr=0.00021974, gnorm=1.282, loss_scale=8192, train_wall=127, wall=271955
2023-01-15 19:22:11 | INFO | train_inner | epoch 105:   1528 / 1978 loss=3.016, nll_loss=0.886, word_ins=2.712, length=3.046, ppl=8.09, wps=45793.8, ups=0.77, wpb=59248.1, bsz=2059.8, num_updates=207200, lr=0.000219687, gnorm=1.279, loss_scale=8192, train_wall=129, wall=272085
2023-01-15 19:24:19 | INFO | train_inner | epoch 105:   1628 / 1978 loss=3.043, nll_loss=0.915, word_ins=2.739, length=3.036, ppl=8.24, wps=46073.8, ups=0.78, wpb=59158.3, bsz=2024.8, num_updates=207300, lr=0.000219634, gnorm=1.243, loss_scale=8192, train_wall=128, wall=272213
2023-01-15 19:26:27 | INFO | train_inner | epoch 105:   1728 / 1978 loss=3.047, nll_loss=0.912, word_ins=2.736, length=3.111, ppl=8.26, wps=46155, ups=0.78, wpb=59050.6, bsz=1934.8, num_updates=207400, lr=0.000219581, gnorm=1.324, loss_scale=8192, train_wall=128, wall=272341
2023-01-15 19:28:35 | INFO | train_inner | epoch 105:   1828 / 1978 loss=3.017, nll_loss=0.889, word_ins=2.715, length=3.016, ppl=8.09, wps=46425.8, ups=0.78, wpb=59670.1, bsz=2058.8, num_updates=207500, lr=0.000219529, gnorm=1.207, loss_scale=8192, train_wall=128, wall=272470
2023-01-15 19:30:44 | INFO | train_inner | epoch 105:   1928 / 1978 loss=3.042, nll_loss=0.909, word_ins=2.733, length=3.081, ppl=8.23, wps=45760.6, ups=0.78, wpb=58776.2, bsz=1959.3, num_updates=207600, lr=0.000219476, gnorm=1.329, loss_scale=8192, train_wall=128, wall=272598
2023-01-15 19:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 19:32:01 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 4.606 | nll_loss 1.96 | word_ins 3.724 | length 8.815 | ppl 24.35 | wps 130797 | wpb 40242.5 | bsz 1500 | num_updates 207650 | best_loss 4.422
2023-01-15 19:32:01 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 19:32:29 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint105.pt (epoch 105 @ 207650 updates, score 4.606) (writing took 27.77055995585397 seconds)
2023-01-15 19:32:29 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2023-01-15 19:32:29 | INFO | train | epoch 105 | loss 3.025 | nll_loss 0.894 | word_ins 2.719 | length 3.052 | ppl 8.14 | wps 45234.8 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 207650 | lr 0.000219449 | gnorm 1.286 | loss_scale 8192 | train_wall 2535 | wall 272703
2023-01-15 19:32:29 | INFO | fairseq.trainer | begin training epoch 106
2023-01-15 19:33:44 | INFO | train_inner | epoch 106:     50 / 1978 loss=3.003, nll_loss=0.876, word_ins=2.703, length=3, ppl=8.01, wps=33086, ups=0.55, wpb=59715.1, bsz=1995.5, num_updates=207700, lr=0.000219423, gnorm=1.282, loss_scale=8192, train_wall=128, wall=272779
2023-01-15 19:35:52 | INFO | train_inner | epoch 106:    150 / 1978 loss=3.011, nll_loss=0.882, word_ins=2.709, length=3.021, ppl=8.06, wps=46022.3, ups=0.78, wpb=58821.8, bsz=1978.6, num_updates=207800, lr=0.00021937, gnorm=1.288, loss_scale=8192, train_wall=128, wall=272906
2023-01-15 19:38:01 | INFO | train_inner | epoch 106:    250 / 1978 loss=3.008, nll_loss=0.881, word_ins=2.708, length=3.005, ppl=8.05, wps=46379.8, ups=0.78, wpb=59707, bsz=2026, num_updates=207900, lr=0.000219317, gnorm=1.322, loss_scale=8192, train_wall=128, wall=273035
2023-01-15 19:40:08 | INFO | train_inner | epoch 106:    350 / 1978 loss=2.995, nll_loss=0.866, word_ins=2.695, length=3.002, ppl=7.97, wps=46441.2, ups=0.78, wpb=59176, bsz=2027.6, num_updates=208000, lr=0.000219265, gnorm=1.196, loss_scale=8192, train_wall=127, wall=273162
2023-01-15 19:42:15 | INFO | train_inner | epoch 106:    450 / 1978 loss=3.038, nll_loss=0.906, word_ins=2.73, length=3.073, ppl=8.21, wps=47167.5, ups=0.79, wpb=59684.8, bsz=1906.7, num_updates=208100, lr=0.000219212, gnorm=1.33, loss_scale=8192, train_wall=126, wall=273289
2023-01-15 19:44:22 | INFO | train_inner | epoch 106:    550 / 1978 loss=3.032, nll_loss=0.897, word_ins=2.722, length=3.096, ppl=8.18, wps=46854, ups=0.79, wpb=59371.5, bsz=1934.6, num_updates=208200, lr=0.000219159, gnorm=1.306, loss_scale=8192, train_wall=127, wall=273416
2023-01-15 19:46:30 | INFO | train_inner | epoch 106:    650 / 1978 loss=3.038, nll_loss=0.91, word_ins=2.734, length=3.04, ppl=8.22, wps=46443, ups=0.78, wpb=59376, bsz=2017.4, num_updates=208300, lr=0.000219107, gnorm=1.262, loss_scale=8192, train_wall=128, wall=273544
2023-01-15 19:48:37 | INFO | train_inner | epoch 106:    750 / 1978 loss=3.06, nll_loss=0.923, word_ins=2.746, length=3.133, ppl=8.34, wps=46584.9, ups=0.79, wpb=59230.2, bsz=1965.3, num_updates=208400, lr=0.000219054, gnorm=1.312, loss_scale=8192, train_wall=127, wall=273671
2023-01-15 19:50:45 | INFO | train_inner | epoch 106:    850 / 1978 loss=3.028, nll_loss=0.9, word_ins=2.725, length=3.021, ppl=8.15, wps=45916.4, ups=0.78, wpb=58864, bsz=1991.6, num_updates=208500, lr=0.000219001, gnorm=1.272, loss_scale=8192, train_wall=128, wall=273799
2023-01-15 19:52:54 | INFO | train_inner | epoch 106:    950 / 1978 loss=3.016, nll_loss=0.885, word_ins=2.712, length=3.035, ppl=8.09, wps=46088.4, ups=0.78, wpb=59411.7, bsz=2007.3, num_updates=208600, lr=0.000218949, gnorm=1.309, loss_scale=8192, train_wall=129, wall=273928
2023-01-15 19:55:02 | INFO | train_inner | epoch 106:   1050 / 1978 loss=3.034, nll_loss=0.902, word_ins=2.727, length=3.066, ppl=8.19, wps=46220.7, ups=0.78, wpb=59234.2, bsz=2043.2, num_updates=208700, lr=0.000218896, gnorm=1.288, loss_scale=16384, train_wall=128, wall=274056
2023-01-15 19:56:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 19:57:11 | INFO | train_inner | epoch 106:   1151 / 1978 loss=2.99, nll_loss=0.861, word_ins=2.69, length=2.998, ppl=7.94, wps=45915.3, ups=0.77, wpb=59252.3, bsz=2113.7, num_updates=208800, lr=0.000218844, gnorm=1.271, loss_scale=8192, train_wall=129, wall=274185
2023-01-15 19:59:19 | INFO | train_inner | epoch 106:   1251 / 1978 loss=3.016, nll_loss=0.881, word_ins=2.707, length=3.097, ppl=8.09, wps=46112.6, ups=0.78, wpb=59238.7, bsz=2040.7, num_updates=208900, lr=0.000218792, gnorm=1.294, loss_scale=8192, train_wall=128, wall=274314
2023-01-15 20:01:29 | INFO | train_inner | epoch 106:   1351 / 1978 loss=3.039, nll_loss=0.91, word_ins=2.734, length=3.05, ppl=8.22, wps=46490, ups=0.78, wpb=59282.2, bsz=1953.6, num_updates=209000, lr=0.000218739, gnorm=1.293, loss_scale=8192, train_wall=127, wall=274441
2023-01-15 20:05:16 | INFO | train_inner | epoch 106:   1451 / 1978 loss=3.024, nll_loss=0.897, word_ins=2.722, length=3.022, ppl=8.14, wps=26320.7, ups=0.44, wpb=59764.1, bsz=2046.6, num_updates=209100, lr=0.000218687, gnorm=1.275, loss_scale=8192, train_wall=227, wall=274670
2023-01-15 20:07:23 | INFO | train_inner | epoch 106:   1551 / 1978 loss=3.051, nll_loss=0.913, word_ins=2.737, length=3.143, ppl=8.29, wps=46125.2, ups=0.79, wpb=58643.3, bsz=1918.6, num_updates=209200, lr=0.000218635, gnorm=1.305, loss_scale=8192, train_wall=127, wall=274797
2023-01-15 20:09:32 | INFO | train_inner | epoch 106:   1651 / 1978 loss=3, nll_loss=0.869, word_ins=2.696, length=3.037, ppl=8, wps=45854.8, ups=0.77, wpb=59294.9, bsz=2036.3, num_updates=209300, lr=0.000218582, gnorm=1.28, loss_scale=8192, train_wall=129, wall=274926
2023-01-15 20:11:40 | INFO | train_inner | epoch 106:   1751 / 1978 loss=3.016, nll_loss=0.888, word_ins=2.713, length=3.023, ppl=8.09, wps=46390.9, ups=0.78, wpb=59481.6, bsz=2021.3, num_updates=209400, lr=0.00021853, gnorm=1.312, loss_scale=8192, train_wall=128, wall=275054
2023-01-15 20:13:49 | INFO | train_inner | epoch 106:   1851 / 1978 loss=3.018, nll_loss=0.89, word_ins=2.716, length=3.028, ppl=8.1, wps=46062.9, ups=0.77, wpb=59469.8, bsz=2037.8, num_updates=209500, lr=0.000218478, gnorm=1.293, loss_scale=8192, train_wall=129, wall=275184
2023-01-15 20:15:57 | INFO | train_inner | epoch 106:   1951 / 1978 loss=3.019, nll_loss=0.885, word_ins=2.711, length=3.078, ppl=8.1, wps=46154.9, ups=0.78, wpb=58892.3, bsz=2022, num_updates=209600, lr=0.000218426, gnorm=1.253, loss_scale=8192, train_wall=127, wall=275311
2023-01-15 20:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 20:16:51 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 4.585 | nll_loss 1.963 | word_ins 3.729 | length 8.563 | ppl 24 | wps 133050 | wpb 40242.5 | bsz 1500 | num_updates 209627 | best_loss 4.422
2023-01-15 20:16:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 20:17:20 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint106.pt (epoch 106 @ 209627 updates, score 4.585) (writing took 29.394194413442165 seconds)
2023-01-15 20:17:20 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2023-01-15 20:17:20 | INFO | train | epoch 106 | loss 3.022 | nll_loss 0.891 | word_ins 2.717 | length 3.05 | ppl 8.12 | wps 43539.5 | ups 0.73 | wpb 59282.1 | bsz 2002.7 | num_updates 209627 | lr 0.000218412 | gnorm 1.287 | loss_scale 8192 | train_wall 2624 | wall 275394
2023-01-15 20:17:20 | INFO | fairseq.trainer | begin training epoch 107
2023-01-15 20:19:07 | INFO | train_inner | epoch 107:     73 / 1978 loss=2.992, nll_loss=0.866, word_ins=2.694, length=2.982, ppl=7.96, wps=31387.7, ups=0.53, wpb=59614.7, bsz=2061.1, num_updates=209700, lr=0.000218374, gnorm=1.276, loss_scale=8192, train_wall=128, wall=275501
2023-01-15 20:21:15 | INFO | train_inner | epoch 107:    173 / 1978 loss=3.006, nll_loss=0.876, word_ins=2.703, length=3.025, ppl=8.03, wps=46272.9, ups=0.78, wpb=59195.4, bsz=2000.2, num_updates=209800, lr=0.000218322, gnorm=1.302, loss_scale=8192, train_wall=128, wall=275629
2023-01-15 20:23:23 | INFO | train_inner | epoch 107:    273 / 1978 loss=3.014, nll_loss=0.886, word_ins=2.712, length=3.023, ppl=8.08, wps=46427.3, ups=0.78, wpb=59484.4, bsz=2002.6, num_updates=209900, lr=0.00021827, gnorm=1.291, loss_scale=8192, train_wall=128, wall=275757
2023-01-15 20:25:30 | INFO | train_inner | epoch 107:    373 / 1978 loss=3.011, nll_loss=0.881, word_ins=2.708, length=3.03, ppl=8.06, wps=46741.1, ups=0.79, wpb=59449, bsz=1931, num_updates=210000, lr=0.000218218, gnorm=1.251, loss_scale=8192, train_wall=127, wall=275884
2023-01-15 20:27:39 | INFO | train_inner | epoch 107:    473 / 1978 loss=3.001, nll_loss=0.872, word_ins=2.699, length=3.016, ppl=8, wps=46308, ups=0.78, wpb=59659.2, bsz=2048.8, num_updates=210100, lr=0.000218166, gnorm=1.291, loss_scale=8192, train_wall=129, wall=276013
2023-01-15 20:29:48 | INFO | train_inner | epoch 107:    573 / 1978 loss=3.017, nll_loss=0.889, word_ins=2.715, length=3.018, ppl=8.09, wps=46250.6, ups=0.78, wpb=59475.1, bsz=2018.6, num_updates=210200, lr=0.000218114, gnorm=1.293, loss_scale=8192, train_wall=128, wall=276142
2023-01-15 20:31:56 | INFO | train_inner | epoch 107:    673 / 1978 loss=3.037, nll_loss=0.906, word_ins=2.731, length=3.066, ppl=8.21, wps=45846.7, ups=0.78, wpb=58857.8, bsz=1980, num_updates=210300, lr=0.000218062, gnorm=1.265, loss_scale=8192, train_wall=128, wall=276270
2023-01-15 20:34:04 | INFO | train_inner | epoch 107:    773 / 1978 loss=3.027, nll_loss=0.898, word_ins=2.723, length=3.043, ppl=8.15, wps=46502, ups=0.78, wpb=59635.1, bsz=1939.4, num_updates=210400, lr=0.00021801, gnorm=1.331, loss_scale=8192, train_wall=128, wall=276398
2023-01-15 20:36:12 | INFO | train_inner | epoch 107:    873 / 1978 loss=3.025, nll_loss=0.897, word_ins=2.723, length=3.019, ppl=8.14, wps=46360.4, ups=0.78, wpb=59221.7, bsz=1995, num_updates=210500, lr=0.000217959, gnorm=1.302, loss_scale=8192, train_wall=127, wall=276526
2023-01-15 20:38:21 | INFO | train_inner | epoch 107:    973 / 1978 loss=3.008, nll_loss=0.878, word_ins=2.705, length=3.031, ppl=8.05, wps=45871.9, ups=0.78, wpb=59100.9, bsz=2011.9, num_updates=210600, lr=0.000217907, gnorm=1.312, loss_scale=8192, train_wall=129, wall=276655
2023-01-15 20:40:29 | INFO | train_inner | epoch 107:   1073 / 1978 loss=3.007, nll_loss=0.878, word_ins=2.705, length=3.016, ppl=8.04, wps=46474.1, ups=0.78, wpb=59504, bsz=2017, num_updates=210700, lr=0.000217855, gnorm=1.263, loss_scale=8192, train_wall=128, wall=276783
2023-01-15 20:42:37 | INFO | train_inner | epoch 107:   1173 / 1978 loss=3.022, nll_loss=0.892, word_ins=2.717, length=3.054, ppl=8.12, wps=46892.7, ups=0.78, wpb=60070.4, bsz=1950.7, num_updates=210800, lr=0.000217803, gnorm=1.312, loss_scale=8192, train_wall=128, wall=276911
2023-01-15 20:44:44 | INFO | train_inner | epoch 107:   1273 / 1978 loss=3.035, nll_loss=0.901, word_ins=2.726, length=3.088, ppl=8.19, wps=46051.6, ups=0.79, wpb=58546.2, bsz=2003.9, num_updates=210900, lr=0.000217752, gnorm=1.296, loss_scale=8192, train_wall=127, wall=277038
2023-01-15 20:46:53 | INFO | train_inner | epoch 107:   1373 / 1978 loss=3.029, nll_loss=0.896, word_ins=2.721, length=3.072, ppl=8.16, wps=46045.3, ups=0.78, wpb=59188.8, bsz=2024.9, num_updates=211000, lr=0.0002177, gnorm=1.297, loss_scale=8192, train_wall=128, wall=277167
2023-01-15 20:49:02 | INFO | train_inner | epoch 107:   1473 / 1978 loss=3.012, nll_loss=0.882, word_ins=2.708, length=3.04, ppl=8.07, wps=46002.7, ups=0.78, wpb=59259.6, bsz=2045.2, num_updates=211100, lr=0.000217649, gnorm=1.305, loss_scale=8192, train_wall=129, wall=277296
2023-01-15 20:51:09 | INFO | train_inner | epoch 107:   1573 / 1978 loss=3.017, nll_loss=0.883, word_ins=2.709, length=3.08, ppl=8.09, wps=46061.5, ups=0.79, wpb=58558.5, bsz=1981.7, num_updates=211200, lr=0.000217597, gnorm=1.264, loss_scale=8192, train_wall=127, wall=277423
2023-01-15 20:53:16 | INFO | train_inner | epoch 107:   1673 / 1978 loss=3.043, nll_loss=0.908, word_ins=2.732, length=3.108, ppl=8.24, wps=46161.5, ups=0.79, wpb=58748.6, bsz=1989.8, num_updates=211300, lr=0.000217546, gnorm=1.256, loss_scale=8192, train_wall=127, wall=277550
2023-01-15 20:55:24 | INFO | train_inner | epoch 107:   1773 / 1978 loss=3.027, nll_loss=0.895, word_ins=2.72, length=3.074, ppl=8.15, wps=46370.7, ups=0.78, wpb=59113.7, bsz=2027, num_updates=211400, lr=0.000217494, gnorm=1.251, loss_scale=8192, train_wall=127, wall=277678
2023-01-15 20:57:33 | INFO | train_inner | epoch 107:   1873 / 1978 loss=3.018, nll_loss=0.885, word_ins=2.711, length=3.071, ppl=8.1, wps=45986.1, ups=0.77, wpb=59431.5, bsz=2043.8, num_updates=211500, lr=0.000217443, gnorm=1.329, loss_scale=8192, train_wall=129, wall=277807
2023-01-15 20:59:41 | INFO | train_inner | epoch 107:   1973 / 1978 loss=3.035, nll_loss=0.907, word_ins=2.731, length=3.042, ppl=8.2, wps=46457.8, ups=0.78, wpb=59482.5, bsz=1973, num_updates=211600, lr=0.000217391, gnorm=1.278, loss_scale=8192, train_wall=128, wall=277935
2023-01-15 20:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 21:00:07 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 4.644 | nll_loss 1.963 | word_ins 3.73 | length 9.146 | ppl 25.01 | wps 109264 | wpb 40242.5 | bsz 1500 | num_updates 211605 | best_loss 4.422
2023-01-15 21:00:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 21:00:35 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint107.pt (epoch 107 @ 211605 updates, score 4.644) (writing took 28.73506542155519 seconds)
2023-01-15 21:00:35 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2023-01-15 21:00:35 | INFO | train | epoch 107 | loss 3.019 | nll_loss 0.889 | word_ins 2.715 | length 3.045 | ppl 8.11 | wps 45187.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 211605 | lr 0.000217389 | gnorm 1.288 | loss_scale 8192 | train_wall 2529 | wall 277990
2023-01-15 21:00:35 | INFO | fairseq.trainer | begin training epoch 108
2023-01-15 21:02:49 | INFO | train_inner | epoch 108:     95 / 1978 loss=3.006, nll_loss=0.872, word_ins=2.7, length=3.065, ppl=8.04, wps=31299.3, ups=0.53, wpb=59022.7, bsz=1913.4, num_updates=211700, lr=0.00021734, gnorm=1.285, loss_scale=8192, train_wall=128, wall=278124
2023-01-15 21:04:56 | INFO | train_inner | epoch 108:    195 / 1978 loss=3.028, nll_loss=0.898, word_ins=2.724, length=3.04, ppl=8.15, wps=46611.3, ups=0.79, wpb=59136.1, bsz=1956.2, num_updates=211800, lr=0.000217289, gnorm=1.247, loss_scale=8192, train_wall=127, wall=278250
2023-01-15 21:07:05 | INFO | train_inner | epoch 108:    295 / 1978 loss=3.011, nll_loss=0.886, word_ins=2.712, length=2.988, ppl=8.06, wps=46310, ups=0.78, wpb=59459.3, bsz=2031.9, num_updates=211900, lr=0.000217237, gnorm=1.296, loss_scale=8192, train_wall=128, wall=278379
2023-01-15 21:09:14 | INFO | train_inner | epoch 108:    395 / 1978 loss=2.993, nll_loss=0.868, word_ins=2.695, length=2.979, ppl=7.96, wps=46313.9, ups=0.77, wpb=59787.8, bsz=2071, num_updates=212000, lr=0.000217186, gnorm=1.288, loss_scale=8192, train_wall=129, wall=278508
2023-01-15 21:11:21 | INFO | train_inner | epoch 108:    495 / 1978 loss=3.029, nll_loss=0.898, word_ins=2.724, length=3.051, ppl=8.16, wps=46584.6, ups=0.79, wpb=59211.2, bsz=1967.1, num_updates=212100, lr=0.000217135, gnorm=1.287, loss_scale=8192, train_wall=127, wall=278635
2023-01-15 21:13:28 | INFO | train_inner | epoch 108:    595 / 1978 loss=3.002, nll_loss=0.872, word_ins=2.699, length=3.03, ppl=8.01, wps=46712.7, ups=0.79, wpb=59427.5, bsz=2002.7, num_updates=212200, lr=0.000217084, gnorm=1.329, loss_scale=8192, train_wall=127, wall=278762
2023-01-15 21:15:37 | INFO | train_inner | epoch 108:    695 / 1978 loss=3.005, nll_loss=0.875, word_ins=2.701, length=3.036, ppl=8.03, wps=46460.6, ups=0.78, wpb=59666.7, bsz=2050.6, num_updates=212300, lr=0.000217033, gnorm=1.271, loss_scale=8192, train_wall=128, wall=278891
2023-01-15 21:17:45 | INFO | train_inner | epoch 108:    795 / 1978 loss=2.991, nll_loss=0.866, word_ins=2.693, length=2.974, ppl=7.95, wps=46195.6, ups=0.78, wpb=59169.1, bsz=2064.4, num_updates=212400, lr=0.000216982, gnorm=1.274, loss_scale=8192, train_wall=128, wall=279019
2023-01-15 21:19:52 | INFO | train_inner | epoch 108:    895 / 1978 loss=3.048, nll_loss=0.922, word_ins=2.745, length=3.029, ppl=8.27, wps=46142.4, ups=0.79, wpb=58609.1, bsz=2014.5, num_updates=212500, lr=0.00021693, gnorm=1.277, loss_scale=8192, train_wall=127, wall=279146
2023-01-15 21:21:59 | INFO | train_inner | epoch 108:    995 / 1978 loss=3.013, nll_loss=0.884, word_ins=2.71, length=3.035, ppl=8.07, wps=46889.4, ups=0.78, wpb=59773.3, bsz=1989.8, num_updates=212600, lr=0.000216879, gnorm=1.274, loss_scale=8192, train_wall=127, wall=279273
2023-01-15 21:24:07 | INFO | train_inner | epoch 108:   1095 / 1978 loss=3.016, nll_loss=0.882, word_ins=2.709, length=3.068, ppl=8.09, wps=46243.4, ups=0.78, wpb=59022.9, bsz=1941.5, num_updates=212700, lr=0.000216828, gnorm=1.292, loss_scale=8192, train_wall=127, wall=279401
2023-01-15 21:26:15 | INFO | train_inner | epoch 108:   1195 / 1978 loss=3.018, nll_loss=0.891, word_ins=2.717, length=3.012, ppl=8.1, wps=46437.5, ups=0.78, wpb=59557.9, bsz=1984.2, num_updates=212800, lr=0.000216777, gnorm=1.289, loss_scale=8192, train_wall=128, wall=279529
2023-01-15 21:28:23 | INFO | train_inner | epoch 108:   1295 / 1978 loss=3.043, nll_loss=0.913, word_ins=2.737, length=3.066, ppl=8.24, wps=46396.9, ups=0.78, wpb=59162.4, bsz=1947.3, num_updates=212900, lr=0.000216727, gnorm=1.284, loss_scale=16384, train_wall=127, wall=279657
2023-01-15 21:28:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 21:28:24 | INFO | train_inner | epoch 108:   1296 / 1978 loss=None, nll_loss=None, word_ins=None, length=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, loss_scale=8192, train_wall=1, wall=279658
2023-01-15 21:30:32 | INFO | train_inner | epoch 108:   1396 / 1978 loss=3.021, nll_loss=0.897, word_ins=2.722, length=2.991, ppl=8.12, wps=46464.3, ups=0.78, wpb=59579.8, bsz=1964.4, num_updates=213000, lr=0.000216676, gnorm=1.32, loss_scale=8192, train_wall=128, wall=279786
2023-01-15 21:32:39 | INFO | train_inner | epoch 108:   1496 / 1978 loss=3.006, nll_loss=0.873, word_ins=2.7, length=3.06, ppl=8.03, wps=47116, ups=0.79, wpb=59711.2, bsz=2020.5, num_updates=213100, lr=0.000216625, gnorm=1.304, loss_scale=8192, train_wall=127, wall=279913
2023-01-15 21:34:46 | INFO | train_inner | epoch 108:   1596 / 1978 loss=3.064, nll_loss=0.93, word_ins=2.752, length=3.115, ppl=8.36, wps=46301.4, ups=0.78, wpb=59006.8, bsz=1930.3, num_updates=213200, lr=0.000216574, gnorm=1.311, loss_scale=8192, train_wall=127, wall=280040
2023-01-15 21:36:56 | INFO | train_inner | epoch 108:   1696 / 1978 loss=2.985, nll_loss=0.864, word_ins=2.691, length=2.936, ppl=7.92, wps=45829.7, ups=0.77, wpb=59474.6, bsz=2135.1, num_updates=213300, lr=0.000216523, gnorm=1.302, loss_scale=8192, train_wall=130, wall=280170
2023-01-15 21:39:05 | INFO | train_inner | epoch 108:   1796 / 1978 loss=3.035, nll_loss=0.9, word_ins=2.725, length=3.095, ppl=8.2, wps=45445.7, ups=0.77, wpb=58692.7, bsz=2061.3, num_updates=213400, lr=0.000216473, gnorm=1.264, loss_scale=8192, train_wall=129, wall=280299
2023-01-15 21:41:12 | INFO | train_inner | epoch 108:   1896 / 1978 loss=3.035, nll_loss=0.903, word_ins=2.728, length=3.072, ppl=8.2, wps=46405.8, ups=0.79, wpb=58689.1, bsz=1975.2, num_updates=213500, lr=0.000216422, gnorm=1.282, loss_scale=8192, train_wall=126, wall=280426
2023-01-15 21:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 21:43:16 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 4.541 | nll_loss 1.974 | word_ins 3.736 | length 8.045 | ppl 23.28 | wps 139356 | wpb 40242.5 | bsz 1500 | num_updates 213582 | best_loss 4.422
2023-01-15 21:43:16 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 21:43:44 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint108.pt (epoch 108 @ 213582 updates, score 4.541) (writing took 27.376812463160604 seconds)
2023-01-15 21:43:44 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2023-01-15 21:43:44 | INFO | train | epoch 108 | loss 3.018 | nll_loss 0.889 | word_ins 2.715 | length 3.035 | ppl 8.1 | wps 45285.4 | ups 0.76 | wpb 59283.2 | bsz 2003.1 | num_updates 213582 | lr 0.00021638 | gnorm 1.287 | loss_scale 8192 | train_wall 2524 | wall 280578
2023-01-15 21:43:44 | INFO | fairseq.trainer | begin training epoch 109
2023-01-15 21:44:20 | INFO | train_inner | epoch 109:     18 / 1978 loss=3.015, nll_loss=0.884, word_ins=2.71, length=3.045, ppl=8.08, wps=31741, ups=0.53, wpb=59645.2, bsz=2035, num_updates=213600, lr=0.000216371, gnorm=1.265, loss_scale=8192, train_wall=128, wall=280614
2023-01-15 21:46:27 | INFO | train_inner | epoch 109:    118 / 1978 loss=3.01, nll_loss=0.88, word_ins=2.707, length=3.027, ppl=8.05, wps=46796.6, ups=0.79, wpb=59411.1, bsz=1981, num_updates=213700, lr=0.000216321, gnorm=1.271, loss_scale=8192, train_wall=127, wall=280741
2023-01-15 21:48:35 | INFO | train_inner | epoch 109:    218 / 1978 loss=2.988, nll_loss=0.863, word_ins=2.691, length=2.97, ppl=7.93, wps=46035.5, ups=0.78, wpb=59176.1, bsz=2079.9, num_updates=213800, lr=0.00021627, gnorm=1.27, loss_scale=8192, train_wall=128, wall=280869
2023-01-15 21:50:43 | INFO | train_inner | epoch 109:    318 / 1978 loss=2.996, nll_loss=0.872, word_ins=2.699, length=2.969, ppl=7.98, wps=46827.2, ups=0.78, wpb=59970.8, bsz=2067.4, num_updates=213900, lr=0.000216219, gnorm=1.28, loss_scale=8192, train_wall=128, wall=280997
2023-01-15 21:52:49 | INFO | train_inner | epoch 109:    418 / 1978 loss=3.046, nll_loss=0.907, word_ins=2.731, length=3.145, ppl=8.26, wps=46610.3, ups=0.79, wpb=58808.4, bsz=1898.2, num_updates=214000, lr=0.000216169, gnorm=1.322, loss_scale=8192, train_wall=126, wall=281123
2023-01-15 21:54:57 | INFO | train_inner | epoch 109:    518 / 1978 loss=3.034, nll_loss=0.909, word_ins=2.733, length=3.007, ppl=8.19, wps=46327.2, ups=0.78, wpb=59079.4, bsz=1961.9, num_updates=214100, lr=0.000216118, gnorm=1.288, loss_scale=8192, train_wall=127, wall=281251
2023-01-15 21:57:05 | INFO | train_inner | epoch 109:    618 / 1978 loss=2.99, nll_loss=0.864, word_ins=2.692, length=2.981, ppl=7.95, wps=46576.8, ups=0.78, wpb=59770.4, bsz=2031.8, num_updates=214200, lr=0.000216068, gnorm=1.276, loss_scale=8192, train_wall=128, wall=281379
2023-01-15 21:59:12 | INFO | train_inner | epoch 109:    718 / 1978 loss=3.019, nll_loss=0.888, word_ins=2.714, length=3.048, ppl=8.11, wps=46542.5, ups=0.79, wpb=59051.6, bsz=1982, num_updates=214300, lr=0.000216017, gnorm=1.302, loss_scale=8192, train_wall=127, wall=281506
2023-01-15 22:01:20 | INFO | train_inner | epoch 109:    818 / 1978 loss=2.99, nll_loss=0.863, word_ins=2.691, length=2.99, ppl=7.94, wps=46010.1, ups=0.78, wpb=59059.6, bsz=2089.1, num_updates=214400, lr=0.000215967, gnorm=1.28, loss_scale=8192, train_wall=128, wall=281635
2023-01-15 22:03:29 | INFO | train_inner | epoch 109:    918 / 1978 loss=3, nll_loss=0.872, word_ins=2.699, length=3.005, ppl=8, wps=46444.5, ups=0.78, wpb=59892.5, bsz=2072.9, num_updates=214500, lr=0.000215917, gnorm=1.282, loss_scale=8192, train_wall=129, wall=281763
2023-01-15 22:05:37 | INFO | train_inner | epoch 109:   1018 / 1978 loss=3.004, nll_loss=0.876, word_ins=2.703, length=3.011, ppl=8.02, wps=46137.6, ups=0.78, wpb=59095.1, bsz=2025.5, num_updates=214600, lr=0.000215866, gnorm=1.227, loss_scale=8192, train_wall=128, wall=281892
2023-01-15 22:07:46 | INFO | train_inner | epoch 109:   1118 / 1978 loss=3.014, nll_loss=0.885, word_ins=2.711, length=3.028, ppl=8.08, wps=46561.4, ups=0.78, wpb=59606.3, bsz=1976.1, num_updates=214700, lr=0.000215816, gnorm=1.318, loss_scale=8192, train_wall=128, wall=282020
2023-01-15 22:09:55 | INFO | train_inner | epoch 109:   1218 / 1978 loss=2.998, nll_loss=0.869, word_ins=2.697, length=3.019, ppl=7.99, wps=45859.6, ups=0.77, wpb=59351.8, bsz=2146.4, num_updates=214800, lr=0.000215766, gnorm=1.239, loss_scale=8192, train_wall=129, wall=282149
2023-01-15 22:12:04 | INFO | train_inner | epoch 109:   1318 / 1978 loss=3.03, nll_loss=0.901, word_ins=2.726, length=3.048, ppl=8.17, wps=46521.6, ups=0.78, wpb=59875.8, bsz=1984.5, num_updates=214900, lr=0.000215716, gnorm=1.271, loss_scale=8192, train_wall=128, wall=282278
2023-01-15 22:14:11 | INFO | train_inner | epoch 109:   1418 / 1978 loss=3.03, nll_loss=0.901, word_ins=2.726, length=3.045, ppl=8.17, wps=46251.9, ups=0.79, wpb=58799.4, bsz=1958, num_updates=215000, lr=0.000215666, gnorm=1.31, loss_scale=8192, train_wall=127, wall=282405
2023-01-15 22:16:18 | INFO | train_inner | epoch 109:   1518 / 1978 loss=3.037, nll_loss=0.902, word_ins=2.727, length=3.104, ppl=8.21, wps=46765.5, ups=0.78, wpb=59638.9, bsz=1950.1, num_updates=215100, lr=0.000215615, gnorm=1.336, loss_scale=8192, train_wall=127, wall=282532
2023-01-15 22:18:25 | INFO | train_inner | epoch 109:   1618 / 1978 loss=3.036, nll_loss=0.907, word_ins=2.731, length=3.057, ppl=8.2, wps=46517.7, ups=0.79, wpb=59064.5, bsz=1975, num_updates=215200, lr=0.000215565, gnorm=1.303, loss_scale=8192, train_wall=127, wall=282659
2023-01-15 22:20:33 | INFO | train_inner | epoch 109:   1718 / 1978 loss=3.019, nll_loss=0.888, word_ins=2.714, length=3.058, ppl=8.11, wps=46488.2, ups=0.78, wpb=59400.4, bsz=2015.4, num_updates=215300, lr=0.000215515, gnorm=1.295, loss_scale=8192, train_wall=127, wall=282787
2023-01-15 22:22:40 | INFO | train_inner | epoch 109:   1818 / 1978 loss=3.041, nll_loss=0.905, word_ins=2.729, length=3.119, ppl=8.23, wps=46210.8, ups=0.79, wpb=58699.8, bsz=1917.5, num_updates=215400, lr=0.000215465, gnorm=1.314, loss_scale=8192, train_wall=127, wall=282914
2023-01-15 22:24:48 | INFO | train_inner | epoch 109:   1918 / 1978 loss=3.017, nll_loss=0.887, word_ins=2.713, length=3.04, ppl=8.1, wps=46065.8, ups=0.78, wpb=58893.2, bsz=2000, num_updates=215500, lr=0.000215415, gnorm=1.283, loss_scale=8192, train_wall=128, wall=283042
2023-01-15 22:26:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 22:26:56 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 4.574 | nll_loss 1.97 | word_ins 3.735 | length 8.396 | ppl 23.82 | wps 59950.3 | wpb 40242.5 | bsz 1500 | num_updates 215560 | best_loss 4.422
2023-01-15 22:26:56 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 22:27:24 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint109.pt (epoch 109 @ 215560 updates, score 4.574) (writing took 28.258006290066987 seconds)
2023-01-15 22:27:24 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2023-01-15 22:27:24 | INFO | train | epoch 109 | loss 3.016 | nll_loss 0.886 | word_ins 2.712 | length 3.038 | ppl 8.09 | wps 44746.7 | ups 0.75 | wpb 59284.3 | bsz 2002.6 | num_updates 215560 | lr 0.000215385 | gnorm 1.288 | loss_scale 8192 | train_wall 2522 | wall 283198
2023-01-15 22:27:24 | INFO | fairseq.trainer | begin training epoch 110
2023-01-15 22:28:28 | INFO | train_inner | epoch 110:     40 / 1978 loss=3.036, nll_loss=0.899, word_ins=2.724, length=3.115, ppl=8.2, wps=26761.3, ups=0.46, wpb=58791.7, bsz=1905.8, num_updates=215600, lr=0.000215365, gnorm=1.294, loss_scale=8192, train_wall=126, wall=283262
2023-01-15 22:30:35 | INFO | train_inner | epoch 110:    140 / 1978 loss=3.035, nll_loss=0.904, word_ins=2.729, length=3.054, ppl=8.19, wps=46740.6, ups=0.79, wpb=59486.3, bsz=1940.2, num_updates=215700, lr=0.000215315, gnorm=1.266, loss_scale=8192, train_wall=127, wall=283389
2023-01-15 22:32:42 | INFO | train_inner | epoch 110:    240 / 1978 loss=3.011, nll_loss=0.88, word_ins=2.706, length=3.045, ppl=8.06, wps=46212.8, ups=0.78, wpb=58885, bsz=1970.2, num_updates=215800, lr=0.000215265, gnorm=1.318, loss_scale=8192, train_wall=127, wall=283516
2023-01-15 22:34:51 | INFO | train_inner | epoch 110:    340 / 1978 loss=3.012, nll_loss=0.882, word_ins=2.709, length=3.029, ppl=8.07, wps=46073.1, ups=0.78, wpb=59361.8, bsz=1974.9, num_updates=215900, lr=0.000215216, gnorm=1.349, loss_scale=8192, train_wall=129, wall=283645
2023-01-15 22:37:00 | INFO | train_inner | epoch 110:    440 / 1978 loss=2.998, nll_loss=0.868, word_ins=2.696, length=3.02, ppl=7.99, wps=45808.3, ups=0.77, wpb=59196.7, bsz=2006.2, num_updates=216000, lr=0.000215166, gnorm=1.307, loss_scale=8192, train_wall=129, wall=283775
2023-01-15 22:39:09 | INFO | train_inner | epoch 110:    540 / 1978 loss=3.006, nll_loss=0.875, word_ins=2.702, length=3.045, ppl=8.04, wps=45997.3, ups=0.78, wpb=59213.5, bsz=2060.2, num_updates=216100, lr=0.000215116, gnorm=1.297, loss_scale=8192, train_wall=129, wall=283903
2023-01-15 22:41:17 | INFO | train_inner | epoch 110:    640 / 1978 loss=3.006, nll_loss=0.879, word_ins=2.706, length=3.008, ppl=8.04, wps=46433.2, ups=0.78, wpb=59504.5, bsz=2031.2, num_updates=216200, lr=0.000215066, gnorm=1.273, loss_scale=8192, train_wall=128, wall=284031
2023-01-15 22:43:26 | INFO | train_inner | epoch 110:    740 / 1978 loss=3.01, nll_loss=0.887, word_ins=2.713, length=2.978, ppl=8.06, wps=46260.4, ups=0.78, wpb=59439.3, bsz=2043.8, num_updates=216300, lr=0.000215016, gnorm=1.284, loss_scale=8192, train_wall=128, wall=284160
2023-01-15 22:45:35 | INFO | train_inner | epoch 110:    840 / 1978 loss=2.998, nll_loss=0.871, word_ins=2.698, length=3.004, ppl=7.99, wps=46687.4, ups=0.78, wpb=60139.8, bsz=2031.8, num_updates=216400, lr=0.000214967, gnorm=1.327, loss_scale=8192, train_wall=129, wall=284289
2023-01-15 22:47:41 | INFO | train_inner | epoch 110:    940 / 1978 loss=3.013, nll_loss=0.882, word_ins=2.709, length=3.042, ppl=8.07, wps=46617, ups=0.79, wpb=59056.7, bsz=1964.8, num_updates=216500, lr=0.000214917, gnorm=1.285, loss_scale=8192, train_wall=126, wall=284415
2023-01-15 22:49:49 | INFO | train_inner | epoch 110:   1040 / 1978 loss=3.03, nll_loss=0.9, word_ins=2.725, length=3.042, ppl=8.17, wps=45979.9, ups=0.78, wpb=58688.8, bsz=2001.8, num_updates=216600, lr=0.000214868, gnorm=1.27, loss_scale=8192, train_wall=127, wall=284543
2023-01-15 22:51:56 | INFO | train_inner | epoch 110:   1140 / 1978 loss=3.032, nll_loss=0.896, word_ins=2.722, length=3.099, ppl=8.18, wps=46263.5, ups=0.79, wpb=58908.6, bsz=1956.2, num_updates=216700, lr=0.000214818, gnorm=1.29, loss_scale=8192, train_wall=127, wall=284670
2023-01-15 22:54:05 | INFO | train_inner | epoch 110:   1240 / 1978 loss=2.995, nll_loss=0.867, word_ins=2.695, length=2.996, ppl=7.97, wps=45989.3, ups=0.78, wpb=59201.9, bsz=2083, num_updates=216800, lr=0.000214768, gnorm=1.253, loss_scale=8192, train_wall=128, wall=284799
2023-01-15 22:56:14 | INFO | train_inner | epoch 110:   1340 / 1978 loss=3.001, nll_loss=0.873, word_ins=2.7, length=3.008, ppl=8, wps=46343.7, ups=0.78, wpb=59602.9, bsz=2084, num_updates=216900, lr=0.000214719, gnorm=1.252, loss_scale=8192, train_wall=128, wall=284928
2023-01-15 22:58:21 | INFO | train_inner | epoch 110:   1440 / 1978 loss=3.038, nll_loss=0.907, word_ins=2.731, length=3.061, ppl=8.21, wps=46696.6, ups=0.79, wpb=59243.9, bsz=1943.3, num_updates=217000, lr=0.000214669, gnorm=1.274, loss_scale=16384, train_wall=127, wall=285055
2023-01-15 22:59:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-15 23:00:30 | INFO | train_inner | epoch 110:   1541 / 1978 loss=3.014, nll_loss=0.886, word_ins=2.712, length=3.02, ppl=8.08, wps=45822.8, ups=0.77, wpb=59473, bsz=2011.8, num_updates=217100, lr=0.00021462, gnorm=1.31, loss_scale=8192, train_wall=130, wall=285184
2023-01-15 23:02:38 | INFO | train_inner | epoch 110:   1641 / 1978 loss=3.026, nll_loss=0.894, word_ins=2.72, length=3.066, ppl=8.15, wps=46233.7, ups=0.78, wpb=59085.6, bsz=2006.5, num_updates=217200, lr=0.000214571, gnorm=1.273, loss_scale=8192, train_wall=128, wall=285312
2023-01-15 23:04:46 | INFO | train_inner | epoch 110:   1741 / 1978 loss=3.013, nll_loss=0.884, word_ins=2.71, length=3.029, ppl=8.07, wps=46306.5, ups=0.78, wpb=59272.4, bsz=2006.7, num_updates=217300, lr=0.000214521, gnorm=1.272, loss_scale=8192, train_wall=128, wall=285440
2023-01-15 23:06:53 | INFO | train_inner | epoch 110:   1841 / 1978 loss=3.034, nll_loss=0.902, word_ins=2.726, length=3.081, ppl=8.19, wps=46593, ups=0.79, wpb=59297.5, bsz=1955.7, num_updates=217400, lr=0.000214472, gnorm=1.299, loss_scale=8192, train_wall=127, wall=285568
2023-01-15 23:09:02 | INFO | train_inner | epoch 110:   1941 / 1978 loss=3.016, nll_loss=0.885, word_ins=2.711, length=3.047, ppl=8.09, wps=46290.4, ups=0.78, wpb=59534.1, bsz=2010.6, num_updates=217500, lr=0.000214423, gnorm=1.305, loss_scale=8192, train_wall=128, wall=285696
2023-01-15 23:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 23:10:06 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 4.582 | nll_loss 1.973 | word_ins 3.737 | length 8.457 | ppl 23.96 | wps 129478 | wpb 40242.5 | bsz 1500 | num_updates 217537 | best_loss 4.422
2023-01-15 23:10:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 23:10:34 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint110.pt (epoch 110 @ 217537 updates, score 4.582) (writing took 28.054091969970614 seconds)
2023-01-15 23:10:34 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2023-01-15 23:10:34 | INFO | train | epoch 110 | loss 3.015 | nll_loss 0.885 | word_ins 2.711 | length 3.036 | ppl 8.08 | wps 45249.2 | ups 0.76 | wpb 59285.7 | bsz 2002.9 | num_updates 217537 | lr 0.000214404 | gnorm 1.289 | loss_scale 8192 | train_wall 2528 | wall 285789
2023-01-15 23:10:34 | INFO | fairseq.trainer | begin training epoch 111
2023-01-15 23:12:10 | INFO | train_inner | epoch 111:     63 / 1978 loss=3.005, nll_loss=0.87, word_ins=2.698, length=3.071, ppl=8.03, wps=31607.5, ups=0.53, wpb=59371, bsz=1912.7, num_updates=217600, lr=0.000214373, gnorm=1.314, loss_scale=8192, train_wall=128, wall=285884
2023-01-15 23:14:19 | INFO | train_inner | epoch 111:    163 / 1978 loss=2.97, nll_loss=0.846, word_ins=2.676, length=2.945, ppl=7.84, wps=46030.6, ups=0.77, wpb=59546.5, bsz=2084.2, num_updates=217700, lr=0.000214324, gnorm=1.268, loss_scale=8192, train_wall=129, wall=286013
2023-01-15 23:16:27 | INFO | train_inner | epoch 111:    263 / 1978 loss=3.005, nll_loss=0.875, word_ins=2.703, length=3.023, ppl=8.03, wps=45781.2, ups=0.78, wpb=58577.3, bsz=2017.9, num_updates=217800, lr=0.000214275, gnorm=1.277, loss_scale=8192, train_wall=128, wall=286141
2023-01-15 23:18:35 | INFO | train_inner | epoch 111:    363 / 1978 loss=3.02, nll_loss=0.891, word_ins=2.716, length=3.035, ppl=8.11, wps=46275.5, ups=0.78, wpb=59331.6, bsz=1975.2, num_updates=217900, lr=0.000214226, gnorm=1.287, loss_scale=8192, train_wall=128, wall=286270
2023-01-15 23:20:44 | INFO | train_inner | epoch 111:    463 / 1978 loss=3.006, nll_loss=0.886, word_ins=2.712, length=2.945, ppl=8.04, wps=46039.8, ups=0.78, wpb=59246.4, bsz=2071.4, num_updates=218000, lr=0.000214176, gnorm=1.256, loss_scale=8192, train_wall=128, wall=286398
2023-01-15 23:22:53 | INFO | train_inner | epoch 111:    563 / 1978 loss=2.998, nll_loss=0.869, word_ins=2.696, length=3.019, ppl=7.99, wps=46313.7, ups=0.78, wpb=59627.1, bsz=2025.8, num_updates=218100, lr=0.000214127, gnorm=1.275, loss_scale=8192, train_wall=128, wall=286527
2023-01-15 23:25:00 | INFO | train_inner | epoch 111:    663 / 1978 loss=3.006, nll_loss=0.878, word_ins=2.705, length=3.01, ppl=8.03, wps=46572.4, ups=0.78, wpb=59397.8, bsz=1987.9, num_updates=218200, lr=0.000214078, gnorm=1.296, loss_scale=8192, train_wall=127, wall=286655
2023-01-15 23:27:09 | INFO | train_inner | epoch 111:    763 / 1978 loss=3.049, nll_loss=0.915, word_ins=2.739, length=3.093, ppl=8.27, wps=45699.1, ups=0.78, wpb=58640.5, bsz=1929.9, num_updates=218300, lr=0.000214029, gnorm=1.292, loss_scale=8192, train_wall=128, wall=286783
2023-01-15 23:29:18 | INFO | train_inner | epoch 111:    863 / 1978 loss=2.998, nll_loss=0.87, word_ins=2.697, length=3.007, ppl=7.99, wps=46335.2, ups=0.78, wpb=59699.4, bsz=1982.3, num_updates=218400, lr=0.00021398, gnorm=1.277, loss_scale=8192, train_wall=129, wall=286912
2023-01-15 23:31:26 | INFO | train_inner | epoch 111:    963 / 1978 loss=3.013, nll_loss=0.881, word_ins=2.707, length=3.056, ppl=8.07, wps=46503.8, ups=0.78, wpb=59503.8, bsz=1967.4, num_updates=218500, lr=0.000213931, gnorm=1.3, loss_scale=8192, train_wall=128, wall=287040
2023-01-15 23:33:35 | INFO | train_inner | epoch 111:   1063 / 1978 loss=3.009, nll_loss=0.887, word_ins=2.713, length=2.968, ppl=8.05, wps=45621.4, ups=0.77, wpb=59073.4, bsz=2103.2, num_updates=218600, lr=0.000213882, gnorm=1.246, loss_scale=8192, train_wall=129, wall=287169
2023-01-15 23:35:43 | INFO | train_inner | epoch 111:   1163 / 1978 loss=3.019, nll_loss=0.883, word_ins=2.709, length=3.1, ppl=8.11, wps=46541.8, ups=0.79, wpb=59284.1, bsz=1945.7, num_updates=218700, lr=0.000213833, gnorm=1.339, loss_scale=8192, train_wall=127, wall=287297
2023-01-15 23:37:51 | INFO | train_inner | epoch 111:   1263 / 1978 loss=3.019, nll_loss=0.892, word_ins=2.718, length=3.015, ppl=8.11, wps=45928.3, ups=0.78, wpb=59113.9, bsz=2025.1, num_updates=218800, lr=0.000213785, gnorm=1.287, loss_scale=8192, train_wall=128, wall=287425
2023-01-15 23:39:59 | INFO | train_inner | epoch 111:   1363 / 1978 loss=3.005, nll_loss=0.875, word_ins=2.703, length=3.02, ppl=8.03, wps=46180.6, ups=0.78, wpb=58854.1, bsz=2017.9, num_updates=218900, lr=0.000213736, gnorm=1.286, loss_scale=8192, train_wall=127, wall=287553
2023-01-15 23:42:07 | INFO | train_inner | epoch 111:   1463 / 1978 loss=3.024, nll_loss=0.896, word_ins=2.721, length=3.032, ppl=8.13, wps=46425.8, ups=0.78, wpb=59466.1, bsz=2012.4, num_updates=219000, lr=0.000213687, gnorm=1.299, loss_scale=8192, train_wall=128, wall=287681
2023-01-15 23:44:15 | INFO | train_inner | epoch 111:   1563 / 1978 loss=3.015, nll_loss=0.885, word_ins=2.711, length=3.042, ppl=8.09, wps=46474.8, ups=0.78, wpb=59551.9, bsz=1971.8, num_updates=219100, lr=0.000213638, gnorm=1.262, loss_scale=8192, train_wall=128, wall=287809
2023-01-15 23:46:22 | INFO | train_inner | epoch 111:   1663 / 1978 loss=3.019, nll_loss=0.884, word_ins=2.71, length=3.086, ppl=8.1, wps=46498.1, ups=0.79, wpb=59035.3, bsz=1993, num_updates=219200, lr=0.000213589, gnorm=1.314, loss_scale=8192, train_wall=127, wall=287936
2023-01-15 23:48:30 | INFO | train_inner | epoch 111:   1763 / 1978 loss=3.034, nll_loss=0.903, word_ins=2.727, length=3.069, ppl=8.19, wps=45982.1, ups=0.78, wpb=58839.2, bsz=1940.3, num_updates=219300, lr=0.000213541, gnorm=1.284, loss_scale=8192, train_wall=128, wall=288064
2023-01-15 23:50:38 | INFO | train_inner | epoch 111:   1863 / 1978 loss=2.997, nll_loss=0.869, word_ins=2.696, length=3.004, ppl=7.98, wps=46553.5, ups=0.78, wpb=59761.2, bsz=2035.9, num_updates=219400, lr=0.000213492, gnorm=1.281, loss_scale=8192, train_wall=128, wall=288192
2023-01-15 23:52:47 | INFO | train_inner | epoch 111:   1963 / 1978 loss=3.004, nll_loss=0.873, word_ins=2.699, length=3.041, ppl=8.02, wps=46508.9, ups=0.78, wpb=59686.8, bsz=2032.2, num_updates=219500, lr=0.000213443, gnorm=1.303, loss_scale=8192, train_wall=128, wall=288321
2023-01-15 23:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-15 23:53:21 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 4.591 | nll_loss 1.973 | word_ins 3.734 | length 8.566 | ppl 24.1 | wps 103443 | wpb 40242.5 | bsz 1500 | num_updates 219515 | best_loss 4.422
2023-01-15 23:53:21 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-15 23:53:47 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint111.pt (epoch 111 @ 219515 updates, score 4.591) (writing took 26.354378107003868 seconds)
2023-01-15 23:53:47 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2023-01-15 23:53:47 | INFO | train | epoch 111 | loss 3.011 | nll_loss 0.882 | word_ins 2.708 | length 3.027 | ppl 8.06 | wps 45229.4 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 219515 | lr 0.000213436 | gnorm 1.286 | loss_scale 8192 | train_wall 2531 | wall 288381
2023-01-15 23:53:47 | INFO | fairseq.trainer | begin training epoch 112
2023-01-15 23:55:49 | INFO | train_inner | epoch 112:     85 / 1978 loss=2.984, nll_loss=0.862, word_ins=2.69, length=2.938, ppl=7.91, wps=32563.5, ups=0.55, wpb=59423.5, bsz=2153, num_updates=219600, lr=0.000213395, gnorm=1.27, loss_scale=8192, train_wall=130, wall=288503
2023-01-15 23:57:58 | INFO | train_inner | epoch 112:    185 / 1978 loss=2.999, nll_loss=0.871, word_ins=2.699, length=3.006, ppl=8, wps=46130.3, ups=0.78, wpb=59479, bsz=2030.5, num_updates=219700, lr=0.000213346, gnorm=1.291, loss_scale=8192, train_wall=129, wall=288632
2023-01-16 00:00:06 | INFO | train_inner | epoch 112:    285 / 1978 loss=3.012, nll_loss=0.884, word_ins=2.71, length=3.024, ppl=8.07, wps=46443.3, ups=0.78, wpb=59330.1, bsz=2004.9, num_updates=219800, lr=0.000213298, gnorm=1.27, loss_scale=8192, train_wall=128, wall=288760
2023-01-16 00:02:13 | INFO | train_inner | epoch 112:    385 / 1978 loss=2.999, nll_loss=0.868, word_ins=2.695, length=3.033, ppl=7.99, wps=46782.7, ups=0.79, wpb=59398.6, bsz=1967, num_updates=219900, lr=0.000213249, gnorm=1.305, loss_scale=8192, train_wall=127, wall=288887
2023-01-16 00:04:20 | INFO | train_inner | epoch 112:    485 / 1978 loss=3.028, nll_loss=0.896, word_ins=2.721, length=3.07, ppl=8.16, wps=46854.9, ups=0.79, wpb=59592, bsz=1892.6, num_updates=220000, lr=0.000213201, gnorm=1.29, loss_scale=8192, train_wall=127, wall=289014
2023-01-16 00:06:28 | INFO | train_inner | epoch 112:    585 / 1978 loss=3.009, nll_loss=0.88, word_ins=2.706, length=3.029, ppl=8.05, wps=46468.8, ups=0.78, wpb=59559.3, bsz=2030.1, num_updates=220100, lr=0.000213152, gnorm=1.288, loss_scale=8192, train_wall=128, wall=289142
2023-01-16 00:08:35 | INFO | train_inner | epoch 112:    685 / 1978 loss=3.026, nll_loss=0.892, word_ins=2.718, length=3.08, ppl=8.15, wps=46314.5, ups=0.79, wpb=58792.6, bsz=1949.2, num_updates=220200, lr=0.000213104, gnorm=1.275, loss_scale=8192, train_wall=127, wall=289269
2023-01-16 00:10:43 | INFO | train_inner | epoch 112:    785 / 1978 loss=3.011, nll_loss=0.88, word_ins=2.706, length=3.049, ppl=8.06, wps=46252, ups=0.78, wpb=59184.6, bsz=1981.8, num_updates=220300, lr=0.000213056, gnorm=1.313, loss_scale=8192, train_wall=128, wall=289397
2023-01-16 00:12:51 | INFO | train_inner | epoch 112:    885 / 1978 loss=3.008, nll_loss=0.878, word_ins=2.704, length=3.04, ppl=8.05, wps=46263.1, ups=0.78, wpb=59000.5, bsz=1978.6, num_updates=220400, lr=0.000213007, gnorm=1.281, loss_scale=8192, train_wall=127, wall=289525
2023-01-16 00:15:00 | INFO | train_inner | epoch 112:    985 / 1978 loss=2.999, nll_loss=0.87, word_ins=2.698, length=3.012, ppl=8, wps=45760.2, ups=0.77, wpb=59142.9, bsz=2033.5, num_updates=220500, lr=0.000212959, gnorm=1.308, loss_scale=8192, train_wall=129, wall=289654
2023-01-16 00:17:06 | INFO | train_inner | epoch 112:   1085 / 1978 loss=3.029, nll_loss=0.897, word_ins=2.722, length=3.076, ppl=8.16, wps=46956.6, ups=0.79, wpb=59305.9, bsz=1909, num_updates=220600, lr=0.000212911, gnorm=1.294, loss_scale=8192, train_wall=126, wall=289780
2023-01-16 00:19:14 | INFO | train_inner | epoch 112:   1185 / 1978 loss=3.032, nll_loss=0.907, word_ins=2.731, length=3.009, ppl=8.18, wps=46457, ups=0.78, wpb=59471.8, bsz=1973.8, num_updates=220700, lr=0.000212862, gnorm=1.285, loss_scale=8192, train_wall=128, wall=289908
2023-01-16 00:21:23 | INFO | train_inner | epoch 112:   1285 / 1978 loss=3.002, nll_loss=0.876, word_ins=2.702, length=2.996, ppl=8.01, wps=46542.5, ups=0.78, wpb=59859.3, bsz=2027, num_updates=220800, lr=0.000212814, gnorm=1.314, loss_scale=8192, train_wall=128, wall=290037
2023-01-16 00:23:30 | INFO | train_inner | epoch 112:   1385 / 1978 loss=3.033, nll_loss=0.901, word_ins=2.725, length=3.076, ppl=8.18, wps=46184.2, ups=0.78, wpb=58904.2, bsz=1952, num_updates=220900, lr=0.000212766, gnorm=1.263, loss_scale=8192, train_wall=127, wall=290165
2023-01-16 00:25:38 | INFO | train_inner | epoch 112:   1485 / 1978 loss=3.004, nll_loss=0.874, word_ins=2.701, length=3.029, ppl=8.02, wps=46303.1, ups=0.78, wpb=58988.4, bsz=1999.8, num_updates=221000, lr=0.000212718, gnorm=1.281, loss_scale=8192, train_wall=127, wall=290292
2023-01-16 00:27:46 | INFO | train_inner | epoch 112:   1585 / 1978 loss=2.992, nll_loss=0.864, word_ins=2.692, length=3.003, ppl=7.95, wps=46402.8, ups=0.78, wpb=59351.6, bsz=2037.5, num_updates=221100, lr=0.00021267, gnorm=1.304, loss_scale=8192, train_wall=128, wall=290420
2023-01-16 00:29:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 00:29:55 | INFO | train_inner | epoch 112:   1686 / 1978 loss=3.011, nll_loss=0.883, word_ins=2.709, length=3.013, ppl=8.06, wps=45741, ups=0.77, wpb=59117, bsz=2045.9, num_updates=221200, lr=0.000212622, gnorm=1.322, loss_scale=8192, train_wall=129, wall=290549
2023-01-16 00:32:03 | INFO | train_inner | epoch 112:   1786 / 1978 loss=3.008, nll_loss=0.878, word_ins=2.705, length=3.031, ppl=8.04, wps=46288, ups=0.78, wpb=59230.7, bsz=2015.8, num_updates=221300, lr=0.000212574, gnorm=1.354, loss_scale=8192, train_wall=128, wall=290677
2023-01-16 00:34:13 | INFO | train_inner | epoch 112:   1886 / 1978 loss=2.999, nll_loss=0.874, word_ins=2.701, length=2.978, ppl=7.99, wps=45772.3, ups=0.77, wpb=59489.6, bsz=2088, num_updates=221400, lr=0.000212526, gnorm=1.295, loss_scale=8192, train_wall=130, wall=290807
2023-01-16 00:36:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 00:36:27 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 4.586 | nll_loss 1.982 | word_ins 3.747 | length 8.396 | ppl 24.02 | wps 152094 | wpb 40242.5 | bsz 1500 | num_updates 221492 | best_loss 4.422
2023-01-16 00:36:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 00:36:54 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint112.pt (epoch 112 @ 221492 updates, score 4.586) (writing took 27.45865455130115 seconds)
2023-01-16 00:36:54 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2023-01-16 00:36:54 | INFO | train | epoch 112 | loss 3.011 | nll_loss 0.881 | word_ins 2.708 | length 3.029 | ppl 8.06 | wps 45303.6 | ups 0.76 | wpb 59283.6 | bsz 2003 | num_updates 221492 | lr 0.000212481 | gnorm 1.293 | loss_scale 8192 | train_wall 2527 | wall 290968
2023-01-16 00:36:54 | INFO | fairseq.trainer | begin training epoch 113
2023-01-16 00:37:28 | INFO | train_inner | epoch 113:      8 / 1978 loss=3.011, nll_loss=0.882, word_ins=2.707, length=3.032, ppl=8.06, wps=30277.6, ups=0.51, wpb=59115.3, bsz=2025.4, num_updates=221500, lr=0.000212478, gnorm=1.245, loss_scale=8192, train_wall=128, wall=291002
2023-01-16 00:39:36 | INFO | train_inner | epoch 113:    108 / 1978 loss=3.021, nll_loss=0.893, word_ins=2.719, length=3.025, ppl=8.12, wps=45727, ups=0.78, wpb=58610.2, bsz=2016.6, num_updates=221600, lr=0.00021243, gnorm=1.263, loss_scale=8192, train_wall=128, wall=291130
2023-01-16 00:41:46 | INFO | train_inner | epoch 113:    208 / 1978 loss=3.004, nll_loss=0.881, word_ins=2.708, length=2.959, ppl=8.02, wps=46260.9, ups=0.77, wpb=59761.7, bsz=2007.7, num_updates=221700, lr=0.000212382, gnorm=1.278, loss_scale=8192, train_wall=129, wall=291260
2023-01-16 00:43:54 | INFO | train_inner | epoch 113:    308 / 1978 loss=2.981, nll_loss=0.854, word_ins=2.683, length=2.979, ppl=7.89, wps=45878, ups=0.78, wpb=59028.2, bsz=2111.8, num_updates=221800, lr=0.000212334, gnorm=1.25, loss_scale=8192, train_wall=128, wall=291388
2023-01-16 00:46:03 | INFO | train_inner | epoch 113:    408 / 1978 loss=2.975, nll_loss=0.851, word_ins=2.68, length=2.956, ppl=7.87, wps=46499.5, ups=0.78, wpb=59733, bsz=2121.4, num_updates=221900, lr=0.000212286, gnorm=1.297, loss_scale=8192, train_wall=128, wall=291517
2023-01-16 00:48:10 | INFO | train_inner | epoch 113:    508 / 1978 loss=3.013, nll_loss=0.879, word_ins=2.706, length=3.078, ppl=8.07, wps=46273.1, ups=0.79, wpb=58804.5, bsz=1957.7, num_updates=222000, lr=0.000212238, gnorm=1.324, loss_scale=8192, train_wall=127, wall=291644
2023-01-16 00:50:18 | INFO | train_inner | epoch 113:    608 / 1978 loss=3.009, nll_loss=0.881, word_ins=2.708, length=3.01, ppl=8.05, wps=46111.8, ups=0.78, wpb=58944.9, bsz=1958.2, num_updates=222100, lr=0.00021219, gnorm=1.305, loss_scale=8192, train_wall=128, wall=291772
2023-01-16 00:52:24 | INFO | train_inner | epoch 113:    708 / 1978 loss=3.038, nll_loss=0.906, word_ins=2.731, length=3.074, ppl=8.21, wps=46800.8, ups=0.79, wpb=59162.9, bsz=1874.5, num_updates=222200, lr=0.000212143, gnorm=1.29, loss_scale=8192, train_wall=126, wall=291898
2023-01-16 00:54:31 | INFO | train_inner | epoch 113:    808 / 1978 loss=3.008, nll_loss=0.88, word_ins=2.707, length=3.007, ppl=8.04, wps=46453.8, ups=0.78, wpb=59181.3, bsz=1997.8, num_updates=222300, lr=0.000212095, gnorm=1.259, loss_scale=8192, train_wall=127, wall=292026
2023-01-16 00:56:40 | INFO | train_inner | epoch 113:    908 / 1978 loss=3.01, nll_loss=0.88, word_ins=2.707, length=3.035, ppl=8.06, wps=46321, ups=0.78, wpb=59477.7, bsz=2008.7, num_updates=222400, lr=0.000212047, gnorm=1.29, loss_scale=8192, train_wall=128, wall=292154
2023-01-16 00:58:46 | INFO | train_inner | epoch 113:   1008 / 1978 loss=3.029, nll_loss=0.894, word_ins=2.72, length=3.091, ppl=8.16, wps=47097.1, ups=0.79, wpb=59319.6, bsz=1897.4, num_updates=222500, lr=0.000212, gnorm=1.318, loss_scale=8192, train_wall=126, wall=292280
2023-01-16 01:00:55 | INFO | train_inner | epoch 113:   1108 / 1978 loss=3.009, nll_loss=0.886, word_ins=2.712, length=2.973, ppl=8.05, wps=46275.3, ups=0.78, wpb=59149.4, bsz=2071, num_updates=222600, lr=0.000211952, gnorm=1.232, loss_scale=8192, train_wall=128, wall=292408
2023-01-16 01:03:02 | INFO | train_inner | epoch 113:   1208 / 1978 loss=3.023, nll_loss=0.892, word_ins=2.717, length=3.052, ppl=8.13, wps=46553.9, ups=0.78, wpb=59324.5, bsz=1926.4, num_updates=222700, lr=0.000211904, gnorm=1.346, loss_scale=8192, train_wall=127, wall=292537
2023-01-16 01:05:10 | INFO | train_inner | epoch 113:   1308 / 1978 loss=3.024, nll_loss=0.894, word_ins=2.72, length=3.039, ppl=8.13, wps=46329.6, ups=0.78, wpb=59240.4, bsz=1988.5, num_updates=222800, lr=0.000211857, gnorm=1.283, loss_scale=8192, train_wall=128, wall=292664
2023-01-16 01:07:17 | INFO | train_inner | epoch 113:   1408 / 1978 loss=3.025, nll_loss=0.89, word_ins=2.715, length=3.095, ppl=8.14, wps=46754.3, ups=0.79, wpb=59166.1, bsz=1953.4, num_updates=222900, lr=0.000211809, gnorm=1.282, loss_scale=8192, train_wall=126, wall=292791
2023-01-16 01:09:25 | INFO | train_inner | epoch 113:   1508 / 1978 loss=2.981, nll_loss=0.858, word_ins=2.686, length=2.955, ppl=7.9, wps=46590.7, ups=0.78, wpb=59762.8, bsz=2049.5, num_updates=223000, lr=0.000211762, gnorm=1.329, loss_scale=8192, train_wall=128, wall=292919
2023-01-16 01:11:32 | INFO | train_inner | epoch 113:   1608 / 1978 loss=3.011, nll_loss=0.88, word_ins=2.706, length=3.053, ppl=8.06, wps=47066.1, ups=0.79, wpb=59680.8, bsz=1987.8, num_updates=223100, lr=0.000211714, gnorm=1.321, loss_scale=8192, train_wall=127, wall=293046
2023-01-16 01:13:40 | INFO | train_inner | epoch 113:   1708 / 1978 loss=3.001, nll_loss=0.873, word_ins=2.7, length=3.012, ppl=8.01, wps=46172.1, ups=0.78, wpb=59091, bsz=2042.6, num_updates=223200, lr=0.000211667, gnorm=1.229, loss_scale=8192, train_wall=128, wall=293174
2023-01-16 01:15:48 | INFO | train_inner | epoch 113:   1808 / 1978 loss=3.021, nll_loss=0.891, word_ins=2.717, length=3.04, ppl=8.12, wps=46231.4, ups=0.78, wpb=59213.5, bsz=2005.3, num_updates=223300, lr=0.000211619, gnorm=1.325, loss_scale=8192, train_wall=128, wall=293302
2023-01-16 01:17:55 | INFO | train_inner | epoch 113:   1908 / 1978 loss=2.998, nll_loss=0.867, word_ins=2.694, length=3.041, ppl=7.99, wps=46487.6, ups=0.79, wpb=59157.7, bsz=2043.6, num_updates=223400, lr=0.000211572, gnorm=1.285, loss_scale=8192, train_wall=127, wall=293429
2023-01-16 01:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 01:19:37 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 4.621 | nll_loss 1.982 | word_ins 3.746 | length 8.748 | ppl 24.61 | wps 98418 | wpb 40242.5 | bsz 1500 | num_updates 223470 | best_loss 4.422
2023-01-16 01:19:37 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 01:20:05 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint113.pt (epoch 113 @ 223470 updates, score 4.621) (writing took 27.918228059075773 seconds)
2023-01-16 01:20:05 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2023-01-16 01:20:05 | INFO | train | epoch 113 | loss 3.01 | nll_loss 0.881 | word_ins 2.707 | length 3.025 | ppl 8.05 | wps 45254.1 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 223470 | lr 0.000211539 | gnorm 1.292 | loss_scale 8192 | train_wall 2521 | wall 293560
2023-01-16 01:20:05 | INFO | fairseq.trainer | begin training epoch 114
2023-01-16 01:20:55 | INFO | train_inner | epoch 114:     30 / 1978 loss=3.005, nll_loss=0.877, word_ins=2.703, length=3.017, ppl=8.03, wps=33477.2, ups=0.56, wpb=60050.7, bsz=2038.9, num_updates=223500, lr=0.000211525, gnorm=1.343, loss_scale=8192, train_wall=128, wall=293609
2023-01-16 01:23:03 | INFO | train_inner | epoch 114:    130 / 1978 loss=3.002, nll_loss=0.877, word_ins=2.704, length=2.978, ppl=8.01, wps=46648, ups=0.78, wpb=59702.3, bsz=2006.2, num_updates=223600, lr=0.000211477, gnorm=1.309, loss_scale=8192, train_wall=128, wall=293737
2023-01-16 01:25:11 | INFO | train_inner | epoch 114:    230 / 1978 loss=3.005, nll_loss=0.875, word_ins=2.701, length=3.037, ppl=8.03, wps=46450.5, ups=0.78, wpb=59550.4, bsz=1998.8, num_updates=223700, lr=0.00021143, gnorm=1.317, loss_scale=8192, train_wall=128, wall=293865
2023-01-16 01:27:18 | INFO | train_inner | epoch 114:    330 / 1978 loss=3.02, nll_loss=0.887, word_ins=2.713, length=3.078, ppl=8.11, wps=46734, ups=0.78, wpb=59577.7, bsz=1935.4, num_updates=223800, lr=0.000211383, gnorm=1.344, loss_scale=8192, train_wall=127, wall=293992
2023-01-16 01:29:26 | INFO | train_inner | epoch 114:    430 / 1978 loss=3.01, nll_loss=0.88, word_ins=2.707, length=3.035, ppl=8.06, wps=46722.6, ups=0.79, wpb=59403.5, bsz=2008, num_updates=223900, lr=0.000211336, gnorm=1.296, loss_scale=8192, train_wall=127, wall=294120
2023-01-16 01:31:33 | INFO | train_inner | epoch 114:    530 / 1978 loss=3, nll_loss=0.872, word_ins=2.699, length=3.01, ppl=8, wps=46093.9, ups=0.78, wpb=58840.5, bsz=2032.8, num_updates=224000, lr=0.000211289, gnorm=1.272, loss_scale=8192, train_wall=127, wall=294247
2023-01-16 01:33:40 | INFO | train_inner | epoch 114:    630 / 1978 loss=3.002, nll_loss=0.873, word_ins=2.7, length=3.019, ppl=8.01, wps=46626.5, ups=0.79, wpb=59185.3, bsz=2000.6, num_updates=224100, lr=0.000211241, gnorm=1.292, loss_scale=8192, train_wall=127, wall=294374
2023-01-16 01:35:46 | INFO | train_inner | epoch 114:    730 / 1978 loss=3.03, nll_loss=0.895, word_ins=2.72, length=3.094, ppl=8.17, wps=46574.4, ups=0.79, wpb=58730.8, bsz=1916.4, num_updates=224200, lr=0.000211194, gnorm=1.301, loss_scale=8192, train_wall=126, wall=294500
2023-01-16 01:37:55 | INFO | train_inner | epoch 114:    830 / 1978 loss=2.992, nll_loss=0.868, word_ins=2.696, length=2.963, ppl=7.96, wps=46127.3, ups=0.78, wpb=59250.5, bsz=2097.2, num_updates=224300, lr=0.000211147, gnorm=1.233, loss_scale=8192, train_wall=128, wall=294629
2023-01-16 01:40:03 | INFO | train_inner | epoch 114:    930 / 1978 loss=3.002, nll_loss=0.878, word_ins=2.705, length=2.974, ppl=8.01, wps=46289.3, ups=0.78, wpb=59424.2, bsz=2064.9, num_updates=224400, lr=0.0002111, gnorm=1.27, loss_scale=8192, train_wall=128, wall=294757
2023-01-16 01:42:12 | INFO | train_inner | epoch 114:   1030 / 1978 loss=3.003, nll_loss=0.875, word_ins=2.702, length=3.016, ppl=8.02, wps=46357.1, ups=0.78, wpb=59559.8, bsz=2022.6, num_updates=224500, lr=0.000211053, gnorm=1.28, loss_scale=8192, train_wall=128, wall=294886
2023-01-16 01:44:20 | INFO | train_inner | epoch 114:   1130 / 1978 loss=3.001, nll_loss=0.872, word_ins=2.699, length=3.017, ppl=8, wps=46322.1, ups=0.78, wpb=59424.9, bsz=2020.5, num_updates=224600, lr=0.000211006, gnorm=1.291, loss_scale=8192, train_wall=128, wall=295014
2023-01-16 01:46:28 | INFO | train_inner | epoch 114:   1230 / 1978 loss=3.002, nll_loss=0.869, word_ins=2.696, length=3.054, ppl=8.01, wps=46317.7, ups=0.78, wpb=59163.8, bsz=1995.4, num_updates=224700, lr=0.000210959, gnorm=1.286, loss_scale=8192, train_wall=128, wall=295142
2023-01-16 01:48:35 | INFO | train_inner | epoch 114:   1330 / 1978 loss=3.012, nll_loss=0.884, word_ins=2.71, length=3.022, ppl=8.07, wps=46748, ups=0.79, wpb=59365.7, bsz=1963.4, num_updates=224800, lr=0.000210912, gnorm=1.265, loss_scale=8192, train_wall=127, wall=295269
2023-01-16 01:50:43 | INFO | train_inner | epoch 114:   1430 / 1978 loss=2.982, nll_loss=0.859, word_ins=2.688, length=2.949, ppl=7.9, wps=46104.5, ups=0.78, wpb=59068.8, bsz=2073, num_updates=224900, lr=0.000210865, gnorm=1.283, loss_scale=8192, train_wall=128, wall=295397
2023-01-16 01:52:49 | INFO | train_inner | epoch 114:   1530 / 1978 loss=3.026, nll_loss=0.896, word_ins=2.721, length=3.052, ppl=8.14, wps=46815.4, ups=0.79, wpb=59330.9, bsz=1946.8, num_updates=225000, lr=0.000210819, gnorm=1.308, loss_scale=8192, train_wall=127, wall=295524
2023-01-16 01:54:57 | INFO | train_inner | epoch 114:   1630 / 1978 loss=3.038, nll_loss=0.905, word_ins=2.729, length=3.09, ppl=8.21, wps=46274.1, ups=0.78, wpb=59132.8, bsz=1919.1, num_updates=225100, lr=0.000210772, gnorm=1.343, loss_scale=8192, train_wall=128, wall=295651
2023-01-16 01:57:05 | INFO | train_inner | epoch 114:   1730 / 1978 loss=3.023, nll_loss=0.895, word_ins=2.72, length=3.031, ppl=8.13, wps=46361.8, ups=0.79, wpb=58991.3, bsz=2014.9, num_updates=225200, lr=0.000210725, gnorm=1.326, loss_scale=8192, train_wall=127, wall=295779
2023-01-16 01:58:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 01:59:14 | INFO | train_inner | epoch 114:   1831 / 1978 loss=2.995, nll_loss=0.871, word_ins=2.698, length=2.974, ppl=7.97, wps=46044.6, ups=0.77, wpb=59746.5, bsz=2073.3, num_updates=225300, lr=0.000210678, gnorm=1.271, loss_scale=8192, train_wall=130, wall=295908
2023-01-16 02:01:23 | INFO | train_inner | epoch 114:   1931 / 1978 loss=3.027, nll_loss=0.895, word_ins=2.72, length=3.07, ppl=8.15, wps=45608.8, ups=0.78, wpb=58739, bsz=1940.5, num_updates=225400, lr=0.000210631, gnorm=1.285, loss_scale=8192, train_wall=128, wall=296037
2023-01-16 02:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 02:02:35 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 4.616 | nll_loss 1.969 | word_ins 3.733 | length 8.829 | ppl 24.53 | wps 125014 | wpb 40242.5 | bsz 1500 | num_updates 225447 | best_loss 4.422
2023-01-16 02:02:35 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 02:03:02 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint114.pt (epoch 114 @ 225447 updates, score 4.616) (writing took 27.1369764120318 seconds)
2023-01-16 02:03:02 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2023-01-16 02:03:02 | INFO | train | epoch 114 | loss 3.008 | nll_loss 0.879 | word_ins 2.706 | length 3.024 | ppl 8.05 | wps 45486.6 | ups 0.77 | wpb 59284.3 | bsz 2002.9 | num_updates 225447 | lr 0.000210609 | gnorm 1.295 | loss_scale 8192 | train_wall 2522 | wall 296136
2023-01-16 02:03:02 | INFO | fairseq.trainer | begin training epoch 115
2023-01-16 02:04:22 | INFO | train_inner | epoch 115:     53 / 1978 loss=2.983, nll_loss=0.857, word_ins=2.686, length=2.971, ppl=7.91, wps=33040.4, ups=0.56, wpb=59139.5, bsz=2043.4, num_updates=225500, lr=0.000210585, gnorm=1.321, loss_scale=8192, train_wall=128, wall=296216
2023-01-16 02:06:30 | INFO | train_inner | epoch 115:    153 / 1978 loss=3.029, nll_loss=0.897, word_ins=2.722, length=3.068, ppl=8.16, wps=46130.2, ups=0.78, wpb=58860.4, bsz=1967, num_updates=225600, lr=0.000210538, gnorm=1.279, loss_scale=8192, train_wall=127, wall=296344
2023-01-16 02:08:37 | INFO | train_inner | epoch 115:    253 / 1978 loss=2.985, nll_loss=0.856, word_ins=2.684, length=3.008, ppl=7.92, wps=46714, ups=0.79, wpb=59473.8, bsz=1985.4, num_updates=225700, lr=0.000210491, gnorm=1.302, loss_scale=8192, train_wall=127, wall=296471
2023-01-16 02:10:44 | INFO | train_inner | epoch 115:    353 / 1978 loss=3.003, nll_loss=0.872, word_ins=2.699, length=3.04, ppl=8.02, wps=46681.4, ups=0.78, wpb=59476, bsz=1950.1, num_updates=225800, lr=0.000210445, gnorm=1.36, loss_scale=8192, train_wall=127, wall=296598
2023-01-16 02:12:51 | INFO | train_inner | epoch 115:    453 / 1978 loss=2.992, nll_loss=0.868, word_ins=2.696, length=2.959, ppl=7.95, wps=46955.2, ups=0.79, wpb=59650.6, bsz=2002.1, num_updates=225900, lr=0.000210398, gnorm=1.3, loss_scale=8192, train_wall=127, wall=296726
2023-01-16 02:14:59 | INFO | train_inner | epoch 115:    553 / 1978 loss=3.02, nll_loss=0.894, word_ins=2.718, length=3.014, ppl=8.11, wps=47182.5, ups=0.79, wpb=60019.6, bsz=1990, num_updates=226000, lr=0.000210352, gnorm=1.299, loss_scale=8192, train_wall=127, wall=296853
2023-01-16 02:17:06 | INFO | train_inner | epoch 115:    653 / 1978 loss=3.01, nll_loss=0.88, word_ins=2.707, length=3.036, ppl=8.06, wps=46204.9, ups=0.78, wpb=58928.9, bsz=1956.8, num_updates=226100, lr=0.000210305, gnorm=1.28, loss_scale=8192, train_wall=127, wall=296980
2023-01-16 02:19:15 | INFO | train_inner | epoch 115:    753 / 1978 loss=2.989, nll_loss=0.864, word_ins=2.691, length=2.981, ppl=7.94, wps=46335.3, ups=0.77, wpb=59846.2, bsz=2014, num_updates=226200, lr=0.000210259, gnorm=1.33, loss_scale=8192, train_wall=129, wall=297109
2023-01-16 02:21:23 | INFO | train_inner | epoch 115:    853 / 1978 loss=3.034, nll_loss=0.904, word_ins=2.729, length=3.05, ppl=8.19, wps=46340.9, ups=0.79, wpb=58986.5, bsz=1898.4, num_updates=226300, lr=0.000210212, gnorm=1.294, loss_scale=8192, train_wall=127, wall=297237
2023-01-16 02:23:31 | INFO | train_inner | epoch 115:    953 / 1978 loss=2.98, nll_loss=0.854, word_ins=2.682, length=2.978, ppl=7.89, wps=46270.3, ups=0.78, wpb=59463.9, bsz=2080.6, num_updates=226400, lr=0.000210166, gnorm=1.317, loss_scale=8192, train_wall=128, wall=297365
2023-01-16 02:25:40 | INFO | train_inner | epoch 115:   1053 / 1978 loss=3, nll_loss=0.876, word_ins=2.703, length=2.971, ppl=8, wps=46215.6, ups=0.77, wpb=59702.4, bsz=2075.8, num_updates=226500, lr=0.000210119, gnorm=1.251, loss_scale=8192, train_wall=129, wall=297494
2023-01-16 02:27:48 | INFO | train_inner | epoch 115:   1153 / 1978 loss=3.008, nll_loss=0.884, word_ins=2.71, length=2.974, ppl=8.04, wps=46008, ups=0.78, wpb=58926.8, bsz=2056.1, num_updates=226600, lr=0.000210073, gnorm=1.295, loss_scale=8192, train_wall=128, wall=297623
2023-01-16 02:29:56 | INFO | train_inner | epoch 115:   1253 / 1978 loss=3.001, nll_loss=0.87, word_ins=2.697, length=3.041, ppl=8, wps=46351.2, ups=0.78, wpb=59297.8, bsz=2042, num_updates=226700, lr=0.000210027, gnorm=1.277, loss_scale=8192, train_wall=128, wall=297750
2023-01-16 02:32:04 | INFO | train_inner | epoch 115:   1353 / 1978 loss=3.03, nll_loss=0.897, word_ins=2.722, length=3.077, ppl=8.17, wps=46338.3, ups=0.79, wpb=58933.9, bsz=1915.8, num_updates=226800, lr=0.00020998, gnorm=1.303, loss_scale=8192, train_wall=127, wall=297878
2023-01-16 02:34:11 | INFO | train_inner | epoch 115:   1453 / 1978 loss=3.014, nll_loss=0.885, word_ins=2.711, length=3.036, ppl=8.08, wps=46664, ups=0.79, wpb=59366.1, bsz=1975.8, num_updates=226900, lr=0.000209934, gnorm=1.298, loss_scale=8192, train_wall=127, wall=298005
2023-01-16 02:36:19 | INFO | train_inner | epoch 115:   1553 / 1978 loss=2.997, nll_loss=0.87, word_ins=2.697, length=2.994, ppl=7.98, wps=46554.8, ups=0.78, wpb=59553.8, bsz=2015.6, num_updates=227000, lr=0.000209888, gnorm=1.308, loss_scale=8192, train_wall=128, wall=298133
2023-01-16 02:38:27 | INFO | train_inner | epoch 115:   1653 / 1978 loss=3.005, nll_loss=0.879, word_ins=2.705, length=2.999, ppl=8.03, wps=46283.6, ups=0.78, wpb=59235.3, bsz=2088.6, num_updates=227100, lr=0.000209842, gnorm=1.266, loss_scale=8192, train_wall=128, wall=298261
2023-01-16 02:40:33 | INFO | train_inner | epoch 115:   1753 / 1978 loss=3.024, nll_loss=0.891, word_ins=2.717, length=3.066, ppl=8.13, wps=46294.6, ups=0.79, wpb=58650.8, bsz=2000.4, num_updates=227200, lr=0.000209795, gnorm=1.29, loss_scale=8192, train_wall=126, wall=298388
2023-01-16 02:42:42 | INFO | train_inner | epoch 115:   1853 / 1978 loss=2.998, nll_loss=0.868, word_ins=2.696, length=3.028, ppl=7.99, wps=46137.9, ups=0.78, wpb=59198.4, bsz=2025, num_updates=227300, lr=0.000209749, gnorm=1.271, loss_scale=8192, train_wall=128, wall=298516
2023-01-16 02:44:49 | INFO | train_inner | epoch 115:   1953 / 1978 loss=3.01, nll_loss=0.882, word_ins=2.708, length=3.021, ppl=8.06, wps=46502.5, ups=0.79, wpb=59062, bsz=1978.8, num_updates=227400, lr=0.000209703, gnorm=1.264, loss_scale=8192, train_wall=127, wall=298643
2023-01-16 02:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 02:45:34 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 4.586 | nll_loss 1.978 | word_ins 3.741 | length 8.446 | ppl 24.01 | wps 153589 | wpb 40242.5 | bsz 1500 | num_updates 227425 | best_loss 4.422
2023-01-16 02:45:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 02:46:01 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint115.pt (epoch 115 @ 227425 updates, score 4.586) (writing took 27.064442629925907 seconds)
2023-01-16 02:46:01 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2023-01-16 02:46:01 | INFO | train | epoch 115 | loss 3.006 | nll_loss 0.878 | word_ins 2.704 | length 3.015 | ppl 8.03 | wps 45468.6 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 227425 | lr 0.000209692 | gnorm 1.293 | loss_scale 8192 | train_wall 2522 | wall 298715
2023-01-16 02:46:01 | INFO | fairseq.trainer | begin training epoch 116
2023-01-16 02:47:49 | INFO | train_inner | epoch 116:     75 / 1978 loss=2.994, nll_loss=0.871, word_ins=2.698, length=2.967, ppl=7.97, wps=32840.9, ups=0.55, wpb=59222.1, bsz=2008.8, num_updates=227500, lr=0.000209657, gnorm=1.222, loss_scale=8192, train_wall=128, wall=298823
2023-01-16 02:49:58 | INFO | train_inner | epoch 116:    175 / 1978 loss=2.983, nll_loss=0.858, word_ins=2.686, length=2.975, ppl=7.91, wps=46614, ups=0.78, wpb=60022.8, bsz=2010.4, num_updates=227600, lr=0.000209611, gnorm=1.3, loss_scale=8192, train_wall=128, wall=298952
2023-01-16 02:52:05 | INFO | train_inner | epoch 116:    275 / 1978 loss=3.003, nll_loss=0.873, word_ins=2.701, length=3.024, ppl=8.02, wps=45976.8, ups=0.78, wpb=58651.6, bsz=1969.8, num_updates=227700, lr=0.000209565, gnorm=1.33, loss_scale=8192, train_wall=127, wall=299080
2023-01-16 02:54:15 | INFO | train_inner | epoch 116:    375 / 1978 loss=3.003, nll_loss=0.88, word_ins=2.707, length=2.955, ppl=8.01, wps=45366.7, ups=0.77, wpb=58896.9, bsz=2060.5, num_updates=227800, lr=0.000209519, gnorm=1.231, loss_scale=8192, train_wall=130, wall=299209
2023-01-16 02:56:24 | INFO | train_inner | epoch 116:    475 / 1978 loss=2.995, nll_loss=0.871, word_ins=2.699, length=2.96, ppl=7.97, wps=46064.5, ups=0.78, wpb=59087.9, bsz=2062.2, num_updates=227900, lr=0.000209473, gnorm=1.263, loss_scale=8192, train_wall=128, wall=299338
2023-01-16 02:58:32 | INFO | train_inner | epoch 116:    575 / 1978 loss=3.008, nll_loss=0.879, word_ins=2.705, length=3.026, ppl=8.04, wps=46422.1, ups=0.78, wpb=59629.3, bsz=1996.8, num_updates=228000, lr=0.000209427, gnorm=1.307, loss_scale=8192, train_wall=128, wall=299466
2023-01-16 03:00:39 | INFO | train_inner | epoch 116:    675 / 1978 loss=3.036, nll_loss=0.903, word_ins=2.728, length=3.077, ppl=8.2, wps=46382.8, ups=0.79, wpb=58977, bsz=1950.9, num_updates=228100, lr=0.000209381, gnorm=1.316, loss_scale=8192, train_wall=127, wall=299593
2023-01-16 03:02:47 | INFO | train_inner | epoch 116:    775 / 1978 loss=2.98, nll_loss=0.853, word_ins=2.681, length=2.984, ppl=7.89, wps=46243.4, ups=0.78, wpb=59021.2, bsz=2085.9, num_updates=228200, lr=0.000209335, gnorm=1.263, loss_scale=8192, train_wall=127, wall=299721
2023-01-16 03:04:55 | INFO | train_inner | epoch 116:    875 / 1978 loss=3.006, nll_loss=0.882, word_ins=2.708, length=2.978, ppl=8.03, wps=46337.6, ups=0.78, wpb=59383.7, bsz=2008.6, num_updates=228300, lr=0.000209289, gnorm=1.264, loss_scale=8192, train_wall=128, wall=299849
2023-01-16 03:07:02 | INFO | train_inner | epoch 116:    975 / 1978 loss=3.022, nll_loss=0.889, word_ins=2.714, length=3.077, ppl=8.12, wps=46695.7, ups=0.79, wpb=59171.2, bsz=1924.1, num_updates=228400, lr=0.000209243, gnorm=1.3, loss_scale=8192, train_wall=126, wall=299976
2023-01-16 03:09:10 | INFO | train_inner | epoch 116:   1075 / 1978 loss=2.987, nll_loss=0.864, word_ins=2.691, length=2.961, ppl=7.93, wps=46481, ups=0.78, wpb=59576.7, bsz=2045, num_updates=228500, lr=0.000209198, gnorm=1.271, loss_scale=8192, train_wall=128, wall=300104
2023-01-16 03:11:18 | INFO | train_inner | epoch 116:   1175 / 1978 loss=2.977, nll_loss=0.846, word_ins=2.675, length=3.012, ppl=7.87, wps=46398.1, ups=0.78, wpb=59450.3, bsz=2088.5, num_updates=228600, lr=0.000209152, gnorm=1.287, loss_scale=8192, train_wall=128, wall=300232
2023-01-16 03:13:26 | INFO | train_inner | epoch 116:   1275 / 1978 loss=3.008, nll_loss=0.879, word_ins=2.706, length=3.023, ppl=8.04, wps=46740.5, ups=0.78, wpb=59598.8, bsz=1976.8, num_updates=228700, lr=0.000209106, gnorm=1.335, loss_scale=8192, train_wall=127, wall=300360
2023-01-16 03:15:33 | INFO | train_inner | epoch 116:   1375 / 1978 loss=3.013, nll_loss=0.888, word_ins=2.713, length=2.995, ppl=8.07, wps=46649.8, ups=0.79, wpb=59341.6, bsz=1987.4, num_updates=228800, lr=0.000209061, gnorm=1.311, loss_scale=8192, train_wall=127, wall=300487
2023-01-16 03:17:41 | INFO | train_inner | epoch 116:   1475 / 1978 loss=3.003, nll_loss=0.874, word_ins=2.701, length=3.015, ppl=8.01, wps=45933.5, ups=0.78, wpb=59026.4, bsz=2031.4, num_updates=228900, lr=0.000209015, gnorm=1.285, loss_scale=8192, train_wall=128, wall=300615
2023-01-16 03:19:48 | INFO | train_inner | epoch 116:   1575 / 1978 loss=3.015, nll_loss=0.885, word_ins=2.711, length=3.037, ppl=8.08, wps=47102.2, ups=0.79, wpb=59584, bsz=1919.8, num_updates=229000, lr=0.000208969, gnorm=1.314, loss_scale=8192, train_wall=126, wall=300742
2023-01-16 03:21:55 | INFO | train_inner | epoch 116:   1675 / 1978 loss=3.005, nll_loss=0.88, word_ins=2.707, length=2.976, ppl=8.03, wps=46254.8, ups=0.78, wpb=59047.5, bsz=2010.4, num_updates=229100, lr=0.000208924, gnorm=1.31, loss_scale=8192, train_wall=127, wall=300870
2023-01-16 03:24:04 | INFO | train_inner | epoch 116:   1775 / 1978 loss=3.03, nll_loss=0.893, word_ins=2.718, length=3.121, ppl=8.17, wps=46245, ups=0.78, wpb=59264.9, bsz=1963.4, num_updates=229200, lr=0.000208878, gnorm=1.32, loss_scale=8192, train_wall=128, wall=300998
2023-01-16 03:26:12 | INFO | train_inner | epoch 116:   1875 / 1978 loss=3.004, nll_loss=0.874, word_ins=2.7, length=3.038, ppl=8.02, wps=46386.2, ups=0.78, wpb=59360.1, bsz=1985.7, num_updates=229300, lr=0.000208832, gnorm=1.323, loss_scale=8192, train_wall=128, wall=301126
2023-01-16 03:27:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 03:28:20 | INFO | train_inner | epoch 116:   1976 / 1978 loss=3.014, nll_loss=0.885, word_ins=2.71, length=3.04, ppl=8.08, wps=46407.1, ups=0.78, wpb=59464, bsz=1987.6, num_updates=229400, lr=0.000208787, gnorm=1.265, loss_scale=8192, train_wall=128, wall=301254
2023-01-16 03:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 03:28:34 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 4.602 | nll_loss 1.977 | word_ins 3.739 | length 8.636 | ppl 24.29 | wps 127460 | wpb 40242.5 | bsz 1500 | num_updates 229402 | best_loss 4.422
2023-01-16 03:28:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 03:29:02 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint116.pt (epoch 116 @ 229402 updates, score 4.602) (writing took 27.803355977870524 seconds)
2023-01-16 03:29:02 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2023-01-16 03:29:02 | INFO | train | epoch 116 | loss 3.004 | nll_loss 0.877 | word_ins 2.703 | length 3.012 | ppl 8.02 | wps 45412.5 | ups 0.77 | wpb 59284.9 | bsz 2003.1 | num_updates 229402 | lr 0.000208786 | gnorm 1.292 | loss_scale 8192 | train_wall 2525 | wall 301296
2023-01-16 03:29:02 | INFO | fairseq.trainer | begin training epoch 117
2023-01-16 03:31:19 | INFO | train_inner | epoch 117:     98 / 1978 loss=2.998, nll_loss=0.87, word_ins=2.697, length=3.004, ppl=7.99, wps=32998, ups=0.56, wpb=59103.4, bsz=1966.5, num_updates=229500, lr=0.000208741, gnorm=1.288, loss_scale=8192, train_wall=127, wall=301433
2023-01-16 03:33:28 | INFO | train_inner | epoch 117:    198 / 1978 loss=3.004, nll_loss=0.876, word_ins=2.703, length=3.018, ppl=8.02, wps=46413, ups=0.78, wpb=59551.1, bsz=2013.8, num_updates=229600, lr=0.000208696, gnorm=1.304, loss_scale=8192, train_wall=128, wall=301562
2023-01-16 03:35:35 | INFO | train_inner | epoch 117:    298 / 1978 loss=3.018, nll_loss=0.89, word_ins=2.716, length=3.018, ppl=8.1, wps=46441.5, ups=0.78, wpb=59296.8, bsz=1947.1, num_updates=229700, lr=0.000208651, gnorm=1.327, loss_scale=8192, train_wall=127, wall=301690
2023-01-16 03:37:44 | INFO | train_inner | epoch 117:    398 / 1978 loss=3.004, nll_loss=0.878, word_ins=2.704, length=2.994, ppl=8.02, wps=46277.5, ups=0.78, wpb=59302.9, bsz=2030.2, num_updates=229800, lr=0.000208605, gnorm=1.284, loss_scale=8192, train_wall=128, wall=301818
2023-01-16 03:39:50 | INFO | train_inner | epoch 117:    498 / 1978 loss=3.01, nll_loss=0.88, word_ins=2.706, length=3.043, ppl=8.06, wps=46565.9, ups=0.79, wpb=59015.8, bsz=1947.8, num_updates=229900, lr=0.00020856, gnorm=1.296, loss_scale=8192, train_wall=127, wall=301944
2023-01-16 03:41:57 | INFO | train_inner | epoch 117:    598 / 1978 loss=3.006, nll_loss=0.875, word_ins=2.701, length=3.046, ppl=8.03, wps=46659, ups=0.79, wpb=59156.7, bsz=1938, num_updates=230000, lr=0.000208514, gnorm=1.328, loss_scale=8192, train_wall=127, wall=302071
2023-01-16 03:44:04 | INFO | train_inner | epoch 117:    698 / 1978 loss=3.012, nll_loss=0.881, word_ins=2.707, length=3.049, ppl=8.07, wps=46600.6, ups=0.79, wpb=59185.7, bsz=1984.4, num_updates=230100, lr=0.000208469, gnorm=1.296, loss_scale=8192, train_wall=127, wall=302198
2023-01-16 03:46:12 | INFO | train_inner | epoch 117:    798 / 1978 loss=2.996, nll_loss=0.865, word_ins=2.693, length=3.028, ppl=7.98, wps=46145.4, ups=0.78, wpb=59157.7, bsz=1977.4, num_updates=230200, lr=0.000208424, gnorm=1.263, loss_scale=8192, train_wall=128, wall=302326
2023-01-16 03:48:29 | INFO | train_inner | epoch 117:    898 / 1978 loss=2.989, nll_loss=0.864, word_ins=2.692, length=2.977, ppl=7.94, wps=43886.4, ups=0.73, wpb=59769.3, bsz=2072.3, num_updates=230300, lr=0.000208379, gnorm=1.267, loss_scale=8192, train_wall=136, wall=302463
2023-01-16 03:50:37 | INFO | train_inner | epoch 117:    998 / 1978 loss=2.972, nll_loss=0.85, word_ins=2.679, length=2.932, ppl=7.85, wps=46256.2, ups=0.78, wpb=59441.5, bsz=2110.5, num_updates=230400, lr=0.000208333, gnorm=1.282, loss_scale=8192, train_wall=128, wall=302591
2023-01-16 03:52:45 | INFO | train_inner | epoch 117:   1098 / 1978 loss=2.984, nll_loss=0.862, word_ins=2.69, length=2.938, ppl=7.91, wps=46229, ups=0.78, wpb=59113.3, bsz=2084.2, num_updates=230500, lr=0.000208288, gnorm=1.29, loss_scale=8192, train_wall=128, wall=302719
2023-01-16 03:54:53 | INFO | train_inner | epoch 117:   1198 / 1978 loss=3.009, nll_loss=0.88, word_ins=2.706, length=3.026, ppl=8.05, wps=46220.3, ups=0.78, wpb=59266.2, bsz=2040.4, num_updates=230600, lr=0.000208243, gnorm=1.247, loss_scale=8192, train_wall=128, wall=302847
2023-01-16 03:57:00 | INFO | train_inner | epoch 117:   1298 / 1978 loss=3.013, nll_loss=0.888, word_ins=2.714, length=2.99, ppl=8.07, wps=46572, ups=0.79, wpb=58895, bsz=1978.2, num_updates=230700, lr=0.000208198, gnorm=1.319, loss_scale=8192, train_wall=126, wall=302974
2023-01-16 03:59:07 | INFO | train_inner | epoch 117:   1398 / 1978 loss=3.021, nll_loss=0.893, word_ins=2.717, length=3.037, ppl=8.12, wps=46122.7, ups=0.79, wpb=58753.5, bsz=1937.8, num_updates=230800, lr=0.000208153, gnorm=1.283, loss_scale=8192, train_wall=127, wall=303101
2023-01-16 04:01:16 | INFO | train_inner | epoch 117:   1498 / 1978 loss=2.992, nll_loss=0.865, word_ins=2.693, length=2.996, ppl=7.96, wps=46207.5, ups=0.78, wpb=59369.7, bsz=2051, num_updates=230900, lr=0.000208108, gnorm=1.286, loss_scale=8192, train_wall=128, wall=303230
2023-01-16 04:03:23 | INFO | train_inner | epoch 117:   1598 / 1978 loss=3.019, nll_loss=0.889, word_ins=2.714, length=3.048, ppl=8.11, wps=46793, ups=0.79, wpb=59461, bsz=1939.2, num_updates=231000, lr=0.000208063, gnorm=1.322, loss_scale=8192, train_wall=127, wall=303357
2023-01-16 04:05:30 | INFO | train_inner | epoch 117:   1698 / 1978 loss=2.995, nll_loss=0.872, word_ins=2.699, length=2.954, ppl=7.97, wps=46757.9, ups=0.79, wpb=59429.4, bsz=2036.6, num_updates=231100, lr=0.000208018, gnorm=1.282, loss_scale=8192, train_wall=127, wall=303484
2023-01-16 04:07:37 | INFO | train_inner | epoch 117:   1798 / 1978 loss=3.026, nll_loss=0.89, word_ins=2.715, length=3.102, ppl=8.14, wps=46103.9, ups=0.79, wpb=58694.7, bsz=1951.2, num_updates=231200, lr=0.000207973, gnorm=1.29, loss_scale=8192, train_wall=127, wall=303611
2023-01-16 04:09:45 | INFO | train_inner | epoch 117:   1898 / 1978 loss=2.999, nll_loss=0.873, word_ins=2.7, length=2.994, ppl=7.99, wps=46731, ups=0.78, wpb=59730.7, bsz=2003.7, num_updates=231300, lr=0.000207928, gnorm=1.288, loss_scale=8192, train_wall=128, wall=303739
2023-01-16 04:11:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 04:11:39 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 4.675 | nll_loss 1.971 | word_ins 3.734 | length 9.406 | ppl 25.55 | wps 118790 | wpb 40242.5 | bsz 1500 | num_updates 231380 | best_loss 4.422
2023-01-16 04:11:39 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 04:12:07 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint117.pt (epoch 117 @ 231380 updates, score 4.675) (writing took 28.22383180214092 seconds)
2023-01-16 04:12:07 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2023-01-16 04:12:07 | INFO | train | epoch 117 | loss 3.002 | nll_loss 0.875 | word_ins 2.701 | length 3.008 | ppl 8.01 | wps 45362 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 231380 | lr 0.000207892 | gnorm 1.292 | loss_scale 8192 | train_wall 2528 | wall 303881
2023-01-16 04:12:07 | INFO | fairseq.trainer | begin training epoch 118
2023-01-16 04:12:45 | INFO | train_inner | epoch 118:     20 / 1978 loss=2.975, nll_loss=0.847, word_ins=2.676, length=2.991, ppl=7.86, wps=33012.1, ups=0.55, wpb=59600.9, bsz=2032.2, num_updates=231400, lr=0.000207883, gnorm=1.292, loss_scale=8192, train_wall=127, wall=303919
2023-01-16 04:14:54 | INFO | train_inner | epoch 118:    120 / 1978 loss=2.994, nll_loss=0.869, word_ins=2.696, length=2.975, ppl=7.97, wps=46017.1, ups=0.78, wpb=59064, bsz=2028.2, num_updates=231500, lr=0.000207838, gnorm=1.309, loss_scale=8192, train_wall=128, wall=304048
2023-01-16 04:17:00 | INFO | train_inner | epoch 118:    220 / 1978 loss=3.045, nll_loss=0.916, word_ins=2.74, length=3.056, ppl=8.25, wps=46665.9, ups=0.79, wpb=58973, bsz=1833.4, num_updates=231600, lr=0.000207793, gnorm=1.334, loss_scale=8192, train_wall=126, wall=304174
2023-01-16 04:19:08 | INFO | train_inner | epoch 118:    320 / 1978 loss=3.007, nll_loss=0.876, word_ins=2.703, length=3.037, ppl=8.04, wps=46599.3, ups=0.78, wpb=59416.5, bsz=1960.3, num_updates=231700, lr=0.000207748, gnorm=1.319, loss_scale=8192, train_wall=127, wall=304302
2023-01-16 04:21:16 | INFO | train_inner | epoch 118:    420 / 1978 loss=2.965, nll_loss=0.84, word_ins=2.67, length=2.949, ppl=7.81, wps=46473.9, ups=0.78, wpb=59835.9, bsz=2135.8, num_updates=231800, lr=0.000207703, gnorm=1.22, loss_scale=8192, train_wall=129, wall=304430
2023-01-16 04:23:24 | INFO | train_inner | epoch 118:    520 / 1978 loss=3.009, nll_loss=0.881, word_ins=2.708, length=3.016, ppl=8.05, wps=46618.6, ups=0.78, wpb=59586.3, bsz=1939.7, num_updates=231900, lr=0.000207658, gnorm=1.287, loss_scale=8192, train_wall=128, wall=304558
2023-01-16 04:25:32 | INFO | train_inner | epoch 118:    620 / 1978 loss=2.989, nll_loss=0.861, word_ins=2.689, length=2.996, ppl=7.94, wps=46199.8, ups=0.78, wpb=58984.5, bsz=2055.8, num_updates=232000, lr=0.000207614, gnorm=1.213, loss_scale=8192, train_wall=127, wall=304686
2023-01-16 04:27:39 | INFO | train_inner | epoch 118:    720 / 1978 loss=3.016, nll_loss=0.89, word_ins=2.716, length=3.002, ppl=8.09, wps=46499.5, ups=0.79, wpb=58879.4, bsz=1917, num_updates=232100, lr=0.000207569, gnorm=1.302, loss_scale=8192, train_wall=126, wall=304813
2023-01-16 04:29:46 | INFO | train_inner | epoch 118:    820 / 1978 loss=2.988, nll_loss=0.865, word_ins=2.692, length=2.96, ppl=7.94, wps=46417.9, ups=0.78, wpb=59388.9, bsz=2027.4, num_updates=232200, lr=0.000207524, gnorm=1.275, loss_scale=8192, train_wall=128, wall=304941
2023-01-16 04:31:54 | INFO | train_inner | epoch 118:    920 / 1978 loss=3.021, nll_loss=0.895, word_ins=2.72, length=3.014, ppl=8.12, wps=46681.8, ups=0.78, wpb=59545.4, bsz=1970.6, num_updates=232300, lr=0.00020748, gnorm=1.294, loss_scale=8192, train_wall=127, wall=305068
2023-01-16 04:34:02 | INFO | train_inner | epoch 118:   1020 / 1978 loss=2.984, nll_loss=0.855, word_ins=2.683, length=3.003, ppl=7.91, wps=46444.7, ups=0.78, wpb=59422.8, bsz=2065.9, num_updates=232400, lr=0.000207435, gnorm=1.33, loss_scale=8192, train_wall=128, wall=305196
2023-01-16 04:36:10 | INFO | train_inner | epoch 118:   1120 / 1978 loss=2.988, nll_loss=0.867, word_ins=2.694, length=2.939, ppl=7.94, wps=46193.6, ups=0.78, wpb=59311.9, bsz=2039.3, num_updates=232500, lr=0.00020739, gnorm=1.269, loss_scale=8192, train_wall=128, wall=305324
2023-01-16 04:38:17 | INFO | train_inner | epoch 118:   1220 / 1978 loss=3.008, nll_loss=0.876, word_ins=2.703, length=3.053, ppl=8.04, wps=46688.3, ups=0.79, wpb=58918.9, bsz=1922.6, num_updates=232600, lr=0.000207346, gnorm=1.31, loss_scale=8192, train_wall=126, wall=305451
2023-01-16 04:40:24 | INFO | train_inner | epoch 118:   1320 / 1978 loss=3, nll_loss=0.871, word_ins=2.698, length=3.021, ppl=8, wps=46985.4, ups=0.78, wpb=59941, bsz=2009.9, num_updates=232700, lr=0.000207301, gnorm=1.31, loss_scale=8192, train_wall=127, wall=305578
2023-01-16 04:42:32 | INFO | train_inner | epoch 118:   1420 / 1978 loss=2.994, nll_loss=0.867, word_ins=2.694, length=3.001, ppl=7.97, wps=46420.3, ups=0.78, wpb=59565.3, bsz=2056.6, num_updates=232800, lr=0.000207257, gnorm=1.307, loss_scale=8192, train_wall=128, wall=305707
2023-01-16 04:44:41 | INFO | train_inner | epoch 118:   1520 / 1978 loss=2.991, nll_loss=0.867, word_ins=2.694, length=2.969, ppl=7.95, wps=46476.2, ups=0.78, wpb=59594.1, bsz=2058, num_updates=232900, lr=0.000207212, gnorm=1.219, loss_scale=8192, train_wall=128, wall=305835
2023-01-16 04:46:47 | INFO | train_inner | epoch 118:   1620 / 1978 loss=3.022, nll_loss=0.886, word_ins=2.711, length=3.104, ppl=8.12, wps=46828.1, ups=0.79, wpb=59028.2, bsz=1917.8, num_updates=233000, lr=0.000207168, gnorm=1.315, loss_scale=8192, train_wall=126, wall=305961
2023-01-16 04:48:55 | INFO | train_inner | epoch 118:   1720 / 1978 loss=3.009, nll_loss=0.881, word_ins=2.706, length=3.03, ppl=8.05, wps=46609.4, ups=0.78, wpb=59652.3, bsz=2003.6, num_updates=233100, lr=0.000207123, gnorm=1.297, loss_scale=8192, train_wall=128, wall=306089
2023-01-16 04:51:03 | INFO | train_inner | epoch 118:   1820 / 1978 loss=2.987, nll_loss=0.863, word_ins=2.691, length=2.966, ppl=7.93, wps=46251, ups=0.78, wpb=59260.8, bsz=2095.9, num_updates=233200, lr=0.000207079, gnorm=1.246, loss_scale=8192, train_wall=128, wall=306217
2023-01-16 04:53:10 | INFO | train_inner | epoch 118:   1920 / 1978 loss=2.987, nll_loss=0.86, word_ins=2.688, length=2.992, ppl=7.93, wps=46177.6, ups=0.79, wpb=58702.6, bsz=1995.9, num_updates=233300, lr=0.000207034, gnorm=1.25, loss_scale=8192, train_wall=127, wall=306344
2023-01-16 04:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 04:54:35 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 4.629 | nll_loss 1.978 | word_ins 3.741 | length 8.884 | ppl 24.74 | wps 117000 | wpb 40242.5 | bsz 1500 | num_updates 233358 | best_loss 4.422
2023-01-16 04:54:35 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 04:55:03 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint118.pt (epoch 118 @ 233358 updates, score 4.629) (writing took 27.328726364765316 seconds)
2023-01-16 04:55:03 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2023-01-16 04:55:03 | INFO | train | epoch 118 | loss 3.001 | nll_loss 0.873 | word_ins 2.7 | length 3.006 | ppl 8 | wps 45529.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 233358 | lr 0.000207009 | gnorm 1.285 | loss_scale 8192 | train_wall 2519 | wall 306457
2023-01-16 04:55:03 | INFO | fairseq.trainer | begin training epoch 119
2023-01-16 04:56:07 | INFO | train_inner | epoch 119:     42 / 1978 loss=3.006, nll_loss=0.88, word_ins=2.706, length=3.004, ppl=8.04, wps=33120.6, ups=0.56, wpb=58689.1, bsz=2027.4, num_updates=233400, lr=0.00020699, gnorm=1.268, loss_scale=8192, train_wall=127, wall=306521
2023-01-16 04:57:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 04:58:16 | INFO | train_inner | epoch 119:    143 / 1978 loss=2.991, nll_loss=0.865, word_ins=2.693, length=2.985, ppl=7.95, wps=46179, ups=0.78, wpb=59425.2, bsz=1977, num_updates=233500, lr=0.000206946, gnorm=1.293, loss_scale=8192, train_wall=128, wall=306650
2023-01-16 05:00:24 | INFO | train_inner | epoch 119:    243 / 1978 loss=2.989, nll_loss=0.86, word_ins=2.688, length=3.015, ppl=7.94, wps=46109.4, ups=0.78, wpb=59273.9, bsz=1975.2, num_updates=233600, lr=0.000206901, gnorm=1.305, loss_scale=8192, train_wall=128, wall=306779
2023-01-16 05:02:33 | INFO | train_inner | epoch 119:    343 / 1978 loss=2.98, nll_loss=0.853, word_ins=2.682, length=2.986, ppl=7.89, wps=46280, ups=0.78, wpb=59558.3, bsz=2073.4, num_updates=233700, lr=0.000206857, gnorm=1.282, loss_scale=8192, train_wall=128, wall=306907
2023-01-16 05:04:40 | INFO | train_inner | epoch 119:    443 / 1978 loss=3.006, nll_loss=0.88, word_ins=2.707, length=3, ppl=8.04, wps=46363.9, ups=0.79, wpb=59023.8, bsz=1996.4, num_updates=233800, lr=0.000206813, gnorm=1.282, loss_scale=8192, train_wall=127, wall=307035
2023-01-16 05:06:47 | INFO | train_inner | epoch 119:    543 / 1978 loss=3.003, nll_loss=0.872, word_ins=2.699, length=3.044, ppl=8.02, wps=46527.3, ups=0.79, wpb=59066.2, bsz=1910.7, num_updates=233900, lr=0.000206769, gnorm=1.332, loss_scale=8192, train_wall=127, wall=307162
2023-01-16 05:08:55 | INFO | train_inner | epoch 119:    643 / 1978 loss=3.007, nll_loss=0.883, word_ins=2.709, length=2.983, ppl=8.04, wps=46122.2, ups=0.78, wpb=59036.2, bsz=2048.2, num_updates=234000, lr=0.000206725, gnorm=1.294, loss_scale=8192, train_wall=128, wall=307290
2023-01-16 05:11:02 | INFO | train_inner | epoch 119:    743 / 1978 loss=3.002, nll_loss=0.871, word_ins=2.698, length=3.037, ppl=8.01, wps=46907.3, ups=0.79, wpb=59418.4, bsz=1945.4, num_updates=234100, lr=0.00020668, gnorm=1.332, loss_scale=8192, train_wall=126, wall=307416
2023-01-16 05:13:10 | INFO | train_inner | epoch 119:    843 / 1978 loss=2.99, nll_loss=0.867, word_ins=2.694, length=2.955, ppl=7.94, wps=46577.3, ups=0.78, wpb=59478.3, bsz=1979.2, num_updates=234200, lr=0.000206636, gnorm=1.294, loss_scale=8192, train_wall=127, wall=307544
2023-01-16 05:15:17 | INFO | train_inner | epoch 119:    943 / 1978 loss=2.968, nll_loss=0.845, word_ins=2.674, length=2.947, ppl=7.83, wps=46585.1, ups=0.78, wpb=59415.2, bsz=2094.9, num_updates=234300, lr=0.000206592, gnorm=1.275, loss_scale=8192, train_wall=127, wall=307671
2023-01-16 05:17:25 | INFO | train_inner | epoch 119:   1043 / 1978 loss=3.009, nll_loss=0.886, word_ins=2.711, length=2.986, ppl=8.05, wps=46429.5, ups=0.78, wpb=59176.1, bsz=1983, num_updates=234400, lr=0.000206548, gnorm=1.214, loss_scale=8192, train_wall=127, wall=307799
2023-01-16 05:19:33 | INFO | train_inner | epoch 119:   1143 / 1978 loss=3, nll_loss=0.875, word_ins=2.702, length=2.98, ppl=8, wps=45930.4, ups=0.78, wpb=59061.9, bsz=2013.8, num_updates=234500, lr=0.000206504, gnorm=1.288, loss_scale=8192, train_wall=128, wall=307927
2023-01-16 05:21:41 | INFO | train_inner | epoch 119:   1243 / 1978 loss=2.998, nll_loss=0.87, word_ins=2.697, length=3.006, ppl=7.99, wps=46778.6, ups=0.78, wpb=59648, bsz=2046.1, num_updates=234600, lr=0.00020646, gnorm=1.275, loss_scale=8192, train_wall=127, wall=308055
2023-01-16 05:23:47 | INFO | train_inner | epoch 119:   1343 / 1978 loss=3.02, nll_loss=0.889, word_ins=2.714, length=3.061, ppl=8.11, wps=46650.2, ups=0.79, wpb=58924.7, bsz=1988.8, num_updates=234700, lr=0.000206416, gnorm=1.27, loss_scale=8192, train_wall=126, wall=308181
2023-01-16 05:25:55 | INFO | train_inner | epoch 119:   1443 / 1978 loss=2.98, nll_loss=0.86, word_ins=2.688, length=2.924, ppl=7.89, wps=46905.1, ups=0.78, wpb=59878, bsz=2072.3, num_updates=234800, lr=0.000206372, gnorm=1.283, loss_scale=8192, train_wall=127, wall=308309
2023-01-16 05:28:03 | INFO | train_inner | epoch 119:   1543 / 1978 loss=2.995, nll_loss=0.865, word_ins=2.692, length=3.031, ppl=7.97, wps=46305.5, ups=0.78, wpb=59223, bsz=2015.5, num_updates=234900, lr=0.000206328, gnorm=1.279, loss_scale=8192, train_wall=128, wall=308437
2023-01-16 05:30:10 | INFO | train_inner | epoch 119:   1643 / 1978 loss=3.016, nll_loss=0.889, word_ins=2.714, length=3.019, ppl=8.09, wps=46567.9, ups=0.79, wpb=59251.3, bsz=1998.4, num_updates=235000, lr=0.000206284, gnorm=1.314, loss_scale=8192, train_wall=127, wall=308564
2023-01-16 05:32:19 | INFO | train_inner | epoch 119:   1743 / 1978 loss=3.011, nll_loss=0.887, word_ins=2.712, length=2.994, ppl=8.06, wps=45893.3, ups=0.77, wpb=59294, bsz=2036.7, num_updates=235100, lr=0.00020624, gnorm=1.268, loss_scale=8192, train_wall=129, wall=308693
2023-01-16 05:34:26 | INFO | train_inner | epoch 119:   1843 / 1978 loss=3.009, nll_loss=0.879, word_ins=2.705, length=3.036, ppl=8.05, wps=47071.7, ups=0.79, wpb=59675.3, bsz=1938.8, num_updates=235200, lr=0.000206197, gnorm=1.329, loss_scale=8192, train_wall=127, wall=308820
2023-01-16 05:36:33 | INFO | train_inner | epoch 119:   1943 / 1978 loss=3.014, nll_loss=0.888, word_ins=2.714, length=3.007, ppl=8.08, wps=46532.1, ups=0.79, wpb=59043.9, bsz=1989.3, num_updates=235300, lr=0.000206153, gnorm=1.3, loss_scale=8192, train_wall=127, wall=308947
2023-01-16 05:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 05:37:30 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 4.567 | nll_loss 1.948 | word_ins 3.716 | length 8.51 | ppl 23.71 | wps 103097 | wpb 40242.5 | bsz 1500 | num_updates 235335 | best_loss 4.422
2023-01-16 05:37:30 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 05:37:58 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint119.pt (epoch 119 @ 235335 updates, score 4.567) (writing took 27.81130442628637 seconds)
2023-01-16 05:37:58 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2023-01-16 05:37:58 | INFO | train | epoch 119 | loss 2.999 | nll_loss 0.873 | word_ins 2.7 | length 2.999 | ppl 8 | wps 45514.8 | ups 0.77 | wpb 59283.6 | bsz 2002.8 | num_updates 235335 | lr 0.000206137 | gnorm 1.288 | loss_scale 8192 | train_wall 2519 | wall 309032
2023-01-16 05:37:58 | INFO | fairseq.trainer | begin training epoch 120
2023-01-16 05:39:32 | INFO | train_inner | epoch 120:     65 / 1978 loss=3.025, nll_loss=0.901, word_ins=2.725, length=3.003, ppl=8.14, wps=32897.2, ups=0.56, wpb=58983.3, bsz=1889.8, num_updates=235400, lr=0.000206109, gnorm=1.286, loss_scale=8192, train_wall=127, wall=309126
2023-01-16 05:41:40 | INFO | train_inner | epoch 120:    165 / 1978 loss=2.958, nll_loss=0.837, word_ins=2.667, length=2.912, ppl=7.77, wps=46498.3, ups=0.78, wpb=59593.7, bsz=2107.1, num_updates=235500, lr=0.000206065, gnorm=1.283, loss_scale=8192, train_wall=128, wall=309254
2023-01-16 05:43:52 | INFO | train_inner | epoch 120:    265 / 1978 loss=2.979, nll_loss=0.857, word_ins=2.685, length=2.94, ppl=7.89, wps=45094.2, ups=0.76, wpb=59481.3, bsz=2014.4, num_updates=235600, lr=0.000206021, gnorm=1.309, loss_scale=8192, train_wall=132, wall=309386
2023-01-16 05:46:00 | INFO | train_inner | epoch 120:    365 / 1978 loss=2.988, nll_loss=0.863, word_ins=2.691, length=2.972, ppl=7.93, wps=46826, ups=0.79, wpb=59588.1, bsz=2014.3, num_updates=235700, lr=0.000205978, gnorm=1.239, loss_scale=8192, train_wall=127, wall=309514
2023-01-16 05:48:07 | INFO | train_inner | epoch 120:    465 / 1978 loss=3.022, nll_loss=0.891, word_ins=2.717, length=3.056, ppl=8.12, wps=46445.9, ups=0.79, wpb=58965.7, bsz=1984.6, num_updates=235800, lr=0.000205934, gnorm=1.25, loss_scale=8192, train_wall=127, wall=309641
2023-01-16 05:50:15 | INFO | train_inner | epoch 120:    565 / 1978 loss=3, nll_loss=0.871, word_ins=2.698, length=3.015, ppl=8, wps=45851.9, ups=0.78, wpb=58944.8, bsz=2002.5, num_updates=235900, lr=0.00020589, gnorm=1.271, loss_scale=8192, train_wall=128, wall=309769
2023-01-16 05:52:23 | INFO | train_inner | epoch 120:    665 / 1978 loss=3.006, nll_loss=0.877, word_ins=2.704, length=3.022, ppl=8.03, wps=46786.7, ups=0.78, wpb=59653, bsz=1949, num_updates=236000, lr=0.000205847, gnorm=1.341, loss_scale=8192, train_wall=127, wall=309897
2023-01-16 05:54:32 | INFO | train_inner | epoch 120:    765 / 1978 loss=2.968, nll_loss=0.84, word_ins=2.669, length=2.99, ppl=7.83, wps=45834.4, ups=0.77, wpb=59199.4, bsz=2088.7, num_updates=236100, lr=0.000205803, gnorm=1.293, loss_scale=8192, train_wall=129, wall=310026
2023-01-16 05:56:39 | INFO | train_inner | epoch 120:    865 / 1978 loss=3.001, nll_loss=0.874, word_ins=2.7, length=3.011, ppl=8.01, wps=46747.4, ups=0.79, wpb=59356.3, bsz=1973.6, num_updates=236200, lr=0.00020576, gnorm=1.298, loss_scale=8192, train_wall=127, wall=310153
2023-01-16 05:58:45 | INFO | train_inner | epoch 120:    965 / 1978 loss=3.038, nll_loss=0.906, word_ins=2.73, length=3.081, ppl=8.21, wps=46410.5, ups=0.79, wpb=58681.1, bsz=1898.8, num_updates=236300, lr=0.000205716, gnorm=1.309, loss_scale=8192, train_wall=126, wall=310279
2023-01-16 06:00:55 | INFO | train_inner | epoch 120:   1065 / 1978 loss=3.007, nll_loss=0.883, word_ins=2.709, length=2.976, ppl=8.04, wps=45439.1, ups=0.77, wpb=59054.7, bsz=1974.6, num_updates=236400, lr=0.000205673, gnorm=1.29, loss_scale=8192, train_wall=130, wall=310409
2023-01-16 06:03:04 | INFO | train_inner | epoch 120:   1165 / 1978 loss=2.991, nll_loss=0.866, word_ins=2.694, length=2.971, ppl=7.95, wps=45690.2, ups=0.78, wpb=58936.6, bsz=2027.6, num_updates=236500, lr=0.000205629, gnorm=1.275, loss_scale=8192, train_wall=129, wall=310538
2023-01-16 06:05:12 | INFO | train_inner | epoch 120:   1265 / 1978 loss=3.007, nll_loss=0.877, word_ins=2.703, length=3.035, ppl=8.04, wps=46589.4, ups=0.78, wpb=59404.8, bsz=1983, num_updates=236600, lr=0.000205586, gnorm=1.263, loss_scale=8192, train_wall=127, wall=310666
2023-01-16 06:07:19 | INFO | train_inner | epoch 120:   1365 / 1978 loss=3.011, nll_loss=0.884, word_ins=2.71, length=3.007, ppl=8.06, wps=45887.7, ups=0.78, wpb=58522.9, bsz=1941.4, num_updates=236700, lr=0.000205542, gnorm=1.301, loss_scale=8192, train_wall=127, wall=310793
2023-01-16 06:09:30 | INFO | train_inner | epoch 120:   1465 / 1978 loss=2.997, nll_loss=0.867, word_ins=2.694, length=3.03, ppl=7.98, wps=45772.5, ups=0.77, wpb=59741.9, bsz=1984.3, num_updates=236800, lr=0.000205499, gnorm=1.323, loss_scale=8192, train_wall=128, wall=310924
2023-01-16 06:11:37 | INFO | train_inner | epoch 120:   1565 / 1978 loss=2.99, nll_loss=0.863, word_ins=2.69, length=3.003, ppl=7.95, wps=46651.9, ups=0.78, wpb=59453.1, bsz=2021.8, num_updates=236900, lr=0.000205455, gnorm=1.278, loss_scale=8192, train_wall=127, wall=311051
2023-01-16 06:13:45 | INFO | train_inner | epoch 120:   1665 / 1978 loss=3.032, nll_loss=0.903, word_ins=2.727, length=3.051, ppl=8.18, wps=46124.9, ups=0.78, wpb=58987.2, bsz=1950.3, num_updates=237000, lr=0.000205412, gnorm=1.269, loss_scale=8192, train_wall=128, wall=311179
2023-01-16 06:15:54 | INFO | train_inner | epoch 120:   1765 / 1978 loss=2.993, nll_loss=0.862, word_ins=2.689, length=3.046, ppl=7.96, wps=46312.4, ups=0.77, wpb=59844.3, bsz=2026.3, num_updates=237100, lr=0.000205369, gnorm=1.264, loss_scale=8192, train_wall=129, wall=311308
2023-01-16 06:18:03 | INFO | train_inner | epoch 120:   1865 / 1978 loss=2.971, nll_loss=0.847, word_ins=2.676, length=2.947, ppl=7.84, wps=46532.5, ups=0.78, wpb=59764.2, bsz=2144.9, num_updates=237200, lr=0.000205325, gnorm=1.274, loss_scale=8192, train_wall=128, wall=311437
2023-01-16 06:20:11 | INFO | train_inner | epoch 120:   1965 / 1978 loss=2.984, nll_loss=0.862, word_ins=2.689, length=2.946, ppl=7.91, wps=46348.4, ups=0.78, wpb=59396, bsz=2056.2, num_updates=237300, lr=0.000205282, gnorm=1.291, loss_scale=8192, train_wall=128, wall=311565
2023-01-16 06:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 06:20:40 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 4.633 | nll_loss 1.997 | word_ins 3.753 | length 8.803 | ppl 24.81 | wps 154670 | wpb 40242.5 | bsz 1500 | num_updates 237313 | best_loss 4.422
2023-01-16 06:20:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 06:21:06 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint120.pt (epoch 120 @ 237313 updates, score 4.633) (writing took 26.473437699023634 seconds)
2023-01-16 06:21:06 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2023-01-16 06:21:06 | INFO | train | epoch 120 | loss 2.998 | nll_loss 0.871 | word_ins 2.698 | length 3.001 | ppl 7.99 | wps 45302.6 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 237313 | lr 0.000205277 | gnorm 1.286 | loss_scale 8192 | train_wall 2530 | wall 311620
2023-01-16 06:21:06 | INFO | fairseq.trainer | begin training epoch 121
2023-01-16 06:23:07 | INFO | train_inner | epoch 121:     87 / 1978 loss=3.018, nll_loss=0.891, word_ins=2.716, length=3.018, ppl=8.1, wps=33325.2, ups=0.57, wpb=58826.9, bsz=1913.4, num_updates=237400, lr=0.000205239, gnorm=1.302, loss_scale=8192, train_wall=126, wall=311741
2023-01-16 06:25:16 | INFO | train_inner | epoch 121:    187 / 1978 loss=2.973, nll_loss=0.85, word_ins=2.679, length=2.944, ppl=7.85, wps=46432.5, ups=0.78, wpb=59618.4, bsz=2034, num_updates=237500, lr=0.000205196, gnorm=1.265, loss_scale=8192, train_wall=128, wall=311870
2023-01-16 06:27:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 06:27:24 | INFO | train_inner | epoch 121:    288 / 1978 loss=3.017, nll_loss=0.885, word_ins=2.711, length=3.065, ppl=8.1, wps=45972.3, ups=0.78, wpb=59140.9, bsz=1978, num_updates=237600, lr=0.000205152, gnorm=1.302, loss_scale=8192, train_wall=128, wall=311999
2023-01-16 06:29:31 | INFO | train_inner | epoch 121:    388 / 1978 loss=2.997, nll_loss=0.865, word_ins=2.693, length=3.036, ppl=7.98, wps=46493.4, ups=0.79, wpb=58980.8, bsz=1953.6, num_updates=237700, lr=0.000205109, gnorm=1.311, loss_scale=8192, train_wall=127, wall=312125
2023-01-16 06:31:38 | INFO | train_inner | epoch 121:    488 / 1978 loss=2.997, nll_loss=0.871, word_ins=2.698, length=2.992, ppl=7.98, wps=46679.5, ups=0.79, wpb=59017.9, bsz=1955.6, num_updates=237800, lr=0.000205066, gnorm=1.252, loss_scale=8192, train_wall=126, wall=312252
2023-01-16 06:33:45 | INFO | train_inner | epoch 121:    588 / 1978 loss=2.971, nll_loss=0.85, word_ins=2.678, length=2.926, ppl=7.84, wps=46879.6, ups=0.79, wpb=59604.9, bsz=2088.2, num_updates=237900, lr=0.000205023, gnorm=1.239, loss_scale=8192, train_wall=127, wall=312379
2023-01-16 06:35:52 | INFO | train_inner | epoch 121:    688 / 1978 loss=2.998, nll_loss=0.867, word_ins=2.694, length=3.035, ppl=7.99, wps=46843.6, ups=0.79, wpb=59475.4, bsz=1942.7, num_updates=238000, lr=0.00020498, gnorm=1.3, loss_scale=8192, train_wall=127, wall=312506
2023-01-16 06:37:59 | INFO | train_inner | epoch 121:    788 / 1978 loss=2.991, nll_loss=0.863, word_ins=2.691, length=3.002, ppl=7.95, wps=46214.5, ups=0.78, wpb=58970.3, bsz=2005.5, num_updates=238100, lr=0.000204937, gnorm=1.287, loss_scale=8192, train_wall=127, wall=312634
2023-01-16 06:40:07 | INFO | train_inner | epoch 121:    888 / 1978 loss=2.994, nll_loss=0.87, word_ins=2.697, length=2.972, ppl=7.97, wps=47056.5, ups=0.79, wpb=59772, bsz=2023.9, num_updates=238200, lr=0.000204894, gnorm=1.294, loss_scale=8192, train_wall=127, wall=312761
2023-01-16 06:42:13 | INFO | train_inner | epoch 121:    988 / 1978 loss=3.022, nll_loss=0.895, word_ins=2.721, length=3.013, ppl=8.12, wps=46461.5, ups=0.79, wpb=58749.7, bsz=1878.5, num_updates=238300, lr=0.000204851, gnorm=1.282, loss_scale=8192, train_wall=126, wall=312887
2023-01-16 06:44:20 | INFO | train_inner | epoch 121:   1088 / 1978 loss=3.003, nll_loss=0.876, word_ins=2.702, length=3.008, ppl=8.01, wps=46416.1, ups=0.78, wpb=59141.5, bsz=1997.2, num_updates=238400, lr=0.000204808, gnorm=1.268, loss_scale=8192, train_wall=127, wall=313014
2023-01-16 06:46:28 | INFO | train_inner | epoch 121:   1188 / 1978 loss=2.996, nll_loss=0.865, word_ins=2.693, length=3.034, ppl=7.98, wps=46368.9, ups=0.78, wpb=59399.9, bsz=2055.8, num_updates=238500, lr=0.000204765, gnorm=1.288, loss_scale=8192, train_wall=128, wall=313143
2023-01-16 06:48:35 | INFO | train_inner | epoch 121:   1288 / 1978 loss=3.005, nll_loss=0.881, word_ins=2.707, length=2.975, ppl=8.03, wps=46544.9, ups=0.79, wpb=58940.3, bsz=1971.2, num_updates=238600, lr=0.000204722, gnorm=1.285, loss_scale=8192, train_wall=126, wall=313269
2023-01-16 06:50:47 | INFO | train_inner | epoch 121:   1388 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.682, length=2.945, ppl=7.87, wps=44823.6, ups=0.76, wpb=59072.8, bsz=2103.8, num_updates=238700, lr=0.000204679, gnorm=1.286, loss_scale=8192, train_wall=132, wall=313401
2023-01-16 06:52:54 | INFO | train_inner | epoch 121:   1488 / 1978 loss=3.017, nll_loss=0.888, word_ins=2.713, length=3.036, ppl=8.09, wps=46852.3, ups=0.79, wpb=59597, bsz=1955.8, num_updates=238800, lr=0.000204636, gnorm=1.312, loss_scale=8192, train_wall=127, wall=313528
2023-01-16 06:55:03 | INFO | train_inner | epoch 121:   1588 / 1978 loss=2.962, nll_loss=0.839, word_ins=2.669, length=2.937, ppl=7.79, wps=46503.2, ups=0.78, wpb=59825.1, bsz=2102.8, num_updates=238900, lr=0.000204594, gnorm=1.269, loss_scale=8192, train_wall=128, wall=313657
2023-01-16 06:57:12 | INFO | train_inner | epoch 121:   1688 / 1978 loss=2.971, nll_loss=0.849, word_ins=2.677, length=2.934, ppl=7.84, wps=46424.7, ups=0.78, wpb=59835.2, bsz=2093.7, num_updates=239000, lr=0.000204551, gnorm=1.267, loss_scale=8192, train_wall=129, wall=313786
2023-01-16 06:59:19 | INFO | train_inner | epoch 121:   1788 / 1978 loss=2.989, nll_loss=0.859, word_ins=2.687, length=3.016, ppl=7.94, wps=46653.9, ups=0.78, wpb=59433, bsz=2018.4, num_updates=239100, lr=0.000204508, gnorm=1.291, loss_scale=8192, train_wall=127, wall=313913
2023-01-16 07:01:26 | INFO | train_inner | epoch 121:   1888 / 1978 loss=3.006, nll_loss=0.876, word_ins=2.702, length=3.041, ppl=8.03, wps=46308.7, ups=0.79, wpb=58971.3, bsz=2002, num_updates=239200, lr=0.000204465, gnorm=1.272, loss_scale=8192, train_wall=127, wall=314041
2023-01-16 07:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 07:03:35 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 4.575 | nll_loss 1.955 | word_ins 3.719 | length 8.561 | ppl 23.83 | wps 92776.5 | wpb 40242.5 | bsz 1500 | num_updates 239290 | best_loss 4.422
2023-01-16 07:03:35 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 07:04:01 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint121.pt (epoch 121 @ 239290 updates, score 4.575) (writing took 26.67008050205186 seconds)
2023-01-16 07:04:01 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2023-01-16 07:04:01 | INFO | train | epoch 121 | loss 2.995 | nll_loss 0.868 | word_ins 2.695 | length 2.998 | ppl 7.97 | wps 45516.6 | ups 0.77 | wpb 59284.7 | bsz 2002.8 | num_updates 239290 | lr 0.000204427 | gnorm 1.284 | loss_scale 8192 | train_wall 2520 | wall 314195
2023-01-16 07:04:01 | INFO | fairseq.trainer | begin training epoch 122
2023-01-16 07:04:25 | INFO | train_inner | epoch 122:     10 / 1978 loss=3.006, nll_loss=0.878, word_ins=2.704, length=3.021, ppl=8.03, wps=33041.9, ups=0.56, wpb=59143, bsz=1953.3, num_updates=239300, lr=0.000204422, gnorm=1.311, loss_scale=8192, train_wall=127, wall=314220
2023-01-16 07:06:32 | INFO | train_inner | epoch 122:    110 / 1978 loss=2.996, nll_loss=0.865, word_ins=2.693, length=3.039, ppl=7.98, wps=46511.5, ups=0.79, wpb=58820, bsz=1919.8, num_updates=239400, lr=0.00020438, gnorm=1.304, loss_scale=8192, train_wall=126, wall=314346
2023-01-16 07:08:40 | INFO | train_inner | epoch 122:    210 / 1978 loss=2.973, nll_loss=0.854, word_ins=2.683, length=2.905, ppl=7.85, wps=46352.3, ups=0.78, wpb=59418.7, bsz=2068.7, num_updates=239500, lr=0.000204337, gnorm=1.232, loss_scale=8192, train_wall=128, wall=314474
2023-01-16 07:10:47 | INFO | train_inner | epoch 122:    310 / 1978 loss=2.998, nll_loss=0.867, word_ins=2.694, length=3.04, ppl=7.99, wps=46791.7, ups=0.79, wpb=59162.5, bsz=1910.3, num_updates=239600, lr=0.000204294, gnorm=1.299, loss_scale=8192, train_wall=126, wall=314601
2023-01-16 07:12:54 | INFO | train_inner | epoch 122:    410 / 1978 loss=2.984, nll_loss=0.863, word_ins=2.69, length=2.936, ppl=7.91, wps=46529.3, ups=0.78, wpb=59482.5, bsz=2027.9, num_updates=239700, lr=0.000204252, gnorm=1.266, loss_scale=8192, train_wall=128, wall=314728
2023-01-16 07:15:02 | INFO | train_inner | epoch 122:    510 / 1978 loss=2.992, nll_loss=0.864, word_ins=2.691, length=3.008, ppl=7.95, wps=46596.1, ups=0.78, wpb=59587, bsz=2035, num_updates=239800, lr=0.000204209, gnorm=1.284, loss_scale=8192, train_wall=128, wall=314856
2023-01-16 07:17:11 | INFO | train_inner | epoch 122:    610 / 1978 loss=2.976, nll_loss=0.858, word_ins=2.686, length=2.901, ppl=7.87, wps=46263.5, ups=0.77, wpb=59773.6, bsz=2130.2, num_updates=239900, lr=0.000204167, gnorm=1.268, loss_scale=8192, train_wall=129, wall=314986
2023-01-16 07:19:19 | INFO | train_inner | epoch 122:    710 / 1978 loss=2.991, nll_loss=0.862, word_ins=2.69, length=3.01, ppl=7.95, wps=46210.1, ups=0.79, wpb=58714.6, bsz=2014.5, num_updates=240000, lr=0.000204124, gnorm=1.303, loss_scale=8192, train_wall=127, wall=315113
2023-01-16 07:21:26 | INFO | train_inner | epoch 122:    810 / 1978 loss=3.02, nll_loss=0.892, word_ins=2.717, length=3.038, ppl=8.11, wps=46281.7, ups=0.79, wpb=58945.9, bsz=1943.4, num_updates=240100, lr=0.000204082, gnorm=1.262, loss_scale=8192, train_wall=127, wall=315240
2023-01-16 07:23:36 | INFO | train_inner | epoch 122:    910 / 1978 loss=2.996, nll_loss=0.871, word_ins=2.698, length=2.985, ppl=7.98, wps=45835.3, ups=0.77, wpb=59496.8, bsz=2013.6, num_updates=240200, lr=0.000204039, gnorm=1.293, loss_scale=8192, train_wall=128, wall=315370
2023-01-16 07:25:42 | INFO | train_inner | epoch 122:   1010 / 1978 loss=3.009, nll_loss=0.881, word_ins=2.707, length=3.026, ppl=8.05, wps=46949.1, ups=0.79, wpb=59502.7, bsz=1918.3, num_updates=240300, lr=0.000203997, gnorm=1.373, loss_scale=8192, train_wall=127, wall=315497
2023-01-16 07:27:49 | INFO | train_inner | epoch 122:   1110 / 1978 loss=2.991, nll_loss=0.86, word_ins=2.688, length=3.027, ppl=7.95, wps=46989.2, ups=0.79, wpb=59478.2, bsz=1967, num_updates=240400, lr=0.000203954, gnorm=1.304, loss_scale=8192, train_wall=126, wall=315623
2023-01-16 07:29:57 | INFO | train_inner | epoch 122:   1210 / 1978 loss=2.985, nll_loss=0.858, word_ins=2.687, length=2.98, ppl=7.92, wps=46274.6, ups=0.78, wpb=59078.9, bsz=2064, num_updates=240500, lr=0.000203912, gnorm=1.256, loss_scale=8192, train_wall=127, wall=315751
2023-01-16 07:32:05 | INFO | train_inner | epoch 122:   1310 / 1978 loss=2.976, nll_loss=0.852, word_ins=2.68, length=2.955, ppl=7.87, wps=46636.8, ups=0.78, wpb=59866.5, bsz=2060.4, num_updates=240600, lr=0.000203869, gnorm=1.29, loss_scale=8192, train_wall=128, wall=315879
2023-01-16 07:34:12 | INFO | train_inner | epoch 122:   1410 / 1978 loss=3.015, nll_loss=0.884, word_ins=2.709, length=3.053, ppl=8.08, wps=46618.7, ups=0.79, wpb=59222.6, bsz=1965, num_updates=240700, lr=0.000203827, gnorm=1.356, loss_scale=8192, train_wall=127, wall=316006
2023-01-16 07:36:19 | INFO | train_inner | epoch 122:   1510 / 1978 loss=3.009, nll_loss=0.884, word_ins=2.71, length=2.989, ppl=8.05, wps=46473.5, ups=0.79, wpb=58950.9, bsz=1978.8, num_updates=240800, lr=0.000203785, gnorm=1.305, loss_scale=8192, train_wall=127, wall=316133
2023-01-16 07:38:27 | INFO | train_inner | epoch 122:   1610 / 1978 loss=2.986, nll_loss=0.865, word_ins=2.692, length=2.938, ppl=7.92, wps=46312.7, ups=0.78, wpb=59280.6, bsz=2051.3, num_updates=240900, lr=0.000203742, gnorm=1.295, loss_scale=8192, train_wall=128, wall=316261
2023-01-16 07:40:35 | INFO | train_inner | epoch 122:   1710 / 1978 loss=2.989, nll_loss=0.865, word_ins=2.692, length=2.966, ppl=7.94, wps=46817.6, ups=0.78, wpb=59708.7, bsz=2025.4, num_updates=241000, lr=0.0002037, gnorm=1.295, loss_scale=8192, train_wall=127, wall=316389
2023-01-16 07:42:42 | INFO | train_inner | epoch 122:   1810 / 1978 loss=3.005, nll_loss=0.875, word_ins=2.702, length=3.033, ppl=8.03, wps=46332.8, ups=0.78, wpb=59143.1, bsz=1985.8, num_updates=241100, lr=0.000203658, gnorm=1.277, loss_scale=8192, train_wall=127, wall=316516
2023-01-16 07:44:48 | INFO | train_inner | epoch 122:   1910 / 1978 loss=3.003, nll_loss=0.87, word_ins=2.696, length=3.068, ppl=8.02, wps=47039.4, ups=0.79, wpb=59173.7, bsz=1973.7, num_updates=241200, lr=0.000203616, gnorm=1.265, loss_scale=8192, train_wall=126, wall=316642
2023-01-16 07:46:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 07:46:27 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 4.598 | nll_loss 1.984 | word_ins 3.744 | length 8.541 | ppl 24.22 | wps 120725 | wpb 40242.5 | bsz 1500 | num_updates 241268 | best_loss 4.422
2023-01-16 07:46:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 07:46:53 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint122.pt (epoch 122 @ 241268 updates, score 4.598) (writing took 26.474213007837534 seconds)
2023-01-16 07:46:53 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2023-01-16 07:46:53 | INFO | train | epoch 122 | loss 2.995 | nll_loss 0.868 | word_ins 2.695 | length 2.993 | ppl 7.97 | wps 45590.6 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 241268 | lr 0.000203587 | gnorm 1.291 | loss_scale 8192 | train_wall 2516 | wall 316767
2023-01-16 07:46:53 | INFO | fairseq.trainer | begin training epoch 123
2023-01-16 07:47:46 | INFO | train_inner | epoch 123:     32 / 1978 loss=3.002, nll_loss=0.88, word_ins=2.705, length=2.968, ppl=8.01, wps=32985.5, ups=0.56, wpb=58815.6, bsz=1994.5, num_updates=241300, lr=0.000203574, gnorm=1.277, loss_scale=8192, train_wall=127, wall=316820
2023-01-16 07:49:53 | INFO | train_inner | epoch 123:    132 / 1978 loss=2.989, nll_loss=0.861, word_ins=2.689, length=3, ppl=7.94, wps=46630.7, ups=0.79, wpb=59261.9, bsz=1979.9, num_updates=241400, lr=0.000203531, gnorm=1.273, loss_scale=8192, train_wall=127, wall=316947
2023-01-16 07:52:01 | INFO | train_inner | epoch 123:    232 / 1978 loss=2.978, nll_loss=0.854, word_ins=2.682, length=2.958, ppl=7.88, wps=46605.2, ups=0.78, wpb=59520.5, bsz=2056.6, num_updates=241500, lr=0.000203489, gnorm=1.316, loss_scale=8192, train_wall=127, wall=317075
2023-01-16 07:54:09 | INFO | train_inner | epoch 123:    332 / 1978 loss=2.987, nll_loss=0.861, word_ins=2.689, length=2.98, ppl=7.93, wps=46066.1, ups=0.78, wpb=58918.3, bsz=2014.4, num_updates=241600, lr=0.000203447, gnorm=1.28, loss_scale=8192, train_wall=128, wall=317203
2023-01-16 07:56:17 | INFO | train_inner | epoch 123:    432 / 1978 loss=2.981, nll_loss=0.854, word_ins=2.682, length=2.986, ppl=7.89, wps=46808.9, ups=0.78, wpb=59767.1, bsz=2009.8, num_updates=241700, lr=0.000203405, gnorm=1.295, loss_scale=16384, train_wall=127, wall=317331
2023-01-16 07:56:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 07:58:25 | INFO | train_inner | epoch 123:    533 / 1978 loss=2.996, nll_loss=0.874, word_ins=2.701, length=2.957, ppl=7.98, wps=46090.5, ups=0.78, wpb=59019.2, bsz=1893.8, num_updates=241800, lr=0.000203363, gnorm=1.278, loss_scale=8192, train_wall=128, wall=317459
2023-01-16 08:00:36 | INFO | train_inner | epoch 123:    633 / 1978 loss=2.984, nll_loss=0.857, word_ins=2.685, length=2.99, ppl=7.91, wps=44653.9, ups=0.76, wpb=58779.6, bsz=2001.8, num_updates=241900, lr=0.000203321, gnorm=1.254, loss_scale=8192, train_wall=131, wall=317590
2023-01-16 08:02:44 | INFO | train_inner | epoch 123:    733 / 1978 loss=2.97, nll_loss=0.844, word_ins=2.674, length=2.959, ppl=7.83, wps=46243.1, ups=0.78, wpb=59110.1, bsz=2096.1, num_updates=242000, lr=0.000203279, gnorm=1.245, loss_scale=8192, train_wall=128, wall=317718
2023-01-16 08:04:53 | INFO | train_inner | epoch 123:    833 / 1978 loss=2.975, nll_loss=0.852, word_ins=2.681, length=2.939, ppl=7.86, wps=46037.2, ups=0.78, wpb=59252.6, bsz=2102.2, num_updates=242100, lr=0.000203237, gnorm=1.277, loss_scale=8192, train_wall=129, wall=317847
2023-01-16 08:07:00 | INFO | train_inner | epoch 123:    933 / 1978 loss=3.028, nll_loss=0.9, word_ins=2.724, length=3.037, ppl=8.16, wps=46571.6, ups=0.79, wpb=59070.8, bsz=1888.4, num_updates=242200, lr=0.000203195, gnorm=1.32, loss_scale=8192, train_wall=127, wall=317974
2023-01-16 08:09:07 | INFO | train_inner | epoch 123:   1033 / 1978 loss=2.989, nll_loss=0.859, word_ins=2.686, length=3.023, ppl=7.94, wps=46409.6, ups=0.79, wpb=58862.8, bsz=1994, num_updates=242300, lr=0.000203153, gnorm=1.278, loss_scale=8192, train_wall=127, wall=318101
2023-01-16 08:11:15 | INFO | train_inner | epoch 123:   1133 / 1978 loss=3.004, nll_loss=0.877, word_ins=2.703, length=3.01, ppl=8.02, wps=46628.4, ups=0.78, wpb=59645.6, bsz=2004.6, num_updates=242400, lr=0.000203111, gnorm=1.315, loss_scale=8192, train_wall=128, wall=318229
2023-01-16 08:13:23 | INFO | train_inner | epoch 123:   1233 / 1978 loss=2.966, nll_loss=0.845, word_ins=2.674, length=2.924, ppl=7.81, wps=46794.4, ups=0.78, wpb=60289.8, bsz=2096.8, num_updates=242500, lr=0.000203069, gnorm=1.264, loss_scale=8192, train_wall=129, wall=318357
2023-01-16 08:15:30 | INFO | train_inner | epoch 123:   1333 / 1978 loss=3.018, nll_loss=0.893, word_ins=2.718, length=2.998, ppl=8.1, wps=46243.6, ups=0.79, wpb=58677.6, bsz=1951.1, num_updates=242600, lr=0.000203027, gnorm=1.29, loss_scale=8192, train_wall=127, wall=318484
2023-01-16 08:17:37 | INFO | train_inner | epoch 123:   1433 / 1978 loss=2.998, nll_loss=0.876, word_ins=2.702, length=2.966, ppl=7.99, wps=46940.4, ups=0.79, wpb=59682.5, bsz=2041.1, num_updates=242700, lr=0.000202986, gnorm=1.258, loss_scale=8192, train_wall=127, wall=318611
2023-01-16 08:19:45 | INFO | train_inner | epoch 123:   1533 / 1978 loss=2.981, nll_loss=0.861, word_ins=2.688, length=2.934, ppl=7.9, wps=46415.2, ups=0.78, wpb=59458.3, bsz=2045.9, num_updates=242800, lr=0.000202944, gnorm=1.279, loss_scale=8192, train_wall=128, wall=318740
2023-01-16 08:21:52 | INFO | train_inner | epoch 123:   1633 / 1978 loss=3.04, nll_loss=0.908, word_ins=2.732, length=3.082, ppl=8.23, wps=46295.5, ups=0.79, wpb=58734.5, bsz=1911.4, num_updates=242900, lr=0.000202902, gnorm=1.33, loss_scale=8192, train_wall=127, wall=318866
2023-01-16 08:24:00 | INFO | train_inner | epoch 123:   1733 / 1978 loss=2.985, nll_loss=0.855, word_ins=2.683, length=3.019, ppl=7.92, wps=46545.6, ups=0.78, wpb=59399.2, bsz=2036.2, num_updates=243000, lr=0.00020286, gnorm=1.306, loss_scale=8192, train_wall=127, wall=318994
2023-01-16 08:26:08 | INFO | train_inner | epoch 123:   1833 / 1978 loss=3.004, nll_loss=0.878, word_ins=2.704, length=2.996, ppl=8.02, wps=46718.2, ups=0.78, wpb=59706.4, bsz=1995, num_updates=243100, lr=0.000202818, gnorm=1.305, loss_scale=8192, train_wall=128, wall=319122
2023-01-16 08:28:14 | INFO | train_inner | epoch 123:   1933 / 1978 loss=3.019, nll_loss=0.885, word_ins=2.711, length=3.08, ppl=8.11, wps=46771, ups=0.79, wpb=59044.5, bsz=1910.4, num_updates=243200, lr=0.000202777, gnorm=1.35, loss_scale=8192, train_wall=126, wall=319248
2023-01-16 08:29:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 08:29:29 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 4.639 | nll_loss 1.971 | word_ins 3.736 | length 9.029 | ppl 24.91 | wps 122721 | wpb 40242.5 | bsz 1500 | num_updates 243245 | best_loss 4.422
2023-01-16 08:29:29 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 08:29:55 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint123.pt (epoch 123 @ 243245 updates, score 4.639) (writing took 26.361033169087023 seconds)
2023-01-16 08:29:55 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2023-01-16 08:29:55 | INFO | train | epoch 123 | loss 2.994 | nll_loss 0.868 | word_ins 2.695 | length 2.99 | ppl 7.97 | wps 45398.1 | ups 0.77 | wpb 59283.5 | bsz 2002.8 | num_updates 243245 | lr 0.000202758 | gnorm 1.289 | loss_scale 8192 | train_wall 2522 | wall 319349
2023-01-16 08:29:55 | INFO | fairseq.trainer | begin training epoch 124
2023-01-16 08:31:15 | INFO | train_inner | epoch 124:     55 / 1978 loss=3.001, nll_loss=0.877, word_ins=2.703, length=2.974, ppl=8, wps=32729.8, ups=0.55, wpb=59335.2, bsz=1941.2, num_updates=243300, lr=0.000202735, gnorm=1.314, loss_scale=8192, train_wall=127, wall=319429
2023-01-16 08:33:22 | INFO | train_inner | epoch 124:    155 / 1978 loss=2.985, nll_loss=0.858, word_ins=2.686, length=2.993, ppl=7.92, wps=46131.6, ups=0.79, wpb=58623.6, bsz=2016.3, num_updates=243400, lr=0.000202693, gnorm=1.262, loss_scale=8192, train_wall=127, wall=319557
2023-01-16 08:35:30 | INFO | train_inner | epoch 124:    255 / 1978 loss=2.971, nll_loss=0.846, word_ins=2.675, length=2.955, ppl=7.84, wps=46570.2, ups=0.79, wpb=59245.3, bsz=2085.2, num_updates=243500, lr=0.000202652, gnorm=1.244, loss_scale=8192, train_wall=127, wall=319684
2023-01-16 08:37:38 | INFO | train_inner | epoch 124:    355 / 1978 loss=2.991, nll_loss=0.867, word_ins=2.694, length=2.975, ppl=7.95, wps=46396.4, ups=0.78, wpb=59692.8, bsz=2030, num_updates=243600, lr=0.00020261, gnorm=1.271, loss_scale=8192, train_wall=128, wall=319812
2023-01-16 08:39:49 | INFO | train_inner | epoch 124:    455 / 1978 loss=3.003, nll_loss=0.876, word_ins=2.702, length=3.007, ppl=8.02, wps=45270.9, ups=0.76, wpb=59242.7, bsz=1933.6, num_updates=243700, lr=0.000202569, gnorm=1.344, loss_scale=8192, train_wall=131, wall=319943
2023-01-16 08:41:57 | INFO | train_inner | epoch 124:    555 / 1978 loss=2.979, nll_loss=0.858, word_ins=2.686, length=2.934, ppl=7.89, wps=46558.9, ups=0.78, wpb=59357.6, bsz=2063, num_updates=243800, lr=0.000202527, gnorm=1.269, loss_scale=8192, train_wall=127, wall=320071
2023-01-16 08:44:06 | INFO | train_inner | epoch 124:    655 / 1978 loss=2.983, nll_loss=0.859, word_ins=2.687, length=2.959, ppl=7.9, wps=45917.5, ups=0.78, wpb=59230.6, bsz=2065.6, num_updates=243900, lr=0.000202486, gnorm=1.271, loss_scale=8192, train_wall=128, wall=320200
2023-01-16 08:46:14 | INFO | train_inner | epoch 124:    755 / 1978 loss=3.013, nll_loss=0.885, word_ins=2.71, length=3.028, ppl=8.07, wps=46225.8, ups=0.78, wpb=59161.3, bsz=1921.3, num_updates=244000, lr=0.000202444, gnorm=1.309, loss_scale=8192, train_wall=128, wall=320328
2023-01-16 08:48:21 | INFO | train_inner | epoch 124:    855 / 1978 loss=2.97, nll_loss=0.853, word_ins=2.681, length=2.889, ppl=7.84, wps=46549.2, ups=0.78, wpb=59435.8, bsz=2048.5, num_updates=244100, lr=0.000202403, gnorm=1.271, loss_scale=8192, train_wall=127, wall=320455
2023-01-16 08:50:29 | INFO | train_inner | epoch 124:    955 / 1978 loss=2.994, nll_loss=0.864, word_ins=2.691, length=3.025, ppl=7.97, wps=46295.9, ups=0.78, wpb=59111.3, bsz=1991.3, num_updates=244200, lr=0.000202361, gnorm=1.316, loss_scale=8192, train_wall=127, wall=320583
2023-01-16 08:52:38 | INFO | train_inner | epoch 124:   1055 / 1978 loss=2.997, nll_loss=0.871, word_ins=2.698, length=2.993, ppl=7.98, wps=45782.5, ups=0.78, wpb=58899.5, bsz=2026.3, num_updates=244300, lr=0.00020232, gnorm=1.265, loss_scale=8192, train_wall=128, wall=320712
2023-01-16 08:54:46 | INFO | train_inner | epoch 124:   1155 / 1978 loss=2.973, nll_loss=0.848, word_ins=2.676, length=2.967, ppl=7.85, wps=46345.6, ups=0.78, wpb=59477.8, bsz=2081.4, num_updates=244400, lr=0.000202278, gnorm=1.295, loss_scale=8192, train_wall=128, wall=320840
2023-01-16 08:56:54 | INFO | train_inner | epoch 124:   1255 / 1978 loss=3.022, nll_loss=0.898, word_ins=2.722, length=2.998, ppl=8.12, wps=46666.1, ups=0.78, wpb=59575.8, bsz=1897.9, num_updates=244500, lr=0.000202237, gnorm=1.294, loss_scale=8192, train_wall=127, wall=320968
2023-01-16 08:59:02 | INFO | train_inner | epoch 124:   1355 / 1978 loss=2.976, nll_loss=0.848, word_ins=2.677, length=2.985, ppl=7.87, wps=46284.3, ups=0.78, wpb=59214, bsz=2045.3, num_updates=244600, lr=0.000202196, gnorm=1.29, loss_scale=8192, train_wall=128, wall=321096
2023-01-16 09:01:09 | INFO | train_inner | epoch 124:   1455 / 1978 loss=2.998, nll_loss=0.869, word_ins=2.696, length=3.023, ppl=7.99, wps=46695.9, ups=0.79, wpb=59304.2, bsz=2006.3, num_updates=244700, lr=0.000202154, gnorm=1.327, loss_scale=8192, train_wall=127, wall=321223
2023-01-16 09:03:16 | INFO | train_inner | epoch 124:   1555 / 1978 loss=2.989, nll_loss=0.866, word_ins=2.693, length=2.96, ppl=7.94, wps=46728, ups=0.79, wpb=59467, bsz=2036.9, num_updates=244800, lr=0.000202113, gnorm=1.303, loss_scale=8192, train_wall=127, wall=321350
2023-01-16 09:05:23 | INFO | train_inner | epoch 124:   1655 / 1978 loss=2.996, nll_loss=0.866, word_ins=2.693, length=3.031, ppl=7.98, wps=46478.9, ups=0.78, wpb=59285.5, bsz=2023, num_updates=244900, lr=0.000202072, gnorm=1.285, loss_scale=8192, train_wall=127, wall=321478
2023-01-16 09:07:30 | INFO | train_inner | epoch 124:   1755 / 1978 loss=2.991, nll_loss=0.865, word_ins=2.692, length=2.992, ppl=7.95, wps=46819.8, ups=0.79, wpb=59458.2, bsz=1982.9, num_updates=245000, lr=0.000202031, gnorm=1.28, loss_scale=8192, train_wall=127, wall=321605
2023-01-16 09:09:38 | INFO | train_inner | epoch 124:   1855 / 1978 loss=2.971, nll_loss=0.847, word_ins=2.676, length=2.953, ppl=7.84, wps=47095.4, ups=0.78, wpb=60132.3, bsz=2081, num_updates=245100, lr=0.000201989, gnorm=1.343, loss_scale=8192, train_wall=127, wall=321732
2023-01-16 09:11:45 | INFO | train_inner | epoch 124:   1955 / 1978 loss=3.039, nll_loss=0.909, word_ins=2.732, length=3.061, ppl=8.22, wps=46387.4, ups=0.79, wpb=58851.6, bsz=1880.6, num_updates=245200, lr=0.000201948, gnorm=1.293, loss_scale=8192, train_wall=127, wall=321859
2023-01-16 09:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 09:12:31 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 4.625 | nll_loss 1.967 | word_ins 3.731 | length 8.943 | ppl 24.68 | wps 159508 | wpb 40242.5 | bsz 1500 | num_updates 245223 | best_loss 4.422
2023-01-16 09:12:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 09:12:58 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint124.pt (epoch 124 @ 245223 updates, score 4.625) (writing took 26.512467982713133 seconds)
2023-01-16 09:12:58 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2023-01-16 09:12:58 | INFO | train | epoch 124 | loss 2.993 | nll_loss 0.867 | word_ins 2.694 | length 2.988 | ppl 7.96 | wps 45407 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 245223 | lr 0.000201939 | gnorm 1.293 | loss_scale 8192 | train_wall 2522 | wall 321932
2023-01-16 09:12:58 | INFO | fairseq.trainer | begin training epoch 125
2023-01-16 09:14:47 | INFO | train_inner | epoch 125:     77 / 1978 loss=2.988, nll_loss=0.861, word_ins=2.689, length=2.995, ppl=7.94, wps=32273.1, ups=0.55, wpb=58623.9, bsz=1928.9, num_updates=245300, lr=0.000201907, gnorm=1.238, loss_scale=8192, train_wall=126, wall=322041
2023-01-16 09:16:54 | INFO | train_inner | epoch 125:    177 / 1978 loss=2.989, nll_loss=0.862, word_ins=2.69, length=2.983, ppl=7.94, wps=46325.7, ups=0.79, wpb=58939.9, bsz=1989.3, num_updates=245400, lr=0.000201866, gnorm=1.268, loss_scale=8192, train_wall=127, wall=322168
2023-01-16 09:19:00 | INFO | train_inner | epoch 125:    277 / 1978 loss=2.995, nll_loss=0.872, word_ins=2.699, length=2.965, ppl=7.97, wps=46872.6, ups=0.79, wpb=59274.7, bsz=1957.1, num_updates=245500, lr=0.000201825, gnorm=1.272, loss_scale=8192, train_wall=126, wall=322294
2023-01-16 09:21:09 | INFO | train_inner | epoch 125:    377 / 1978 loss=2.973, nll_loss=0.848, word_ins=2.677, length=2.952, ppl=7.85, wps=46008.8, ups=0.78, wpb=59023.6, bsz=2079.8, num_updates=245600, lr=0.000201784, gnorm=1.273, loss_scale=8192, train_wall=128, wall=322423
2023-01-16 09:23:16 | INFO | train_inner | epoch 125:    477 / 1978 loss=2.999, nll_loss=0.876, word_ins=2.702, length=2.967, ppl=7.99, wps=46306.7, ups=0.78, wpb=59011.5, bsz=1987.1, num_updates=245700, lr=0.000201743, gnorm=1.255, loss_scale=8192, train_wall=127, wall=322550
2023-01-16 09:25:23 | INFO | train_inner | epoch 125:    577 / 1978 loss=2.975, nll_loss=0.85, word_ins=2.679, length=2.96, ppl=7.86, wps=46771.8, ups=0.79, wpb=59330.8, bsz=1991, num_updates=245800, lr=0.000201701, gnorm=1.312, loss_scale=8192, train_wall=127, wall=322677
2023-01-16 09:25:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 09:27:32 | INFO | train_inner | epoch 125:    678 / 1978 loss=2.984, nll_loss=0.861, word_ins=2.688, length=2.96, ppl=7.91, wps=46135.7, ups=0.78, wpb=59393.7, bsz=1987.9, num_updates=245900, lr=0.00020166, gnorm=1.319, loss_scale=8192, train_wall=129, wall=322806
2023-01-16 09:29:38 | INFO | train_inner | epoch 125:    778 / 1978 loss=3.008, nll_loss=0.879, word_ins=2.705, length=3.028, ppl=8.04, wps=46880.1, ups=0.79, wpb=59149.1, bsz=1905.3, num_updates=246000, lr=0.000201619, gnorm=1.296, loss_scale=8192, train_wall=126, wall=322932
2023-01-16 09:31:45 | INFO | train_inner | epoch 125:    878 / 1978 loss=2.991, nll_loss=0.872, word_ins=2.698, length=2.933, ppl=7.95, wps=46871.1, ups=0.79, wpb=59662.3, bsz=2010.4, num_updates=246100, lr=0.000201578, gnorm=1.345, loss_scale=8192, train_wall=127, wall=323059
2023-01-16 09:33:52 | INFO | train_inner | epoch 125:    978 / 1978 loss=3.002, nll_loss=0.872, word_ins=2.699, length=3.031, ppl=8.01, wps=46676, ups=0.79, wpb=59104.5, bsz=1936.2, num_updates=246200, lr=0.000201538, gnorm=1.242, loss_scale=8192, train_wall=126, wall=323186
2023-01-16 09:35:59 | INFO | train_inner | epoch 125:   1078 / 1978 loss=2.993, nll_loss=0.86, word_ins=2.688, length=3.055, ppl=7.96, wps=46960.6, ups=0.79, wpb=59718.9, bsz=1958.4, num_updates=246300, lr=0.000201497, gnorm=1.342, loss_scale=8192, train_wall=127, wall=323313
2023-01-16 09:38:07 | INFO | train_inner | epoch 125:   1178 / 1978 loss=2.982, nll_loss=0.86, word_ins=2.688, length=2.938, ppl=7.9, wps=46098.1, ups=0.78, wpb=59008.5, bsz=2068.4, num_updates=246400, lr=0.000201456, gnorm=1.286, loss_scale=8192, train_wall=128, wall=323441
2023-01-16 09:40:15 | INFO | train_inner | epoch 125:   1278 / 1978 loss=2.981, nll_loss=0.86, word_ins=2.687, length=2.938, ppl=7.9, wps=46159.6, ups=0.78, wpb=59294.3, bsz=2093.5, num_updates=246500, lr=0.000201415, gnorm=1.291, loss_scale=8192, train_wall=128, wall=323570
2023-01-16 09:42:23 | INFO | train_inner | epoch 125:   1378 / 1978 loss=3.007, nll_loss=0.876, word_ins=2.703, length=3.044, ppl=8.04, wps=45909, ups=0.79, wpb=58476.7, bsz=1995.2, num_updates=246600, lr=0.000201374, gnorm=1.267, loss_scale=8192, train_wall=127, wall=323697
2023-01-16 09:44:30 | INFO | train_inner | epoch 125:   1478 / 1978 loss=3.015, nll_loss=0.889, word_ins=2.714, length=3.016, ppl=8.09, wps=46494, ups=0.79, wpb=58982.6, bsz=2054, num_updates=246700, lr=0.000201333, gnorm=1.286, loss_scale=8192, train_wall=127, wall=323824
2023-01-16 09:46:38 | INFO | train_inner | epoch 125:   1578 / 1978 loss=2.981, nll_loss=0.856, word_ins=2.684, length=2.972, ppl=7.89, wps=46411.6, ups=0.78, wpb=59485.5, bsz=2047.5, num_updates=246800, lr=0.000201292, gnorm=1.288, loss_scale=8192, train_wall=128, wall=323952
2023-01-16 09:48:45 | INFO | train_inner | epoch 125:   1678 / 1978 loss=2.979, nll_loss=0.852, word_ins=2.68, length=2.994, ppl=7.89, wps=46783.7, ups=0.79, wpb=59594.4, bsz=2061.3, num_updates=246900, lr=0.000201252, gnorm=1.271, loss_scale=8192, train_wall=127, wall=324079
2023-01-16 09:50:51 | INFO | train_inner | epoch 125:   1778 / 1978 loss=2.998, nll_loss=0.87, word_ins=2.696, length=3.018, ppl=7.99, wps=47534.2, ups=0.79, wpb=59921.1, bsz=1883.4, num_updates=247000, lr=0.000201211, gnorm=1.343, loss_scale=8192, train_wall=126, wall=324205
2023-01-16 09:52:59 | INFO | train_inner | epoch 125:   1878 / 1978 loss=2.999, nll_loss=0.874, word_ins=2.7, length=2.99, ppl=8, wps=46560.9, ups=0.78, wpb=59658.8, bsz=1990.2, num_updates=247100, lr=0.00020117, gnorm=1.274, loss_scale=8192, train_wall=128, wall=324334
2023-01-16 09:55:07 | INFO | train_inner | epoch 125:   1978 / 1978 loss=2.978, nll_loss=0.852, word_ins=2.68, length=2.977, ppl=7.88, wps=46840.3, ups=0.78, wpb=59802.3, bsz=2067.6, num_updates=247200, lr=0.000201129, gnorm=1.34, loss_scale=8192, train_wall=127, wall=324461
2023-01-16 09:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 09:55:20 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 4.596 | nll_loss 1.989 | word_ins 3.748 | length 8.481 | ppl 24.19 | wps 152696 | wpb 40242.5 | bsz 1500 | num_updates 247200 | best_loss 4.422
2023-01-16 09:55:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 09:55:46 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint125.pt (epoch 125 @ 247200 updates, score 4.596) (writing took 26.394324337132275 seconds)
2023-01-16 09:55:46 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2023-01-16 09:55:46 | INFO | train | epoch 125 | loss 2.99 | nll_loss 0.865 | word_ins 2.692 | length 2.984 | ppl 7.95 | wps 45633.2 | ups 0.77 | wpb 59283.2 | bsz 2002.7 | num_updates 247200 | lr 0.000201129 | gnorm 1.29 | loss_scale 8192 | train_wall 2514 | wall 324500
2023-01-16 09:55:46 | INFO | fairseq.trainer | begin training epoch 126
2023-01-16 09:58:04 | INFO | train_inner | epoch 126:    100 / 1978 loss=2.971, nll_loss=0.853, word_ins=2.681, length=2.896, ppl=7.84, wps=33642.9, ups=0.57, wpb=59481.1, bsz=1999.4, num_updates=247300, lr=0.000201089, gnorm=1.297, loss_scale=8192, train_wall=127, wall=324638
2023-01-16 10:00:10 | INFO | train_inner | epoch 126:    200 / 1978 loss=3, nll_loss=0.874, word_ins=2.701, length=2.996, ppl=8, wps=46791, ups=0.79, wpb=59113.1, bsz=1922.2, num_updates=247400, lr=0.000201048, gnorm=1.326, loss_scale=8192, train_wall=126, wall=324764
2023-01-16 10:02:17 | INFO | train_inner | epoch 126:    300 / 1978 loss=2.997, nll_loss=0.868, word_ins=2.696, length=3.015, ppl=7.98, wps=46743.9, ups=0.79, wpb=59161.2, bsz=1907, num_updates=247500, lr=0.000201008, gnorm=1.267, loss_scale=8192, train_wall=126, wall=324891
2023-01-16 10:04:25 | INFO | train_inner | epoch 126:    400 / 1978 loss=2.959, nll_loss=0.835, word_ins=2.665, length=2.936, ppl=7.78, wps=46087.2, ups=0.78, wpb=59274.3, bsz=2084.6, num_updates=247600, lr=0.000200967, gnorm=1.332, loss_scale=8192, train_wall=128, wall=325020
2023-01-16 10:06:34 | INFO | train_inner | epoch 126:    500 / 1978 loss=2.973, nll_loss=0.849, word_ins=2.678, length=2.945, ppl=7.85, wps=46109.2, ups=0.78, wpb=59259.6, bsz=2099.9, num_updates=247700, lr=0.000200926, gnorm=1.26, loss_scale=8192, train_wall=128, wall=325148
2023-01-16 10:08:42 | INFO | train_inner | epoch 126:    600 / 1978 loss=2.991, nll_loss=0.865, word_ins=2.692, length=2.992, ppl=7.95, wps=46899.4, ups=0.78, wpb=59803.5, bsz=2063.2, num_updates=247800, lr=0.000200886, gnorm=1.275, loss_scale=8192, train_wall=127, wall=325276
2023-01-16 10:10:50 | INFO | train_inner | epoch 126:    700 / 1978 loss=2.981, nll_loss=0.854, word_ins=2.682, length=2.991, ppl=7.9, wps=46378.5, ups=0.78, wpb=59381.2, bsz=2016.2, num_updates=247900, lr=0.000200845, gnorm=1.293, loss_scale=8192, train_wall=128, wall=325404
2023-01-16 10:12:56 | INFO | train_inner | epoch 126:    800 / 1978 loss=2.997, nll_loss=0.867, word_ins=2.695, length=3.022, ppl=7.98, wps=46911.9, ups=0.79, wpb=59123.8, bsz=1944.6, num_updates=248000, lr=0.000200805, gnorm=1.317, loss_scale=8192, train_wall=126, wall=325530
2023-01-16 10:15:02 | INFO | train_inner | epoch 126:    900 / 1978 loss=2.99, nll_loss=0.865, word_ins=2.692, length=2.976, ppl=7.94, wps=46801.2, ups=0.79, wpb=59330.8, bsz=2004.7, num_updates=248100, lr=0.000200764, gnorm=1.281, loss_scale=8192, train_wall=127, wall=325656
2023-01-16 10:17:10 | INFO | train_inner | epoch 126:   1000 / 1978 loss=2.968, nll_loss=0.842, word_ins=2.671, length=2.968, ppl=7.83, wps=46937.5, ups=0.78, wpb=59848.8, bsz=1964.6, num_updates=248200, lr=0.000200724, gnorm=1.312, loss_scale=8192, train_wall=127, wall=325784
2023-01-16 10:19:18 | INFO | train_inner | epoch 126:   1100 / 1978 loss=2.984, nll_loss=0.853, word_ins=2.681, length=3.022, ppl=7.91, wps=46213.4, ups=0.78, wpb=59182.6, bsz=2025.7, num_updates=248300, lr=0.000200683, gnorm=1.296, loss_scale=8192, train_wall=128, wall=325912
2023-01-16 10:21:27 | INFO | train_inner | epoch 126:   1200 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.681, length=2.952, ppl=7.87, wps=45871.3, ups=0.77, wpb=59285.5, bsz=2016.6, num_updates=248400, lr=0.000200643, gnorm=1.283, loss_scale=8192, train_wall=129, wall=326041
2023-01-16 10:23:36 | INFO | train_inner | epoch 126:   1300 / 1978 loss=2.993, nll_loss=0.865, word_ins=2.692, length=3.015, ppl=7.96, wps=45959.8, ups=0.78, wpb=59274.6, bsz=2059.2, num_updates=248500, lr=0.000200603, gnorm=1.257, loss_scale=8192, train_wall=129, wall=326170
2023-01-16 10:25:47 | INFO | train_inner | epoch 126:   1400 / 1978 loss=2.987, nll_loss=0.861, word_ins=2.689, length=2.979, ppl=7.93, wps=45044.6, ups=0.77, wpb=58731.3, bsz=2028.6, num_updates=248600, lr=0.000200562, gnorm=1.258, loss_scale=8192, train_wall=130, wall=326301
2023-01-16 10:27:55 | INFO | train_inner | epoch 126:   1500 / 1978 loss=2.993, nll_loss=0.865, word_ins=2.692, length=3.011, ppl=7.96, wps=46172.4, ups=0.78, wpb=59225.9, bsz=1983.9, num_updates=248700, lr=0.000200522, gnorm=1.294, loss_scale=8192, train_wall=128, wall=326429
2023-01-16 10:30:02 | INFO | train_inner | epoch 126:   1600 / 1978 loss=3.016, nll_loss=0.888, word_ins=2.713, length=3.033, ppl=8.09, wps=46556.1, ups=0.78, wpb=59372.4, bsz=1926.8, num_updates=248800, lr=0.000200482, gnorm=1.319, loss_scale=8192, train_wall=127, wall=326556
2023-01-16 10:32:10 | INFO | train_inner | epoch 126:   1700 / 1978 loss=3.027, nll_loss=0.905, word_ins=2.729, length=2.986, ppl=8.15, wps=45884.4, ups=0.78, wpb=58761, bsz=2002.6, num_updates=248900, lr=0.000200441, gnorm=1.316, loss_scale=8192, train_wall=128, wall=326685
2023-01-16 10:34:18 | INFO | train_inner | epoch 126:   1800 / 1978 loss=3.003, nll_loss=0.877, word_ins=2.703, length=2.999, ppl=8.01, wps=46695.2, ups=0.79, wpb=59458.4, bsz=1933.6, num_updates=249000, lr=0.000200401, gnorm=1.307, loss_scale=8192, train_wall=127, wall=326812
2023-01-16 10:36:27 | INFO | train_inner | epoch 126:   1900 / 1978 loss=2.985, nll_loss=0.859, word_ins=2.686, length=2.991, ppl=7.92, wps=46271.7, ups=0.77, wpb=59768.8, bsz=2066.2, num_updates=249100, lr=0.000200361, gnorm=1.297, loss_scale=8192, train_wall=129, wall=326941
2023-01-16 10:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 10:38:21 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 4.588 | nll_loss 1.991 | word_ins 3.754 | length 8.346 | ppl 24.06 | wps 111512 | wpb 40242.5 | bsz 1500 | num_updates 249178 | best_loss 4.422
2023-01-16 10:38:21 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 10:38:48 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint126.pt (epoch 126 @ 249178 updates, score 4.588) (writing took 26.748973982874304 seconds)
2023-01-16 10:38:48 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2023-01-16 10:38:48 | INFO | train | epoch 126 | loss 2.989 | nll_loss 0.864 | word_ins 2.691 | length 2.987 | ppl 7.94 | wps 45412.5 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 249178 | lr 0.00020033 | gnorm 1.293 | loss_scale 8192 | train_wall 2524 | wall 327082
2023-01-16 10:38:48 | INFO | fairseq.trainer | begin training epoch 127
2023-01-16 10:39:29 | INFO | train_inner | epoch 127:     22 / 1978 loss=2.988, nll_loss=0.862, word_ins=2.689, length=2.989, ppl=7.93, wps=32281.7, ups=0.55, wpb=58825.1, bsz=2035.4, num_updates=249200, lr=0.000200321, gnorm=1.256, loss_scale=8192, train_wall=128, wall=327123
2023-01-16 10:41:39 | INFO | train_inner | epoch 127:    122 / 1978 loss=2.963, nll_loss=0.839, word_ins=2.669, length=2.948, ppl=7.8, wps=46042.5, ups=0.77, wpb=59524, bsz=2062.5, num_updates=249300, lr=0.000200281, gnorm=1.265, loss_scale=8192, train_wall=129, wall=327253
2023-01-16 10:43:46 | INFO | train_inner | epoch 127:    222 / 1978 loss=3.001, nll_loss=0.876, word_ins=2.702, length=2.991, ppl=8.01, wps=46431.2, ups=0.79, wpb=59077.7, bsz=1978.8, num_updates=249400, lr=0.00020024, gnorm=1.298, loss_scale=8192, train_wall=127, wall=327380
2023-01-16 10:45:54 | INFO | train_inner | epoch 127:    322 / 1978 loss=2.988, nll_loss=0.862, word_ins=2.69, length=2.984, ppl=7.93, wps=45507.7, ups=0.78, wpb=58192.4, bsz=1976.6, num_updates=249500, lr=0.0002002, gnorm=1.288, loss_scale=8192, train_wall=128, wall=327508
2023-01-16 10:48:01 | INFO | train_inner | epoch 127:    422 / 1978 loss=2.968, nll_loss=0.84, word_ins=2.67, length=2.98, ppl=7.82, wps=46805.1, ups=0.79, wpb=59586.6, bsz=2009.4, num_updates=249600, lr=0.00020016, gnorm=1.306, loss_scale=8192, train_wall=127, wall=327635
2023-01-16 10:50:09 | INFO | train_inner | epoch 127:    522 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.681, length=2.951, ppl=7.87, wps=46575.5, ups=0.78, wpb=59553.1, bsz=2059.9, num_updates=249700, lr=0.00020012, gnorm=1.303, loss_scale=8192, train_wall=128, wall=327763
2023-01-16 10:52:16 | INFO | train_inner | epoch 127:    622 / 1978 loss=2.961, nll_loss=0.839, word_ins=2.669, length=2.922, ppl=7.79, wps=46760.3, ups=0.79, wpb=59495.9, bsz=2051.8, num_updates=249800, lr=0.00020008, gnorm=1.251, loss_scale=8192, train_wall=127, wall=327890
2023-01-16 10:54:23 | INFO | train_inner | epoch 127:    722 / 1978 loss=2.975, nll_loss=0.843, word_ins=2.673, length=3.026, ppl=7.86, wps=46903.3, ups=0.79, wpb=59410.9, bsz=1985.5, num_updates=249900, lr=0.00020004, gnorm=1.272, loss_scale=8192, train_wall=126, wall=328017
2023-01-16 10:54:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 10:56:32 | INFO | train_inner | epoch 127:    823 / 1978 loss=2.998, nll_loss=0.874, word_ins=2.701, length=2.969, ppl=7.99, wps=45828, ups=0.77, wpb=59210.2, bsz=1977, num_updates=250000, lr=0.0002, gnorm=1.355, loss_scale=8192, train_wall=129, wall=328146
2023-01-16 10:58:40 | INFO | train_inner | epoch 127:    923 / 1978 loss=2.975, nll_loss=0.846, word_ins=2.675, length=3.003, ppl=7.86, wps=46352.9, ups=0.78, wpb=59233.8, bsz=2044.2, num_updates=250100, lr=0.00019996, gnorm=1.299, loss_scale=8192, train_wall=128, wall=328274
2023-01-16 11:00:47 | INFO | train_inner | epoch 127:   1023 / 1978 loss=2.996, nll_loss=0.868, word_ins=2.695, length=3.016, ppl=7.98, wps=46297.8, ups=0.79, wpb=58849.9, bsz=1975.8, num_updates=250200, lr=0.00019992, gnorm=1.303, loss_scale=8192, train_wall=127, wall=328401
2023-01-16 11:02:54 | INFO | train_inner | epoch 127:   1123 / 1978 loss=2.984, nll_loss=0.869, word_ins=2.695, length=2.893, ppl=7.91, wps=47172.8, ups=0.79, wpb=60031.5, bsz=1997.3, num_updates=250300, lr=0.00019988, gnorm=1.317, loss_scale=8192, train_wall=127, wall=328528
2023-01-16 11:05:02 | INFO | train_inner | epoch 127:   1223 / 1978 loss=2.999, nll_loss=0.877, word_ins=2.703, length=2.96, ppl=7.99, wps=46391.8, ups=0.78, wpb=59338.2, bsz=1986.2, num_updates=250400, lr=0.00019984, gnorm=1.294, loss_scale=8192, train_wall=128, wall=328656
2023-01-16 11:07:09 | INFO | train_inner | epoch 127:   1323 / 1978 loss=3.007, nll_loss=0.876, word_ins=2.702, length=3.047, ppl=8.04, wps=46527.1, ups=0.79, wpb=58969.7, bsz=1931.3, num_updates=250500, lr=0.0001998, gnorm=1.278, loss_scale=8192, train_wall=127, wall=328783
2023-01-16 11:09:16 | INFO | train_inner | epoch 127:   1423 / 1978 loss=2.994, nll_loss=0.872, word_ins=2.698, length=2.96, ppl=7.97, wps=46541.3, ups=0.78, wpb=59413.4, bsz=1997.4, num_updates=250600, lr=0.00019976, gnorm=1.275, loss_scale=8192, train_wall=127, wall=328911
2023-01-16 11:11:24 | INFO | train_inner | epoch 127:   1523 / 1978 loss=2.979, nll_loss=0.858, word_ins=2.686, length=2.93, ppl=7.88, wps=46088.5, ups=0.78, wpb=58977.5, bsz=2066.3, num_updates=250700, lr=0.000199721, gnorm=1.247, loss_scale=8192, train_wall=128, wall=329038
2023-01-16 11:13:32 | INFO | train_inner | epoch 127:   1623 / 1978 loss=3.002, nll_loss=0.88, word_ins=2.706, length=2.955, ppl=8.01, wps=46580, ups=0.78, wpb=59514.4, bsz=1951.5, num_updates=250800, lr=0.000199681, gnorm=1.262, loss_scale=8192, train_wall=128, wall=329166
2023-01-16 11:15:39 | INFO | train_inner | epoch 127:   1723 / 1978 loss=3.016, nll_loss=0.89, word_ins=2.715, length=3.015, ppl=8.09, wps=46474.7, ups=0.79, wpb=58882, bsz=1984.6, num_updates=250900, lr=0.000199641, gnorm=1.274, loss_scale=8192, train_wall=126, wall=329293
2023-01-16 11:17:47 | INFO | train_inner | epoch 127:   1823 / 1978 loss=3, nll_loss=0.875, word_ins=2.701, length=2.988, ppl=8, wps=46775.6, ups=0.78, wpb=59700.2, bsz=2002.6, num_updates=251000, lr=0.000199601, gnorm=1.319, loss_scale=8192, train_wall=127, wall=329421
2023-01-16 11:19:54 | INFO | train_inner | epoch 127:   1923 / 1978 loss=2.99, nll_loss=0.864, word_ins=2.691, length=2.987, ppl=7.94, wps=46925.9, ups=0.79, wpb=59764.4, bsz=1979, num_updates=251100, lr=0.000199561, gnorm=1.301, loss_scale=8192, train_wall=127, wall=329548
2023-01-16 11:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 11:21:19 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 4.666 | nll_loss 1.999 | word_ins 3.761 | length 9.051 | ppl 25.38 | wps 171244 | wpb 40242.5 | bsz 1500 | num_updates 251155 | best_loss 4.422
2023-01-16 11:21:19 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 11:21:46 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint127.pt (epoch 127 @ 251155 updates, score 4.666) (writing took 27.141569855622947 seconds)
2023-01-16 11:21:46 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2023-01-16 11:21:46 | INFO | train | epoch 127 | loss 2.987 | nll_loss 0.862 | word_ins 2.69 | length 2.976 | ppl 7.93 | wps 45461.6 | ups 0.77 | wpb 59283.3 | bsz 2002.2 | num_updates 251155 | lr 0.00019954 | gnorm 1.291 | loss_scale 8192 | train_wall 2518 | wall 329660
2023-01-16 11:21:46 | INFO | fairseq.trainer | begin training epoch 128
2023-01-16 11:22:54 | INFO | train_inner | epoch 128:     45 / 1978 loss=2.984, nll_loss=0.855, word_ins=2.683, length=3.01, ppl=7.91, wps=32688.5, ups=0.55, wpb=58920.8, bsz=1949.8, num_updates=251200, lr=0.000199522, gnorm=1.348, loss_scale=8192, train_wall=127, wall=329728
2023-01-16 11:25:03 | INFO | train_inner | epoch 128:    145 / 1978 loss=2.966, nll_loss=0.845, word_ins=2.674, length=2.91, ppl=7.81, wps=46260.1, ups=0.78, wpb=59490.5, bsz=2014.3, num_updates=251300, lr=0.000199482, gnorm=1.269, loss_scale=8192, train_wall=128, wall=329857
2023-01-16 11:27:10 | INFO | train_inner | epoch 128:    245 / 1978 loss=2.994, nll_loss=0.872, word_ins=2.698, length=2.96, ppl=7.97, wps=46407.8, ups=0.79, wpb=59086.1, bsz=1994.2, num_updates=251400, lr=0.000199442, gnorm=1.315, loss_scale=8192, train_wall=127, wall=329984
2023-01-16 11:29:18 | INFO | train_inner | epoch 128:    345 / 1978 loss=2.985, nll_loss=0.859, word_ins=2.687, length=2.98, ppl=7.92, wps=45836.9, ups=0.78, wpb=58814.3, bsz=2022.7, num_updates=251500, lr=0.000199403, gnorm=1.254, loss_scale=8192, train_wall=128, wall=330112
2023-01-16 11:31:25 | INFO | train_inner | epoch 128:    445 / 1978 loss=2.988, nll_loss=0.863, word_ins=2.691, length=2.975, ppl=7.94, wps=46747.4, ups=0.79, wpb=59377.7, bsz=1949, num_updates=251600, lr=0.000199363, gnorm=1.28, loss_scale=8192, train_wall=127, wall=330239
2023-01-16 11:33:34 | INFO | train_inner | epoch 128:    545 / 1978 loss=2.961, nll_loss=0.833, word_ins=2.663, length=2.98, ppl=7.79, wps=46162.6, ups=0.78, wpb=59135.8, bsz=2071.1, num_updates=251700, lr=0.000199323, gnorm=1.28, loss_scale=8192, train_wall=128, wall=330368
2023-01-16 11:35:41 | INFO | train_inner | epoch 128:    645 / 1978 loss=2.973, nll_loss=0.846, word_ins=2.675, length=2.985, ppl=7.85, wps=46412.9, ups=0.78, wpb=59339.8, bsz=1985, num_updates=251800, lr=0.000199284, gnorm=1.248, loss_scale=8192, train_wall=128, wall=330495
2023-01-16 11:37:49 | INFO | train_inner | epoch 128:    745 / 1978 loss=2.986, nll_loss=0.86, word_ins=2.687, length=2.984, ppl=7.92, wps=46830.8, ups=0.79, wpb=59638.9, bsz=1940.7, num_updates=251900, lr=0.000199244, gnorm=1.321, loss_scale=8192, train_wall=127, wall=330623
2023-01-16 11:39:57 | INFO | train_inner | epoch 128:    845 / 1978 loss=2.974, nll_loss=0.847, word_ins=2.676, length=2.984, ppl=7.86, wps=46496, ups=0.78, wpb=59431.6, bsz=2045.6, num_updates=252000, lr=0.000199205, gnorm=1.252, loss_scale=8192, train_wall=128, wall=330751
2023-01-16 11:42:04 | INFO | train_inner | epoch 128:    945 / 1978 loss=2.992, nll_loss=0.867, word_ins=2.694, length=2.978, ppl=7.95, wps=46630.5, ups=0.79, wpb=59325.4, bsz=1971.7, num_updates=252100, lr=0.000199165, gnorm=1.304, loss_scale=8192, train_wall=127, wall=330878
2023-01-16 11:44:12 | INFO | train_inner | epoch 128:   1045 / 1978 loss=3.018, nll_loss=0.892, word_ins=2.717, length=3.013, ppl=8.1, wps=46060.6, ups=0.78, wpb=58954.3, bsz=1970.6, num_updates=252200, lr=0.000199126, gnorm=1.309, loss_scale=8192, train_wall=128, wall=331006
2023-01-16 11:46:19 | INFO | train_inner | epoch 128:   1145 / 1978 loss=2.991, nll_loss=0.867, word_ins=2.694, length=2.971, ppl=7.95, wps=46703.8, ups=0.79, wpb=59464.8, bsz=2003.8, num_updates=252300, lr=0.000199086, gnorm=1.312, loss_scale=8192, train_wall=127, wall=331133
2023-01-16 11:48:28 | INFO | train_inner | epoch 128:   1245 / 1978 loss=2.97, nll_loss=0.849, word_ins=2.678, length=2.918, ppl=7.84, wps=46186.2, ups=0.78, wpb=59501.4, bsz=2057.9, num_updates=252400, lr=0.000199047, gnorm=1.272, loss_scale=8192, train_wall=129, wall=331262
2023-01-16 11:50:35 | INFO | train_inner | epoch 128:   1345 / 1978 loss=2.98, nll_loss=0.852, word_ins=2.68, length=2.996, ppl=7.89, wps=46652.4, ups=0.79, wpb=59383.9, bsz=2009, num_updates=252500, lr=0.000199007, gnorm=1.321, loss_scale=8192, train_wall=127, wall=331389
2023-01-16 11:52:43 | INFO | train_inner | epoch 128:   1445 / 1978 loss=2.991, nll_loss=0.865, word_ins=2.692, length=2.992, ppl=7.95, wps=46487.9, ups=0.78, wpb=59510.5, bsz=2043.4, num_updates=252600, lr=0.000198968, gnorm=1.316, loss_scale=8192, train_wall=128, wall=331517
2023-01-16 11:54:50 | INFO | train_inner | epoch 128:   1545 / 1978 loss=3.024, nll_loss=0.891, word_ins=2.716, length=3.079, ppl=8.13, wps=46243.6, ups=0.79, wpb=58556, bsz=1926.9, num_updates=252700, lr=0.000198929, gnorm=1.316, loss_scale=8192, train_wall=126, wall=331644
2023-01-16 11:56:58 | INFO | train_inner | epoch 128:   1645 / 1978 loss=2.985, nll_loss=0.86, word_ins=2.687, length=2.977, ppl=7.92, wps=45852.7, ups=0.78, wpb=58942.7, bsz=2057.9, num_updates=252800, lr=0.000198889, gnorm=1.268, loss_scale=8192, train_wall=128, wall=331773
2023-01-16 11:59:05 | INFO | train_inner | epoch 128:   1745 / 1978 loss=2.983, nll_loss=0.854, word_ins=2.682, length=3.008, ppl=7.91, wps=46587.6, ups=0.79, wpb=58889.1, bsz=1980.8, num_updates=252900, lr=0.00019885, gnorm=1.272, loss_scale=8192, train_wall=126, wall=331899
2023-01-16 12:01:13 | INFO | train_inner | epoch 128:   1845 / 1978 loss=2.986, nll_loss=0.855, word_ins=2.683, length=3.033, ppl=7.92, wps=46694.4, ups=0.78, wpb=59804.4, bsz=1944.4, num_updates=253000, lr=0.000198811, gnorm=1.312, loss_scale=8192, train_wall=128, wall=332027
2023-01-16 12:03:22 | INFO | train_inner | epoch 128:   1945 / 1978 loss=2.991, nll_loss=0.871, word_ins=2.698, length=2.937, ppl=7.95, wps=46264.1, ups=0.78, wpb=59620.8, bsz=2065.4, num_updates=253100, lr=0.000198771, gnorm=1.253, loss_scale=8192, train_wall=129, wall=332156
2023-01-16 12:04:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 12:04:17 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 4.598 | nll_loss 1.965 | word_ins 3.73 | length 8.678 | ppl 24.21 | wps 116634 | wpb 40242.5 | bsz 1500 | num_updates 253133 | best_loss 4.422
2023-01-16 12:04:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 12:04:44 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint128.pt (epoch 128 @ 253133 updates, score 4.598) (writing took 27.122123403009027 seconds)
2023-01-16 12:04:44 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2023-01-16 12:04:44 | INFO | train | epoch 128 | loss 2.985 | nll_loss 0.86 | word_ins 2.687 | length 2.98 | ppl 7.92 | wps 45486 | ups 0.77 | wpb 59284.3 | bsz 2002.6 | num_updates 253133 | lr 0.000198758 | gnorm 1.29 | loss_scale 8192 | train_wall 2522 | wall 332238
2023-01-16 12:04:44 | INFO | fairseq.trainer | begin training epoch 129
2023-01-16 12:06:21 | INFO | train_inner | epoch 129:     67 / 1978 loss=2.936, nll_loss=0.817, word_ins=2.648, length=2.874, ppl=7.65, wps=33045.2, ups=0.56, wpb=59329.9, bsz=2128.1, num_updates=253200, lr=0.000198732, gnorm=1.252, loss_scale=8192, train_wall=128, wall=332335
2023-01-16 12:08:28 | INFO | train_inner | epoch 129:    167 / 1978 loss=2.972, nll_loss=0.848, word_ins=2.677, length=2.954, ppl=7.85, wps=46810.1, ups=0.79, wpb=59472.3, bsz=1961.7, num_updates=253300, lr=0.000198693, gnorm=1.322, loss_scale=8192, train_wall=127, wall=332463
2023-01-16 12:10:35 | INFO | train_inner | epoch 129:    267 / 1978 loss=3, nll_loss=0.876, word_ins=2.703, length=2.974, ppl=8, wps=46304.6, ups=0.79, wpb=58724.9, bsz=1951.4, num_updates=253400, lr=0.000198654, gnorm=1.336, loss_scale=8192, train_wall=127, wall=332589
2023-01-16 12:12:43 | INFO | train_inner | epoch 129:    367 / 1978 loss=2.972, nll_loss=0.848, word_ins=2.677, length=2.953, ppl=7.85, wps=45758.5, ups=0.78, wpb=58361.3, bsz=2015.8, num_updates=253500, lr=0.000198615, gnorm=1.194, loss_scale=8192, train_wall=127, wall=332717
2023-01-16 12:14:51 | INFO | train_inner | epoch 129:    467 / 1978 loss=2.972, nll_loss=0.849, word_ins=2.678, length=2.939, ppl=7.85, wps=46103.6, ups=0.78, wpb=59037.3, bsz=2055, num_updates=253600, lr=0.000198575, gnorm=1.261, loss_scale=8192, train_wall=128, wall=332845
2023-01-16 12:16:58 | INFO | train_inner | epoch 129:    567 / 1978 loss=2.994, nll_loss=0.87, word_ins=2.697, length=2.969, ppl=7.97, wps=46292.1, ups=0.79, wpb=58875, bsz=1958, num_updates=253700, lr=0.000198536, gnorm=1.285, loss_scale=8192, train_wall=127, wall=332972
2023-01-16 12:19:07 | INFO | train_inner | epoch 129:    667 / 1978 loss=2.969, nll_loss=0.844, word_ins=2.673, length=2.966, ppl=7.83, wps=46440.4, ups=0.78, wpb=59771.2, bsz=2020.5, num_updates=253800, lr=0.000198497, gnorm=1.283, loss_scale=8192, train_wall=128, wall=333101
2023-01-16 12:21:14 | INFO | train_inner | epoch 129:    767 / 1978 loss=2.973, nll_loss=0.848, word_ins=2.676, length=2.966, ppl=7.85, wps=46857, ups=0.79, wpb=59624.4, bsz=1976.6, num_updates=253900, lr=0.000198458, gnorm=1.289, loss_scale=8192, train_wall=127, wall=333228
2023-01-16 12:23:21 | INFO | train_inner | epoch 129:    867 / 1978 loss=2.999, nll_loss=0.867, word_ins=2.694, length=3.052, ppl=7.99, wps=46861.8, ups=0.79, wpb=59403.1, bsz=1959.4, num_updates=254000, lr=0.000198419, gnorm=1.324, loss_scale=8192, train_wall=127, wall=333355
2023-01-16 12:23:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 12:25:31 | INFO | train_inner | epoch 129:    968 / 1978 loss=2.988, nll_loss=0.864, word_ins=2.691, length=2.969, ppl=7.93, wps=45327.9, ups=0.77, wpb=59086.4, bsz=2030.7, num_updates=254100, lr=0.00019838, gnorm=1.253, loss_scale=8192, train_wall=130, wall=333485
2023-01-16 12:27:39 | INFO | train_inner | epoch 129:   1068 / 1978 loss=3.007, nll_loss=0.886, word_ins=2.711, length=2.959, ppl=8.04, wps=46433.5, ups=0.78, wpb=59228.9, bsz=1916.7, num_updates=254200, lr=0.000198341, gnorm=1.281, loss_scale=8192, train_wall=127, wall=333613
2023-01-16 12:29:47 | INFO | train_inner | epoch 129:   1168 / 1978 loss=2.976, nll_loss=0.85, word_ins=2.678, length=2.977, ppl=7.87, wps=46357.7, ups=0.78, wpb=59359.2, bsz=2015.9, num_updates=254300, lr=0.000198302, gnorm=1.328, loss_scale=8192, train_wall=128, wall=333741
2023-01-16 12:31:55 | INFO | train_inner | epoch 129:   1268 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.681, length=2.949, ppl=7.87, wps=46616.6, ups=0.78, wpb=59907.8, bsz=2047, num_updates=254400, lr=0.000198263, gnorm=1.307, loss_scale=8192, train_wall=128, wall=333869
2023-01-16 12:34:03 | INFO | train_inner | epoch 129:   1368 / 1978 loss=2.99, nll_loss=0.868, word_ins=2.695, length=2.953, ppl=7.94, wps=46727.9, ups=0.78, wpb=59583.3, bsz=2071.2, num_updates=254500, lr=0.000198224, gnorm=1.22, loss_scale=8192, train_wall=127, wall=333997
2023-01-16 12:36:12 | INFO | train_inner | epoch 129:   1468 / 1978 loss=2.977, nll_loss=0.852, word_ins=2.68, length=2.968, ppl=7.87, wps=46286.2, ups=0.78, wpb=59676.5, bsz=2055.4, num_updates=254600, lr=0.000198185, gnorm=1.315, loss_scale=8192, train_wall=129, wall=334126
2023-01-16 12:38:20 | INFO | train_inner | epoch 129:   1568 / 1978 loss=2.978, nll_loss=0.851, word_ins=2.68, length=2.986, ppl=7.88, wps=46232.3, ups=0.78, wpb=59110.3, bsz=2080, num_updates=254700, lr=0.000198146, gnorm=1.3, loss_scale=8192, train_wall=128, wall=334254
2023-01-16 12:40:28 | INFO | train_inner | epoch 129:   1668 / 1978 loss=2.98, nll_loss=0.858, word_ins=2.685, length=2.949, ppl=7.89, wps=46443.1, ups=0.78, wpb=59416.4, bsz=2064.3, num_updates=254800, lr=0.000198107, gnorm=1.242, loss_scale=8192, train_wall=128, wall=334382
2023-01-16 12:42:35 | INFO | train_inner | epoch 129:   1768 / 1978 loss=2.997, nll_loss=0.866, word_ins=2.693, length=3.037, ppl=7.98, wps=46415.7, ups=0.78, wpb=59324.4, bsz=1952.2, num_updates=254900, lr=0.000198068, gnorm=1.304, loss_scale=8192, train_wall=128, wall=334509
2023-01-16 12:44:42 | INFO | train_inner | epoch 129:   1868 / 1978 loss=3.01, nll_loss=0.883, word_ins=2.708, length=3.016, ppl=8.05, wps=46976.3, ups=0.79, wpb=59614.1, bsz=1951.8, num_updates=255000, lr=0.00019803, gnorm=1.323, loss_scale=8192, train_wall=127, wall=334636
2023-01-16 12:46:49 | INFO | train_inner | epoch 129:   1968 / 1978 loss=3.015, nll_loss=0.888, word_ins=2.713, length=3.017, ppl=8.08, wps=46549.8, ups=0.79, wpb=59034.4, bsz=1887, num_updates=255100, lr=0.000197991, gnorm=1.309, loss_scale=8192, train_wall=127, wall=334763
2023-01-16 12:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 12:47:24 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 4.668 | nll_loss 1.989 | word_ins 3.746 | length 9.213 | ppl 25.42 | wps 117530 | wpb 40242.5 | bsz 1500 | num_updates 255110 | best_loss 4.422
2023-01-16 12:47:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 12:47:51 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint129.pt (epoch 129 @ 255110 updates, score 4.668) (writing took 26.815719410777092 seconds)
2023-01-16 12:47:51 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2023-01-16 12:47:51 | INFO | train | epoch 129 | loss 2.985 | nll_loss 0.86 | word_ins 2.687 | length 2.973 | ppl 7.92 | wps 45303.4 | ups 0.76 | wpb 59282.7 | bsz 2002.7 | num_updates 255110 | lr 0.000197987 | gnorm 1.286 | loss_scale 8192 | train_wall 2521 | wall 334825
2023-01-16 12:47:51 | INFO | fairseq.trainer | begin training epoch 130
2023-01-16 12:50:10 | INFO | train_inner | epoch 130:     90 / 1978 loss=2.962, nll_loss=0.836, word_ins=2.666, length=2.963, ppl=7.79, wps=29106.8, ups=0.5, wpb=58423.1, bsz=2022.6, num_updates=255200, lr=0.000197952, gnorm=1.29, loss_scale=8192, train_wall=128, wall=334964
2023-01-16 12:52:17 | INFO | train_inner | epoch 130:    190 / 1978 loss=2.978, nll_loss=0.853, word_ins=2.682, length=2.964, ppl=7.88, wps=46610.7, ups=0.78, wpb=59381.5, bsz=2003, num_updates=255300, lr=0.000197913, gnorm=1.224, loss_scale=8192, train_wall=127, wall=335091
2023-01-16 12:54:25 | INFO | train_inner | epoch 130:    290 / 1978 loss=2.982, nll_loss=0.86, word_ins=2.688, length=2.944, ppl=7.9, wps=46456.1, ups=0.78, wpb=59363.2, bsz=1942.8, num_updates=255400, lr=0.000197874, gnorm=1.321, loss_scale=8192, train_wall=128, wall=335219
2023-01-16 12:56:34 | INFO | train_inner | epoch 130:    390 / 1978 loss=2.979, nll_loss=0.859, word_ins=2.687, length=2.922, ppl=7.88, wps=46108.5, ups=0.78, wpb=59342.4, bsz=2072.8, num_updates=255500, lr=0.000197836, gnorm=1.301, loss_scale=8192, train_wall=128, wall=335348
2023-01-16 12:58:42 | INFO | train_inner | epoch 130:    490 / 1978 loss=2.987, nll_loss=0.861, word_ins=2.689, length=2.983, ppl=7.93, wps=46056.6, ups=0.78, wpb=59179.6, bsz=2027.6, num_updates=255600, lr=0.000197797, gnorm=1.272, loss_scale=8192, train_wall=128, wall=335476
2023-01-16 13:00:51 | INFO | train_inner | epoch 130:    590 / 1978 loss=2.966, nll_loss=0.842, word_ins=2.67, length=2.955, ppl=7.81, wps=46339, ups=0.78, wpb=59558.7, bsz=2050, num_updates=255700, lr=0.000197758, gnorm=1.279, loss_scale=8192, train_wall=128, wall=335605
2023-01-16 13:03:00 | INFO | train_inner | epoch 130:    690 / 1978 loss=2.952, nll_loss=0.832, word_ins=2.662, length=2.893, ppl=7.74, wps=45977, ups=0.77, wpb=59337.5, bsz=2110, num_updates=255800, lr=0.00019772, gnorm=1.272, loss_scale=8192, train_wall=129, wall=335734
2023-01-16 13:05:07 | INFO | train_inner | epoch 130:    790 / 1978 loss=2.993, nll_loss=0.867, word_ins=2.695, length=2.98, ppl=7.96, wps=46108.1, ups=0.79, wpb=58453.2, bsz=1997.4, num_updates=255900, lr=0.000197681, gnorm=1.272, loss_scale=8192, train_wall=127, wall=335861
2023-01-16 13:07:14 | INFO | train_inner | epoch 130:    890 / 1978 loss=3.003, nll_loss=0.881, word_ins=2.706, length=2.969, ppl=8.02, wps=46661.3, ups=0.78, wpb=59512.1, bsz=1943.6, num_updates=256000, lr=0.000197642, gnorm=1.269, loss_scale=8192, train_wall=127, wall=335988
2023-01-16 13:09:22 | INFO | train_inner | epoch 130:    990 / 1978 loss=2.973, nll_loss=0.849, word_ins=2.677, length=2.965, ppl=7.85, wps=46806.2, ups=0.78, wpb=59685.5, bsz=1975.4, num_updates=256100, lr=0.000197604, gnorm=1.333, loss_scale=8192, train_wall=127, wall=336116
2023-01-16 13:11:29 | INFO | train_inner | epoch 130:   1090 / 1978 loss=2.985, nll_loss=0.862, word_ins=2.689, length=2.96, ppl=7.92, wps=45976.3, ups=0.78, wpb=58668.9, bsz=2021.8, num_updates=256200, lr=0.000197565, gnorm=1.257, loss_scale=8192, train_wall=127, wall=336243
2023-01-16 13:13:38 | INFO | train_inner | epoch 130:   1190 / 1978 loss=2.976, nll_loss=0.856, word_ins=2.684, length=2.923, ppl=7.87, wps=46155.4, ups=0.78, wpb=59325.9, bsz=2118.8, num_updates=256300, lr=0.000197527, gnorm=1.23, loss_scale=8192, train_wall=128, wall=336372
2023-01-16 13:15:45 | INFO | train_inner | epoch 130:   1290 / 1978 loss=3.002, nll_loss=0.876, word_ins=2.702, length=2.993, ppl=8.01, wps=46763.3, ups=0.79, wpb=59484.4, bsz=1920.3, num_updates=256400, lr=0.000197488, gnorm=1.314, loss_scale=8192, train_wall=127, wall=336499
2023-01-16 13:17:52 | INFO | train_inner | epoch 130:   1390 / 1978 loss=2.997, nll_loss=0.868, word_ins=2.695, length=3.019, ppl=7.98, wps=47016.7, ups=0.79, wpb=59725.4, bsz=1932.9, num_updates=256500, lr=0.00019745, gnorm=1.332, loss_scale=8192, train_wall=127, wall=336626
2023-01-16 13:20:00 | INFO | train_inner | epoch 130:   1490 / 1978 loss=3.008, nll_loss=0.88, word_ins=2.706, length=3.021, ppl=8.04, wps=46579.4, ups=0.78, wpb=59517.8, bsz=1946.2, num_updates=256600, lr=0.000197411, gnorm=1.33, loss_scale=8192, train_wall=128, wall=336754
2023-01-16 13:22:07 | INFO | train_inner | epoch 130:   1590 / 1978 loss=2.988, nll_loss=0.861, word_ins=2.688, length=2.995, ppl=7.93, wps=46786.7, ups=0.79, wpb=59418.6, bsz=1957.6, num_updates=256700, lr=0.000197373, gnorm=1.294, loss_scale=8192, train_wall=127, wall=336881
2023-01-16 13:24:15 | INFO | train_inner | epoch 130:   1690 / 1978 loss=2.974, nll_loss=0.847, word_ins=2.676, length=2.98, ppl=7.86, wps=46451.6, ups=0.78, wpb=59325.7, bsz=2021.4, num_updates=256800, lr=0.000197334, gnorm=1.296, loss_scale=8192, train_wall=128, wall=337009
2023-01-16 13:26:22 | INFO | train_inner | epoch 130:   1790 / 1978 loss=2.997, nll_loss=0.867, word_ins=2.694, length=3.023, ppl=7.98, wps=46584.3, ups=0.79, wpb=59190.3, bsz=1966.6, num_updates=256900, lr=0.000197296, gnorm=1.254, loss_scale=8192, train_wall=127, wall=337136
2023-01-16 13:28:29 | INFO | train_inner | epoch 130:   1890 / 1978 loss=2.965, nll_loss=0.839, word_ins=2.668, length=2.973, ppl=7.81, wps=46838.3, ups=0.79, wpb=59448.6, bsz=2036, num_updates=257000, lr=0.000197257, gnorm=1.27, loss_scale=8192, train_wall=127, wall=337263
2023-01-16 13:30:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 13:30:34 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 4.673 | nll_loss 1.99 | word_ins 3.752 | length 9.21 | ppl 25.5 | wps 101551 | wpb 40242.5 | bsz 1500 | num_updates 257088 | best_loss 4.422
2023-01-16 13:30:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 13:31:01 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint130.pt (epoch 130 @ 257088 updates, score 4.673) (writing took 26.938835026696324 seconds)
2023-01-16 13:31:01 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2023-01-16 13:31:01 | INFO | train | epoch 130 | loss 2.983 | nll_loss 0.858 | word_ins 2.686 | length 2.97 | ppl 7.9 | wps 45284 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 257088 | lr 0.000197224 | gnorm 1.285 | loss_scale 8192 | train_wall 2521 | wall 337415
2023-01-16 13:31:01 | INFO | fairseq.trainer | begin training epoch 131
2023-01-16 13:31:27 | INFO | train_inner | epoch 131:     12 / 1978 loss=2.991, nll_loss=0.868, word_ins=2.694, length=2.967, ppl=7.95, wps=33214.6, ups=0.56, wpb=59335.6, bsz=1954.2, num_updates=257100, lr=0.000197219, gnorm=1.295, loss_scale=8192, train_wall=127, wall=337441
2023-01-16 13:33:35 | INFO | train_inner | epoch 131:    112 / 1978 loss=2.985, nll_loss=0.863, word_ins=2.691, length=2.943, ppl=7.92, wps=46268.3, ups=0.78, wpb=58950.3, bsz=1966.1, num_updates=257200, lr=0.000197181, gnorm=1.294, loss_scale=8192, train_wall=127, wall=337569
2023-01-16 13:35:43 | INFO | train_inner | epoch 131:    212 / 1978 loss=2.977, nll_loss=0.852, word_ins=2.68, length=2.968, ppl=7.87, wps=46115.1, ups=0.78, wpb=59409.8, bsz=2008.6, num_updates=257300, lr=0.000197142, gnorm=1.263, loss_scale=8192, train_wall=129, wall=337698
2023-01-16 13:37:51 | INFO | train_inner | epoch 131:    312 / 1978 loss=2.964, nll_loss=0.839, word_ins=2.669, length=2.948, ppl=7.8, wps=46525.9, ups=0.78, wpb=59533.6, bsz=1957.6, num_updates=257400, lr=0.000197104, gnorm=1.281, loss_scale=8192, train_wall=128, wall=337826
2023-01-16 13:40:00 | INFO | train_inner | epoch 131:    412 / 1978 loss=2.976, nll_loss=0.852, word_ins=2.68, length=2.962, ppl=7.87, wps=46296.8, ups=0.78, wpb=59337.9, bsz=2051, num_updates=257500, lr=0.000197066, gnorm=1.312, loss_scale=8192, train_wall=128, wall=337954
2023-01-16 13:42:08 | INFO | train_inner | epoch 131:    512 / 1978 loss=2.943, nll_loss=0.826, word_ins=2.656, length=2.87, ppl=7.69, wps=46414.2, ups=0.78, wpb=59558.6, bsz=2103.4, num_updates=257600, lr=0.000197028, gnorm=1.218, loss_scale=8192, train_wall=128, wall=338082
2023-01-16 13:44:16 | INFO | train_inner | epoch 131:    612 / 1978 loss=2.977, nll_loss=0.853, word_ins=2.681, length=2.959, ppl=7.87, wps=46026.5, ups=0.78, wpb=58794.1, bsz=2014, num_updates=257700, lr=0.000196989, gnorm=1.324, loss_scale=8192, train_wall=127, wall=338210
2023-01-16 13:46:23 | INFO | train_inner | epoch 131:    712 / 1978 loss=3.003, nll_loss=0.878, word_ins=2.704, length=2.99, ppl=8.02, wps=46414.6, ups=0.78, wpb=59193.7, bsz=1958.7, num_updates=257800, lr=0.000196951, gnorm=1.273, loss_scale=8192, train_wall=127, wall=338337
2023-01-16 13:48:31 | INFO | train_inner | epoch 131:    812 / 1978 loss=2.973, nll_loss=0.85, word_ins=2.678, length=2.944, ppl=7.85, wps=46227.2, ups=0.78, wpb=59162.8, bsz=2039, num_updates=257900, lr=0.000196913, gnorm=1.253, loss_scale=8192, train_wall=128, wall=338465
2023-01-16 13:50:40 | INFO | train_inner | epoch 131:    912 / 1978 loss=2.954, nll_loss=0.831, word_ins=2.661, length=2.93, ppl=7.75, wps=46248.9, ups=0.78, wpb=59473.6, bsz=2137.6, num_updates=258000, lr=0.000196875, gnorm=1.277, loss_scale=8192, train_wall=128, wall=338594
2023-01-16 13:52:47 | INFO | train_inner | epoch 131:   1012 / 1978 loss=2.992, nll_loss=0.867, word_ins=2.694, length=2.977, ppl=7.95, wps=46452.6, ups=0.78, wpb=59209.5, bsz=1955.9, num_updates=258100, lr=0.000196837, gnorm=1.283, loss_scale=8192, train_wall=127, wall=338721
2023-01-16 13:52:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 13:54:57 | INFO | train_inner | epoch 131:   1113 / 1978 loss=2.983, nll_loss=0.856, word_ins=2.684, length=2.988, ppl=7.9, wps=45870.9, ups=0.77, wpb=59502.9, bsz=2040.1, num_updates=258200, lr=0.000196799, gnorm=1.247, loss_scale=8192, train_wall=129, wall=338851
2023-01-16 13:57:04 | INFO | train_inner | epoch 131:   1213 / 1978 loss=3.009, nll_loss=0.886, word_ins=2.711, length=2.98, ppl=8.05, wps=46292.3, ups=0.79, wpb=58685.7, bsz=1929.3, num_updates=258300, lr=0.00019676, gnorm=1.272, loss_scale=8192, train_wall=127, wall=338978
2023-01-16 13:59:12 | INFO | train_inner | epoch 131:   1313 / 1978 loss=2.991, nll_loss=0.868, word_ins=2.694, length=2.962, ppl=7.95, wps=46277.4, ups=0.78, wpb=59180.3, bsz=1999.2, num_updates=258400, lr=0.000196722, gnorm=1.287, loss_scale=8192, train_wall=128, wall=339106
2023-01-16 14:01:19 | INFO | train_inner | epoch 131:   1413 / 1978 loss=2.977, nll_loss=0.851, word_ins=2.679, length=2.984, ppl=7.87, wps=46531.1, ups=0.78, wpb=59328.5, bsz=2055, num_updates=258500, lr=0.000196684, gnorm=1.303, loss_scale=8192, train_wall=127, wall=339233
2023-01-16 14:03:29 | INFO | train_inner | epoch 131:   1513 / 1978 loss=2.98, nll_loss=0.859, word_ins=2.687, length=2.931, ppl=7.89, wps=46372.4, ups=0.77, wpb=60029.7, bsz=2036.7, num_updates=258600, lr=0.000196646, gnorm=1.266, loss_scale=8192, train_wall=129, wall=339363
2023-01-16 14:05:35 | INFO | train_inner | epoch 131:   1613 / 1978 loss=3.016, nll_loss=0.884, word_ins=2.709, length=3.066, ppl=8.09, wps=46537.6, ups=0.79, wpb=58638.7, bsz=1870.5, num_updates=258700, lr=0.000196608, gnorm=1.325, loss_scale=8192, train_wall=126, wall=339489
2023-01-16 14:07:42 | INFO | train_inner | epoch 131:   1713 / 1978 loss=2.971, nll_loss=0.845, word_ins=2.673, length=2.977, ppl=7.84, wps=46587.3, ups=0.78, wpb=59371.1, bsz=2015, num_updates=258800, lr=0.00019657, gnorm=1.241, loss_scale=8192, train_wall=127, wall=339616
2023-01-16 14:09:49 | INFO | train_inner | epoch 131:   1813 / 1978 loss=2.985, nll_loss=0.86, word_ins=2.687, length=2.979, ppl=7.92, wps=46510.5, ups=0.79, wpb=59189, bsz=1971, num_updates=258900, lr=0.000196532, gnorm=1.276, loss_scale=8192, train_wall=127, wall=339743
2023-01-16 14:11:58 | INFO | train_inner | epoch 131:   1913 / 1978 loss=2.977, nll_loss=0.848, word_ins=2.676, length=3.01, ppl=7.87, wps=46263.3, ups=0.78, wpb=59513.5, bsz=1951.7, num_updates=259000, lr=0.000196494, gnorm=1.338, loss_scale=8192, train_wall=128, wall=339872
2023-01-16 14:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 14:13:34 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 4.611 | nll_loss 1.983 | word_ins 3.742 | length 8.694 | ppl 24.44 | wps 79631 | wpb 40242.5 | bsz 1500 | num_updates 259065 | best_loss 4.422
2023-01-16 14:13:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 14:14:03 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint131.pt (epoch 131 @ 259065 updates, score 4.611) (writing took 28.42920308932662 seconds)
2023-01-16 14:14:03 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2023-01-16 14:14:03 | INFO | train | epoch 131 | loss 2.981 | nll_loss 0.857 | word_ins 2.685 | length 2.966 | ppl 7.9 | wps 45393.7 | ups 0.77 | wpb 59282.8 | bsz 2002.5 | num_updates 259065 | lr 0.00019647 | gnorm 1.283 | loss_scale 8192 | train_wall 2525 | wall 339997
2023-01-16 14:14:03 | INFO | fairseq.trainer | begin training epoch 132
2023-01-16 14:15:00 | INFO | train_inner | epoch 132:     35 / 1978 loss=2.99, nll_loss=0.869, word_ins=2.695, length=2.948, ppl=7.94, wps=32766.1, ups=0.55, wpb=59502.4, bsz=1986.8, num_updates=259100, lr=0.000196456, gnorm=1.324, loss_scale=8192, train_wall=129, wall=340054
2023-01-16 14:17:07 | INFO | train_inner | epoch 132:    135 / 1978 loss=2.982, nll_loss=0.862, word_ins=2.69, length=2.926, ppl=7.9, wps=45972.5, ups=0.78, wpb=58783.6, bsz=2033.6, num_updates=259200, lr=0.000196419, gnorm=1.295, loss_scale=8192, train_wall=128, wall=340182
2023-01-16 14:19:15 | INFO | train_inner | epoch 132:    235 / 1978 loss=2.981, nll_loss=0.858, word_ins=2.686, length=2.956, ppl=7.9, wps=46035.2, ups=0.78, wpb=58678.2, bsz=1982, num_updates=259300, lr=0.000196381, gnorm=1.265, loss_scale=8192, train_wall=127, wall=340309
2023-01-16 14:21:23 | INFO | train_inner | epoch 132:    335 / 1978 loss=2.988, nll_loss=0.864, word_ins=2.692, length=2.968, ppl=7.94, wps=46671.5, ups=0.78, wpb=59650.7, bsz=1957.4, num_updates=259400, lr=0.000196343, gnorm=1.324, loss_scale=8192, train_wall=128, wall=340437
2023-01-16 14:23:32 | INFO | train_inner | epoch 132:    435 / 1978 loss=2.942, nll_loss=0.822, word_ins=2.653, length=2.882, ppl=7.68, wps=46005, ups=0.77, wpb=59496, bsz=2112.8, num_updates=259500, lr=0.000196305, gnorm=1.237, loss_scale=8192, train_wall=129, wall=340566
2023-01-16 14:25:41 | INFO | train_inner | epoch 132:    535 / 1978 loss=2.982, nll_loss=0.859, word_ins=2.687, length=2.949, ppl=7.9, wps=46104.5, ups=0.78, wpb=59467.9, bsz=2045, num_updates=259600, lr=0.000196267, gnorm=1.299, loss_scale=8192, train_wall=129, wall=340695
2023-01-16 14:27:49 | INFO | train_inner | epoch 132:    635 / 1978 loss=2.98, nll_loss=0.853, word_ins=2.681, length=2.988, ppl=7.89, wps=46379.3, ups=0.78, wpb=59216.4, bsz=1975, num_updates=259700, lr=0.000196229, gnorm=1.275, loss_scale=8192, train_wall=127, wall=340823
2023-01-16 14:29:58 | INFO | train_inner | epoch 132:    735 / 1978 loss=2.969, nll_loss=0.843, word_ins=2.673, length=2.961, ppl=7.83, wps=45527.8, ups=0.77, wpb=58837.5, bsz=2046.8, num_updates=259800, lr=0.000196192, gnorm=1.333, loss_scale=8192, train_wall=129, wall=340952
2023-01-16 14:32:07 | INFO | train_inner | epoch 132:    835 / 1978 loss=2.97, nll_loss=0.852, word_ins=2.68, length=2.897, ppl=7.84, wps=46015.7, ups=0.77, wpb=59396.6, bsz=2049.8, num_updates=259900, lr=0.000196154, gnorm=1.26, loss_scale=8192, train_wall=129, wall=341081
2023-01-16 14:34:14 | INFO | train_inner | epoch 132:    935 / 1978 loss=2.981, nll_loss=0.854, word_ins=2.682, length=2.989, ppl=7.89, wps=46570.9, ups=0.79, wpb=59324.8, bsz=1947, num_updates=260000, lr=0.000196116, gnorm=1.269, loss_scale=8192, train_wall=127, wall=341209
2023-01-16 14:36:22 | INFO | train_inner | epoch 132:   1035 / 1978 loss=2.981, nll_loss=0.849, word_ins=2.678, length=3.031, ppl=7.89, wps=46559.6, ups=0.78, wpb=59588, bsz=1986.4, num_updates=260100, lr=0.000196078, gnorm=1.286, loss_scale=8192, train_wall=128, wall=341337
2023-01-16 14:38:30 | INFO | train_inner | epoch 132:   1135 / 1978 loss=2.99, nll_loss=0.863, word_ins=2.69, length=3, ppl=7.95, wps=46163, ups=0.78, wpb=58869.4, bsz=1947.5, num_updates=260200, lr=0.000196041, gnorm=1.263, loss_scale=8192, train_wall=127, wall=341464
2023-01-16 14:40:39 | INFO | train_inner | epoch 132:   1235 / 1978 loss=2.977, nll_loss=0.857, word_ins=2.684, length=2.925, ppl=7.87, wps=46135.7, ups=0.77, wpb=59618.6, bsz=2082.1, num_updates=260300, lr=0.000196003, gnorm=1.26, loss_scale=8192, train_wall=129, wall=341593
2023-01-16 14:42:49 | INFO | train_inner | epoch 132:   1335 / 1978 loss=2.989, nll_loss=0.865, word_ins=2.693, length=2.966, ppl=7.94, wps=45366.8, ups=0.77, wpb=58882.1, bsz=1992.6, num_updates=260400, lr=0.000195965, gnorm=1.253, loss_scale=8192, train_wall=129, wall=341723
2023-01-16 14:44:58 | INFO | train_inner | epoch 132:   1435 / 1978 loss=3.008, nll_loss=0.882, word_ins=2.708, length=3, ppl=8.04, wps=46064.7, ups=0.77, wpb=59514.6, bsz=1870.9, num_updates=260500, lr=0.000195928, gnorm=1.355, loss_scale=8192, train_wall=129, wall=341852
2023-01-16 14:47:08 | INFO | train_inner | epoch 132:   1535 / 1978 loss=2.992, nll_loss=0.864, word_ins=2.691, length=3.011, ppl=7.96, wps=45756, ups=0.77, wpb=59241.1, bsz=1959.9, num_updates=260600, lr=0.00019589, gnorm=1.269, loss_scale=8192, train_wall=129, wall=341982
2023-01-16 14:49:19 | INFO | train_inner | epoch 132:   1635 / 1978 loss=2.962, nll_loss=0.837, word_ins=2.666, length=2.956, ppl=7.79, wps=45571.4, ups=0.76, wpb=59680.5, bsz=2060.4, num_updates=260700, lr=0.000195853, gnorm=1.286, loss_scale=8192, train_wall=131, wall=342113
2023-01-16 14:51:28 | INFO | train_inner | epoch 132:   1735 / 1978 loss=2.991, nll_loss=0.865, word_ins=2.693, length=2.988, ppl=7.95, wps=45908.6, ups=0.77, wpb=59305.2, bsz=1936, num_updates=260800, lr=0.000195815, gnorm=1.297, loss_scale=8192, train_wall=129, wall=342242
2023-01-16 14:53:37 | INFO | train_inner | epoch 132:   1835 / 1978 loss=2.979, nll_loss=0.854, word_ins=2.682, length=2.977, ppl=7.89, wps=46373, ups=0.78, wpb=59822.7, bsz=1997.6, num_updates=260900, lr=0.000195778, gnorm=1.26, loss_scale=8192, train_wall=129, wall=342371
2023-01-16 14:55:45 | INFO | train_inner | epoch 132:   1935 / 1978 loss=2.964, nll_loss=0.84, word_ins=2.669, length=2.943, ppl=7.8, wps=46443.5, ups=0.78, wpb=59398.3, bsz=2066.4, num_updates=261000, lr=0.00019574, gnorm=1.253, loss_scale=8192, train_wall=128, wall=342499
2023-01-16 14:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 14:56:55 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 4.493 | nll_loss 1.953 | word_ins 3.718 | length 7.747 | ppl 22.51 | wps 113638 | wpb 40242.5 | bsz 1500 | num_updates 261043 | best_loss 4.422
2023-01-16 14:56:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 14:57:22 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint132.pt (epoch 132 @ 261043 updates, score 4.493) (writing took 26.761159948073328 seconds)
2023-01-16 14:57:22 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2023-01-16 14:57:22 | INFO | train | epoch 132 | loss 2.98 | nll_loss 0.856 | word_ins 2.684 | length 2.961 | ppl 7.89 | wps 45116.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 261043 | lr 0.000195724 | gnorm 1.281 | loss_scale 8192 | train_wall 2539 | wall 342596
2023-01-16 14:57:22 | INFO | fairseq.trainer | begin training epoch 133
2023-01-16 14:58:48 | INFO | train_inner | epoch 133:     57 / 1978 loss=2.975, nll_loss=0.86, word_ins=2.687, length=2.878, ppl=7.86, wps=32134.8, ups=0.55, wpb=58810.7, bsz=2041.9, num_updates=261100, lr=0.000195703, gnorm=1.31, loss_scale=8192, train_wall=129, wall=342682
2023-01-16 15:00:56 | INFO | train_inner | epoch 133:    157 / 1978 loss=2.977, nll_loss=0.852, word_ins=2.682, length=2.953, ppl=7.87, wps=45945, ups=0.78, wpb=58890.8, bsz=2013.4, num_updates=261200, lr=0.000195665, gnorm=1.297, loss_scale=8192, train_wall=128, wall=342810
2023-01-16 15:03:06 | INFO | train_inner | epoch 133:    257 / 1978 loss=2.978, nll_loss=0.852, word_ins=2.68, length=2.986, ppl=7.88, wps=45451.3, ups=0.77, wpb=59007.9, bsz=1983.5, num_updates=261300, lr=0.000195628, gnorm=1.294, loss_scale=8192, train_wall=129, wall=342940
2023-01-16 15:05:15 | INFO | train_inner | epoch 133:    357 / 1978 loss=2.984, nll_loss=0.858, word_ins=2.685, length=2.989, ppl=7.91, wps=46547.2, ups=0.78, wpb=60023.1, bsz=1933.4, num_updates=261400, lr=0.00019559, gnorm=1.315, loss_scale=8192, train_wall=129, wall=343069
2023-01-16 15:07:26 | INFO | train_inner | epoch 133:    457 / 1978 loss=2.963, nll_loss=0.843, word_ins=2.671, length=2.918, ppl=7.8, wps=45567.7, ups=0.76, wpb=59706.1, bsz=2082.6, num_updates=261500, lr=0.000195553, gnorm=1.247, loss_scale=8192, train_wall=131, wall=343200
2023-01-16 15:09:38 | INFO | train_inner | epoch 133:    557 / 1978 loss=2.96, nll_loss=0.841, word_ins=2.67, length=2.895, ppl=7.78, wps=44331.7, ups=0.76, wpb=58559.3, bsz=2132.2, num_updates=261600, lr=0.000195515, gnorm=1.245, loss_scale=8192, train_wall=132, wall=343332
2023-01-16 15:11:47 | INFO | train_inner | epoch 133:    657 / 1978 loss=2.986, nll_loss=0.864, word_ins=2.691, length=2.953, ppl=7.92, wps=46210.2, ups=0.77, wpb=59777.5, bsz=1992.5, num_updates=261700, lr=0.000195478, gnorm=1.308, loss_scale=8192, train_wall=129, wall=343461
2023-01-16 15:13:55 | INFO | train_inner | epoch 133:    757 / 1978 loss=2.978, nll_loss=0.85, word_ins=2.678, length=2.997, ppl=7.88, wps=46387.8, ups=0.78, wpb=59261.5, bsz=2021.7, num_updates=261800, lr=0.000195441, gnorm=1.293, loss_scale=8192, train_wall=128, wall=343589
2023-01-16 15:16:04 | INFO | train_inner | epoch 133:    857 / 1978 loss=2.979, nll_loss=0.856, word_ins=2.684, length=2.953, ppl=7.89, wps=46098.7, ups=0.78, wpb=59268, bsz=2010.4, num_updates=261900, lr=0.000195403, gnorm=1.33, loss_scale=8192, train_wall=128, wall=343718
2023-01-16 15:18:10 | INFO | train_inner | epoch 133:    957 / 1978 loss=3.014, nll_loss=0.883, word_ins=2.709, length=3.05, ppl=8.08, wps=46219.1, ups=0.79, wpb=58611.8, bsz=1884.5, num_updates=262000, lr=0.000195366, gnorm=1.332, loss_scale=8192, train_wall=127, wall=343844
2023-01-16 15:20:20 | INFO | train_inner | epoch 133:   1057 / 1978 loss=2.979, nll_loss=0.855, word_ins=2.682, length=2.964, ppl=7.88, wps=45802, ups=0.77, wpb=59460, bsz=1992.4, num_updates=262100, lr=0.000195329, gnorm=1.249, loss_scale=8192, train_wall=129, wall=343974
2023-01-16 15:22:31 | INFO | train_inner | epoch 133:   1157 / 1978 loss=2.985, nll_loss=0.859, word_ins=2.686, length=2.993, ppl=7.92, wps=45564.9, ups=0.77, wpb=59392.6, bsz=1951.1, num_updates=262200, lr=0.000195292, gnorm=1.262, loss_scale=16384, train_wall=130, wall=344105
2023-01-16 15:22:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 15:24:42 | INFO | train_inner | epoch 133:   1258 / 1978 loss=2.974, nll_loss=0.856, word_ins=2.684, length=2.902, ppl=7.86, wps=44998.8, ups=0.76, wpb=59232.2, bsz=2014.3, num_updates=262300, lr=0.000195254, gnorm=1.258, loss_scale=8192, train_wall=131, wall=344236
2023-01-16 15:26:52 | INFO | train_inner | epoch 133:   1358 / 1978 loss=2.961, nll_loss=0.837, word_ins=2.667, length=2.947, ppl=7.79, wps=45013.4, ups=0.77, wpb=58498.2, bsz=2046.3, num_updates=262400, lr=0.000195217, gnorm=1.254, loss_scale=8192, train_wall=130, wall=344366
2023-01-16 15:29:02 | INFO | train_inner | epoch 133:   1458 / 1978 loss=2.98, nll_loss=0.859, word_ins=2.686, length=2.933, ppl=7.89, wps=45842.6, ups=0.77, wpb=59521.9, bsz=1998.3, num_updates=262500, lr=0.00019518, gnorm=1.355, loss_scale=8192, train_wall=129, wall=344496
2023-01-16 15:31:10 | INFO | train_inner | epoch 133:   1558 / 1978 loss=2.995, nll_loss=0.869, word_ins=2.695, length=2.995, ppl=7.97, wps=46353.5, ups=0.78, wpb=59271.7, bsz=1968.4, num_updates=262600, lr=0.000195143, gnorm=1.29, loss_scale=8192, train_wall=128, wall=344624
2023-01-16 15:33:19 | INFO | train_inner | epoch 133:   1658 / 1978 loss=2.979, nll_loss=0.854, word_ins=2.682, length=2.974, ppl=7.89, wps=46144.8, ups=0.78, wpb=59538.7, bsz=2010.9, num_updates=262700, lr=0.000195106, gnorm=1.266, loss_scale=8192, train_wall=129, wall=344753
2023-01-16 15:35:28 | INFO | train_inner | epoch 133:   1758 / 1978 loss=2.96, nll_loss=0.838, word_ins=2.667, length=2.932, ppl=7.78, wps=46458.8, ups=0.78, wpb=59769.4, bsz=2059.2, num_updates=262800, lr=0.000195069, gnorm=1.255, loss_scale=8192, train_wall=128, wall=344882
2023-01-16 15:37:37 | INFO | train_inner | epoch 133:   1858 / 1978 loss=2.976, nll_loss=0.851, word_ins=2.679, length=2.969, ppl=7.87, wps=45629, ups=0.77, wpb=59205.4, bsz=1983.4, num_updates=262900, lr=0.000195031, gnorm=1.255, loss_scale=8192, train_wall=129, wall=345011
2023-01-16 15:39:48 | INFO | train_inner | epoch 133:   1958 / 1978 loss=2.987, nll_loss=0.862, word_ins=2.689, length=2.974, ppl=7.93, wps=45651.1, ups=0.77, wpb=59521.1, bsz=1990.4, num_updates=263000, lr=0.000194994, gnorm=1.254, loss_scale=8192, train_wall=130, wall=345142
2023-01-16 15:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 15:40:31 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 4.621 | nll_loss 1.957 | word_ins 3.72 | length 9.009 | ppl 24.6 | wps 91082.1 | wpb 40242.5 | bsz 1500 | num_updates 263020 | best_loss 4.422
2023-01-16 15:40:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 15:41:00 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint133.pt (epoch 133 @ 263020 updates, score 4.621) (writing took 28.95971307111904 seconds)
2023-01-16 15:41:00 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2023-01-16 15:41:00 | INFO | train | epoch 133 | loss 2.978 | nll_loss 0.854 | word_ins 2.682 | length 2.96 | ppl 7.88 | wps 44765.6 | ups 0.76 | wpb 59285.3 | bsz 2003.1 | num_updates 263020 | lr 0.000194987 | gnorm 1.284 | loss_scale 8192 | train_wall 2553 | wall 345214
2023-01-16 15:41:00 | INFO | fairseq.trainer | begin training epoch 134
2023-01-16 15:42:58 | INFO | train_inner | epoch 134:     80 / 1978 loss=2.959, nll_loss=0.84, word_ins=2.669, length=2.892, ppl=7.77, wps=31074.5, ups=0.53, wpb=59010.9, bsz=2033.1, num_updates=263100, lr=0.000194957, gnorm=1.261, loss_scale=8192, train_wall=130, wall=345332
2023-01-16 15:45:08 | INFO | train_inner | epoch 134:    180 / 1978 loss=2.96, nll_loss=0.837, word_ins=2.667, length=2.922, ppl=7.78, wps=45159.1, ups=0.77, wpb=59006.8, bsz=2044.1, num_updates=263200, lr=0.00019492, gnorm=1.28, loss_scale=8192, train_wall=130, wall=345462
2023-01-16 15:47:16 | INFO | train_inner | epoch 134:    280 / 1978 loss=2.981, nll_loss=0.86, word_ins=2.687, length=2.934, ppl=7.89, wps=46117.4, ups=0.78, wpb=58917.6, bsz=1974.5, num_updates=263300, lr=0.000194883, gnorm=1.278, loss_scale=8192, train_wall=128, wall=345590
2023-01-16 15:49:24 | INFO | train_inner | epoch 134:    380 / 1978 loss=2.966, nll_loss=0.84, word_ins=2.669, length=2.978, ppl=7.82, wps=46277.9, ups=0.78, wpb=59260, bsz=2000.2, num_updates=263400, lr=0.000194846, gnorm=1.29, loss_scale=8192, train_wall=128, wall=345718
2023-01-16 15:51:33 | INFO | train_inner | epoch 134:    480 / 1978 loss=2.964, nll_loss=0.849, word_ins=2.677, length=2.869, ppl=7.8, wps=46203.8, ups=0.77, wpb=59742.6, bsz=2107.8, num_updates=263500, lr=0.000194809, gnorm=1.21, loss_scale=8192, train_wall=129, wall=345848
2023-01-16 15:53:44 | INFO | train_inner | epoch 134:    580 / 1978 loss=2.976, nll_loss=0.85, word_ins=2.678, length=2.982, ppl=7.87, wps=45227.1, ups=0.77, wpb=59009.8, bsz=2014.2, num_updates=263600, lr=0.000194772, gnorm=1.233, loss_scale=8192, train_wall=130, wall=345978
2023-01-16 15:55:54 | INFO | train_inner | epoch 134:    680 / 1978 loss=2.961, nll_loss=0.836, word_ins=2.665, length=2.954, ppl=7.79, wps=45767.3, ups=0.77, wpb=59553.9, bsz=2029.9, num_updates=263700, lr=0.000194735, gnorm=1.279, loss_scale=8192, train_wall=130, wall=346108
2023-01-16 15:58:04 | INFO | train_inner | epoch 134:    780 / 1978 loss=2.982, nll_loss=0.86, word_ins=2.688, length=2.945, ppl=7.9, wps=46119.2, ups=0.77, wpb=59864.2, bsz=1943.2, num_updates=263800, lr=0.000194698, gnorm=1.32, loss_scale=8192, train_wall=129, wall=346238
2023-01-16 16:00:15 | INFO | train_inner | epoch 134:    880 / 1978 loss=2.98, nll_loss=0.857, word_ins=2.685, length=2.956, ppl=7.89, wps=45579.3, ups=0.76, wpb=59681, bsz=2041.6, num_updates=263900, lr=0.000194662, gnorm=1.303, loss_scale=8192, train_wall=131, wall=346369
2023-01-16 16:02:25 | INFO | train_inner | epoch 134:    980 / 1978 loss=2.974, nll_loss=0.848, word_ins=2.676, length=2.978, ppl=7.86, wps=46039.6, ups=0.77, wpb=59902, bsz=2000.6, num_updates=264000, lr=0.000194625, gnorm=1.307, loss_scale=8192, train_wall=130, wall=346499
2023-01-16 16:04:33 | INFO | train_inner | epoch 134:   1080 / 1978 loss=2.97, nll_loss=0.847, word_ins=2.675, length=2.948, ppl=7.84, wps=46248.1, ups=0.78, wpb=59316.2, bsz=2048.7, num_updates=264100, lr=0.000194588, gnorm=1.236, loss_scale=8192, train_wall=128, wall=346627
2023-01-16 16:06:41 | INFO | train_inner | epoch 134:   1180 / 1978 loss=2.983, nll_loss=0.859, word_ins=2.687, length=2.966, ppl=7.91, wps=46073.2, ups=0.78, wpb=58801, bsz=1956.8, num_updates=264200, lr=0.000194551, gnorm=1.302, loss_scale=8192, train_wall=127, wall=346755
2023-01-16 16:08:49 | INFO | train_inner | epoch 134:   1280 / 1978 loss=2.983, nll_loss=0.861, word_ins=2.688, length=2.945, ppl=7.9, wps=46068, ups=0.78, wpb=58897.3, bsz=2015.2, num_updates=264300, lr=0.000194514, gnorm=1.261, loss_scale=8192, train_wall=128, wall=346883
2023-01-16 16:10:59 | INFO | train_inner | epoch 134:   1380 / 1978 loss=2.958, nll_loss=0.838, word_ins=2.667, length=2.911, ppl=7.77, wps=45929.2, ups=0.77, wpb=59891.9, bsz=2045.1, num_updates=264400, lr=0.000194477, gnorm=1.299, loss_scale=8192, train_wall=130, wall=347013
2023-01-16 16:13:08 | INFO | train_inner | epoch 134:   1480 / 1978 loss=3.016, nll_loss=0.885, word_ins=2.71, length=3.053, ppl=8.09, wps=45698.5, ups=0.77, wpb=58980.1, bsz=1868.7, num_updates=264500, lr=0.000194441, gnorm=1.306, loss_scale=8192, train_wall=129, wall=347142
2023-01-16 16:15:17 | INFO | train_inner | epoch 134:   1580 / 1978 loss=3.007, nll_loss=0.881, word_ins=2.706, length=3.013, ppl=8.04, wps=45486.9, ups=0.77, wpb=58805.1, bsz=1914.2, num_updates=264600, lr=0.000194404, gnorm=1.331, loss_scale=8192, train_wall=129, wall=347272
2023-01-16 16:17:28 | INFO | train_inner | epoch 134:   1680 / 1978 loss=2.992, nll_loss=0.866, word_ins=2.692, length=2.994, ppl=7.95, wps=45219.1, ups=0.77, wpb=58962.8, bsz=1971.1, num_updates=264700, lr=0.000194367, gnorm=1.297, loss_scale=8192, train_wall=130, wall=347402
2023-01-16 16:19:38 | INFO | train_inner | epoch 134:   1780 / 1978 loss=2.978, nll_loss=0.858, word_ins=2.685, length=2.933, ppl=7.88, wps=45548.6, ups=0.77, wpb=59201.6, bsz=2044.7, num_updates=264800, lr=0.000194331, gnorm=1.282, loss_scale=8192, train_wall=130, wall=347532
2023-01-16 16:21:45 | INFO | train_inner | epoch 134:   1880 / 1978 loss=2.978, nll_loss=0.852, word_ins=2.68, length=2.985, ppl=7.88, wps=46723, ups=0.79, wpb=59475.2, bsz=1993.7, num_updates=264900, lr=0.000194294, gnorm=1.291, loss_scale=8192, train_wall=127, wall=347659
2023-01-16 16:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 16:24:05 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 4.569 | nll_loss 1.948 | word_ins 3.712 | length 8.568 | ppl 23.73 | wps 112170 | wpb 40242.5 | bsz 1500 | num_updates 264998 | best_loss 4.422
2023-01-16 16:24:05 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 16:24:32 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint134.pt (epoch 134 @ 264998 updates, score 4.569) (writing took 27.427897976711392 seconds)
2023-01-16 16:24:32 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2023-01-16 16:24:32 | INFO | train | epoch 134 | loss 2.977 | nll_loss 0.854 | word_ins 2.681 | length 2.956 | ppl 7.87 | wps 44895.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 264998 | lr 0.000194258 | gnorm 1.283 | loss_scale 8192 | train_wall 2551 | wall 347826
2023-01-16 16:24:32 | INFO | fairseq.trainer | begin training epoch 135
2023-01-16 16:24:47 | INFO | train_inner | epoch 135:      2 / 1978 loss=2.973, nll_loss=0.848, word_ins=2.676, length=2.968, ppl=7.85, wps=32738.8, ups=0.55, wpb=59386.8, bsz=1980.2, num_updates=265000, lr=0.000194257, gnorm=1.308, loss_scale=8192, train_wall=128, wall=347841
2023-01-16 16:26:54 | INFO | train_inner | epoch 135:    102 / 1978 loss=2.98, nll_loss=0.859, word_ins=2.687, length=2.928, ppl=7.89, wps=46464, ups=0.78, wpb=59395.1, bsz=1951.8, num_updates=265100, lr=0.000194221, gnorm=1.327, loss_scale=8192, train_wall=128, wall=347968
2023-01-16 16:29:06 | INFO | train_inner | epoch 135:    202 / 1978 loss=2.956, nll_loss=0.834, word_ins=2.663, length=2.93, ppl=7.76, wps=45142.6, ups=0.76, wpb=59338.8, bsz=2026.6, num_updates=265200, lr=0.000194184, gnorm=1.347, loss_scale=8192, train_wall=131, wall=348100
2023-01-16 16:31:16 | INFO | train_inner | epoch 135:    302 / 1978 loss=2.962, nll_loss=0.841, word_ins=2.67, length=2.919, ppl=7.79, wps=45764.5, ups=0.77, wpb=59391.2, bsz=2006.6, num_updates=265300, lr=0.000194147, gnorm=1.346, loss_scale=8192, train_wall=129, wall=348230
2023-01-16 16:33:27 | INFO | train_inner | epoch 135:    402 / 1978 loss=2.962, nll_loss=0.84, word_ins=2.669, length=2.929, ppl=7.79, wps=45674.5, ups=0.76, wpb=59834.6, bsz=2043.6, num_updates=265400, lr=0.000194111, gnorm=1.284, loss_scale=8192, train_wall=131, wall=348361
2023-01-16 16:35:37 | INFO | train_inner | epoch 135:    502 / 1978 loss=2.987, nll_loss=0.864, word_ins=2.691, length=2.965, ppl=7.93, wps=45437.1, ups=0.77, wpb=59076.8, bsz=1983, num_updates=265500, lr=0.000194074, gnorm=1.291, loss_scale=8192, train_wall=130, wall=348491
2023-01-16 16:37:45 | INFO | train_inner | epoch 135:    602 / 1978 loss=3, nll_loss=0.876, word_ins=2.702, length=2.983, ppl=8, wps=46017.4, ups=0.78, wpb=59235.6, bsz=1946, num_updates=265600, lr=0.000194038, gnorm=1.273, loss_scale=8192, train_wall=128, wall=348619
2023-01-16 16:39:52 | INFO | train_inner | epoch 135:    702 / 1978 loss=2.983, nll_loss=0.861, word_ins=2.688, length=2.947, ppl=7.91, wps=46414.5, ups=0.79, wpb=58876, bsz=1969, num_updates=265700, lr=0.000194001, gnorm=1.231, loss_scale=8192, train_wall=127, wall=348746
2023-01-16 16:42:00 | INFO | train_inner | epoch 135:    802 / 1978 loss=2.986, nll_loss=0.861, word_ins=2.688, length=2.985, ppl=7.92, wps=46366.7, ups=0.78, wpb=59344.7, bsz=1980, num_updates=265800, lr=0.000193965, gnorm=1.278, loss_scale=8192, train_wall=128, wall=348874
2023-01-16 16:44:09 | INFO | train_inner | epoch 135:    902 / 1978 loss=2.981, nll_loss=0.86, word_ins=2.687, length=2.937, ppl=7.89, wps=45741.6, ups=0.77, wpb=59029.4, bsz=2011, num_updates=265900, lr=0.000193928, gnorm=1.267, loss_scale=8192, train_wall=129, wall=349003
2023-01-16 16:46:21 | INFO | train_inner | epoch 135:   1002 / 1978 loss=2.971, nll_loss=0.847, word_ins=2.675, length=2.956, ppl=7.84, wps=45317.5, ups=0.76, wpb=59599.4, bsz=2044, num_updates=266000, lr=0.000193892, gnorm=1.285, loss_scale=8192, train_wall=131, wall=349135
2023-01-16 16:48:31 | INFO | train_inner | epoch 135:   1102 / 1978 loss=2.978, nll_loss=0.85, word_ins=2.678, length=3.01, ppl=7.88, wps=45893.8, ups=0.77, wpb=59742.5, bsz=1983.7, num_updates=266100, lr=0.000193855, gnorm=1.318, loss_scale=8192, train_wall=130, wall=349265
2023-01-16 16:50:41 | INFO | train_inner | epoch 135:   1202 / 1978 loss=2.988, nll_loss=0.858, word_ins=2.685, length=3.025, ppl=7.93, wps=45398.9, ups=0.77, wpb=59090.6, bsz=1949.6, num_updates=266200, lr=0.000193819, gnorm=1.308, loss_scale=8192, train_wall=130, wall=349395
2023-01-16 16:52:51 | INFO | train_inner | epoch 135:   1302 / 1978 loss=2.963, nll_loss=0.838, word_ins=2.667, length=2.959, ppl=7.8, wps=45741.4, ups=0.77, wpb=59562.8, bsz=1967.6, num_updates=266300, lr=0.000193782, gnorm=1.322, loss_scale=8192, train_wall=130, wall=349525
2023-01-16 16:53:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 16:55:03 | INFO | train_inner | epoch 135:   1403 / 1978 loss=2.953, nll_loss=0.835, word_ins=2.665, length=2.879, ppl=7.74, wps=45150.1, ups=0.76, wpb=59618, bsz=2156.1, num_updates=266400, lr=0.000193746, gnorm=1.253, loss_scale=8192, train_wall=132, wall=349657
2023-01-16 16:57:10 | INFO | train_inner | epoch 135:   1503 / 1978 loss=2.991, nll_loss=0.864, word_ins=2.691, length=3.005, ppl=7.95, wps=46390.6, ups=0.79, wpb=58955.5, bsz=1975.1, num_updates=266500, lr=0.00019371, gnorm=1.3, loss_scale=8192, train_wall=127, wall=349785
2023-01-16 16:59:19 | INFO | train_inner | epoch 135:   1603 / 1978 loss=2.973, nll_loss=0.854, word_ins=2.682, length=2.907, ppl=7.85, wps=46309.7, ups=0.78, wpb=59451.6, bsz=1975.8, num_updates=266600, lr=0.000193673, gnorm=1.259, loss_scale=8192, train_wall=128, wall=349913
2023-01-16 17:01:29 | INFO | train_inner | epoch 135:   1703 / 1978 loss=2.965, nll_loss=0.84, word_ins=2.669, length=2.964, ppl=7.81, wps=45427.8, ups=0.77, wpb=59112.1, bsz=2059.6, num_updates=266700, lr=0.000193637, gnorm=1.244, loss_scale=8192, train_wall=130, wall=350043
2023-01-16 17:03:39 | INFO | train_inner | epoch 135:   1803 / 1978 loss=2.984, nll_loss=0.861, word_ins=2.688, length=2.958, ppl=7.91, wps=45487.1, ups=0.77, wpb=58951.9, bsz=1998.2, num_updates=266800, lr=0.000193601, gnorm=1.222, loss_scale=8192, train_wall=129, wall=350173
2023-01-16 17:05:50 | INFO | train_inner | epoch 135:   1903 / 1978 loss=2.968, nll_loss=0.842, word_ins=2.671, length=2.97, ppl=7.82, wps=44853.2, ups=0.76, wpb=59003.7, bsz=2110.2, num_updates=266900, lr=0.000193565, gnorm=1.301, loss_scale=8192, train_wall=131, wall=350304
2023-01-16 17:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 17:07:44 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 4.655 | nll_loss 1.976 | word_ins 3.737 | length 9.175 | ppl 25.19 | wps 81735.9 | wpb 40242.5 | bsz 1500 | num_updates 266975 | best_loss 4.422
2023-01-16 17:07:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 17:08:13 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint135.pt (epoch 135 @ 266975 updates, score 4.655) (writing took 29.16046918183565 seconds)
2023-01-16 17:08:13 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2023-01-16 17:08:13 | INFO | train | epoch 135 | loss 2.977 | nll_loss 0.853 | word_ins 2.681 | length 2.958 | ppl 7.87 | wps 44721.8 | ups 0.75 | wpb 59284.7 | bsz 2002.7 | num_updates 266975 | lr 0.000193537 | gnorm 1.287 | loss_scale 8192 | train_wall 2557 | wall 350447
2023-01-16 17:08:13 | INFO | fairseq.trainer | begin training epoch 136
2023-01-16 17:08:59 | INFO | train_inner | epoch 136:     25 / 1978 loss=3.02, nll_loss=0.892, word_ins=2.717, length=3.03, ppl=8.11, wps=31123.3, ups=0.53, wpb=58882.2, bsz=1876.3, num_updates=267000, lr=0.000193528, gnorm=1.307, loss_scale=8192, train_wall=129, wall=350493
2023-01-16 17:11:11 | INFO | train_inner | epoch 136:    125 / 1978 loss=2.969, nll_loss=0.853, word_ins=2.681, length=2.879, ppl=7.83, wps=45286.1, ups=0.76, wpb=59400.6, bsz=2031.8, num_updates=267100, lr=0.000193492, gnorm=1.247, loss_scale=8192, train_wall=131, wall=350625
2023-01-16 17:13:18 | INFO | train_inner | epoch 136:    225 / 1978 loss=2.962, nll_loss=0.838, word_ins=2.667, length=2.953, ppl=7.79, wps=46870, ups=0.79, wpb=59685.2, bsz=1937.2, num_updates=267200, lr=0.000193456, gnorm=1.274, loss_scale=8192, train_wall=127, wall=350752
2023-01-16 17:15:26 | INFO | train_inner | epoch 136:    325 / 1978 loss=2.966, nll_loss=0.839, word_ins=2.668, length=2.972, ppl=7.81, wps=46197.8, ups=0.78, wpb=59310.1, bsz=1984.6, num_updates=267300, lr=0.00019342, gnorm=1.329, loss_scale=8192, train_wall=128, wall=350880
2023-01-16 17:17:34 | INFO | train_inner | epoch 136:    425 / 1978 loss=2.98, nll_loss=0.858, word_ins=2.687, length=2.937, ppl=7.89, wps=46147.7, ups=0.78, wpb=58788.5, bsz=2000.8, num_updates=267400, lr=0.000193383, gnorm=1.268, loss_scale=8192, train_wall=127, wall=351008
2023-01-16 17:19:45 | INFO | train_inner | epoch 136:    525 / 1978 loss=2.979, nll_loss=0.856, word_ins=2.684, length=2.95, ppl=7.88, wps=45093, ups=0.76, wpb=59089.5, bsz=2031.7, num_updates=267500, lr=0.000193347, gnorm=1.268, loss_scale=8192, train_wall=131, wall=351139
2023-01-16 17:21:55 | INFO | train_inner | epoch 136:    625 / 1978 loss=2.999, nll_loss=0.868, word_ins=2.695, length=3.033, ppl=7.99, wps=45475.3, ups=0.77, wpb=59142.6, bsz=1904.2, num_updates=267600, lr=0.000193311, gnorm=1.295, loss_scale=8192, train_wall=130, wall=351269
2023-01-16 17:24:06 | INFO | train_inner | epoch 136:    725 / 1978 loss=2.987, nll_loss=0.87, word_ins=2.697, length=2.9, ppl=7.93, wps=44801, ups=0.76, wpb=58935.6, bsz=1984.9, num_updates=267700, lr=0.000193275, gnorm=1.284, loss_scale=8192, train_wall=131, wall=351400
2023-01-16 17:26:17 | INFO | train_inner | epoch 136:    825 / 1978 loss=2.954, nll_loss=0.832, word_ins=2.661, length=2.927, ppl=7.75, wps=45546.7, ups=0.77, wpb=59289.9, bsz=2116.2, num_updates=267800, lr=0.000193239, gnorm=1.238, loss_scale=8192, train_wall=130, wall=351531
2023-01-16 17:28:26 | INFO | train_inner | epoch 136:    925 / 1978 loss=2.989, nll_loss=0.869, word_ins=2.696, length=2.935, ppl=7.94, wps=45233.8, ups=0.77, wpb=58665.3, bsz=2029.7, num_updates=267900, lr=0.000193203, gnorm=1.29, loss_scale=8192, train_wall=129, wall=351660
2023-01-16 17:30:34 | INFO | train_inner | epoch 136:   1025 / 1978 loss=2.982, nll_loss=0.851, word_ins=2.679, length=3.031, ppl=7.9, wps=46760.4, ups=0.78, wpb=59583.3, bsz=1933.2, num_updates=268000, lr=0.000193167, gnorm=1.29, loss_scale=8192, train_wall=127, wall=351788
2023-01-16 17:32:43 | INFO | train_inner | epoch 136:   1125 / 1978 loss=2.964, nll_loss=0.842, word_ins=2.671, length=2.929, ppl=7.8, wps=45838, ups=0.78, wpb=59071.8, bsz=2053.1, num_updates=268100, lr=0.000193131, gnorm=1.256, loss_scale=8192, train_wall=128, wall=351917
2023-01-16 17:34:50 | INFO | train_inner | epoch 136:   1225 / 1978 loss=2.982, nll_loss=0.856, word_ins=2.683, length=2.99, ppl=7.9, wps=46838.8, ups=0.79, wpb=59638.4, bsz=1919.3, num_updates=268200, lr=0.000193095, gnorm=1.314, loss_scale=8192, train_wall=127, wall=352044
2023-01-16 17:37:00 | INFO | train_inner | epoch 136:   1325 / 1978 loss=2.988, nll_loss=0.861, word_ins=2.688, length=2.996, ppl=7.93, wps=45529.7, ups=0.77, wpb=59308.8, bsz=1938.4, num_updates=268300, lr=0.000193059, gnorm=1.325, loss_scale=8192, train_wall=130, wall=352174
2023-01-16 17:39:12 | INFO | train_inner | epoch 136:   1425 / 1978 loss=2.953, nll_loss=0.834, word_ins=2.663, length=2.902, ppl=7.74, wps=45406.2, ups=0.76, wpb=59695.6, bsz=2079.5, num_updates=268400, lr=0.000193023, gnorm=1.28, loss_scale=8192, train_wall=131, wall=352306
2023-01-16 17:41:22 | INFO | train_inner | epoch 136:   1525 / 1978 loss=2.983, nll_loss=0.858, word_ins=2.686, length=2.974, ppl=7.91, wps=45374.1, ups=0.77, wpb=59298.4, bsz=1969.1, num_updates=268500, lr=0.000192987, gnorm=1.255, loss_scale=8192, train_wall=130, wall=352436
2023-01-16 17:43:34 | INFO | train_inner | epoch 136:   1625 / 1978 loss=2.98, nll_loss=0.855, word_ins=2.683, length=2.976, ppl=7.89, wps=45085.2, ups=0.76, wpb=59275.2, bsz=2016.6, num_updates=268600, lr=0.000192951, gnorm=1.313, loss_scale=8192, train_wall=131, wall=352568
2023-01-16 17:45:45 | INFO | train_inner | epoch 136:   1725 / 1978 loss=2.951, nll_loss=0.832, word_ins=2.661, length=2.897, ppl=7.73, wps=45416.1, ups=0.76, wpb=59497.6, bsz=2125.3, num_updates=268700, lr=0.000192915, gnorm=1.257, loss_scale=8192, train_wall=131, wall=352699
2023-01-16 17:47:53 | INFO | train_inner | epoch 136:   1825 / 1978 loss=2.962, nll_loss=0.84, word_ins=2.669, length=2.927, ppl=7.79, wps=46250.2, ups=0.78, wpb=59082.2, bsz=2080.8, num_updates=268800, lr=0.000192879, gnorm=1.212, loss_scale=8192, train_wall=128, wall=352827
2023-01-16 17:50:00 | INFO | train_inner | epoch 136:   1925 / 1978 loss=2.985, nll_loss=0.864, word_ins=2.69, length=2.952, ppl=7.92, wps=46600.4, ups=0.78, wpb=59553.1, bsz=1976.3, num_updates=268900, lr=0.000192843, gnorm=1.299, loss_scale=8192, train_wall=128, wall=352954
2023-01-16 17:51:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 17:51:22 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 4.597 | nll_loss 1.967 | word_ins 3.725 | length 8.713 | ppl 24.2 | wps 122768 | wpb 40242.5 | bsz 1500 | num_updates 268953 | best_loss 4.422
2023-01-16 17:51:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 17:51:49 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint136.pt (epoch 136 @ 268953 updates, score 4.597) (writing took 27.347130016889423 seconds)
2023-01-16 17:51:49 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2023-01-16 17:51:49 | INFO | train | epoch 136 | loss 2.975 | nll_loss 0.852 | word_ins 2.68 | length 2.951 | ppl 7.86 | wps 44820.3 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 268953 | lr 0.000192824 | gnorm 1.28 | loss_scale 8192 | train_wall 2554 | wall 353063
2023-01-16 17:51:49 | INFO | fairseq.trainer | begin training epoch 137
2023-01-16 17:53:04 | INFO | train_inner | epoch 137:     47 / 1978 loss=2.971, nll_loss=0.852, word_ins=2.68, length=2.906, ppl=7.84, wps=32428.1, ups=0.54, wpb=59566.2, bsz=1994.1, num_updates=269000, lr=0.000192807, gnorm=1.294, loss_scale=8192, train_wall=129, wall=353138
2023-01-16 17:55:16 | INFO | train_inner | epoch 137:    147 / 1978 loss=2.945, nll_loss=0.827, word_ins=2.658, length=2.875, ppl=7.7, wps=45105, ups=0.76, wpb=59555.2, bsz=2080.6, num_updates=269100, lr=0.000192772, gnorm=1.246, loss_scale=8192, train_wall=132, wall=353270
2023-01-16 17:57:25 | INFO | train_inner | epoch 137:    247 / 1978 loss=3.001, nll_loss=0.876, word_ins=2.703, length=2.987, ppl=8.01, wps=45755.4, ups=0.77, wpb=59125, bsz=1894.1, num_updates=269200, lr=0.000192736, gnorm=1.302, loss_scale=8192, train_wall=129, wall=353399
2023-01-16 17:59:36 | INFO | train_inner | epoch 137:    347 / 1978 loss=2.979, nll_loss=0.857, word_ins=2.685, length=2.942, ppl=7.89, wps=45516.2, ups=0.76, wpb=59625.2, bsz=1952.8, num_updates=269300, lr=0.0001927, gnorm=1.3, loss_scale=8192, train_wall=131, wall=353530
2023-01-16 18:01:46 | INFO | train_inner | epoch 137:    447 / 1978 loss=2.958, nll_loss=0.839, word_ins=2.669, length=2.888, ppl=7.77, wps=45664.6, ups=0.77, wpb=59245.9, bsz=2067.6, num_updates=269400, lr=0.000192664, gnorm=1.259, loss_scale=8192, train_wall=129, wall=353660
2023-01-16 18:03:54 | INFO | train_inner | epoch 137:    547 / 1978 loss=2.974, nll_loss=0.852, word_ins=2.68, length=2.941, ppl=7.86, wps=46410.9, ups=0.78, wpb=59391, bsz=1976.6, num_updates=269500, lr=0.000192629, gnorm=1.247, loss_scale=8192, train_wall=128, wall=353788
2023-01-16 18:06:02 | INFO | train_inner | epoch 137:    647 / 1978 loss=2.965, nll_loss=0.845, word_ins=2.673, length=2.914, ppl=7.81, wps=46520.6, ups=0.78, wpb=59707, bsz=2057, num_updates=269600, lr=0.000192593, gnorm=1.28, loss_scale=8192, train_wall=128, wall=353916
2023-01-16 18:08:10 | INFO | train_inner | epoch 137:    747 / 1978 loss=2.993, nll_loss=0.866, word_ins=2.694, length=2.997, ppl=7.96, wps=45940, ups=0.79, wpb=58398.3, bsz=1923.1, num_updates=269700, lr=0.000192557, gnorm=1.28, loss_scale=8192, train_wall=127, wall=354044
2023-01-16 18:10:19 | INFO | train_inner | epoch 137:    847 / 1978 loss=2.952, nll_loss=0.828, word_ins=2.658, length=2.941, ppl=7.74, wps=45745.1, ups=0.77, wpb=59296.2, bsz=2045.1, num_updates=269800, lr=0.000192521, gnorm=1.274, loss_scale=8192, train_wall=129, wall=354173
2023-01-16 18:12:31 | INFO | train_inner | epoch 137:    947 / 1978 loss=2.968, nll_loss=0.852, word_ins=2.679, length=2.885, ppl=7.82, wps=45401.7, ups=0.76, wpb=59865.2, bsz=2086.2, num_updates=269900, lr=0.000192486, gnorm=1.336, loss_scale=8192, train_wall=131, wall=354305
2023-01-16 18:14:41 | INFO | train_inner | epoch 137:   1047 / 1978 loss=2.983, nll_loss=0.852, word_ins=2.68, length=3.026, ppl=7.91, wps=45392.5, ups=0.77, wpb=59027.2, bsz=1983, num_updates=270000, lr=0.00019245, gnorm=1.275, loss_scale=8192, train_wall=130, wall=354435
2023-01-16 18:16:51 | INFO | train_inner | epoch 137:   1147 / 1978 loss=2.967, nll_loss=0.845, word_ins=2.674, length=2.936, ppl=7.82, wps=45584.8, ups=0.77, wpb=59374.7, bsz=2000.6, num_updates=270100, lr=0.000192414, gnorm=1.271, loss_scale=8192, train_wall=130, wall=354565
2023-01-16 18:19:01 | INFO | train_inner | epoch 137:   1247 / 1978 loss=2.975, nll_loss=0.852, word_ins=2.68, length=2.952, ppl=7.86, wps=45680.5, ups=0.77, wpb=59139.6, bsz=1966.9, num_updates=270200, lr=0.000192379, gnorm=1.318, loss_scale=8192, train_wall=129, wall=354695
2023-01-16 18:21:10 | INFO | train_inner | epoch 137:   1347 / 1978 loss=2.98, nll_loss=0.86, word_ins=2.687, length=2.937, ppl=7.89, wps=45980.8, ups=0.78, wpb=59289.8, bsz=2013.4, num_updates=270300, lr=0.000192343, gnorm=1.296, loss_scale=8192, train_wall=129, wall=354824
2023-01-16 18:23:17 | INFO | train_inner | epoch 137:   1447 / 1978 loss=2.965, nll_loss=0.842, word_ins=2.671, length=2.937, ppl=7.81, wps=46405.9, ups=0.79, wpb=59034.4, bsz=2008.2, num_updates=270400, lr=0.000192308, gnorm=1.261, loss_scale=8192, train_wall=127, wall=354951
2023-01-16 18:23:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 18:25:27 | INFO | train_inner | epoch 137:   1548 / 1978 loss=2.965, nll_loss=0.842, word_ins=2.67, length=2.951, ppl=7.81, wps=46057.1, ups=0.77, wpb=59658.4, bsz=2030.1, num_updates=270500, lr=0.000192272, gnorm=1.28, loss_scale=8192, train_wall=129, wall=355081
2023-01-16 18:27:37 | INFO | train_inner | epoch 137:   1648 / 1978 loss=2.966, nll_loss=0.841, word_ins=2.67, length=2.961, ppl=7.81, wps=45167.7, ups=0.77, wpb=58868.3, bsz=2090.6, num_updates=270600, lr=0.000192237, gnorm=1.229, loss_scale=8192, train_wall=130, wall=355211
2023-01-16 18:29:47 | INFO | train_inner | epoch 137:   1748 / 1978 loss=2.993, nll_loss=0.867, word_ins=2.694, length=2.991, ppl=7.96, wps=45424.7, ups=0.77, wpb=59309.9, bsz=2000.2, num_updates=270700, lr=0.000192201, gnorm=1.266, loss_scale=8192, train_wall=130, wall=355342
2023-01-16 18:31:56 | INFO | train_inner | epoch 137:   1848 / 1978 loss=2.973, nll_loss=0.845, word_ins=2.673, length=2.998, ppl=7.85, wps=46231.1, ups=0.78, wpb=59618.2, bsz=1952.9, num_updates=270800, lr=0.000192166, gnorm=1.311, loss_scale=8192, train_wall=129, wall=355470
2023-01-16 18:34:06 | INFO | train_inner | epoch 137:   1948 / 1978 loss=3.01, nll_loss=0.881, word_ins=2.706, length=3.037, ppl=8.05, wps=45553.5, ups=0.77, wpb=58924.7, bsz=1901.2, num_updates=270900, lr=0.00019213, gnorm=1.299, loss_scale=8192, train_wall=129, wall=355600
2023-01-16 18:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 18:35:00 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 4.683 | nll_loss 1.969 | word_ins 3.733 | length 9.499 | ppl 25.68 | wps 102801 | wpb 40242.5 | bsz 1500 | num_updates 270930 | best_loss 4.422
2023-01-16 18:35:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 18:35:28 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint137.pt (epoch 137 @ 270930 updates, score 4.683) (writing took 28.65714838076383 seconds)
2023-01-16 18:35:28 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2023-01-16 18:35:28 | INFO | train | epoch 137 | loss 2.974 | nll_loss 0.851 | word_ins 2.679 | length 2.95 | ppl 7.86 | wps 44748.2 | ups 0.75 | wpb 59284 | bsz 2003 | num_updates 270930 | lr 0.00019212 | gnorm 1.28 | loss_scale 8192 | train_wall 2556 | wall 355682
2023-01-16 18:35:28 | INFO | fairseq.trainer | begin training epoch 138
2023-01-16 18:37:12 | INFO | train_inner | epoch 138:     70 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.681, length=2.949, ppl=7.87, wps=31726.2, ups=0.54, wpb=59054.8, bsz=1980, num_updates=271000, lr=0.000192095, gnorm=1.32, loss_scale=8192, train_wall=129, wall=355786
2023-01-16 18:39:20 | INFO | train_inner | epoch 138:    170 / 1978 loss=2.968, nll_loss=0.844, word_ins=2.673, length=2.952, ppl=7.82, wps=46620.4, ups=0.78, wpb=59552.4, bsz=1999.4, num_updates=271100, lr=0.000192059, gnorm=1.285, loss_scale=8192, train_wall=128, wall=355914
2023-01-16 18:41:28 | INFO | train_inner | epoch 138:    270 / 1978 loss=2.968, nll_loss=0.843, word_ins=2.672, length=2.965, ppl=7.83, wps=46071.8, ups=0.78, wpb=58936.3, bsz=1996.2, num_updates=271200, lr=0.000192024, gnorm=1.262, loss_scale=8192, train_wall=128, wall=356042
2023-01-16 18:43:36 | INFO | train_inner | epoch 138:    370 / 1978 loss=2.962, nll_loss=0.84, word_ins=2.669, length=2.928, ppl=7.79, wps=46332.8, ups=0.78, wpb=59395.9, bsz=1998.1, num_updates=271300, lr=0.000191988, gnorm=1.278, loss_scale=8192, train_wall=128, wall=356170
2023-01-16 18:45:47 | INFO | train_inner | epoch 138:    470 / 1978 loss=2.96, nll_loss=0.839, word_ins=2.668, length=2.916, ppl=7.78, wps=45131.3, ups=0.76, wpb=59260.6, bsz=2034.7, num_updates=271400, lr=0.000191953, gnorm=1.27, loss_scale=8192, train_wall=131, wall=356301
2023-01-16 18:47:57 | INFO | train_inner | epoch 138:    570 / 1978 loss=3.006, nll_loss=0.879, word_ins=2.705, length=3.012, ppl=8.04, wps=45284.7, ups=0.77, wpb=58828.8, bsz=1906.9, num_updates=271500, lr=0.000191918, gnorm=1.35, loss_scale=8192, train_wall=129, wall=356431
2023-01-16 18:50:07 | INFO | train_inner | epoch 138:    670 / 1978 loss=2.973, nll_loss=0.849, word_ins=2.677, length=2.964, ppl=7.85, wps=45563.1, ups=0.77, wpb=59055.8, bsz=1971.5, num_updates=271600, lr=0.000191882, gnorm=1.263, loss_scale=8192, train_wall=129, wall=356561
2023-01-16 18:52:17 | INFO | train_inner | epoch 138:    770 / 1978 loss=2.975, nll_loss=0.851, word_ins=2.679, length=2.962, ppl=7.86, wps=45576.6, ups=0.77, wpb=59456.7, bsz=1978.2, num_updates=271700, lr=0.000191847, gnorm=1.289, loss_scale=8192, train_wall=130, wall=356691
2023-01-16 18:54:27 | INFO | train_inner | epoch 138:    870 / 1978 loss=2.972, nll_loss=0.849, word_ins=2.678, length=2.948, ppl=7.85, wps=45934, ups=0.77, wpb=59481.8, bsz=2016.5, num_updates=271800, lr=0.000191812, gnorm=1.284, loss_scale=8192, train_wall=129, wall=356821
2023-01-16 18:56:35 | INFO | train_inner | epoch 138:    970 / 1978 loss=2.959, nll_loss=0.838, word_ins=2.667, length=2.925, ppl=7.78, wps=46363, ups=0.78, wpb=59567.2, bsz=2103.3, num_updates=271900, lr=0.000191777, gnorm=1.301, loss_scale=8192, train_wall=128, wall=356949
2023-01-16 18:58:42 | INFO | train_inner | epoch 138:   1070 / 1978 loss=2.999, nll_loss=0.875, word_ins=2.701, length=2.979, ppl=7.99, wps=46547, ups=0.79, wpb=59107, bsz=1989, num_updates=272000, lr=0.000191741, gnorm=1.279, loss_scale=8192, train_wall=127, wall=357076
2023-01-16 19:00:50 | INFO | train_inner | epoch 138:   1170 / 1978 loss=2.97, nll_loss=0.847, word_ins=2.676, length=2.942, ppl=7.83, wps=46383.6, ups=0.78, wpb=59390.9, bsz=1967.1, num_updates=272100, lr=0.000191706, gnorm=1.285, loss_scale=8192, train_wall=128, wall=357204
2023-01-16 19:03:00 | INFO | train_inner | epoch 138:   1270 / 1978 loss=2.998, nll_loss=0.869, word_ins=2.695, length=3.027, ppl=7.99, wps=45772.9, ups=0.77, wpb=59516.7, bsz=1955, num_updates=272200, lr=0.000191671, gnorm=1.322, loss_scale=8192, train_wall=130, wall=357334
2023-01-16 19:05:11 | INFO | train_inner | epoch 138:   1370 / 1978 loss=2.945, nll_loss=0.827, word_ins=2.656, length=2.889, ppl=7.7, wps=45344, ups=0.77, wpb=59163.8, bsz=2070.5, num_updates=272300, lr=0.000191636, gnorm=1.238, loss_scale=8192, train_wall=130, wall=357465
2023-01-16 19:07:22 | INFO | train_inner | epoch 138:   1470 / 1978 loss=2.952, nll_loss=0.83, word_ins=2.66, length=2.926, ppl=7.74, wps=45512.7, ups=0.76, wpb=59589.2, bsz=2027, num_updates=272400, lr=0.0001916, gnorm=1.289, loss_scale=8192, train_wall=131, wall=357596
2023-01-16 19:09:32 | INFO | train_inner | epoch 138:   1570 / 1978 loss=2.961, nll_loss=0.841, word_ins=2.669, length=2.918, ppl=7.79, wps=45588.7, ups=0.76, wpb=59637, bsz=2010.7, num_updates=272500, lr=0.000191565, gnorm=1.232, loss_scale=8192, train_wall=130, wall=357726
2023-01-16 19:11:42 | INFO | train_inner | epoch 138:   1670 / 1978 loss=2.969, nll_loss=0.846, word_ins=2.675, length=2.947, ppl=7.83, wps=45889.4, ups=0.77, wpb=59379.4, bsz=2018.9, num_updates=272600, lr=0.00019153, gnorm=1.241, loss_scale=8192, train_wall=129, wall=357856
2023-01-16 19:13:50 | INFO | train_inner | epoch 138:   1770 / 1978 loss=2.98, nll_loss=0.864, word_ins=2.692, length=2.88, ppl=7.89, wps=46339.5, ups=0.78, wpb=59316.7, bsz=2013.5, num_updates=272700, lr=0.000191495, gnorm=1.269, loss_scale=8192, train_wall=128, wall=357984
2023-01-16 19:15:58 | INFO | train_inner | epoch 138:   1870 / 1978 loss=2.977, nll_loss=0.856, word_ins=2.683, length=2.935, ppl=7.87, wps=45978.1, ups=0.78, wpb=59048.9, bsz=2061.1, num_updates=272800, lr=0.00019146, gnorm=1.257, loss_scale=8192, train_wall=128, wall=358112
2023-01-16 19:18:08 | INFO | train_inner | epoch 138:   1970 / 1978 loss=2.985, nll_loss=0.863, word_ins=2.689, length=2.961, ppl=7.92, wps=45478.9, ups=0.77, wpb=59032.2, bsz=1988.6, num_updates=272900, lr=0.000191425, gnorm=1.266, loss_scale=8192, train_wall=130, wall=358242
2023-01-16 19:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 19:18:33 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 4.661 | nll_loss 1.969 | word_ins 3.729 | length 9.334 | ppl 25.3 | wps 83869.8 | wpb 40242.5 | bsz 1500 | num_updates 272908 | best_loss 4.422
2023-01-16 19:18:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 19:19:03 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint138.pt (epoch 138 @ 272908 updates, score 4.661) (writing took 30.26930219307542 seconds)
2023-01-16 19:19:03 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2023-01-16 19:19:03 | INFO | train | epoch 138 | loss 2.973 | nll_loss 0.85 | word_ins 2.679 | length 2.947 | ppl 7.85 | wps 44844 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 272908 | lr 0.000191422 | gnorm 1.279 | loss_scale 8192 | train_wall 2550 | wall 358297
2023-01-16 19:19:03 | INFO | fairseq.trainer | begin training epoch 139
2023-01-16 19:21:18 | INFO | train_inner | epoch 139:     92 / 1978 loss=2.955, nll_loss=0.837, word_ins=2.666, length=2.885, ppl=7.75, wps=31301.7, ups=0.53, wpb=59561.3, bsz=2026.1, num_updates=273000, lr=0.00019139, gnorm=1.283, loss_scale=8192, train_wall=130, wall=358432
2023-01-16 19:23:29 | INFO | train_inner | epoch 139:    192 / 1978 loss=2.956, nll_loss=0.833, word_ins=2.662, length=2.938, ppl=7.76, wps=45848.5, ups=0.76, wpb=59965.1, bsz=2055.4, num_updates=273100, lr=0.000191355, gnorm=1.271, loss_scale=8192, train_wall=130, wall=358563
2023-01-16 19:25:39 | INFO | train_inner | epoch 139:    292 / 1978 loss=2.977, nll_loss=0.854, word_ins=2.683, length=2.949, ppl=7.88, wps=45489.1, ups=0.77, wpb=58990.8, bsz=1970.6, num_updates=273200, lr=0.00019132, gnorm=1.327, loss_scale=8192, train_wall=129, wall=358693
2023-01-16 19:27:49 | INFO | train_inner | epoch 139:    392 / 1978 loss=2.959, nll_loss=0.836, word_ins=2.665, length=2.936, ppl=7.77, wps=45428.1, ups=0.77, wpb=59339.2, bsz=2009.2, num_updates=273300, lr=0.000191285, gnorm=1.27, loss_scale=8192, train_wall=130, wall=358823
2023-01-16 19:29:57 | INFO | train_inner | epoch 139:    492 / 1978 loss=2.989, nll_loss=0.862, word_ins=2.689, length=2.994, ppl=7.94, wps=46395.6, ups=0.78, wpb=59122.3, bsz=1944, num_updates=273400, lr=0.00019125, gnorm=1.338, loss_scale=8192, train_wall=127, wall=358951
2023-01-16 19:32:05 | INFO | train_inner | epoch 139:    592 / 1978 loss=2.969, nll_loss=0.847, word_ins=2.675, length=2.942, ppl=7.83, wps=46377.3, ups=0.78, wpb=59584.5, bsz=2003.8, num_updates=273500, lr=0.000191215, gnorm=1.26, loss_scale=8192, train_wall=128, wall=359079
2023-01-16 19:34:13 | INFO | train_inner | epoch 139:    692 / 1978 loss=2.988, nll_loss=0.868, word_ins=2.695, length=2.933, ppl=7.93, wps=46107.7, ups=0.78, wpb=58974.4, bsz=1986.9, num_updates=273600, lr=0.00019118, gnorm=1.338, loss_scale=8192, train_wall=128, wall=359207
2023-01-16 19:36:23 | INFO | train_inner | epoch 139:    792 / 1978 loss=2.984, nll_loss=0.86, word_ins=2.687, length=2.971, ppl=7.91, wps=46298.3, ups=0.77, wpb=60026.7, bsz=1943.6, num_updates=273700, lr=0.000191145, gnorm=1.28, loss_scale=8192, train_wall=129, wall=359337
2023-01-16 19:38:33 | INFO | train_inner | epoch 139:    892 / 1978 loss=2.951, nll_loss=0.833, word_ins=2.662, length=2.888, ppl=7.73, wps=45354.5, ups=0.77, wpb=59090.5, bsz=2092, num_updates=273800, lr=0.00019111, gnorm=1.223, loss_scale=8192, train_wall=130, wall=359467
2023-01-16 19:40:44 | INFO | train_inner | epoch 139:    992 / 1978 loss=2.957, nll_loss=0.835, word_ins=2.664, length=2.929, ppl=7.77, wps=45428.7, ups=0.76, wpb=59508.2, bsz=2042, num_updates=273900, lr=0.000191075, gnorm=1.25, loss_scale=8192, train_wall=131, wall=359598
2023-01-16 19:42:55 | INFO | train_inner | epoch 139:   1092 / 1978 loss=2.951, nll_loss=0.83, word_ins=2.66, length=2.909, ppl=7.73, wps=45062.9, ups=0.76, wpb=59141, bsz=2036.3, num_updates=274000, lr=0.00019104, gnorm=1.256, loss_scale=8192, train_wall=131, wall=359730
2023-01-16 19:45:06 | INFO | train_inner | epoch 139:   1192 / 1978 loss=2.961, nll_loss=0.835, word_ins=2.665, length=2.96, ppl=7.79, wps=45324, ups=0.76, wpb=59298, bsz=2045.1, num_updates=274100, lr=0.000191005, gnorm=1.258, loss_scale=8192, train_wall=130, wall=359860
2023-01-16 19:47:13 | INFO | train_inner | epoch 139:   1292 / 1978 loss=2.973, nll_loss=0.848, word_ins=2.676, length=2.972, ppl=7.85, wps=46684.9, ups=0.79, wpb=59234.8, bsz=1934.1, num_updates=274200, lr=0.00019097, gnorm=1.268, loss_scale=8192, train_wall=127, wall=359987
2023-01-16 19:49:21 | INFO | train_inner | epoch 139:   1392 / 1978 loss=2.973, nll_loss=0.848, word_ins=2.677, length=2.967, ppl=7.85, wps=46159.6, ups=0.78, wpb=58976.9, bsz=2041.8, num_updates=274300, lr=0.000190936, gnorm=1.266, loss_scale=8192, train_wall=128, wall=360115
2023-01-16 19:51:28 | INFO | train_inner | epoch 139:   1492 / 1978 loss=2.996, nll_loss=0.873, word_ins=2.699, length=2.97, ppl=7.98, wps=46549.3, ups=0.79, wpb=59163.1, bsz=1913.7, num_updates=274400, lr=0.000190901, gnorm=1.352, loss_scale=8192, train_wall=127, wall=360242
2023-01-16 19:53:38 | INFO | train_inner | epoch 139:   1592 / 1978 loss=2.97, nll_loss=0.846, word_ins=2.674, length=2.955, ppl=7.84, wps=45636.1, ups=0.77, wpb=59210.6, bsz=2011.2, num_updates=274500, lr=0.000190866, gnorm=1.247, loss_scale=8192, train_wall=129, wall=360372
2023-01-16 19:54:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 19:55:49 | INFO | train_inner | epoch 139:   1693 / 1978 loss=2.972, nll_loss=0.849, word_ins=2.677, length=2.948, ppl=7.85, wps=44889.2, ups=0.76, wpb=59095.3, bsz=2023, num_updates=274600, lr=0.000190831, gnorm=1.263, loss_scale=8192, train_wall=131, wall=360504
2023-01-16 19:58:00 | INFO | train_inner | epoch 139:   1793 / 1978 loss=2.986, nll_loss=0.859, word_ins=2.687, length=2.993, ppl=7.92, wps=45264.9, ups=0.77, wpb=59074.4, bsz=1976.2, num_updates=274700, lr=0.000190797, gnorm=1.297, loss_scale=8192, train_wall=130, wall=360634
2023-01-16 20:00:10 | INFO | train_inner | epoch 139:   1893 / 1978 loss=2.967, nll_loss=0.842, word_ins=2.671, length=2.966, ppl=7.82, wps=45595.6, ups=0.77, wpb=59440.4, bsz=2003.5, num_updates=274800, lr=0.000190762, gnorm=1.352, loss_scale=8192, train_wall=130, wall=360764
2023-01-16 20:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 20:02:14 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 4.561 | nll_loss 1.978 | word_ins 3.74 | length 8.212 | ppl 23.61 | wps 101568 | wpb 40242.5 | bsz 1500 | num_updates 274885 | best_loss 4.422
2023-01-16 20:02:14 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 20:02:41 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint139.pt (epoch 139 @ 274885 updates, score 4.561) (writing took 27.47101940913126 seconds)
2023-01-16 20:02:41 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2023-01-16 20:02:41 | INFO | train | epoch 139 | loss 2.971 | nll_loss 0.848 | word_ins 2.676 | length 2.947 | ppl 7.84 | wps 44770.7 | ups 0.76 | wpb 59286.5 | bsz 2003 | num_updates 274885 | lr 0.000190732 | gnorm 1.286 | loss_scale 8192 | train_wall 2556 | wall 360915
2023-01-16 20:02:41 | INFO | fairseq.trainer | begin training epoch 140
2023-01-16 20:03:13 | INFO | train_inner | epoch 140:     15 / 1978 loss=2.99, nll_loss=0.869, word_ins=2.695, length=2.948, ppl=7.95, wps=32256.2, ups=0.55, wpb=58944.8, bsz=1975.5, num_updates=274900, lr=0.000190727, gnorm=1.312, loss_scale=8192, train_wall=130, wall=360947
2023-01-16 20:05:21 | INFO | train_inner | epoch 140:    115 / 1978 loss=2.961, nll_loss=0.84, word_ins=2.669, length=2.912, ppl=7.78, wps=46135.7, ups=0.78, wpb=59161.6, bsz=2027.8, num_updates=275000, lr=0.000190693, gnorm=1.244, loss_scale=8192, train_wall=128, wall=361075
2023-01-16 20:07:30 | INFO | train_inner | epoch 140:    215 / 1978 loss=2.963, nll_loss=0.843, word_ins=2.672, length=2.904, ppl=7.8, wps=46418, ups=0.78, wpb=59532.1, bsz=2049.8, num_updates=275100, lr=0.000190658, gnorm=1.307, loss_scale=8192, train_wall=128, wall=361204
2023-01-16 20:09:38 | INFO | train_inner | epoch 140:    315 / 1978 loss=2.977, nll_loss=0.851, word_ins=2.679, length=2.981, ppl=7.87, wps=46104.4, ups=0.78, wpb=59331.1, bsz=1948.3, num_updates=275200, lr=0.000190623, gnorm=1.326, loss_scale=8192, train_wall=128, wall=361332
2023-01-16 20:11:48 | INFO | train_inner | epoch 140:    415 / 1978 loss=2.947, nll_loss=0.824, word_ins=2.654, length=2.934, ppl=7.71, wps=45997.8, ups=0.77, wpb=59875.8, bsz=2024.6, num_updates=275300, lr=0.000190589, gnorm=1.269, loss_scale=8192, train_wall=130, wall=361463
2023-01-16 20:13:57 | INFO | train_inner | epoch 140:    515 / 1978 loss=2.972, nll_loss=0.854, word_ins=2.681, length=2.909, ppl=7.85, wps=45923.6, ups=0.78, wpb=59183.2, bsz=1950.8, num_updates=275400, lr=0.000190554, gnorm=1.251, loss_scale=8192, train_wall=128, wall=361591
2023-01-16 20:16:07 | INFO | train_inner | epoch 140:    615 / 1978 loss=2.967, nll_loss=0.846, word_ins=2.675, length=2.927, ppl=7.82, wps=45874.9, ups=0.77, wpb=59559.5, bsz=1981.5, num_updates=275500, lr=0.000190519, gnorm=1.276, loss_scale=8192, train_wall=130, wall=361721
2023-01-16 20:18:17 | INFO | train_inner | epoch 140:    715 / 1978 loss=2.985, nll_loss=0.86, word_ins=2.687, length=2.979, ppl=7.92, wps=45626.4, ups=0.77, wpb=59124, bsz=1909.4, num_updates=275600, lr=0.000190485, gnorm=1.342, loss_scale=8192, train_wall=129, wall=361851
2023-01-16 20:20:25 | INFO | train_inner | epoch 140:    815 / 1978 loss=2.956, nll_loss=0.832, word_ins=2.661, length=2.942, ppl=7.76, wps=46058.2, ups=0.78, wpb=59264.6, bsz=2031.5, num_updates=275700, lr=0.00019045, gnorm=1.226, loss_scale=8192, train_wall=128, wall=361979
2023-01-16 20:22:32 | INFO | train_inner | epoch 140:    915 / 1978 loss=2.979, nll_loss=0.854, word_ins=2.683, length=2.959, ppl=7.88, wps=45742.8, ups=0.79, wpb=58070.3, bsz=2019.6, num_updates=275800, lr=0.000190416, gnorm=1.287, loss_scale=8192, train_wall=127, wall=362106
2023-01-16 20:24:40 | INFO | train_inner | epoch 140:   1015 / 1978 loss=2.967, nll_loss=0.842, word_ins=2.671, length=2.964, ppl=7.82, wps=46807.1, ups=0.78, wpb=59807.6, bsz=2021.8, num_updates=275900, lr=0.000190381, gnorm=1.308, loss_scale=8192, train_wall=128, wall=362234
2023-01-16 20:26:51 | INFO | train_inner | epoch 140:   1115 / 1978 loss=2.95, nll_loss=0.833, word_ins=2.662, length=2.884, ppl=7.73, wps=45361.2, ups=0.77, wpb=59160.5, bsz=2115.4, num_updates=276000, lr=0.000190347, gnorm=1.254, loss_scale=8192, train_wall=130, wall=362365
2023-01-16 20:29:01 | INFO | train_inner | epoch 140:   1215 / 1978 loss=2.968, nll_loss=0.852, word_ins=2.679, length=2.891, ppl=7.83, wps=45459.1, ups=0.76, wpb=59441.2, bsz=2030.7, num_updates=276100, lr=0.000190312, gnorm=1.261, loss_scale=8192, train_wall=130, wall=362495
2023-01-16 20:31:11 | INFO | train_inner | epoch 140:   1315 / 1978 loss=2.959, nll_loss=0.831, word_ins=2.66, length=2.984, ppl=7.77, wps=45851.4, ups=0.77, wpb=59490, bsz=2014.1, num_updates=276200, lr=0.000190278, gnorm=1.272, loss_scale=8192, train_wall=129, wall=362625
2023-01-16 20:33:23 | INFO | train_inner | epoch 140:   1415 / 1978 loss=2.95, nll_loss=0.834, word_ins=2.664, length=2.862, ppl=7.73, wps=44974.5, ups=0.76, wpb=59448.7, bsz=2093.7, num_updates=276300, lr=0.000190243, gnorm=1.289, loss_scale=8192, train_wall=132, wall=362757
2023-01-16 20:35:33 | INFO | train_inner | epoch 140:   1515 / 1978 loss=3.001, nll_loss=0.884, word_ins=2.709, length=2.918, ppl=8.01, wps=45503.4, ups=0.77, wpb=58906.7, bsz=1890.1, num_updates=276400, lr=0.000190209, gnorm=1.325, loss_scale=8192, train_wall=129, wall=362887
2023-01-16 20:37:42 | INFO | train_inner | epoch 140:   1615 / 1978 loss=2.976, nll_loss=0.855, word_ins=2.682, length=2.936, ppl=7.87, wps=45755.9, ups=0.77, wpb=59201.3, bsz=2040.8, num_updates=276500, lr=0.000190175, gnorm=1.3, loss_scale=8192, train_wall=129, wall=363016
2023-01-16 20:39:50 | INFO | train_inner | epoch 140:   1715 / 1978 loss=2.984, nll_loss=0.861, word_ins=2.688, length=2.958, ppl=7.91, wps=46252, ups=0.78, wpb=59254.6, bsz=1982.9, num_updates=276600, lr=0.00019014, gnorm=1.303, loss_scale=8192, train_wall=128, wall=363144
2023-01-16 20:41:58 | INFO | train_inner | epoch 140:   1815 / 1978 loss=2.958, nll_loss=0.836, word_ins=2.665, length=2.929, ppl=7.77, wps=46661.5, ups=0.78, wpb=59789.8, bsz=2012.9, num_updates=276700, lr=0.000190106, gnorm=1.25, loss_scale=8192, train_wall=128, wall=363272
2023-01-16 20:44:06 | INFO | train_inner | epoch 140:   1915 / 1978 loss=2.984, nll_loss=0.859, word_ins=2.686, length=2.972, ppl=7.91, wps=45926.4, ups=0.78, wpb=58815.5, bsz=1930.6, num_updates=276800, lr=0.000190071, gnorm=1.296, loss_scale=8192, train_wall=128, wall=363401
2023-01-16 20:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 20:45:44 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 4.598 | nll_loss 1.977 | word_ins 3.74 | length 8.571 | ppl 24.21 | wps 68889.8 | wpb 40242.5 | bsz 1500 | num_updates 276863 | best_loss 4.422
2023-01-16 20:45:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 20:46:14 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint140.pt (epoch 140 @ 276863 updates, score 4.598) (writing took 29.67119280109182 seconds)
2023-01-16 20:46:14 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2023-01-16 20:46:14 | INFO | train | epoch 140 | loss 2.969 | nll_loss 0.848 | word_ins 2.676 | length 2.937 | ppl 7.83 | wps 44889.3 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 276863 | lr 0.00019005 | gnorm 1.283 | loss_scale 8192 | train_wall 2548 | wall 363528
2023-01-16 20:46:14 | INFO | fairseq.trainer | begin training epoch 141
2023-01-16 20:47:15 | INFO | train_inner | epoch 141:     37 / 1978 loss=2.967, nll_loss=0.841, word_ins=2.67, length=2.975, ppl=7.82, wps=31567.3, ups=0.53, wpb=59653.8, bsz=1982.5, num_updates=276900, lr=0.000190037, gnorm=1.299, loss_scale=8192, train_wall=129, wall=363590
2023-01-16 20:49:26 | INFO | train_inner | epoch 141:    137 / 1978 loss=2.959, nll_loss=0.838, word_ins=2.668, length=2.917, ppl=7.78, wps=45006.2, ups=0.77, wpb=58765, bsz=1984.6, num_updates=277000, lr=0.000190003, gnorm=1.29, loss_scale=8192, train_wall=130, wall=363720
2023-01-16 20:51:36 | INFO | train_inner | epoch 141:    237 / 1978 loss=2.947, nll_loss=0.826, word_ins=2.656, length=2.91, ppl=7.71, wps=45651.1, ups=0.77, wpb=59349.5, bsz=2041.1, num_updates=277100, lr=0.000189969, gnorm=1.223, loss_scale=8192, train_wall=130, wall=363850
2023-01-16 20:53:46 | INFO | train_inner | epoch 141:    337 / 1978 loss=2.948, nll_loss=0.832, word_ins=2.661, length=2.872, ppl=7.72, wps=45922.4, ups=0.77, wpb=59628, bsz=2043.4, num_updates=277200, lr=0.000189934, gnorm=1.247, loss_scale=8192, train_wall=130, wall=363980
2023-01-16 20:55:55 | INFO | train_inner | epoch 141:    437 / 1978 loss=2.944, nll_loss=0.825, word_ins=2.655, length=2.889, ppl=7.7, wps=46298.6, ups=0.77, wpb=59814.1, bsz=2100.6, num_updates=277300, lr=0.0001899, gnorm=1.234, loss_scale=8192, train_wall=129, wall=364109
2023-01-16 20:58:03 | INFO | train_inner | epoch 141:    537 / 1978 loss=2.975, nll_loss=0.853, word_ins=2.682, length=2.937, ppl=7.86, wps=46169.8, ups=0.78, wpb=59037.2, bsz=2011.8, num_updates=277400, lr=0.000189866, gnorm=1.358, loss_scale=8192, train_wall=128, wall=364237
2023-01-16 21:00:10 | INFO | train_inner | epoch 141:    637 / 1978 loss=2.986, nll_loss=0.865, word_ins=2.691, length=2.948, ppl=7.92, wps=46579.8, ups=0.79, wpb=59303.9, bsz=1901, num_updates=277500, lr=0.000189832, gnorm=1.306, loss_scale=8192, train_wall=127, wall=364364
2023-01-16 21:02:21 | INFO | train_inner | epoch 141:    737 / 1978 loss=2.974, nll_loss=0.853, word_ins=2.681, length=2.937, ppl=7.86, wps=45501.9, ups=0.77, wpb=59333.4, bsz=1982.2, num_updates=277600, lr=0.000189797, gnorm=1.322, loss_scale=8192, train_wall=130, wall=364495
2023-01-16 21:04:32 | INFO | train_inner | epoch 141:    837 / 1978 loss=2.941, nll_loss=0.821, word_ins=2.651, length=2.896, ppl=7.68, wps=45589.7, ups=0.76, wpb=59843.8, bsz=2070.7, num_updates=277700, lr=0.000189763, gnorm=1.232, loss_scale=8192, train_wall=131, wall=364626
2023-01-16 21:06:41 | INFO | train_inner | epoch 141:    937 / 1978 loss=2.976, nll_loss=0.854, word_ins=2.681, length=2.946, ppl=7.87, wps=45793.6, ups=0.77, wpb=59109.8, bsz=1998.7, num_updates=277800, lr=0.000189729, gnorm=1.288, loss_scale=8192, train_wall=129, wall=364755
2023-01-16 21:08:51 | INFO | train_inner | epoch 141:   1037 / 1978 loss=2.971, nll_loss=0.856, word_ins=2.684, length=2.874, ppl=7.84, wps=44953.5, ups=0.77, wpb=58627.6, bsz=2015.3, num_updates=277900, lr=0.000189695, gnorm=1.27, loss_scale=8192, train_wall=130, wall=364886
2023-01-16 21:11:01 | INFO | train_inner | epoch 141:   1137 / 1978 loss=2.959, nll_loss=0.832, word_ins=2.662, length=2.972, ppl=7.78, wps=45674.1, ups=0.77, wpb=59166.8, bsz=2048.6, num_updates=278000, lr=0.000189661, gnorm=1.267, loss_scale=8192, train_wall=129, wall=365015
2023-01-16 21:13:10 | INFO | train_inner | epoch 141:   1237 / 1978 loss=2.96, nll_loss=0.837, word_ins=2.666, length=2.937, ppl=7.78, wps=45924, ups=0.78, wpb=59100.6, bsz=2068.7, num_updates=278100, lr=0.000189627, gnorm=1.3, loss_scale=8192, train_wall=128, wall=365144
2023-01-16 21:15:18 | INFO | train_inner | epoch 141:   1337 / 1978 loss=2.978, nll_loss=0.851, word_ins=2.679, length=2.995, ppl=7.88, wps=46498.6, ups=0.78, wpb=59532.3, bsz=1941.2, num_updates=278200, lr=0.000189593, gnorm=1.29, loss_scale=8192, train_wall=128, wall=365272
2023-01-16 21:17:26 | INFO | train_inner | epoch 141:   1437 / 1978 loss=2.97, nll_loss=0.849, word_ins=2.677, length=2.935, ppl=7.84, wps=46645.4, ups=0.78, wpb=59765, bsz=1990.8, num_updates=278300, lr=0.000189559, gnorm=1.278, loss_scale=8192, train_wall=128, wall=365400
2023-01-16 21:19:37 | INFO | train_inner | epoch 141:   1537 / 1978 loss=2.965, nll_loss=0.844, word_ins=2.672, length=2.924, ppl=7.81, wps=45204.5, ups=0.76, wpb=59406.3, bsz=2070.1, num_updates=278400, lr=0.000189525, gnorm=1.284, loss_scale=8192, train_wall=131, wall=365531
2023-01-16 21:21:47 | INFO | train_inner | epoch 141:   1637 / 1978 loss=3.03, nll_loss=0.908, word_ins=2.731, length=2.991, ppl=8.17, wps=45326.4, ups=0.77, wpb=58635.9, bsz=1813.7, num_updates=278500, lr=0.00018949, gnorm=1.28, loss_scale=8192, train_wall=129, wall=365661
2023-01-16 21:23:57 | INFO | train_inner | epoch 141:   1737 / 1978 loss=2.952, nll_loss=0.826, word_ins=2.656, length=2.964, ppl=7.74, wps=45679, ups=0.77, wpb=59481.8, bsz=2059.2, num_updates=278600, lr=0.000189456, gnorm=1.27, loss_scale=8192, train_wall=130, wall=365791
2023-01-16 21:24:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 21:26:09 | INFO | train_inner | epoch 141:   1838 / 1978 loss=2.968, nll_loss=0.842, word_ins=2.671, length=2.973, ppl=7.82, wps=45034.9, ups=0.76, wpb=59391.3, bsz=2017, num_updates=278700, lr=0.000189422, gnorm=1.306, loss_scale=8192, train_wall=132, wall=365923
2023-01-16 21:28:18 | INFO | train_inner | epoch 141:   1938 / 1978 loss=2.988, nll_loss=0.864, word_ins=2.691, length=2.969, ppl=7.93, wps=45550.4, ups=0.77, wpb=58783.2, bsz=1975.5, num_updates=278800, lr=0.000189389, gnorm=1.299, loss_scale=8192, train_wall=129, wall=366052
2023-01-16 21:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 21:29:24 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 4.651 | nll_loss 1.96 | word_ins 3.724 | length 9.271 | ppl 25.12 | wps 87488.4 | wpb 40242.5 | bsz 1500 | num_updates 278840 | best_loss 4.422
2023-01-16 21:29:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 21:29:51 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint141.pt (epoch 141 @ 278840 updates, score 4.651) (writing took 26.95490279281512 seconds)
2023-01-16 21:29:51 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2023-01-16 21:29:51 | INFO | train | epoch 141 | loss 2.969 | nll_loss 0.847 | word_ins 2.675 | length 2.939 | ppl 7.83 | wps 44785.5 | ups 0.76 | wpb 59286 | bsz 2002.9 | num_updates 278840 | lr 0.000189375 | gnorm 1.285 | loss_scale 8192 | train_wall 2554 | wall 366145
2023-01-16 21:29:51 | INFO | fairseq.trainer | begin training epoch 142
2023-01-16 21:31:19 | INFO | train_inner | epoch 142:     60 / 1978 loss=2.994, nll_loss=0.868, word_ins=2.694, length=2.998, ppl=7.96, wps=32494.7, ups=0.55, wpb=58789.5, bsz=1902, num_updates=278900, lr=0.000189355, gnorm=1.322, loss_scale=8192, train_wall=126, wall=366233
2023-01-16 21:33:28 | INFO | train_inner | epoch 142:    160 / 1978 loss=2.948, nll_loss=0.827, word_ins=2.658, length=2.9, ppl=7.72, wps=45883.9, ups=0.78, wpb=59133.7, bsz=2090.3, num_updates=279000, lr=0.000189321, gnorm=1.237, loss_scale=8192, train_wall=129, wall=366362
2023-01-16 21:35:37 | INFO | train_inner | epoch 142:    260 / 1978 loss=2.977, nll_loss=0.853, word_ins=2.681, length=2.959, ppl=7.87, wps=45831.6, ups=0.77, wpb=59400.8, bsz=1934.5, num_updates=279100, lr=0.000189287, gnorm=1.306, loss_scale=8192, train_wall=129, wall=366491
2023-01-16 21:37:47 | INFO | train_inner | epoch 142:    360 / 1978 loss=2.963, nll_loss=0.843, word_ins=2.672, length=2.909, ppl=7.8, wps=45074.4, ups=0.77, wpb=58556.2, bsz=2007.7, num_updates=279200, lr=0.000189253, gnorm=1.271, loss_scale=8192, train_wall=130, wall=366621
2023-01-16 21:39:58 | INFO | train_inner | epoch 142:    460 / 1978 loss=2.948, nll_loss=0.826, word_ins=2.656, length=2.92, ppl=7.72, wps=45581.3, ups=0.76, wpb=59639, bsz=2036.4, num_updates=279300, lr=0.000189219, gnorm=1.28, loss_scale=8192, train_wall=130, wall=366752
2023-01-16 21:42:09 | INFO | train_inner | epoch 142:    560 / 1978 loss=2.951, nll_loss=0.827, word_ins=2.657, length=2.938, ppl=7.73, wps=45536.4, ups=0.76, wpb=59561.9, bsz=2031.2, num_updates=279400, lr=0.000189185, gnorm=1.293, loss_scale=8192, train_wall=130, wall=366883
2023-01-16 21:44:20 | INFO | train_inner | epoch 142:    660 / 1978 loss=2.937, nll_loss=0.819, word_ins=2.65, length=2.869, ppl=7.66, wps=45481.2, ups=0.76, wpb=59724, bsz=2107.6, num_updates=279500, lr=0.000189151, gnorm=1.251, loss_scale=8192, train_wall=131, wall=367014
2023-01-16 21:46:28 | INFO | train_inner | epoch 142:    760 / 1978 loss=2.97, nll_loss=0.842, word_ins=2.671, length=2.989, ppl=7.84, wps=46324, ups=0.78, wpb=59046.6, bsz=1966.7, num_updates=279600, lr=0.000189117, gnorm=1.329, loss_scale=8192, train_wall=127, wall=367142
2023-01-16 21:48:36 | INFO | train_inner | epoch 142:    860 / 1978 loss=2.972, nll_loss=0.853, word_ins=2.68, length=2.917, ppl=7.85, wps=46739.3, ups=0.78, wpb=59787.5, bsz=1976.4, num_updates=279700, lr=0.000189084, gnorm=1.291, loss_scale=8192, train_wall=128, wall=367270
2023-01-16 21:50:44 | INFO | train_inner | epoch 142:    960 / 1978 loss=2.967, nll_loss=0.846, word_ins=2.674, length=2.93, ppl=7.82, wps=46344.1, ups=0.78, wpb=59536, bsz=1975.8, num_updates=279800, lr=0.00018905, gnorm=1.27, loss_scale=8192, train_wall=128, wall=367398
2023-01-16 21:52:53 | INFO | train_inner | epoch 142:   1060 / 1978 loss=2.998, nll_loss=0.877, word_ins=2.702, length=2.955, ppl=7.99, wps=45746.8, ups=0.77, wpb=59074.4, bsz=2007, num_updates=279900, lr=0.000189016, gnorm=1.316, loss_scale=8192, train_wall=129, wall=367527
2023-01-16 21:55:04 | INFO | train_inner | epoch 142:   1160 / 1978 loss=2.945, nll_loss=0.826, word_ins=2.656, length=2.891, ppl=7.7, wps=45327.8, ups=0.76, wpb=59401.3, bsz=2108.7, num_updates=280000, lr=0.000188982, gnorm=1.273, loss_scale=8192, train_wall=131, wall=367658
2023-01-16 21:57:14 | INFO | train_inner | epoch 142:   1260 / 1978 loss=2.976, nll_loss=0.852, word_ins=2.68, length=2.956, ppl=7.87, wps=45585.5, ups=0.77, wpb=59325.2, bsz=1970.4, num_updates=280100, lr=0.000188948, gnorm=1.284, loss_scale=8192, train_wall=130, wall=367788
2023-01-16 21:59:23 | INFO | train_inner | epoch 142:   1360 / 1978 loss=2.977, nll_loss=0.851, word_ins=2.679, length=2.983, ppl=7.87, wps=46091.1, ups=0.78, wpb=59451.8, bsz=1956.9, num_updates=280200, lr=0.000188915, gnorm=1.242, loss_scale=8192, train_wall=129, wall=367917
2023-01-16 22:01:33 | INFO | train_inner | epoch 142:   1460 / 1978 loss=2.99, nll_loss=0.87, word_ins=2.696, length=2.943, ppl=7.95, wps=45541.5, ups=0.77, wpb=59036.7, bsz=1952.3, num_updates=280300, lr=0.000188881, gnorm=1.273, loss_scale=8192, train_wall=129, wall=368047
2023-01-16 22:03:39 | INFO | train_inner | epoch 142:   1560 / 1978 loss=2.995, nll_loss=0.865, word_ins=2.691, length=3.035, ppl=7.97, wps=47014.8, ups=0.79, wpb=59410.1, bsz=1884.3, num_updates=280400, lr=0.000188847, gnorm=1.309, loss_scale=8192, train_wall=126, wall=368173
2023-01-16 22:05:49 | INFO | train_inner | epoch 142:   1660 / 1978 loss=2.949, nll_loss=0.831, word_ins=2.661, length=2.884, ppl=7.72, wps=46218.9, ups=0.77, wpb=59747.4, bsz=2076.7, num_updates=280500, lr=0.000188814, gnorm=1.304, loss_scale=8192, train_wall=129, wall=368303
2023-01-16 22:07:57 | INFO | train_inner | epoch 142:   1760 / 1978 loss=2.965, nll_loss=0.84, word_ins=2.669, length=2.957, ppl=7.81, wps=46122.8, ups=0.78, wpb=59128.4, bsz=2007.2, num_updates=280600, lr=0.00018878, gnorm=1.315, loss_scale=8192, train_wall=128, wall=368431
2023-01-16 22:10:06 | INFO | train_inner | epoch 142:   1860 / 1978 loss=2.995, nll_loss=0.872, word_ins=2.698, length=2.968, ppl=7.97, wps=45413, ups=0.78, wpb=58541, bsz=1915.6, num_updates=280700, lr=0.000188746, gnorm=1.253, loss_scale=8192, train_wall=129, wall=368560
2023-01-16 22:12:16 | INFO | train_inner | epoch 142:   1960 / 1978 loss=2.969, nll_loss=0.849, word_ins=2.677, length=2.921, ppl=7.83, wps=45455, ups=0.77, wpb=59217.6, bsz=2049, num_updates=280800, lr=0.000188713, gnorm=1.29, loss_scale=8192, train_wall=130, wall=368690
2023-01-16 22:12:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 22:12:53 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 4.56 | nll_loss 1.954 | word_ins 3.713 | length 8.465 | ppl 23.59 | wps 62370.7 | wpb 40242.5 | bsz 1500 | num_updates 280818 | best_loss 4.422
2023-01-16 22:12:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 22:13:23 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint142.pt (epoch 142 @ 280818 updates, score 4.56) (writing took 29.21022303402424 seconds)
2023-01-16 22:13:23 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2023-01-16 22:13:23 | INFO | train | epoch 142 | loss 2.967 | nll_loss 0.845 | word_ins 2.673 | length 2.937 | ppl 7.82 | wps 44895.2 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 280818 | lr 0.000188707 | gnorm 1.283 | loss_scale 8192 | train_wall 2551 | wall 368757
2023-01-16 22:13:23 | INFO | fairseq.trainer | begin training epoch 143
2023-01-16 22:15:25 | INFO | train_inner | epoch 143:     82 / 1978 loss=2.938, nll_loss=0.821, word_ins=2.652, length=2.854, ppl=7.66, wps=31320.4, ups=0.53, wpb=59025.4, bsz=2083.6, num_updates=280900, lr=0.000188679, gnorm=1.27, loss_scale=8192, train_wall=132, wall=368879
2023-01-16 22:17:36 | INFO | train_inner | epoch 143:    182 / 1978 loss=2.957, nll_loss=0.838, word_ins=2.668, length=2.889, ppl=7.76, wps=45052.4, ups=0.76, wpb=59009.6, bsz=2091.2, num_updates=281000, lr=0.000188646, gnorm=1.224, loss_scale=8192, train_wall=131, wall=369010
2023-01-16 22:19:45 | INFO | train_inner | epoch 143:    282 / 1978 loss=2.965, nll_loss=0.847, word_ins=2.676, length=2.892, ppl=7.81, wps=45959.9, ups=0.77, wpb=59409.1, bsz=2025.8, num_updates=281100, lr=0.000188612, gnorm=1.291, loss_scale=8192, train_wall=129, wall=369139
2023-01-16 22:21:53 | INFO | train_inner | epoch 143:    382 / 1978 loss=2.974, nll_loss=0.852, word_ins=2.68, length=2.943, ppl=7.86, wps=46756.3, ups=0.78, wpb=59993.5, bsz=1960.1, num_updates=281200, lr=0.000188579, gnorm=1.332, loss_scale=8192, train_wall=128, wall=369267
2023-01-16 22:24:01 | INFO | train_inner | epoch 143:    482 / 1978 loss=2.985, nll_loss=0.861, word_ins=2.689, length=2.959, ppl=7.92, wps=46122.2, ups=0.78, wpb=59032, bsz=1921.5, num_updates=281300, lr=0.000188545, gnorm=1.293, loss_scale=8192, train_wall=128, wall=369395
2023-01-16 22:26:10 | INFO | train_inner | epoch 143:    582 / 1978 loss=2.978, nll_loss=0.862, word_ins=2.689, length=2.882, ppl=7.88, wps=46052.3, ups=0.77, wpb=59535.2, bsz=2016.5, num_updates=281400, lr=0.000188512, gnorm=1.261, loss_scale=8192, train_wall=129, wall=369524
2023-01-16 22:28:21 | INFO | train_inner | epoch 143:    682 / 1978 loss=2.963, nll_loss=0.84, word_ins=2.669, length=2.948, ppl=7.8, wps=45446.3, ups=0.77, wpb=59313.8, bsz=2034.9, num_updates=281500, lr=0.000188478, gnorm=1.265, loss_scale=8192, train_wall=130, wall=369655
2023-01-16 22:30:30 | INFO | train_inner | epoch 143:    782 / 1978 loss=2.994, nll_loss=0.869, word_ins=2.696, length=2.983, ppl=7.97, wps=45568.2, ups=0.77, wpb=58833.2, bsz=1951.7, num_updates=281600, lr=0.000188445, gnorm=1.353, loss_scale=8192, train_wall=129, wall=369784
2023-01-16 22:32:40 | INFO | train_inner | epoch 143:    882 / 1978 loss=2.937, nll_loss=0.819, word_ins=2.649, length=2.879, ppl=7.66, wps=46065.6, ups=0.77, wpb=60080.1, bsz=1995.4, num_updates=281700, lr=0.000188411, gnorm=1.287, loss_scale=8192, train_wall=130, wall=369915
2023-01-16 22:34:50 | INFO | train_inner | epoch 143:    982 / 1978 loss=2.949, nll_loss=0.824, word_ins=2.654, length=2.949, ppl=7.72, wps=45392.4, ups=0.77, wpb=59020.2, bsz=2011.5, num_updates=281800, lr=0.000188378, gnorm=1.271, loss_scale=8192, train_wall=130, wall=370045
2023-01-16 22:36:59 | INFO | train_inner | epoch 143:   1082 / 1978 loss=2.972, nll_loss=0.845, word_ins=2.673, length=2.988, ppl=7.85, wps=46447.9, ups=0.78, wpb=59490.9, bsz=1914.6, num_updates=281900, lr=0.000188344, gnorm=1.268, loss_scale=8192, train_wall=128, wall=370173
2023-01-16 22:39:06 | INFO | train_inner | epoch 143:   1182 / 1978 loss=2.965, nll_loss=0.843, word_ins=2.671, length=2.933, ppl=7.81, wps=46782.4, ups=0.79, wpb=59435, bsz=2007, num_updates=282000, lr=0.000188311, gnorm=1.31, loss_scale=8192, train_wall=127, wall=370300
2023-01-16 22:41:14 | INFO | train_inner | epoch 143:   1282 / 1978 loss=2.971, nll_loss=0.845, word_ins=2.673, length=2.977, ppl=7.84, wps=46324.1, ups=0.78, wpb=59386.1, bsz=1993.9, num_updates=282100, lr=0.000188278, gnorm=1.316, loss_scale=8192, train_wall=128, wall=370428
2023-01-16 22:43:22 | INFO | train_inner | epoch 143:   1382 / 1978 loss=2.965, nll_loss=0.844, word_ins=2.672, length=2.93, ppl=7.81, wps=45841.7, ups=0.78, wpb=58938.2, bsz=2036.5, num_updates=282200, lr=0.000188244, gnorm=1.299, loss_scale=8192, train_wall=128, wall=370556
2023-01-16 22:45:31 | INFO | train_inner | epoch 143:   1482 / 1978 loss=2.96, nll_loss=0.836, word_ins=2.665, length=2.951, ppl=7.78, wps=45574.6, ups=0.78, wpb=58750.5, bsz=1957.2, num_updates=282300, lr=0.000188211, gnorm=1.284, loss_scale=8192, train_wall=128, wall=370685
2023-01-16 22:47:41 | INFO | train_inner | epoch 143:   1582 / 1978 loss=2.968, nll_loss=0.845, word_ins=2.673, length=2.945, ppl=7.82, wps=45389.7, ups=0.77, wpb=58982.6, bsz=2029.8, num_updates=282400, lr=0.000188177, gnorm=1.242, loss_scale=8192, train_wall=130, wall=370815
2023-01-16 22:49:52 | INFO | train_inner | epoch 143:   1682 / 1978 loss=2.964, nll_loss=0.844, word_ins=2.672, length=2.924, ppl=7.8, wps=45226.7, ups=0.77, wpb=58953.8, bsz=2014.6, num_updates=282500, lr=0.000188144, gnorm=1.302, loss_scale=8192, train_wall=130, wall=370946
2023-01-16 22:52:03 | INFO | train_inner | epoch 143:   1782 / 1978 loss=2.962, nll_loss=0.841, word_ins=2.669, length=2.926, ppl=7.79, wps=44955.6, ups=0.76, wpb=58963.3, bsz=2069.8, num_updates=282600, lr=0.000188111, gnorm=1.28, loss_scale=8192, train_wall=131, wall=371077
2023-01-16 22:54:12 | INFO | train_inner | epoch 143:   1882 / 1978 loss=2.958, nll_loss=0.833, word_ins=2.662, length=2.951, ppl=7.77, wps=46372.7, ups=0.77, wpb=60054, bsz=2004.8, num_updates=282700, lr=0.000188078, gnorm=1.333, loss_scale=8192, train_wall=129, wall=371206
2023-01-16 22:54:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-16 22:56:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 22:56:28 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 4.678 | nll_loss 1.982 | word_ins 3.744 | length 9.332 | ppl 25.6 | wps 90812.7 | wpb 40242.5 | bsz 1500 | num_updates 282795 | best_loss 4.422
2023-01-16 22:56:28 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 22:56:56 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint143.pt (epoch 143 @ 282795 updates, score 4.678) (writing took 27.552750294096768 seconds)
2023-01-16 22:56:56 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2023-01-16 22:56:56 | INFO | train | epoch 143 | loss 2.965 | nll_loss 0.843 | word_ins 2.672 | length 2.935 | ppl 7.81 | wps 44850 | ups 0.76 | wpb 59284.9 | bsz 2003.1 | num_updates 282795 | lr 0.000188046 | gnorm 1.29 | loss_scale 8192 | train_wall 2553 | wall 371370
2023-01-16 22:56:56 | INFO | fairseq.trainer | begin training epoch 144
2023-01-16 22:57:14 | INFO | train_inner | epoch 144:      5 / 1978 loss=2.973, nll_loss=0.846, word_ins=2.675, length=2.984, ppl=7.85, wps=32719.2, ups=0.55, wpb=59462.8, bsz=1963, num_updates=282800, lr=0.000188044, gnorm=1.331, loss_scale=8192, train_wall=129, wall=371388
2023-01-16 22:59:24 | INFO | train_inner | epoch 144:    105 / 1978 loss=2.945, nll_loss=0.827, word_ins=2.658, length=2.869, ppl=7.7, wps=46069, ups=0.77, wpb=59762.9, bsz=2072.4, num_updates=282900, lr=0.000188011, gnorm=1.259, loss_scale=8192, train_wall=129, wall=371518
2023-01-16 23:01:34 | INFO | train_inner | epoch 144:    205 / 1978 loss=2.965, nll_loss=0.847, word_ins=2.676, length=2.889, ppl=7.81, wps=45424, ups=0.77, wpb=59054.7, bsz=2016.8, num_updates=283000, lr=0.000187978, gnorm=1.309, loss_scale=8192, train_wall=130, wall=371648
2023-01-16 23:03:45 | INFO | train_inner | epoch 144:    305 / 1978 loss=2.956, nll_loss=0.834, word_ins=2.663, length=2.928, ppl=7.76, wps=45126.1, ups=0.76, wpb=59317.1, bsz=2020.3, num_updates=283100, lr=0.000187945, gnorm=1.302, loss_scale=8192, train_wall=131, wall=371779
2023-01-16 23:05:56 | INFO | train_inner | epoch 144:    405 / 1978 loss=2.943, nll_loss=0.822, word_ins=2.652, length=2.902, ppl=7.69, wps=45509.7, ups=0.76, wpb=59682.7, bsz=2062, num_updates=283200, lr=0.000187912, gnorm=1.297, loss_scale=8192, train_wall=131, wall=371910
2023-01-16 23:08:08 | INFO | train_inner | epoch 144:    505 / 1978 loss=2.953, nll_loss=0.835, word_ins=2.664, length=2.891, ppl=7.75, wps=45108.2, ups=0.76, wpb=59157, bsz=1997, num_updates=283300, lr=0.000187878, gnorm=1.233, loss_scale=8192, train_wall=131, wall=372042
2023-01-16 23:10:17 | INFO | train_inner | epoch 144:    605 / 1978 loss=2.973, nll_loss=0.851, word_ins=2.679, length=2.935, ppl=7.85, wps=45768, ups=0.77, wpb=59209.5, bsz=1949.6, num_updates=283400, lr=0.000187845, gnorm=1.32, loss_scale=8192, train_wall=129, wall=372171
2023-01-16 23:12:25 | INFO | train_inner | epoch 144:    705 / 1978 loss=2.96, nll_loss=0.835, word_ins=2.664, length=2.957, ppl=7.78, wps=46284, ups=0.78, wpb=59093.4, bsz=1977.4, num_updates=283500, lr=0.000187812, gnorm=1.254, loss_scale=8192, train_wall=127, wall=372299
2023-01-16 23:14:32 | INFO | train_inner | epoch 144:    805 / 1978 loss=2.962, nll_loss=0.838, word_ins=2.667, length=2.952, ppl=7.79, wps=46716.5, ups=0.78, wpb=59524.9, bsz=1975.3, num_updates=283600, lr=0.000187779, gnorm=1.285, loss_scale=8192, train_wall=127, wall=372426
2023-01-16 23:16:39 | INFO | train_inner | epoch 144:    905 / 1978 loss=2.96, nll_loss=0.838, word_ins=2.667, length=2.934, ppl=7.78, wps=46529.6, ups=0.79, wpb=59070.2, bsz=1991.2, num_updates=283700, lr=0.000187746, gnorm=1.287, loss_scale=8192, train_wall=127, wall=372553
2023-01-16 23:18:49 | INFO | train_inner | epoch 144:   1005 / 1978 loss=2.956, nll_loss=0.832, word_ins=2.661, length=2.949, ppl=7.76, wps=45523.8, ups=0.77, wpb=59220.9, bsz=2052.4, num_updates=283800, lr=0.000187713, gnorm=1.268, loss_scale=8192, train_wall=130, wall=372683
2023-01-16 23:21:00 | INFO | train_inner | epoch 144:   1105 / 1978 loss=2.959, nll_loss=0.84, word_ins=2.669, length=2.901, ppl=7.77, wps=45255, ups=0.77, wpb=59054, bsz=2059.1, num_updates=283900, lr=0.00018768, gnorm=1.21, loss_scale=8192, train_wall=130, wall=372814
2023-01-16 23:23:09 | INFO | train_inner | epoch 144:   1205 / 1978 loss=2.974, nll_loss=0.85, word_ins=2.678, length=2.959, ppl=7.85, wps=45753.8, ups=0.77, wpb=59263.4, bsz=1980.2, num_updates=284000, lr=0.000187647, gnorm=1.319, loss_scale=8192, train_wall=129, wall=372943
2023-01-16 23:25:19 | INFO | train_inner | epoch 144:   1305 / 1978 loss=2.991, nll_loss=0.87, word_ins=2.696, length=2.945, ppl=7.95, wps=45631.3, ups=0.77, wpb=59157.7, bsz=1917.8, num_updates=284100, lr=0.000187614, gnorm=1.337, loss_scale=8192, train_wall=129, wall=373073
2023-01-16 23:27:28 | INFO | train_inner | epoch 144:   1405 / 1978 loss=2.965, nll_loss=0.845, word_ins=2.674, length=2.912, ppl=7.81, wps=45992.9, ups=0.77, wpb=59641.7, bsz=1979.8, num_updates=284200, lr=0.000187581, gnorm=1.32, loss_scale=8192, train_wall=129, wall=373203
2023-01-16 23:29:36 | INFO | train_inner | epoch 144:   1505 / 1978 loss=2.971, nll_loss=0.85, word_ins=2.678, length=2.927, ppl=7.84, wps=46093, ups=0.79, wpb=58676.9, bsz=2000.5, num_updates=284300, lr=0.000187548, gnorm=1.264, loss_scale=8192, train_wall=127, wall=373330
2023-01-16 23:31:44 | INFO | train_inner | epoch 144:   1605 / 1978 loss=2.956, nll_loss=0.833, word_ins=2.662, length=2.941, ppl=7.76, wps=46139, ups=0.78, wpb=59407, bsz=2072.4, num_updates=284400, lr=0.000187515, gnorm=1.259, loss_scale=8192, train_wall=129, wall=373459
2023-01-16 23:33:53 | INFO | train_inner | epoch 144:   1705 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.681, length=2.953, ppl=7.87, wps=46005.6, ups=0.78, wpb=59097.9, bsz=1990.6, num_updates=284500, lr=0.000187482, gnorm=1.336, loss_scale=8192, train_wall=128, wall=373587
2023-01-16 23:36:02 | INFO | train_inner | epoch 144:   1805 / 1978 loss=2.985, nll_loss=0.865, word_ins=2.691, length=2.938, ppl=7.92, wps=46201.5, ups=0.78, wpb=59473.4, bsz=1965.7, num_updates=284600, lr=0.000187449, gnorm=1.321, loss_scale=8192, train_wall=128, wall=373716
2023-01-16 23:38:11 | INFO | train_inner | epoch 144:   1905 / 1978 loss=2.982, nll_loss=0.858, word_ins=2.685, length=2.969, ppl=7.9, wps=45841.6, ups=0.77, wpb=59444.2, bsz=1961.6, num_updates=284700, lr=0.000187416, gnorm=1.336, loss_scale=8192, train_wall=129, wall=373845
2023-01-16 23:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-16 23:40:01 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 4.668 | nll_loss 1.981 | word_ins 3.741 | length 9.268 | ppl 25.42 | wps 76636.4 | wpb 40242.5 | bsz 1500 | num_updates 284773 | best_loss 4.422
2023-01-16 23:40:01 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-16 23:40:29 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint144.pt (epoch 144 @ 284773 updates, score 4.668) (writing took 27.970715554896742 seconds)
2023-01-16 23:40:29 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2023-01-16 23:40:29 | INFO | train | epoch 144 | loss 2.965 | nll_loss 0.844 | word_ins 2.672 | length 2.932 | ppl 7.81 | wps 44871.9 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 284773 | lr 0.000187392 | gnorm 1.293 | loss_scale 8192 | train_wall 2554 | wall 373983
2023-01-16 23:40:29 | INFO | fairseq.trainer | begin training epoch 145
2023-01-16 23:41:17 | INFO | train_inner | epoch 145:     27 / 1978 loss=2.959, nll_loss=0.834, word_ins=2.663, length=2.967, ppl=7.78, wps=32011.9, ups=0.54, wpb=59562.7, bsz=2055, num_updates=284800, lr=0.000187383, gnorm=1.304, loss_scale=8192, train_wall=132, wall=374032
2023-01-16 23:43:30 | INFO | train_inner | epoch 145:    127 / 1978 loss=2.932, nll_loss=0.816, word_ins=2.647, length=2.853, ppl=7.63, wps=45442, ups=0.76, wpb=60058.3, bsz=2148, num_updates=284900, lr=0.00018735, gnorm=1.276, loss_scale=8192, train_wall=132, wall=374164
2023-01-16 23:45:38 | INFO | train_inner | epoch 145:    227 / 1978 loss=2.96, nll_loss=0.837, word_ins=2.667, length=2.933, ppl=7.78, wps=46180.8, ups=0.78, wpb=59207.8, bsz=1940.7, num_updates=285000, lr=0.000187317, gnorm=1.378, loss_scale=8192, train_wall=128, wall=374292
2023-01-16 23:47:46 | INFO | train_inner | epoch 145:    327 / 1978 loss=2.943, nll_loss=0.82, word_ins=2.65, length=2.93, ppl=7.69, wps=46404.8, ups=0.78, wpb=59516.3, bsz=2077.8, num_updates=285100, lr=0.000187284, gnorm=1.257, loss_scale=8192, train_wall=128, wall=374420
2023-01-16 23:49:54 | INFO | train_inner | epoch 145:    427 / 1978 loss=2.984, nll_loss=0.862, word_ins=2.689, length=2.948, ppl=7.91, wps=46059.5, ups=0.78, wpb=58878.5, bsz=2065.9, num_updates=285200, lr=0.000187251, gnorm=1.301, loss_scale=8192, train_wall=128, wall=374548
2023-01-16 23:52:02 | INFO | train_inner | epoch 145:    527 / 1978 loss=2.957, nll_loss=0.837, word_ins=2.666, length=2.914, ppl=7.77, wps=46244, ups=0.78, wpb=59310.6, bsz=1997.5, num_updates=285300, lr=0.000187219, gnorm=1.296, loss_scale=8192, train_wall=128, wall=374676
2023-01-16 23:54:12 | INFO | train_inner | epoch 145:    627 / 1978 loss=2.963, nll_loss=0.845, word_ins=2.673, length=2.899, ppl=7.8, wps=45250.3, ups=0.77, wpb=58884.4, bsz=2021.7, num_updates=285400, lr=0.000187186, gnorm=1.261, loss_scale=8192, train_wall=130, wall=374806
2023-01-16 23:56:22 | INFO | train_inner | epoch 145:    727 / 1978 loss=2.958, nll_loss=0.833, word_ins=2.663, length=2.948, ppl=7.77, wps=45891.8, ups=0.77, wpb=59724.9, bsz=1948.7, num_updates=285500, lr=0.000187153, gnorm=1.31, loss_scale=8192, train_wall=130, wall=374937
2023-01-16 23:58:34 | INFO | train_inner | epoch 145:    827 / 1978 loss=2.958, nll_loss=0.84, word_ins=2.669, length=2.897, ppl=7.77, wps=45124.3, ups=0.76, wpb=59239.8, bsz=2019.9, num_updates=285600, lr=0.00018712, gnorm=1.264, loss_scale=8192, train_wall=131, wall=375068
2023-01-17 00:00:43 | INFO | train_inner | epoch 145:    927 / 1978 loss=2.983, nll_loss=0.859, word_ins=2.686, length=2.973, ppl=7.91, wps=45757.8, ups=0.77, wpb=59357, bsz=1928.9, num_updates=285700, lr=0.000187088, gnorm=1.255, loss_scale=8192, train_wall=129, wall=375198
2023-01-17 00:02:53 | INFO | train_inner | epoch 145:   1027 / 1978 loss=2.953, nll_loss=0.832, word_ins=2.661, length=2.916, ppl=7.74, wps=45561.6, ups=0.77, wpb=59189.5, bsz=2038.3, num_updates=285800, lr=0.000187055, gnorm=1.299, loss_scale=8192, train_wall=130, wall=375327
2023-01-17 00:05:02 | INFO | train_inner | epoch 145:   1127 / 1978 loss=2.979, nll_loss=0.861, word_ins=2.688, length=2.905, ppl=7.88, wps=45997.1, ups=0.78, wpb=59169, bsz=1998, num_updates=285900, lr=0.000187022, gnorm=1.333, loss_scale=8192, train_wall=128, wall=375456
2023-01-17 00:07:10 | INFO | train_inner | epoch 145:   1227 / 1978 loss=2.965, nll_loss=0.841, word_ins=2.669, length=2.96, ppl=7.81, wps=46904.1, ups=0.78, wpb=59881.5, bsz=1912.7, num_updates=286000, lr=0.000186989, gnorm=1.308, loss_scale=8192, train_wall=127, wall=375584
2023-01-17 00:09:18 | INFO | train_inner | epoch 145:   1327 / 1978 loss=2.973, nll_loss=0.85, word_ins=2.677, length=2.957, ppl=7.85, wps=46535.7, ups=0.78, wpb=59681.6, bsz=1941, num_updates=286100, lr=0.000186957, gnorm=1.377, loss_scale=8192, train_wall=128, wall=375712
2023-01-17 00:11:27 | INFO | train_inner | epoch 145:   1427 / 1978 loss=2.977, nll_loss=0.852, word_ins=2.68, length=2.972, ppl=7.87, wps=45251.5, ups=0.77, wpb=58440.6, bsz=1970.3, num_updates=286200, lr=0.000186924, gnorm=1.287, loss_scale=8192, train_wall=129, wall=375841
2023-01-17 00:13:37 | INFO | train_inner | epoch 145:   1527 / 1978 loss=2.988, nll_loss=0.863, word_ins=2.689, length=2.986, ppl=7.93, wps=45972.2, ups=0.77, wpb=59489.1, bsz=1901.7, num_updates=286300, lr=0.000186891, gnorm=1.279, loss_scale=8192, train_wall=129, wall=375971
2023-01-17 00:15:48 | INFO | train_inner | epoch 145:   1627 / 1978 loss=2.941, nll_loss=0.821, word_ins=2.652, length=2.891, ppl=7.68, wps=44763.3, ups=0.76, wpb=58669.2, bsz=2113, num_updates=286400, lr=0.000186859, gnorm=1.239, loss_scale=8192, train_wall=131, wall=376102
2023-01-17 00:17:58 | INFO | train_inner | epoch 145:   1727 / 1978 loss=2.975, nll_loss=0.857, word_ins=2.684, length=2.909, ppl=7.86, wps=45703.4, ups=0.77, wpb=59528.8, bsz=1951.4, num_updates=286500, lr=0.000186826, gnorm=1.267, loss_scale=8192, train_wall=130, wall=376232
2023-01-17 00:20:06 | INFO | train_inner | epoch 145:   1827 / 1978 loss=2.976, nll_loss=0.853, word_ins=2.681, length=2.958, ppl=7.87, wps=46037.5, ups=0.78, wpb=59141.2, bsz=1967.6, num_updates=286600, lr=0.000186794, gnorm=1.25, loss_scale=8192, train_wall=128, wall=376360
2023-01-17 00:22:14 | INFO | train_inner | epoch 145:   1927 / 1978 loss=2.991, nll_loss=0.873, word_ins=2.699, length=2.916, ppl=7.95, wps=46248.7, ups=0.78, wpb=58959.9, bsz=1994.4, num_updates=286700, lr=0.000186761, gnorm=1.309, loss_scale=8192, train_wall=127, wall=376488
2023-01-17 00:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 00:23:33 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 4.638 | nll_loss 1.97 | word_ins 3.731 | length 9.066 | ppl 24.9 | wps 104881 | wpb 40242.5 | bsz 1500 | num_updates 286751 | best_loss 4.422
2023-01-17 00:23:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 00:24:00 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint145.pt (epoch 145 @ 286751 updates, score 4.638) (writing took 26.855531256645918 seconds)
2023-01-17 00:24:00 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2023-01-17 00:24:00 | INFO | train | epoch 145 | loss 2.965 | nll_loss 0.844 | word_ins 2.672 | length 2.928 | ppl 7.81 | wps 44923.7 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 286751 | lr 0.000186744 | gnorm 1.291 | loss_scale 8192 | train_wall 2552 | wall 376594
2023-01-17 00:24:00 | INFO | fairseq.trainer | begin training epoch 146
2023-01-17 00:25:16 | INFO | train_inner | epoch 146:     49 / 1978 loss=2.947, nll_loss=0.83, word_ins=2.66, length=2.873, ppl=7.71, wps=32627.2, ups=0.55, wpb=59458.3, bsz=2086.3, num_updates=286800, lr=0.000186728, gnorm=1.333, loss_scale=8192, train_wall=129, wall=376670
2023-01-17 00:26:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-17 00:27:28 | INFO | train_inner | epoch 146:    150 / 1978 loss=2.972, nll_loss=0.853, word_ins=2.681, length=2.912, ppl=7.85, wps=45200.7, ups=0.76, wpb=59542.3, bsz=1981, num_updates=286900, lr=0.000186696, gnorm=1.293, loss_scale=8192, train_wall=131, wall=376802
2023-01-17 00:29:38 | INFO | train_inner | epoch 146:    250 / 1978 loss=2.983, nll_loss=0.861, word_ins=2.689, length=2.946, ppl=7.91, wps=45003.8, ups=0.77, wpb=58532.1, bsz=1925, num_updates=287000, lr=0.000186663, gnorm=1.33, loss_scale=8192, train_wall=130, wall=376932
2023-01-17 00:31:47 | INFO | train_inner | epoch 146:    350 / 1978 loss=2.971, nll_loss=0.843, word_ins=2.672, length=2.988, ppl=7.84, wps=45882.5, ups=0.77, wpb=59459.7, bsz=1910.7, num_updates=287100, lr=0.000186631, gnorm=1.322, loss_scale=8192, train_wall=129, wall=377062
2023-01-17 00:33:57 | INFO | train_inner | epoch 146:    450 / 1978 loss=2.958, nll_loss=0.839, word_ins=2.668, length=2.903, ppl=7.77, wps=45804.1, ups=0.77, wpb=59571.3, bsz=1989.5, num_updates=287200, lr=0.000186598, gnorm=1.317, loss_scale=8192, train_wall=130, wall=377192
2023-01-17 00:36:07 | INFO | train_inner | epoch 146:    550 / 1978 loss=2.975, nll_loss=0.855, word_ins=2.682, length=2.93, ppl=7.86, wps=45864.6, ups=0.77, wpb=59264.1, bsz=1954.2, num_updates=287300, lr=0.000186566, gnorm=1.322, loss_scale=8192, train_wall=129, wall=377321
2023-01-17 00:38:14 | INFO | train_inner | epoch 146:    650 / 1978 loss=2.965, nll_loss=0.844, word_ins=2.672, length=2.928, ppl=7.81, wps=46828.5, ups=0.78, wpb=59791.7, bsz=1939.7, num_updates=287400, lr=0.000186533, gnorm=1.324, loss_scale=8192, train_wall=127, wall=377448
2023-01-17 00:40:23 | INFO | train_inner | epoch 146:    750 / 1978 loss=2.955, nll_loss=0.837, word_ins=2.666, length=2.883, ppl=7.75, wps=46004.6, ups=0.78, wpb=59223.9, bsz=2048.1, num_updates=287500, lr=0.000186501, gnorm=1.269, loss_scale=8192, train_wall=129, wall=377577
2023-01-17 00:42:31 | INFO | train_inner | epoch 146:    850 / 1978 loss=2.962, nll_loss=0.842, word_ins=2.67, length=2.917, ppl=7.79, wps=45747.6, ups=0.78, wpb=58634.8, bsz=2097, num_updates=287600, lr=0.000186469, gnorm=1.254, loss_scale=8192, train_wall=128, wall=377705
2023-01-17 00:44:40 | INFO | train_inner | epoch 146:    950 / 1978 loss=2.946, nll_loss=0.825, word_ins=2.655, length=2.906, ppl=7.7, wps=46087.8, ups=0.78, wpb=59454.6, bsz=1987.8, num_updates=287700, lr=0.000186436, gnorm=1.27, loss_scale=8192, train_wall=129, wall=377834
2023-01-17 00:46:52 | INFO | train_inner | epoch 146:   1050 / 1978 loss=2.94, nll_loss=0.822, word_ins=2.652, length=2.875, ppl=7.67, wps=45041.6, ups=0.76, wpb=59107.6, bsz=2131.1, num_updates=287800, lr=0.000186404, gnorm=1.287, loss_scale=8192, train_wall=131, wall=377966
2023-01-17 00:49:03 | INFO | train_inner | epoch 146:   1150 / 1978 loss=2.94, nll_loss=0.82, word_ins=2.65, length=2.898, ppl=7.68, wps=45528.3, ups=0.76, wpb=59779.7, bsz=2089, num_updates=287900, lr=0.000186371, gnorm=1.285, loss_scale=8192, train_wall=131, wall=378097
2023-01-17 00:51:13 | INFO | train_inner | epoch 146:   1250 / 1978 loss=2.956, nll_loss=0.839, word_ins=2.668, length=2.886, ppl=7.76, wps=45734.6, ups=0.77, wpb=59332.9, bsz=1983.9, num_updates=288000, lr=0.000186339, gnorm=1.277, loss_scale=8192, train_wall=129, wall=378227
2023-01-17 00:53:22 | INFO | train_inner | epoch 146:   1350 / 1978 loss=2.983, nll_loss=0.865, word_ins=2.692, length=2.913, ppl=7.91, wps=45338.1, ups=0.77, wpb=58821, bsz=1962.3, num_updates=288100, lr=0.000186307, gnorm=1.288, loss_scale=8192, train_wall=129, wall=378356
2023-01-17 00:55:30 | INFO | train_inner | epoch 146:   1450 / 1978 loss=2.948, nll_loss=0.824, word_ins=2.655, length=2.937, ppl=7.72, wps=46209.9, ups=0.78, wpb=58956.2, bsz=2047.2, num_updates=288200, lr=0.000186274, gnorm=1.307, loss_scale=8192, train_wall=127, wall=378484
2023-01-17 00:57:39 | INFO | train_inner | epoch 146:   1550 / 1978 loss=2.973, nll_loss=0.855, word_ins=2.682, length=2.911, ppl=7.85, wps=46381.5, ups=0.78, wpb=59838.9, bsz=2039.5, num_updates=288300, lr=0.000186242, gnorm=1.249, loss_scale=8192, train_wall=129, wall=378613
2023-01-17 00:59:46 | INFO | train_inner | epoch 146:   1650 / 1978 loss=2.974, nll_loss=0.847, word_ins=2.676, length=2.985, ppl=7.86, wps=46688.8, ups=0.78, wpb=59525.4, bsz=1935.9, num_updates=288400, lr=0.00018621, gnorm=1.369, loss_scale=8192, train_wall=127, wall=378741
2023-01-17 01:01:57 | INFO | train_inner | epoch 146:   1750 / 1978 loss=2.974, nll_loss=0.852, word_ins=2.68, length=2.944, ppl=7.86, wps=45243.8, ups=0.77, wpb=59029.2, bsz=2002.6, num_updates=288500, lr=0.000186177, gnorm=1.246, loss_scale=8192, train_wall=130, wall=378871
2023-01-17 01:04:07 | INFO | train_inner | epoch 146:   1850 / 1978 loss=2.982, nll_loss=0.855, word_ins=2.682, length=3.002, ppl=7.9, wps=45496.2, ups=0.77, wpb=59200.9, bsz=1978.6, num_updates=288600, lr=0.000186145, gnorm=1.319, loss_scale=8192, train_wall=130, wall=379001
2023-01-17 01:06:18 | INFO | train_inner | epoch 146:   1950 / 1978 loss=2.946, nll_loss=0.826, word_ins=2.656, length=2.905, ppl=7.71, wps=45430.4, ups=0.77, wpb=59289.5, bsz=2024.9, num_updates=288700, lr=0.000186113, gnorm=1.239, loss_scale=8192, train_wall=130, wall=379132
2023-01-17 01:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 01:07:10 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 4.608 | nll_loss 1.961 | word_ins 3.721 | length 8.878 | ppl 24.39 | wps 83806.5 | wpb 40242.5 | bsz 1500 | num_updates 288728 | best_loss 4.422
2023-01-17 01:07:10 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 01:07:40 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint146.pt (epoch 146 @ 288728 updates, score 4.608) (writing took 30.872494554147124 seconds)
2023-01-17 01:07:40 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2023-01-17 01:07:40 | INFO | train | epoch 146 | loss 2.963 | nll_loss 0.842 | word_ins 2.67 | length 2.924 | ppl 7.8 | wps 44717.1 | ups 0.75 | wpb 59281.7 | bsz 2002.9 | num_updates 288728 | lr 0.000186104 | gnorm 1.295 | loss_scale 8192 | train_wall 2555 | wall 379215
2023-01-17 01:07:40 | INFO | fairseq.trainer | begin training epoch 147
2023-01-17 01:09:27 | INFO | train_inner | epoch 147:     72 / 1978 loss=2.953, nll_loss=0.832, word_ins=2.661, length=2.914, ppl=7.74, wps=31052, ups=0.53, wpb=58959, bsz=2025.4, num_updates=288800, lr=0.000186081, gnorm=1.314, loss_scale=8192, train_wall=130, wall=379322
2023-01-17 01:11:35 | INFO | train_inner | epoch 147:    172 / 1978 loss=2.97, nll_loss=0.849, word_ins=2.677, length=2.933, ppl=7.84, wps=46725.6, ups=0.78, wpb=59549.5, bsz=1914, num_updates=288900, lr=0.000186049, gnorm=1.349, loss_scale=8192, train_wall=127, wall=379449
2023-01-17 01:13:43 | INFO | train_inner | epoch 147:    272 / 1978 loss=2.947, nll_loss=0.827, word_ins=2.657, length=2.898, ppl=7.71, wps=46494.2, ups=0.78, wpb=59592.2, bsz=2030.6, num_updates=289000, lr=0.000186016, gnorm=1.255, loss_scale=8192, train_wall=128, wall=379577
2023-01-17 01:15:51 | INFO | train_inner | epoch 147:    372 / 1978 loss=2.96, nll_loss=0.84, word_ins=2.668, length=2.918, ppl=7.78, wps=46375.6, ups=0.78, wpb=59514.8, bsz=1970.2, num_updates=289100, lr=0.000185984, gnorm=1.359, loss_scale=8192, train_wall=128, wall=379706
2023-01-17 01:18:00 | INFO | train_inner | epoch 147:    472 / 1978 loss=2.976, nll_loss=0.855, word_ins=2.682, length=2.941, ppl=7.87, wps=45688.1, ups=0.78, wpb=58785.1, bsz=1936.2, num_updates=289200, lr=0.000185952, gnorm=1.3, loss_scale=8192, train_wall=128, wall=379834
2023-01-17 01:20:10 | INFO | train_inner | epoch 147:    572 / 1978 loss=2.96, nll_loss=0.835, word_ins=2.664, length=2.956, ppl=7.78, wps=45682.7, ups=0.77, wpb=59370.8, bsz=1962.3, num_updates=289300, lr=0.00018592, gnorm=1.328, loss_scale=8192, train_wall=130, wall=379964
2023-01-17 01:22:21 | INFO | train_inner | epoch 147:    672 / 1978 loss=2.961, nll_loss=0.837, word_ins=2.666, length=2.951, ppl=7.79, wps=45205, ups=0.76, wpb=59113, bsz=1999.5, num_updates=289400, lr=0.000185888, gnorm=1.292, loss_scale=8192, train_wall=130, wall=380095
2023-01-17 01:24:32 | INFO | train_inner | epoch 147:    772 / 1978 loss=2.949, nll_loss=0.831, word_ins=2.66, length=2.886, ppl=7.72, wps=45517.9, ups=0.76, wpb=59560.2, bsz=2070.7, num_updates=289500, lr=0.000185856, gnorm=1.295, loss_scale=8192, train_wall=131, wall=380226
2023-01-17 01:26:42 | INFO | train_inner | epoch 147:    872 / 1978 loss=2.974, nll_loss=0.854, word_ins=2.682, length=2.925, ppl=7.86, wps=45289.1, ups=0.76, wpb=59216.4, bsz=1984.4, num_updates=289600, lr=0.000185824, gnorm=1.293, loss_scale=8192, train_wall=130, wall=380357
2023-01-17 01:28:51 | INFO | train_inner | epoch 147:    972 / 1978 loss=2.967, nll_loss=0.844, word_ins=2.673, length=2.945, ppl=7.82, wps=46056.8, ups=0.78, wpb=59291.1, bsz=2012.9, num_updates=289700, lr=0.000185791, gnorm=1.316, loss_scale=8192, train_wall=128, wall=380485
2023-01-17 01:31:00 | INFO | train_inner | epoch 147:   1072 / 1978 loss=2.942, nll_loss=0.823, word_ins=2.653, length=2.891, ppl=7.68, wps=46065.6, ups=0.78, wpb=59410.7, bsz=2098.3, num_updates=289800, lr=0.000185759, gnorm=1.333, loss_scale=8192, train_wall=129, wall=380614
2023-01-17 01:33:09 | INFO | train_inner | epoch 147:   1172 / 1978 loss=2.952, nll_loss=0.829, word_ins=2.659, length=2.927, ppl=7.74, wps=46138.7, ups=0.78, wpb=59380.1, bsz=2007.4, num_updates=289900, lr=0.000185727, gnorm=1.31, loss_scale=8192, train_wall=128, wall=380743
2023-01-17 01:35:18 | INFO | train_inner | epoch 147:   1272 / 1978 loss=2.957, nll_loss=0.838, word_ins=2.667, length=2.897, ppl=7.76, wps=45488.3, ups=0.77, wpb=58811.3, bsz=2079.7, num_updates=290000, lr=0.000185695, gnorm=1.211, loss_scale=8192, train_wall=129, wall=380872
2023-01-17 01:37:29 | INFO | train_inner | epoch 147:   1372 / 1978 loss=2.956, nll_loss=0.837, word_ins=2.665, length=2.911, ppl=7.76, wps=45546.1, ups=0.77, wpb=59430.4, bsz=2068.2, num_updates=290100, lr=0.000185663, gnorm=1.262, loss_scale=8192, train_wall=130, wall=381003
2023-01-17 01:39:38 | INFO | train_inner | epoch 147:   1472 / 1978 loss=2.969, nll_loss=0.849, word_ins=2.677, length=2.923, ppl=7.83, wps=45989.5, ups=0.77, wpb=59550.4, bsz=1933.7, num_updates=290200, lr=0.000185631, gnorm=1.325, loss_scale=8192, train_wall=129, wall=381132
2023-01-17 01:41:47 | INFO | train_inner | epoch 147:   1572 / 1978 loss=2.987, nll_loss=0.86, word_ins=2.687, length=3.004, ppl=7.93, wps=45677.4, ups=0.78, wpb=58906.9, bsz=1913.3, num_updates=290300, lr=0.000185599, gnorm=1.35, loss_scale=8192, train_wall=129, wall=381261
2023-01-17 01:43:58 | INFO | train_inner | epoch 147:   1672 / 1978 loss=2.99, nll_loss=0.868, word_ins=2.695, length=2.949, ppl=7.95, wps=44661.9, ups=0.77, wpb=58291.5, bsz=2001, num_updates=290400, lr=0.000185567, gnorm=1.247, loss_scale=8192, train_wall=130, wall=381392
2023-01-17 01:46:07 | INFO | train_inner | epoch 147:   1772 / 1978 loss=2.962, nll_loss=0.848, word_ins=2.675, length=2.867, ppl=7.79, wps=46138.7, ups=0.78, wpb=59505.4, bsz=2093.6, num_updates=290500, lr=0.000185535, gnorm=1.278, loss_scale=8192, train_wall=129, wall=381521
2023-01-17 01:48:14 | INFO | train_inner | epoch 147:   1872 / 1978 loss=2.969, nll_loss=0.839, word_ins=2.668, length=3.017, ppl=7.83, wps=47006.1, ups=0.79, wpb=59707.2, bsz=1930.5, num_updates=290600, lr=0.000185504, gnorm=1.355, loss_scale=8192, train_wall=127, wall=381648
2023-01-17 01:50:22 | INFO | train_inner | epoch 147:   1972 / 1978 loss=2.953, nll_loss=0.832, word_ins=2.661, length=2.924, ppl=7.74, wps=46667.4, ups=0.78, wpb=59684.9, bsz=2016.8, num_updates=290700, lr=0.000185472, gnorm=1.322, loss_scale=8192, train_wall=128, wall=381776
2023-01-17 01:50:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 01:50:44 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 4.595 | nll_loss 1.991 | word_ins 3.75 | length 8.451 | ppl 24.17 | wps 94418.2 | wpb 40242.5 | bsz 1500 | num_updates 290706 | best_loss 4.422
2023-01-17 01:50:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 01:51:13 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint147.pt (epoch 147 @ 290706 updates, score 4.595) (writing took 28.261146914213896 seconds)
2023-01-17 01:51:13 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2023-01-17 01:51:13 | INFO | train | epoch 147 | loss 2.963 | nll_loss 0.842 | word_ins 2.67 | length 2.928 | ppl 7.8 | wps 44893.6 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 290706 | lr 0.00018547 | gnorm 1.303 | loss_scale 8192 | train_wall 2550 | wall 381827
2023-01-17 01:51:13 | INFO | fairseq.trainer | begin training epoch 148
2023-01-17 01:53:27 | INFO | train_inner | epoch 148:     94 / 1978 loss=2.952, nll_loss=0.833, word_ins=2.663, length=2.889, ppl=7.74, wps=31599.5, ups=0.54, wpb=58696.9, bsz=1966.9, num_updates=290800, lr=0.00018544, gnorm=1.256, loss_scale=8192, train_wall=130, wall=381961
2023-01-17 01:55:38 | INFO | train_inner | epoch 148:    194 / 1978 loss=2.943, nll_loss=0.826, word_ins=2.657, length=2.856, ppl=7.69, wps=45039.4, ups=0.77, wpb=58840.8, bsz=2069.7, num_updates=290900, lr=0.000185408, gnorm=1.286, loss_scale=8192, train_wall=130, wall=382092
2023-01-17 01:56:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-17 01:57:50 | INFO | train_inner | epoch 148:    295 / 1978 loss=2.955, nll_loss=0.835, word_ins=2.664, length=2.911, ppl=7.76, wps=44731.2, ups=0.76, wpb=59103.2, bsz=2032.2, num_updates=291000, lr=0.000185376, gnorm=1.302, loss_scale=8192, train_wall=132, wall=382224
2023-01-17 02:00:00 | INFO | train_inner | epoch 148:    395 / 1978 loss=2.956, nll_loss=0.831, word_ins=2.661, length=2.948, ppl=7.76, wps=45733, ups=0.77, wpb=59212.4, bsz=1999.5, num_updates=291100, lr=0.000185344, gnorm=1.315, loss_scale=8192, train_wall=129, wall=382354
2023-01-17 02:02:09 | INFO | train_inner | epoch 148:    495 / 1978 loss=2.951, nll_loss=0.83, word_ins=2.659, length=2.919, ppl=7.73, wps=45942.1, ups=0.77, wpb=59508.5, bsz=2057, num_updates=291200, lr=0.000185312, gnorm=1.265, loss_scale=8192, train_wall=129, wall=382483
2023-01-17 02:04:16 | INFO | train_inner | epoch 148:    595 / 1978 loss=2.973, nll_loss=0.855, word_ins=2.682, length=2.904, ppl=7.85, wps=46639.1, ups=0.79, wpb=59107.4, bsz=1926.3, num_updates=291300, lr=0.000185281, gnorm=1.309, loss_scale=8192, train_wall=126, wall=382610
2023-01-17 02:06:24 | INFO | train_inner | epoch 148:    695 / 1978 loss=2.957, nll_loss=0.834, word_ins=2.663, length=2.937, ppl=7.76, wps=46713.9, ups=0.78, wpb=59733.7, bsz=1970.2, num_updates=291400, lr=0.000185249, gnorm=1.336, loss_scale=8192, train_wall=128, wall=382738
2023-01-17 02:08:32 | INFO | train_inner | epoch 148:    795 / 1978 loss=2.941, nll_loss=0.817, word_ins=2.648, length=2.924, ppl=7.68, wps=46299.5, ups=0.78, wpb=59402.4, bsz=2044.6, num_updates=291500, lr=0.000185217, gnorm=1.278, loss_scale=8192, train_wall=128, wall=382866
2023-01-17 02:10:43 | INFO | train_inner | epoch 148:    895 / 1978 loss=2.957, nll_loss=0.836, word_ins=2.665, length=2.923, ppl=7.77, wps=45108.2, ups=0.76, wpb=59185, bsz=2044.5, num_updates=291600, lr=0.000185185, gnorm=1.301, loss_scale=8192, train_wall=131, wall=382997
2023-01-17 02:12:54 | INFO | train_inner | epoch 148:    995 / 1978 loss=2.974, nll_loss=0.856, word_ins=2.684, length=2.905, ppl=7.86, wps=44967.1, ups=0.77, wpb=58708.4, bsz=2016.8, num_updates=291700, lr=0.000185153, gnorm=1.218, loss_scale=8192, train_wall=130, wall=383128
2023-01-17 02:15:04 | INFO | train_inner | epoch 148:   1095 / 1978 loss=2.942, nll_loss=0.817, word_ins=2.648, length=2.946, ppl=7.69, wps=45670.1, ups=0.77, wpb=59255.2, bsz=2033.7, num_updates=291800, lr=0.000185122, gnorm=1.263, loss_scale=8192, train_wall=129, wall=383258
2023-01-17 02:17:15 | INFO | train_inner | epoch 148:   1195 / 1978 loss=2.964, nll_loss=0.843, word_ins=2.671, length=2.926, ppl=7.8, wps=45656.6, ups=0.76, wpb=59965.9, bsz=2005.1, num_updates=291900, lr=0.00018509, gnorm=1.339, loss_scale=8192, train_wall=131, wall=383389
2023-01-17 02:19:24 | INFO | train_inner | epoch 148:   1295 / 1978 loss=2.957, nll_loss=0.837, word_ins=2.665, length=2.918, ppl=7.77, wps=46064.1, ups=0.77, wpb=59663.2, bsz=1990.3, num_updates=292000, lr=0.000185058, gnorm=1.301, loss_scale=8192, train_wall=129, wall=383519
2023-01-17 02:21:32 | INFO | train_inner | epoch 148:   1395 / 1978 loss=2.984, nll_loss=0.862, word_ins=2.688, length=2.953, ppl=7.91, wps=46508.8, ups=0.78, wpb=59454.6, bsz=1893.1, num_updates=292100, lr=0.000185027, gnorm=1.353, loss_scale=8192, train_wall=128, wall=383646
2023-01-17 02:23:40 | INFO | train_inner | epoch 148:   1495 / 1978 loss=2.955, nll_loss=0.833, word_ins=2.662, length=2.926, ppl=7.75, wps=46279.7, ups=0.78, wpb=59208.9, bsz=2039, num_updates=292200, lr=0.000184995, gnorm=1.29, loss_scale=8192, train_wall=128, wall=383774
2023-01-17 02:25:49 | INFO | train_inner | epoch 148:   1595 / 1978 loss=2.971, nll_loss=0.852, word_ins=2.68, length=2.915, ppl=7.84, wps=45789.6, ups=0.78, wpb=58734.8, bsz=2006, num_updates=292300, lr=0.000184963, gnorm=1.28, loss_scale=8192, train_wall=128, wall=383903
2023-01-17 02:28:00 | INFO | train_inner | epoch 148:   1695 / 1978 loss=2.967, nll_loss=0.846, word_ins=2.674, length=2.928, ppl=7.82, wps=45395.1, ups=0.76, wpb=59488, bsz=2009.8, num_updates=292400, lr=0.000184932, gnorm=1.286, loss_scale=8192, train_wall=131, wall=384034
2023-01-17 02:30:12 | INFO | train_inner | epoch 148:   1795 / 1978 loss=2.963, nll_loss=0.846, word_ins=2.674, length=2.884, ppl=7.8, wps=45036.1, ups=0.76, wpb=59426.4, bsz=2068.7, num_updates=292500, lr=0.0001849, gnorm=1.255, loss_scale=8192, train_wall=132, wall=384166
2023-01-17 02:32:22 | INFO | train_inner | epoch 148:   1895 / 1978 loss=2.977, nll_loss=0.855, word_ins=2.682, length=2.954, ppl=7.88, wps=45699.1, ups=0.77, wpb=59451.6, bsz=1927.3, num_updates=292600, lr=0.000184868, gnorm=1.371, loss_scale=8192, train_wall=130, wall=384296
2023-01-17 02:34:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 02:34:24 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 4.651 | nll_loss 1.97 | word_ins 3.731 | length 9.205 | ppl 25.13 | wps 74700.5 | wpb 40242.5 | bsz 1500 | num_updates 292683 | best_loss 4.422
2023-01-17 02:34:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 02:34:51 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint148.pt (epoch 148 @ 292683 updates, score 4.651) (writing took 27.47148043010384 seconds)
2023-01-17 02:34:51 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2023-01-17 02:34:51 | INFO | train | epoch 148 | loss 2.96 | nll_loss 0.839 | word_ins 2.668 | length 2.922 | ppl 7.78 | wps 44760.1 | ups 0.76 | wpb 59283.5 | bsz 2002.7 | num_updates 292683 | lr 0.000184842 | gnorm 1.299 | loss_scale 8192 | train_wall 2557 | wall 384445
2023-01-17 02:34:51 | INFO | fairseq.trainer | begin training epoch 149
2023-01-17 02:35:27 | INFO | train_inner | epoch 149:     17 / 1978 loss=2.97, nll_loss=0.849, word_ins=2.677, length=2.936, ppl=7.84, wps=32032.9, ups=0.54, wpb=59267.3, bsz=1940, num_updates=292700, lr=0.000184837, gnorm=1.376, loss_scale=8192, train_wall=129, wall=384481
2023-01-17 02:37:35 | INFO | train_inner | epoch 149:    117 / 1978 loss=2.949, nll_loss=0.83, word_ins=2.659, length=2.898, ppl=7.72, wps=46267.6, ups=0.78, wpb=59458.5, bsz=2030.9, num_updates=292800, lr=0.000184805, gnorm=1.297, loss_scale=8192, train_wall=128, wall=384609
2023-01-17 02:39:43 | INFO | train_inner | epoch 149:    217 / 1978 loss=2.959, nll_loss=0.84, word_ins=2.669, length=2.902, ppl=7.78, wps=46109, ups=0.78, wpb=59017.1, bsz=1974.2, num_updates=292900, lr=0.000184774, gnorm=1.29, loss_scale=8192, train_wall=128, wall=384737
2023-01-17 02:41:51 | INFO | train_inner | epoch 149:    317 / 1978 loss=2.978, nll_loss=0.858, word_ins=2.685, length=2.931, ppl=7.88, wps=46239, ups=0.78, wpb=59027.6, bsz=1946.6, num_updates=293000, lr=0.000184742, gnorm=1.344, loss_scale=8192, train_wall=127, wall=384865
2023-01-17 02:44:00 | INFO | train_inner | epoch 149:    417 / 1978 loss=2.96, nll_loss=0.834, word_ins=2.663, length=2.972, ppl=7.78, wps=46272.4, ups=0.78, wpb=59552.1, bsz=1950.7, num_updates=293100, lr=0.000184711, gnorm=1.315, loss_scale=8192, train_wall=128, wall=384994
2023-01-17 02:46:11 | INFO | train_inner | epoch 149:    517 / 1978 loss=2.912, nll_loss=0.798, word_ins=2.631, length=2.817, ppl=7.53, wps=45427.8, ups=0.76, wpb=59826.7, bsz=2153, num_updates=293200, lr=0.000184679, gnorm=1.308, loss_scale=8192, train_wall=131, wall=385125
2023-01-17 02:48:22 | INFO | train_inner | epoch 149:    617 / 1978 loss=2.968, nll_loss=0.849, word_ins=2.677, length=2.913, ppl=7.82, wps=45061.8, ups=0.76, wpb=58966.8, bsz=2006.7, num_updates=293300, lr=0.000184648, gnorm=1.29, loss_scale=8192, train_wall=130, wall=385256
2023-01-17 02:50:31 | INFO | train_inner | epoch 149:    717 / 1978 loss=2.958, nll_loss=0.835, word_ins=2.664, length=2.932, ppl=7.77, wps=46046.7, ups=0.78, wpb=59395.1, bsz=2013.8, num_updates=293400, lr=0.000184616, gnorm=1.293, loss_scale=8192, train_wall=129, wall=385385
2023-01-17 02:52:42 | INFO | train_inner | epoch 149:    817 / 1978 loss=2.948, nll_loss=0.825, word_ins=2.655, length=2.93, ppl=7.72, wps=44975.7, ups=0.77, wpb=58680.4, bsz=2001.4, num_updates=293500, lr=0.000184585, gnorm=1.28, loss_scale=8192, train_wall=130, wall=385516
2023-01-17 02:54:49 | INFO | train_inner | epoch 149:    917 / 1978 loss=2.957, nll_loss=0.834, word_ins=2.663, length=2.932, ppl=7.76, wps=46517.1, ups=0.79, wpb=59217.7, bsz=1980.1, num_updates=293600, lr=0.000184553, gnorm=1.323, loss_scale=8192, train_wall=127, wall=385643
2023-01-17 02:56:57 | INFO | train_inner | epoch 149:   1017 / 1978 loss=2.996, nll_loss=0.881, word_ins=2.706, length=2.898, ppl=7.98, wps=46223.7, ups=0.78, wpb=59232.6, bsz=1969.9, num_updates=293700, lr=0.000184522, gnorm=1.324, loss_scale=8192, train_wall=128, wall=385771
2023-01-17 02:59:05 | INFO | train_inner | epoch 149:   1117 / 1978 loss=2.971, nll_loss=0.846, word_ins=2.674, length=2.976, ppl=7.84, wps=46859.7, ups=0.78, wpb=59765.3, bsz=1951.9, num_updates=293800, lr=0.000184491, gnorm=1.342, loss_scale=8192, train_wall=127, wall=385899
2023-01-17 03:01:14 | INFO | train_inner | epoch 149:   1217 / 1978 loss=2.97, nll_loss=0.85, word_ins=2.678, length=2.925, ppl=7.84, wps=46174.8, ups=0.78, wpb=59564.3, bsz=1954.8, num_updates=293900, lr=0.000184459, gnorm=1.363, loss_scale=8192, train_wall=129, wall=386028
2023-01-17 03:03:24 | INFO | train_inner | epoch 149:   1317 / 1978 loss=2.949, nll_loss=0.83, word_ins=2.659, length=2.897, ppl=7.72, wps=45725.8, ups=0.77, wpb=59639.8, bsz=2028.6, num_updates=294000, lr=0.000184428, gnorm=1.286, loss_scale=8192, train_wall=130, wall=386158
2023-01-17 03:05:33 | INFO | train_inner | epoch 149:   1417 / 1978 loss=2.974, nll_loss=0.851, word_ins=2.679, length=2.954, ppl=7.86, wps=45511.7, ups=0.77, wpb=58728, bsz=1957.8, num_updates=294100, lr=0.000184396, gnorm=1.291, loss_scale=8192, train_wall=129, wall=386287
2023-01-17 03:07:44 | INFO | train_inner | epoch 149:   1517 / 1978 loss=2.96, nll_loss=0.839, word_ins=2.667, length=2.928, ppl=7.78, wps=45446.2, ups=0.76, wpb=59445, bsz=1976.6, num_updates=294200, lr=0.000184365, gnorm=1.289, loss_scale=8192, train_wall=130, wall=386418
2023-01-17 03:09:56 | INFO | train_inner | epoch 149:   1617 / 1978 loss=2.968, nll_loss=0.848, word_ins=2.676, length=2.921, ppl=7.83, wps=44643.3, ups=0.76, wpb=58991.2, bsz=1988.2, num_updates=294300, lr=0.000184334, gnorm=1.289, loss_scale=8192, train_wall=132, wall=386550
2023-01-17 03:12:04 | INFO | train_inner | epoch 149:   1717 / 1978 loss=2.958, nll_loss=0.84, word_ins=2.669, length=2.89, ppl=7.77, wps=45968.2, ups=0.78, wpb=58996.5, bsz=2064.3, num_updates=294400, lr=0.000184302, gnorm=1.27, loss_scale=8192, train_wall=128, wall=386678
2023-01-17 03:14:13 | INFO | train_inner | epoch 149:   1817 / 1978 loss=2.957, nll_loss=0.833, word_ins=2.662, length=2.948, ppl=7.76, wps=45893.7, ups=0.78, wpb=59199.6, bsz=2030.7, num_updates=294500, lr=0.000184271, gnorm=1.27, loss_scale=8192, train_wall=129, wall=386807
2023-01-17 03:16:21 | INFO | train_inner | epoch 149:   1917 / 1978 loss=2.946, nll_loss=0.824, word_ins=2.654, length=2.921, ppl=7.71, wps=46483, ups=0.78, wpb=59538.1, bsz=2033.7, num_updates=294600, lr=0.00018424, gnorm=1.282, loss_scale=8192, train_wall=128, wall=386936
2023-01-17 03:17:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 03:17:55 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 4.635 | nll_loss 1.992 | word_ins 3.75 | length 8.843 | ppl 24.84 | wps 94540.6 | wpb 40242.5 | bsz 1500 | num_updates 294661 | best_loss 4.422
2023-01-17 03:17:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 03:18:25 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint149.pt (epoch 149 @ 294661 updates, score 4.635) (writing took 29.942104909103364 seconds)
2023-01-17 03:18:25 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2023-01-17 03:18:25 | INFO | train | epoch 149 | loss 2.959 | nll_loss 0.839 | word_ins 2.667 | length 2.916 | ppl 7.78 | wps 44865.2 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 294661 | lr 0.000184221 | gnorm 1.302 | loss_scale 8192 | train_wall 2550 | wall 387059
2023-01-17 03:18:25 | INFO | fairseq.trainer | begin training epoch 150
2023-01-17 03:19:28 | INFO | train_inner | epoch 150:     39 / 1978 loss=2.934, nll_loss=0.819, word_ins=2.65, length=2.846, ppl=7.64, wps=31811.6, ups=0.54, wpb=59385.6, bsz=2067.8, num_updates=294700, lr=0.000184209, gnorm=1.277, loss_scale=8192, train_wall=130, wall=387122
2023-01-17 03:21:40 | INFO | train_inner | epoch 150:    139 / 1978 loss=2.919, nll_loss=0.805, word_ins=2.636, length=2.832, ppl=7.57, wps=45450.5, ups=0.76, wpb=59869.4, bsz=2069.4, num_updates=294800, lr=0.000184177, gnorm=1.292, loss_scale=8192, train_wall=131, wall=387254
2023-01-17 03:23:51 | INFO | train_inner | epoch 150:    239 / 1978 loss=2.943, nll_loss=0.831, word_ins=2.66, length=2.83, ppl=7.69, wps=45038.4, ups=0.76, wpb=59238.2, bsz=2061, num_updates=294900, lr=0.000184146, gnorm=1.261, loss_scale=8192, train_wall=131, wall=387386
2023-01-17 03:26:03 | INFO | train_inner | epoch 150:    339 / 1978 loss=2.954, nll_loss=0.838, word_ins=2.667, length=2.875, ppl=7.75, wps=45296.5, ups=0.76, wpb=59441.5, bsz=2014.9, num_updates=295000, lr=0.000184115, gnorm=1.271, loss_scale=8192, train_wall=131, wall=387517
2023-01-17 03:27:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-17 03:28:13 | INFO | train_inner | epoch 150:    440 / 1978 loss=2.948, nll_loss=0.832, word_ins=2.662, length=2.858, ppl=7.72, wps=45442.8, ups=0.76, wpb=59424.5, bsz=2020, num_updates=295100, lr=0.000184084, gnorm=1.314, loss_scale=8192, train_wall=130, wall=387648
2023-01-17 03:30:21 | INFO | train_inner | epoch 150:    540 / 1978 loss=2.954, nll_loss=0.83, word_ins=2.66, length=2.937, ppl=7.75, wps=46131.8, ups=0.78, wpb=59067.2, bsz=2003.8, num_updates=295200, lr=0.000184053, gnorm=1.271, loss_scale=8192, train_wall=128, wall=387776
2023-01-17 03:32:28 | INFO | train_inner | epoch 150:    640 / 1978 loss=2.973, nll_loss=0.851, word_ins=2.679, length=2.945, ppl=7.85, wps=46677.2, ups=0.79, wpb=59116.5, bsz=1928.1, num_updates=295300, lr=0.000184021, gnorm=1.323, loss_scale=8192, train_wall=126, wall=387902
2023-01-17 03:34:35 | INFO | train_inner | epoch 150:    740 / 1978 loss=2.967, nll_loss=0.843, word_ins=2.672, length=2.949, ppl=7.82, wps=46437.8, ups=0.79, wpb=58879.5, bsz=1939.7, num_updates=295400, lr=0.00018399, gnorm=1.315, loss_scale=8192, train_wall=127, wall=388029
2023-01-17 03:36:45 | INFO | train_inner | epoch 150:    840 / 1978 loss=2.948, nll_loss=0.829, word_ins=2.659, length=2.895, ppl=7.72, wps=45158, ups=0.77, wpb=58863.4, bsz=2082.6, num_updates=295500, lr=0.000183959, gnorm=1.275, loss_scale=8192, train_wall=130, wall=388159
2023-01-17 03:38:55 | INFO | train_inner | epoch 150:    940 / 1978 loss=2.965, nll_loss=0.843, word_ins=2.672, length=2.935, ppl=7.81, wps=45818.8, ups=0.77, wpb=59277, bsz=1940.8, num_updates=295600, lr=0.000183928, gnorm=1.267, loss_scale=8192, train_wall=129, wall=388289
2023-01-17 03:41:05 | INFO | train_inner | epoch 150:   1040 / 1978 loss=2.972, nll_loss=0.856, word_ins=2.684, length=2.888, ppl=7.85, wps=45621.1, ups=0.77, wpb=59288.3, bsz=1992.3, num_updates=295700, lr=0.000183897, gnorm=1.313, loss_scale=8192, train_wall=130, wall=388419
2023-01-17 03:43:15 | INFO | train_inner | epoch 150:   1140 / 1978 loss=2.949, nll_loss=0.83, word_ins=2.659, length=2.895, ppl=7.72, wps=45545.2, ups=0.77, wpb=59358.5, bsz=2097.8, num_updates=295800, lr=0.000183866, gnorm=1.305, loss_scale=8192, train_wall=130, wall=388549
2023-01-17 03:45:24 | INFO | train_inner | epoch 150:   1240 / 1978 loss=2.969, nll_loss=0.846, word_ins=2.675, length=2.941, ppl=7.83, wps=45323.7, ups=0.77, wpb=58576.7, bsz=2050.7, num_updates=295900, lr=0.000183835, gnorm=1.325, loss_scale=8192, train_wall=129, wall=388678
2023-01-17 03:47:32 | INFO | train_inner | epoch 150:   1340 / 1978 loss=2.967, nll_loss=0.846, word_ins=2.674, length=2.93, ppl=7.82, wps=46711.1, ups=0.78, wpb=59630.7, bsz=1952.7, num_updates=296000, lr=0.000183804, gnorm=1.306, loss_scale=8192, train_wall=127, wall=388806
2023-01-17 03:49:40 | INFO | train_inner | epoch 150:   1440 / 1978 loss=2.963, nll_loss=0.845, word_ins=2.673, length=2.896, ppl=7.8, wps=46518.8, ups=0.78, wpb=59478.1, bsz=2002, num_updates=296100, lr=0.000183773, gnorm=1.284, loss_scale=8192, train_wall=128, wall=388934
2023-01-17 03:51:48 | INFO | train_inner | epoch 150:   1540 / 1978 loss=2.976, nll_loss=0.848, word_ins=2.675, length=3.006, ppl=7.87, wps=46023.7, ups=0.78, wpb=58881.8, bsz=1967.4, num_updates=296200, lr=0.000183742, gnorm=1.288, loss_scale=8192, train_wall=128, wall=389062
2023-01-17 03:53:59 | INFO | train_inner | epoch 150:   1640 / 1978 loss=2.948, nll_loss=0.828, word_ins=2.657, length=2.907, ppl=7.72, wps=45371.4, ups=0.76, wpb=59548, bsz=2076.4, num_updates=296300, lr=0.000183711, gnorm=1.285, loss_scale=8192, train_wall=131, wall=389193
2023-01-17 03:56:09 | INFO | train_inner | epoch 150:   1740 / 1978 loss=2.975, nll_loss=0.853, word_ins=2.68, length=2.95, ppl=7.86, wps=45835.9, ups=0.77, wpb=59546.4, bsz=1897.6, num_updates=296400, lr=0.00018368, gnorm=1.358, loss_scale=8192, train_wall=130, wall=389323
2023-01-17 03:58:18 | INFO | train_inner | epoch 150:   1840 / 1978 loss=2.966, nll_loss=0.847, word_ins=2.675, length=2.907, ppl=7.81, wps=46100.2, ups=0.77, wpb=59661.6, bsz=1938.8, num_updates=296500, lr=0.000183649, gnorm=1.341, loss_scale=8192, train_wall=129, wall=389452
2023-01-17 04:00:30 | INFO | train_inner | epoch 150:   1940 / 1978 loss=2.961, nll_loss=0.837, word_ins=2.666, length=2.948, ppl=7.78, wps=45094.2, ups=0.76, wpb=59336, bsz=2052.6, num_updates=296600, lr=0.000183618, gnorm=1.283, loss_scale=8192, train_wall=131, wall=389584
2023-01-17 04:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 04:01:32 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 4.654 | nll_loss 1.977 | word_ins 3.74 | length 9.144 | ppl 25.18 | wps 106338 | wpb 40242.5 | bsz 1500 | num_updates 296638 | best_loss 4.422
2023-01-17 04:01:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 04:01:59 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint150.pt (epoch 150 @ 296638 updates, score 4.654) (writing took 26.733496837317944 seconds)
2023-01-17 04:01:59 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2023-01-17 04:01:59 | INFO | train | epoch 150 | loss 2.959 | nll_loss 0.839 | word_ins 2.668 | length 2.913 | ppl 7.78 | wps 44837.1 | ups 0.76 | wpb 59281.5 | bsz 2002.7 | num_updates 296638 | lr 0.000183606 | gnorm 1.299 | loss_scale 8192 | train_wall 2555 | wall 389673
2023-01-17 04:01:59 | INFO | fairseq.trainer | begin training epoch 151
2023-01-17 04:03:31 | INFO | train_inner | epoch 151:     62 / 1978 loss=2.942, nll_loss=0.822, word_ins=2.652, length=2.896, ppl=7.68, wps=32705.2, ups=0.55, wpb=59326.6, bsz=2023.1, num_updates=296700, lr=0.000183587, gnorm=1.289, loss_scale=8192, train_wall=129, wall=389765
2023-01-17 04:05:40 | INFO | train_inner | epoch 151:    162 / 1978 loss=2.945, nll_loss=0.828, word_ins=2.658, length=2.87, ppl=7.7, wps=46090.5, ups=0.78, wpb=59300.7, bsz=2044.2, num_updates=296800, lr=0.000183556, gnorm=1.273, loss_scale=8192, train_wall=128, wall=389894
2023-01-17 04:07:47 | INFO | train_inner | epoch 151:    262 / 1978 loss=2.96, nll_loss=0.838, word_ins=2.668, length=2.925, ppl=7.78, wps=46552.5, ups=0.79, wpb=59260.5, bsz=1971, num_updates=296900, lr=0.000183525, gnorm=1.33, loss_scale=8192, train_wall=127, wall=390021
2023-01-17 04:09:57 | INFO | train_inner | epoch 151:    362 / 1978 loss=2.95, nll_loss=0.834, word_ins=2.663, length=2.864, ppl=7.73, wps=45968.5, ups=0.77, wpb=59653.3, bsz=2000.2, num_updates=297000, lr=0.000183494, gnorm=1.313, loss_scale=8192, train_wall=129, wall=390151
2023-01-17 04:12:08 | INFO | train_inner | epoch 151:    462 / 1978 loss=2.941, nll_loss=0.823, word_ins=2.653, length=2.877, ppl=7.68, wps=45578.9, ups=0.77, wpb=59568.6, bsz=2042, num_updates=297100, lr=0.000183463, gnorm=1.312, loss_scale=8192, train_wall=130, wall=390282
2023-01-17 04:14:18 | INFO | train_inner | epoch 151:    562 / 1978 loss=2.984, nll_loss=0.863, word_ins=2.69, length=2.939, ppl=7.91, wps=45195.6, ups=0.77, wpb=58821.3, bsz=1941.2, num_updates=297200, lr=0.000183432, gnorm=1.326, loss_scale=8192, train_wall=130, wall=390412
2023-01-17 04:16:28 | INFO | train_inner | epoch 151:    662 / 1978 loss=2.969, nll_loss=0.849, word_ins=2.677, length=2.921, ppl=7.83, wps=45426.3, ups=0.77, wpb=59157.9, bsz=2005.1, num_updates=297300, lr=0.000183401, gnorm=1.295, loss_scale=8192, train_wall=130, wall=390542
2023-01-17 04:18:38 | INFO | train_inner | epoch 151:    762 / 1978 loss=2.958, nll_loss=0.841, word_ins=2.669, length=2.882, ppl=7.77, wps=45887.9, ups=0.77, wpb=59674.2, bsz=1985.1, num_updates=297400, lr=0.000183371, gnorm=1.313, loss_scale=8192, train_wall=130, wall=390672
2023-01-17 04:20:46 | INFO | train_inner | epoch 151:    862 / 1978 loss=2.946, nll_loss=0.824, word_ins=2.654, length=2.924, ppl=7.71, wps=46739.5, ups=0.78, wpb=59627.7, bsz=2021.3, num_updates=297500, lr=0.00018334, gnorm=1.312, loss_scale=8192, train_wall=127, wall=390800
2023-01-17 04:22:55 | INFO | train_inner | epoch 151:    962 / 1978 loss=2.934, nll_loss=0.82, word_ins=2.65, length=2.843, ppl=7.64, wps=46285.6, ups=0.77, wpb=59728, bsz=2083.4, num_updates=297600, lr=0.000183309, gnorm=1.25, loss_scale=8192, train_wall=129, wall=390929
2023-01-17 04:25:02 | INFO | train_inner | epoch 151:   1062 / 1978 loss=2.948, nll_loss=0.828, word_ins=2.657, length=2.907, ppl=7.71, wps=46522.1, ups=0.79, wpb=59212.6, bsz=2036.6, num_updates=297700, lr=0.000183278, gnorm=1.302, loss_scale=8192, train_wall=127, wall=391056
2023-01-17 04:27:12 | INFO | train_inner | epoch 151:   1162 / 1978 loss=2.968, nll_loss=0.852, word_ins=2.679, length=2.891, ppl=7.83, wps=45547.6, ups=0.77, wpb=59222.8, bsz=1963.2, num_updates=297800, lr=0.000183247, gnorm=1.267, loss_scale=8192, train_wall=130, wall=391186
2023-01-17 04:29:22 | INFO | train_inner | epoch 151:   1262 / 1978 loss=2.981, nll_loss=0.861, word_ins=2.687, length=2.933, ppl=7.89, wps=45585.1, ups=0.77, wpb=59180.4, bsz=1970.5, num_updates=297900, lr=0.000183217, gnorm=1.292, loss_scale=8192, train_wall=129, wall=391316
2023-01-17 04:31:32 | INFO | train_inner | epoch 151:   1362 / 1978 loss=2.974, nll_loss=0.849, word_ins=2.677, length=2.969, ppl=7.85, wps=45306.9, ups=0.77, wpb=58733, bsz=1911.9, num_updates=298000, lr=0.000183186, gnorm=1.271, loss_scale=8192, train_wall=129, wall=391446
2023-01-17 04:33:42 | INFO | train_inner | epoch 151:   1462 / 1978 loss=2.96, nll_loss=0.84, word_ins=2.668, length=2.919, ppl=7.78, wps=45265.4, ups=0.76, wpb=59220.1, bsz=2036.7, num_updates=298100, lr=0.000183155, gnorm=1.289, loss_scale=8192, train_wall=130, wall=391576
2023-01-17 04:35:53 | INFO | train_inner | epoch 151:   1562 / 1978 loss=2.94, nll_loss=0.826, word_ins=2.655, length=2.846, ppl=7.67, wps=45524.7, ups=0.77, wpb=59499.1, bsz=2100.1, num_updates=298200, lr=0.000183124, gnorm=1.339, loss_scale=8192, train_wall=130, wall=391707
2023-01-17 04:38:00 | INFO | train_inner | epoch 151:   1662 / 1978 loss=2.969, nll_loss=0.842, word_ins=2.67, length=2.986, ppl=7.83, wps=46829.3, ups=0.79, wpb=59464.2, bsz=1915.4, num_updates=298300, lr=0.000183094, gnorm=1.352, loss_scale=8192, train_wall=127, wall=391834
2023-01-17 04:40:08 | INFO | train_inner | epoch 151:   1762 / 1978 loss=2.959, nll_loss=0.842, word_ins=2.67, length=2.886, ppl=7.78, wps=46090.9, ups=0.78, wpb=59160.9, bsz=2020.9, num_updates=298400, lr=0.000183063, gnorm=1.286, loss_scale=8192, train_wall=128, wall=391963
2023-01-17 04:42:16 | INFO | train_inner | epoch 151:   1862 / 1978 loss=2.978, nll_loss=0.852, word_ins=2.679, length=2.987, ppl=7.88, wps=46473.2, ups=0.79, wpb=59040.6, bsz=1924, num_updates=298500, lr=0.000183032, gnorm=1.289, loss_scale=8192, train_wall=127, wall=392090
2023-01-17 04:44:27 | INFO | train_inner | epoch 151:   1962 / 1978 loss=2.949, nll_loss=0.834, word_ins=2.663, length=2.862, ppl=7.72, wps=45176.7, ups=0.76, wpb=59180.2, bsz=2053.7, num_updates=298600, lr=0.000183002, gnorm=1.312, loss_scale=8192, train_wall=131, wall=392221
2023-01-17 04:44:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 04:45:02 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 4.655 | nll_loss 1.98 | word_ins 3.741 | length 9.134 | ppl 25.19 | wps 78235.2 | wpb 40242.5 | bsz 1500 | num_updates 298616 | best_loss 4.422
2023-01-17 04:45:02 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 04:45:30 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint151.pt (epoch 151 @ 298616 updates, score 4.655) (writing took 28.514908300712705 seconds)
2023-01-17 04:45:30 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2023-01-17 04:45:30 | INFO | train | epoch 151 | loss 2.958 | nll_loss 0.838 | word_ins 2.667 | length 2.907 | ppl 7.77 | wps 44902 | ups 0.76 | wpb 59284.3 | bsz 2002.6 | num_updates 298616 | lr 0.000182997 | gnorm 1.301 | loss_scale 8192 | train_wall 2550 | wall 392284
2023-01-17 04:45:30 | INFO | fairseq.trainer | begin training epoch 152
2023-01-17 04:47:33 | INFO | train_inner | epoch 152:     84 / 1978 loss=2.968, nll_loss=0.845, word_ins=2.673, length=2.946, ppl=7.82, wps=31493.4, ups=0.54, wpb=58809.3, bsz=2011.9, num_updates=298700, lr=0.000182971, gnorm=1.281, loss_scale=8192, train_wall=131, wall=392407
2023-01-17 04:49:43 | INFO | train_inner | epoch 152:    184 / 1978 loss=2.951, nll_loss=0.833, word_ins=2.662, length=2.888, ppl=7.73, wps=45933.2, ups=0.77, wpb=59478.7, bsz=1952.7, num_updates=298800, lr=0.00018294, gnorm=1.312, loss_scale=8192, train_wall=129, wall=392537
2023-01-17 04:51:53 | INFO | train_inner | epoch 152:    284 / 1978 loss=2.959, nll_loss=0.837, word_ins=2.667, length=2.919, ppl=7.77, wps=45781.4, ups=0.77, wpb=59476.1, bsz=1996.6, num_updates=298900, lr=0.00018291, gnorm=1.319, loss_scale=8192, train_wall=130, wall=392667
2023-01-17 04:54:02 | INFO | train_inner | epoch 152:    384 / 1978 loss=2.936, nll_loss=0.818, word_ins=2.649, length=2.869, ppl=7.65, wps=45584.8, ups=0.77, wpb=59171.5, bsz=2085.4, num_updates=299000, lr=0.000182879, gnorm=1.279, loss_scale=8192, train_wall=130, wall=392797
2023-01-17 04:56:10 | INFO | train_inner | epoch 152:    484 / 1978 loss=2.972, nll_loss=0.852, word_ins=2.68, length=2.922, ppl=7.85, wps=46519, ups=0.79, wpb=59171.2, bsz=1909.8, num_updates=299100, lr=0.000182849, gnorm=1.318, loss_scale=8192, train_wall=127, wall=392924
2023-01-17 04:57:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-01-17 04:58:18 | INFO | train_inner | epoch 152:    585 / 1978 loss=2.948, nll_loss=0.826, word_ins=2.656, length=2.921, ppl=7.72, wps=45671.6, ups=0.78, wpb=58823.8, bsz=2014.3, num_updates=299200, lr=0.000182818, gnorm=1.241, loss_scale=8192, train_wall=129, wall=393053
2023-01-17 05:00:26 | INFO | train_inner | epoch 152:    685 / 1978 loss=2.947, nll_loss=0.828, word_ins=2.657, length=2.901, ppl=7.71, wps=46399, ups=0.78, wpb=59184.3, bsz=2014.1, num_updates=299300, lr=0.000182788, gnorm=1.293, loss_scale=8192, train_wall=127, wall=393180
2023-01-17 05:02:33 | INFO | train_inner | epoch 152:    785 / 1978 loss=2.952, nll_loss=0.833, word_ins=2.662, length=2.897, ppl=7.74, wps=46441.5, ups=0.78, wpb=59173, bsz=2003.6, num_updates=299400, lr=0.000182757, gnorm=1.31, loss_scale=8192, train_wall=127, wall=393308
2023-01-17 05:04:42 | INFO | train_inner | epoch 152:    885 / 1978 loss=2.949, nll_loss=0.827, word_ins=2.657, length=2.922, ppl=7.72, wps=46434.9, ups=0.78, wpb=59669, bsz=2057.9, num_updates=299500, lr=0.000182727, gnorm=1.324, loss_scale=8192, train_wall=128, wall=393436
2023-01-17 05:06:49 | INFO | train_inner | epoch 152:    985 / 1978 loss=2.97, nll_loss=0.852, word_ins=2.68, length=2.897, ppl=7.83, wps=46186.3, ups=0.79, wpb=58697.2, bsz=1941.5, num_updates=299600, lr=0.000182696, gnorm=1.273, loss_scale=8192, train_wall=127, wall=393563
2023-01-17 05:08:57 | INFO | train_inner | epoch 152:   1085 / 1978 loss=2.954, nll_loss=0.83, word_ins=2.659, length=2.95, ppl=7.75, wps=46443.1, ups=0.78, wpb=59359.5, bsz=1998.6, num_updates=299700, lr=0.000182666, gnorm=1.245, loss_scale=8192, train_wall=128, wall=393691
2023-01-17 05:11:04 | INFO | train_inner | epoch 152:   1185 / 1978 loss=2.941, nll_loss=0.824, word_ins=2.654, length=2.871, ppl=7.68, wps=46768.3, ups=0.79, wpb=59572.3, bsz=2029.1, num_updates=299800, lr=0.000182635, gnorm=1.268, loss_scale=8192, train_wall=127, wall=393818
2023-01-17 05:13:12 | INFO | train_inner | epoch 152:   1285 / 1978 loss=2.979, nll_loss=0.858, word_ins=2.686, length=2.938, ppl=7.89, wps=46342.3, ups=0.78, wpb=59130.3, bsz=1959.4, num_updates=299900, lr=0.000182605, gnorm=1.349, loss_scale=8192, train_wall=127, wall=393946
2023-01-17 05:15:19 | INFO | train_inner | epoch 152:   1385 / 1978 loss=2.969, nll_loss=0.849, word_ins=2.677, length=2.919, ppl=7.83, wps=46572.5, ups=0.79, wpb=59319, bsz=2004.9, num_updates=300000, lr=0.000182574, gnorm=1.317, loss_scale=8192, train_wall=127, wall=394073
2023-01-17 05:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-01-17 05:15:32 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 4.63 | nll_loss 1.984 | word_ins 3.745 | length 8.85 | ppl 24.77 | wps 116588 | wpb 40242.5 | bsz 1500 | num_updates 300000 | best_loss 4.422
2023-01-17 05:15:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-01-17 05:15:46 | INFO | fairseq.checkpoint_utils | saved checkpoint s3://syjiang_bucket/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_covamlpdecorderself_amlpseqboth_w5/checkpoint_last.pt (epoch 152 @ 300000 updates, score 4.63) (writing took 14.372627813834697 seconds)
2023-01-17 05:15:46 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2023-01-17 05:15:46 | INFO | train | epoch 152 | loss 2.956 | nll_loss 0.836 | word_ins 2.665 | length 2.908 | ppl 7.76 | wps 45154.4 | ups 0.76 | wpb 59241.3 | bsz 2001.1 | num_updates 300000 | lr 0.000182574 | gnorm 1.294 | loss_scale 8192 | train_wall 1773 | wall 394100
2023-01-17 05:15:46 | INFO | fairseq_cli.train | done training in 394096.3 seconds
