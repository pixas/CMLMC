2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:18740
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:18740
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:18740
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:18740
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for 4 nodes.
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-24 as rank 0
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for 4 nodes.
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for 4 nodes.
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-24 as rank 3
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-24 as rank 1
2023-02-19 22:15:47 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for 4 nodes.
2023-02-19 22:15:47 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-24 as rank 2
2023-02-19 22:15:52 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amlp_activation='softmax', apply_bert_init=True, arch='cmlm_transformer_wmt_en_de', attention_dropout=0.0, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, concatPE=True, cpu=False, criterion='nat_loss', cross_self_attention=False, curriculum=0, data='/mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_cross_attention_type='amlpseq', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=512, decoder_self_attention_type='amlpseq', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:18740', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dont_use_layernorm=False, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, encoder_self_attention_type='mha', eval_bleu=True, eval_bleu_args='{"iter_decode_max_iter": 0, "iter_decode_with_beam": 1}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, insertCausalSelfAttn=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=20, label_smoothing=0.1, landmarks=16, left_pad_source='True', left_pad_target='False', length_loss_factor=0.1, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', maskdistshiftpower=1.0, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=16384, max_tokens_valid=16384, max_update=300000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, ngram_predictor=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=True, no_token_positional_embeddings=False, noise='random_mask', nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, pred_length_offset=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, replacefactor=0.3, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, selfcorrection=0, sentence_avg=False, sg_length_pred=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='de', src_embedding_copy=False, stop_time_hours=0, target_lang='en', task='translation_lev', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=40000, weight_decay=0.01, zero_sharding='none')
2023-02-19 22:15:52 | INFO | fairseq.tasks.translation | [de] dictionary: 39960 types
2023-02-19 22:15:52 | INFO | fairseq.tasks.translation | [en] dictionary: 39960 types
2023-02-19 22:15:52 | INFO | fairseq.data.data_utils | loaded 3000 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/valid.de-en.de
2023-02-19 22:15:52 | INFO | fairseq.data.data_utils | loaded 3000 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/valid.de-en.en
2023-02-19 22:15:52 | INFO | fairseq.tasks.translation | /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict valid de-en 3000 examples
2023-02-19 22:15:53 | INFO | root | Using efficient attention MultiheadAttention
2023-02-19 22:15:53 | INFO | root | Using efficient attention MultiheadAttention
2023-02-19 22:15:53 | INFO | root | Using efficient attention MultiheadAttention
2023-02-19 22:15:53 | INFO | root | Using efficient attention MultiheadAttention
2023-02-19 22:15:53 | INFO | root | Using efficient attention MultiheadAttention
2023-02-19 22:15:53 | INFO | root | Using efficient attention MultiheadAttention
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:53 | INFO | root | Using efficient attention FSAMLPSeq
2023-02-19 22:15:54 | INFO | fairseq_cli.train | CMLMNATransformerModel(
  (encoder): FairseqNATEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39960, 512, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (PEfc): Linear(in_features=1024, out_features=512, bias=True)
  )
  (decoder): NATransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39960, 512, padding_idx=1)
    (PEfc): Linear(in_features=1024, out_features=512, bias=True)
    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (conv): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), groups=8)
          (drop): Dropout(p=0.0, inplace=False)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (v_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (w_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (approx_out_proj): Linear(in_features=128, out_features=64, bias=True)
          (out_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39960, bias=False)
    (embed_length): Embedding(256, 512)
  )
)
2023-02-19 22:15:54 | INFO | fairseq_cli.train | task: translation_lev (TranslationLevenshteinTask)
2023-02-19 22:15:54 | INFO | fairseq_cli.train | model: cmlm_transformer_wmt_en_de (CMLMNATransformerModel)
2023-02-19 22:15:54 | INFO | fairseq_cli.train | criterion: nat_loss (LabelSmoothedDualImitationCriterion)
2023-02-19 22:15:54 | INFO | fairseq_cli.train | num. model params: 67132960 (num. trained: 67132960)
2023-02-19 22:15:55 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-02-19 22:15:55 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-02-19 22:15:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-02-19 22:15:55 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-02-19 22:15:55 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-02-19 22:15:55 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-02-19 22:15:55 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-02-19 22:15:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-02-19 22:15:55 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-02-19 22:15:55 | INFO | fairseq_cli.train | max tokens per GPU = 16384 and max sentences per GPU = None
2023-02-19 22:15:59 | INFO | fairseq.trainer | loaded checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint_last.pt (epoch 105 @ 205671 updates)
2023-02-19 22:15:59 | INFO | fairseq.trainer | loading train data for epoch 105
2023-02-19 22:16:00 | INFO | fairseq.data.data_utils | loaded 3961179 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/train.de-en.de
2023-02-19 22:16:00 | INFO | fairseq.data.data_utils | loaded 3961179 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict/train.de-en.en
2023-02-19 22:16:00 | INFO | fairseq.tasks.translation | /mnt/petrelfs/jiangshuyang/data-bin/wmt14_deen_distill_jointdict train de-en 3961179 examples
2023-02-19 22:16:03 | INFO | fairseq.trainer | begin training epoch 105
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
2023-02-19 22:16:19 | INFO | root | Reducer buckets have been rebuilt in this iteration.
2023-02-19 22:17:04 | INFO | train_inner | epoch 105:     29 / 1978 loss=3.005, nll_loss=0.867, word_ins=2.695, length=3.101, ppl=8.03, wps=27191.8, ups=0.46, wpb=59000.4, bsz=2025.7, num_updates=205700, lr=0.000220487, gnorm=1.375, loss_scale=8192, train_wall=183, wall=0
2023-02-19 22:19:48 | INFO | train_inner | epoch 105:    129 / 1978 loss=3.005, nll_loss=0.865, word_ins=2.694, length=3.119, ppl=8.03, wps=35654.2, ups=0.61, wpb=58703.1, bsz=2106.3, num_updates=205800, lr=0.000220433, gnorm=1.406, loss_scale=8192, train_wall=164, wall=0
2023-02-19 22:22:34 | INFO | train_inner | epoch 105:    229 / 1978 loss=2.982, nll_loss=0.845, word_ins=2.676, length=3.06, ppl=7.9, wps=36185.6, ups=0.61, wpb=59727.2, bsz=2119.3, num_updates=205900, lr=0.00022038, gnorm=1.39, loss_scale=8192, train_wall=165, wall=0
2023-02-19 22:25:17 | INFO | train_inner | epoch 105:    329 / 1978 loss=2.993, nll_loss=0.857, word_ins=2.687, length=3.063, ppl=7.96, wps=36426.3, ups=0.61, wpb=59469.2, bsz=2028.9, num_updates=206000, lr=0.000220326, gnorm=1.371, loss_scale=8192, train_wall=163, wall=0
2023-02-19 22:28:01 | INFO | train_inner | epoch 105:    429 / 1978 loss=3.027, nll_loss=0.888, word_ins=2.715, length=3.121, ppl=8.15, wps=36022.7, ups=0.61, wpb=59271.1, bsz=1968.6, num_updates=206100, lr=0.000220273, gnorm=1.395, loss_scale=8192, train_wall=164, wall=0
2023-02-19 22:30:46 | INFO | train_inner | epoch 105:    529 / 1978 loss=2.995, nll_loss=0.854, word_ins=2.684, length=3.107, ppl=7.97, wps=35925.6, ups=0.61, wpb=59124.8, bsz=2052.1, num_updates=206200, lr=0.000220219, gnorm=1.383, loss_scale=8192, train_wall=164, wall=0
2023-02-19 22:33:29 | INFO | train_inner | epoch 105:    629 / 1978 loss=3.027, nll_loss=0.884, word_ins=2.711, length=3.157, ppl=8.15, wps=36210.9, ups=0.61, wpb=58928.3, bsz=1884.6, num_updates=206300, lr=0.000220166, gnorm=1.375, loss_scale=8192, train_wall=163, wall=0
2023-02-19 22:36:13 | INFO | train_inner | epoch 105:    729 / 1978 loss=2.994, nll_loss=0.855, word_ins=2.685, length=3.086, ppl=7.97, wps=36374.9, ups=0.61, wpb=59689.8, bsz=2023.8, num_updates=206400, lr=0.000220113, gnorm=1.396, loss_scale=8192, train_wall=164, wall=0
2023-02-19 22:38:57 | INFO | train_inner | epoch 105:    829 / 1978 loss=2.996, nll_loss=0.859, word_ins=2.688, length=3.084, ppl=7.98, wps=36234.1, ups=0.61, wpb=59644, bsz=2065.1, num_updates=206500, lr=0.000220059, gnorm=1.387, loss_scale=8192, train_wall=164, wall=0
2023-02-19 22:41:41 | INFO | train_inner | epoch 105:    929 / 1978 loss=2.995, nll_loss=0.854, word_ins=2.684, length=3.12, ppl=7.98, wps=36517.9, ups=0.61, wpb=59926.7, bsz=2010.6, num_updates=206600, lr=0.000220006, gnorm=1.36, loss_scale=8192, train_wall=164, wall=0
2023-02-19 22:44:25 | INFO | train_inner | epoch 105:   1029 / 1978 loss=3.005, nll_loss=0.865, word_ins=2.694, length=3.11, ppl=8.03, wps=36198.1, ups=0.61, wpb=59196, bsz=1969.9, num_updates=206700, lr=0.000219953, gnorm=1.359, loss_scale=8192, train_wall=163, wall=0
2023-02-19 22:47:11 | INFO | train_inner | epoch 105:   1129 / 1978 loss=3.035, nll_loss=0.886, word_ins=2.713, length=3.217, ppl=8.19, wps=35435.9, ups=0.6, wpb=58951.1, bsz=1900.2, num_updates=206800, lr=0.0002199, gnorm=1.403, loss_scale=8192, train_wall=166, wall=0
2023-02-19 22:50:03 | INFO | train_inner | epoch 105:   1229 / 1978 loss=2.999, nll_loss=0.857, word_ins=2.686, length=3.129, ppl=7.99, wps=34515.9, ups=0.58, wpb=59319.3, bsz=1996.6, num_updates=206900, lr=0.000219847, gnorm=1.348, loss_scale=8192, train_wall=172, wall=0
2023-02-19 22:52:55 | INFO | train_inner | epoch 105:   1329 / 1978 loss=3.019, nll_loss=0.877, word_ins=2.705, length=3.147, ppl=8.11, wps=34547.5, ups=0.58, wpb=59490.3, bsz=2013.7, num_updates=207000, lr=0.000219793, gnorm=1.375, loss_scale=8192, train_wall=172, wall=0
2023-02-19 22:55:46 | INFO | train_inner | epoch 105:   1429 / 1978 loss=3.032, nll_loss=0.886, word_ins=2.713, length=3.191, ppl=8.18, wps=34585.7, ups=0.59, wpb=59070.5, bsz=1905.2, num_updates=207100, lr=0.00021974, gnorm=1.36, loss_scale=8192, train_wall=171, wall=0
2023-02-19 22:58:39 | INFO | train_inner | epoch 105:   1529 / 1978 loss=3.003, nll_loss=0.866, word_ins=2.694, length=3.093, ppl=8.02, wps=34204.3, ups=0.58, wpb=59222.4, bsz=2072, num_updates=207200, lr=0.000219687, gnorm=1.34, loss_scale=8192, train_wall=173, wall=0
2023-02-19 23:01:30 | INFO | train_inner | epoch 105:   1629 / 1978 loss=3.022, nll_loss=0.885, word_ins=2.712, length=3.098, ppl=8.12, wps=34612.7, ups=0.59, wpb=59125.7, bsz=2014.8, num_updates=207300, lr=0.000219634, gnorm=1.353, loss_scale=8192, train_wall=171, wall=0
2023-02-19 23:04:22 | INFO | train_inner | epoch 105:   1729 / 1978 loss=3.029, nll_loss=0.883, word_ins=2.71, length=3.19, ppl=8.16, wps=34434, ups=0.58, wpb=59163.2, bsz=1934, num_updates=207400, lr=0.000219581, gnorm=1.393, loss_scale=8192, train_wall=172, wall=0
2023-02-19 23:07:14 | INFO | train_inner | epoch 105:   1829 / 1978 loss=3, nll_loss=0.865, word_ins=2.693, length=3.074, ppl=8, wps=34603.2, ups=0.58, wpb=59639.1, bsz=2067.9, num_updates=207500, lr=0.000219529, gnorm=1.29, loss_scale=8192, train_wall=172, wall=0
2023-02-19 23:11:44 | INFO | train_inner | epoch 105:   1929 / 1978 loss=3.029, nll_loss=0.886, word_ins=2.713, length=3.164, ppl=8.16, wps=21822.5, ups=0.37, wpb=58756.3, bsz=1948.2, num_updates=207600, lr=0.000219476, gnorm=1.398, loss_scale=8192, train_wall=269, wall=0
2023-02-19 23:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-19 23:13:24 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 4.101 | nll_loss 1.949 | word_ins 3.721 | length 3.801 | ppl 17.16 | wps 53276.1 | wpb 40242.5 | bsz 1500 | num_updates 207649 | best_loss 4.083
2023-02-19 23:13:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-19 23:13:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint105.pt (epoch 105 @ 207649 updates, score 4.101) (writing took 5.754618207924068 seconds)
2023-02-19 23:13:30 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2023-02-19 23:13:30 | INFO | train | epoch 105 | loss 3.01 | nll_loss 0.87 | word_ins 2.698 | length 3.122 | ppl 8.06 | wps 30084.9 | ups 0.51 | wpb 59284.3 | bsz 2002.6 | num_updates 207649 | lr 0.00021945 | gnorm 1.373 | loss_scale 8192 | train_wall 7550 | wall 0
2023-02-19 23:13:30 | INFO | fairseq.trainer | begin training epoch 106
2023-02-19 23:15:06 | INFO | train_inner | epoch 106:     51 / 1978 loss=2.989, nll_loss=0.853, word_ins=2.682, length=3.065, ppl=7.94, wps=29474.5, ups=0.49, wpb=59731.5, bsz=2000.4, num_updates=207700, lr=0.000219423, gnorm=1.36, loss_scale=8192, train_wall=172, wall=0
2023-02-19 23:17:58 | INFO | train_inner | epoch 106:    151 / 1978 loss=3.002, nll_loss=0.864, word_ins=2.693, length=3.093, ppl=8.01, wps=34313.9, ups=0.58, wpb=58801.9, bsz=1972.3, num_updates=207800, lr=0.00021937, gnorm=1.36, loss_scale=8192, train_wall=171, wall=0
2023-02-19 23:20:50 | INFO | train_inner | epoch 106:    251 / 1978 loss=2.992, nll_loss=0.855, word_ins=2.685, length=3.069, ppl=7.95, wps=34722.1, ups=0.58, wpb=59722.3, bsz=2030.4, num_updates=207900, lr=0.000219317, gnorm=1.424, loss_scale=8192, train_wall=172, wall=0
2023-02-19 23:23:42 | INFO | train_inner | epoch 106:    351 / 1978 loss=2.987, nll_loss=0.85, word_ins=2.68, length=3.071, ppl=7.93, wps=34377.1, ups=0.58, wpb=59147.5, bsz=2025, num_updates=208000, lr=0.000219265, gnorm=1.302, loss_scale=8192, train_wall=172, wall=0
2023-02-19 23:26:32 | INFO | train_inner | epoch 106:    451 / 1978 loss=3.025, nll_loss=0.882, word_ins=2.709, length=3.166, ppl=8.14, wps=35024.7, ups=0.59, wpb=59737.6, bsz=1901.7, num_updates=208100, lr=0.000219212, gnorm=1.425, loss_scale=8192, train_wall=170, wall=0
2023-02-19 23:29:33 | INFO | train_inner | epoch 106:    551 / 1978 loss=3.021, nll_loss=0.878, word_ins=2.705, length=3.153, ppl=8.12, wps=32800.9, ups=0.55, wpb=59353.6, bsz=1932.5, num_updates=208200, lr=0.000219159, gnorm=1.428, loss_scale=8192, train_wall=181, wall=0
2023-02-19 23:32:18 | INFO | train_inner | epoch 106:    651 / 1978 loss=3.018, nll_loss=0.878, word_ins=2.706, length=3.121, ppl=8.1, wps=36064.3, ups=0.61, wpb=59355.3, bsz=2037, num_updates=208300, lr=0.000219107, gnorm=1.384, loss_scale=8192, train_wall=164, wall=0
2023-02-19 23:35:02 | INFO | train_inner | epoch 106:    751 / 1978 loss=3.04, nll_loss=0.892, word_ins=2.719, length=3.21, ppl=8.22, wps=36126.2, ups=0.61, wpb=59240.7, bsz=1958.2, num_updates=208400, lr=0.000219054, gnorm=1.4, loss_scale=8192, train_wall=164, wall=0
2023-02-19 23:37:47 | INFO | train_inner | epoch 106:    851 / 1978 loss=3.014, nll_loss=0.877, word_ins=2.705, length=3.098, ppl=8.08, wps=35741.5, ups=0.61, wpb=58901, bsz=1991.8, num_updates=208500, lr=0.000219001, gnorm=1.389, loss_scale=8192, train_wall=165, wall=0
2023-02-19 23:40:31 | INFO | train_inner | epoch 106:    951 / 1978 loss=3, nll_loss=0.861, word_ins=2.69, length=3.096, ppl=8, wps=36103.5, ups=0.61, wpb=59391, bsz=2012.1, num_updates=208600, lr=0.000218949, gnorm=1.403, loss_scale=8192, train_wall=164, wall=0
2023-02-19 23:43:16 | INFO | train_inner | epoch 106:   1051 / 1978 loss=3.01, nll_loss=0.868, word_ins=2.696, length=3.134, ppl=8.06, wps=35991.4, ups=0.61, wpb=59192, bsz=2049.8, num_updates=208700, lr=0.000218896, gnorm=1.398, loss_scale=8192, train_wall=164, wall=0
2023-02-19 23:46:00 | INFO | train_inner | epoch 106:   1151 / 1978 loss=2.984, nll_loss=0.845, word_ins=2.675, length=3.083, ppl=7.91, wps=36148.4, ups=0.61, wpb=59311.4, bsz=2097.9, num_updates=208800, lr=0.000218844, gnorm=1.372, loss_scale=8192, train_wall=164, wall=0
2023-02-19 23:48:45 | INFO | train_inner | epoch 106:   1251 / 1978 loss=3.004, nll_loss=0.859, word_ins=2.687, length=3.166, ppl=8.02, wps=35890.9, ups=0.61, wpb=59238.7, bsz=2040.7, num_updates=208900, lr=0.000218792, gnorm=1.351, loss_scale=8192, train_wall=165, wall=0
2023-02-19 23:51:28 | INFO | train_inner | epoch 106:   1351 / 1978 loss=3.018, nll_loss=0.878, word_ins=2.705, length=3.128, ppl=8.1, wps=36247.2, ups=0.61, wpb=59282.2, bsz=1953.6, num_updates=209000, lr=0.000218739, gnorm=1.372, loss_scale=8192, train_wall=163, wall=0
2023-02-19 23:54:13 | INFO | train_inner | epoch 106:   1451 / 1978 loss=3.004, nll_loss=0.866, word_ins=2.695, length=3.089, ppl=8.02, wps=36374.4, ups=0.61, wpb=59764.1, bsz=2046.6, num_updates=209100, lr=0.000218687, gnorm=1.351, loss_scale=8192, train_wall=164, wall=0
2023-02-19 23:56:56 | INFO | train_inner | epoch 106:   1551 / 1978 loss=3.038, nll_loss=0.89, word_ins=2.717, length=3.219, ppl=8.22, wps=35978.8, ups=0.61, wpb=58643.3, bsz=1918.6, num_updates=209200, lr=0.000218635, gnorm=1.388, loss_scale=8192, train_wall=163, wall=0
2023-02-19 23:59:55 | INFO | train_inner | epoch 106:   1651 / 1978 loss=2.991, nll_loss=0.852, word_ins=2.681, length=3.097, ppl=7.95, wps=33112.4, ups=0.56, wpb=59294.9, bsz=2036.3, num_updates=209300, lr=0.000218582, gnorm=1.349, loss_scale=8192, train_wall=179, wall=0
2023-02-20 00:02:52 | INFO | train_inner | epoch 106:   1751 / 1978 loss=3.005, nll_loss=0.868, word_ins=2.696, length=3.083, ppl=8.03, wps=33537.6, ups=0.56, wpb=59481.6, bsz=2021.3, num_updates=209400, lr=0.00021853, gnorm=1.391, loss_scale=8192, train_wall=177, wall=0
2023-02-20 00:05:54 | INFO | train_inner | epoch 106:   1851 / 1978 loss=3.002, nll_loss=0.864, word_ins=2.692, length=3.1, ppl=8.01, wps=32667, ups=0.55, wpb=59469.8, bsz=2037.8, num_updates=209500, lr=0.000218478, gnorm=1.37, loss_scale=8192, train_wall=182, wall=0
2023-02-20 00:08:50 | INFO | train_inner | epoch 106:   1951 / 1978 loss=3.009, nll_loss=0.865, word_ins=2.693, length=3.157, ppl=8.05, wps=33505.1, ups=0.57, wpb=58892.3, bsz=2022, num_updates=209600, lr=0.000218426, gnorm=1.332, loss_scale=8192, train_wall=176, wall=0
2023-02-20 00:09:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 00:10:03 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 4.12 | nll_loss 1.95 | word_ins 3.722 | length 3.979 | ppl 17.39 | wps 46065.6 | wpb 40242.5 | bsz 1500 | num_updates 209627 | best_loss 4.083
2023-02-20 00:10:03 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 00:10:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint106.pt (epoch 106 @ 209627 updates, score 4.12) (writing took 6.272374422289431 seconds)
2023-02-20 00:10:09 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2023-02-20 00:10:09 | INFO | train | epoch 106 | loss 3.008 | nll_loss 0.867 | word_ins 2.696 | length 3.121 | ppl 8.04 | wps 34495.6 | ups 0.58 | wpb 59284.3 | bsz 2002.6 | num_updates 209627 | lr 0.000218412 | gnorm 1.378 | loss_scale 8192 | train_wall 3354 | wall 0
2023-02-20 00:10:09 | INFO | fairseq.trainer | begin training epoch 107
2023-02-20 00:12:32 | INFO | train_inner | epoch 107:     73 / 1978 loss=2.978, nll_loss=0.843, word_ins=2.673, length=3.051, ppl=7.88, wps=26855.2, ups=0.45, wpb=59614.7, bsz=2061.1, num_updates=209700, lr=0.000218374, gnorm=1.36, loss_scale=8192, train_wall=178, wall=0
2023-02-20 00:15:29 | INFO | train_inner | epoch 107:    173 / 1978 loss=2.995, nll_loss=0.856, word_ins=2.685, length=3.098, ppl=7.97, wps=33384.5, ups=0.56, wpb=59195.4, bsz=2000.2, num_updates=209800, lr=0.000218322, gnorm=1.383, loss_scale=16384, train_wall=177, wall=0
2023-02-20 00:18:31 | INFO | train_inner | epoch 107:    273 / 1978 loss=2.997, nll_loss=0.858, word_ins=2.688, length=3.094, ppl=7.99, wps=32760, ups=0.55, wpb=59484.4, bsz=2002.6, num_updates=209900, lr=0.00021827, gnorm=1.388, loss_scale=16384, train_wall=181, wall=0
2023-02-20 00:24:52 | INFO | train_inner | epoch 107:    373 / 1978 loss=3.003, nll_loss=0.864, word_ins=2.692, length=3.106, ppl=8.02, wps=15584.6, ups=0.26, wpb=59449, bsz=1931, num_updates=210000, lr=0.000218218, gnorm=1.348, loss_scale=16384, train_wall=379, wall=0
2023-02-20 00:25:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 00:27:52 | INFO | train_inner | epoch 107:    474 / 1978 loss=2.981, nll_loss=0.844, word_ins=2.674, length=3.073, ppl=7.9, wps=33180.1, ups=0.56, wpb=59669.1, bsz=2048.6, num_updates=210100, lr=0.000218166, gnorm=1.363, loss_scale=8192, train_wall=180, wall=0
2023-02-20 00:30:50 | INFO | train_inner | epoch 107:    574 / 1978 loss=3.005, nll_loss=0.865, word_ins=2.694, length=3.109, ppl=8.03, wps=33383.1, ups=0.56, wpb=59400.2, bsz=2013.6, num_updates=210200, lr=0.000218114, gnorm=1.402, loss_scale=8192, train_wall=178, wall=0
2023-02-20 00:33:47 | INFO | train_inner | epoch 107:    674 / 1978 loss=3.024, nll_loss=0.882, word_ins=2.709, length=3.147, ppl=8.13, wps=33342.7, ups=0.57, wpb=58886.4, bsz=1978.8, num_updates=210300, lr=0.000218062, gnorm=1.38, loss_scale=8192, train_wall=176, wall=0
2023-02-20 00:36:45 | INFO | train_inner | epoch 107:    774 / 1978 loss=3.012, nll_loss=0.871, word_ins=2.699, length=3.128, ppl=8.06, wps=33469.1, ups=0.56, wpb=59653.9, bsz=1945, num_updates=210400, lr=0.00021801, gnorm=1.419, loss_scale=8192, train_wall=178, wall=0
2023-02-20 00:39:46 | INFO | train_inner | epoch 107:    874 / 1978 loss=3.008, nll_loss=0.87, word_ins=2.699, length=3.092, ppl=8.04, wps=32671.3, ups=0.55, wpb=59187.6, bsz=2000.2, num_updates=210500, lr=0.000217959, gnorm=1.383, loss_scale=8192, train_wall=181, wall=0
2023-02-20 00:42:44 | INFO | train_inner | epoch 107:    974 / 1978 loss=3.001, nll_loss=0.863, word_ins=2.691, length=3.093, ppl=8, wps=33217.1, ups=0.56, wpb=59118.1, bsz=2010.3, num_updates=210600, lr=0.000217907, gnorm=1.387, loss_scale=8192, train_wall=178, wall=0
2023-02-20 00:45:48 | INFO | train_inner | epoch 107:   1074 / 1978 loss=2.996, nll_loss=0.857, word_ins=2.686, length=3.096, ppl=7.98, wps=32284.8, ups=0.54, wpb=59489.4, bsz=2006.7, num_updates=210700, lr=0.000217855, gnorm=1.351, loss_scale=8192, train_wall=178, wall=0
2023-02-20 00:48:48 | INFO | train_inner | epoch 107:   1174 / 1978 loss=3.006, nll_loss=0.865, word_ins=2.694, length=3.128, ppl=8.04, wps=33520.7, ups=0.56, wpb=60102.3, bsz=1953.7, num_updates=210800, lr=0.000217803, gnorm=1.402, loss_scale=8192, train_wall=179, wall=0
2023-02-20 00:51:44 | INFO | train_inner | epoch 107:   1274 / 1978 loss=3.019, nll_loss=0.876, word_ins=2.704, length=3.151, ppl=8.11, wps=33089.2, ups=0.57, wpb=58543.7, bsz=2004.2, num_updates=210900, lr=0.000217752, gnorm=1.393, loss_scale=8192, train_wall=177, wall=0
2023-02-20 00:54:43 | INFO | train_inner | epoch 107:   1374 / 1978 loss=3.015, nll_loss=0.872, word_ins=2.7, length=3.149, ppl=8.08, wps=33113.4, ups=0.56, wpb=59091, bsz=2020.3, num_updates=211000, lr=0.0002177, gnorm=1.373, loss_scale=8192, train_wall=178, wall=0
2023-02-20 00:57:40 | INFO | train_inner | epoch 107:   1474 / 1978 loss=2.998, nll_loss=0.858, word_ins=2.687, length=3.107, ppl=7.99, wps=33473.9, ups=0.56, wpb=59363.3, bsz=2046.6, num_updates=211100, lr=0.000217649, gnorm=1.396, loss_scale=8192, train_wall=177, wall=0
2023-02-20 01:00:37 | INFO | train_inner | epoch 107:   1574 / 1978 loss=3.007, nll_loss=0.863, word_ins=2.692, length=3.155, ppl=8.04, wps=33048.8, ups=0.57, wpb=58479.1, bsz=1992.6, num_updates=211200, lr=0.000217597, gnorm=1.341, loss_scale=8192, train_wall=177, wall=0
2023-02-20 01:03:32 | INFO | train_inner | epoch 107:   1674 / 1978 loss=3.026, nll_loss=0.88, word_ins=2.708, length=3.179, ppl=8.14, wps=33666.9, ups=0.57, wpb=58817.5, bsz=1986, num_updates=211300, lr=0.000217546, gnorm=1.379, loss_scale=8192, train_wall=174, wall=0
2023-02-20 01:06:18 | INFO | train_inner | epoch 107:   1774 / 1978 loss=3.01, nll_loss=0.868, word_ins=2.696, length=3.14, ppl=8.05, wps=35645.6, ups=0.6, wpb=59143.6, bsz=2043.3, num_updates=211400, lr=0.000217494, gnorm=1.338, loss_scale=8192, train_wall=166, wall=0
2023-02-20 01:09:07 | INFO | train_inner | epoch 107:   1874 / 1978 loss=3.008, nll_loss=0.865, word_ins=2.693, length=3.144, ppl=8.04, wps=35008, ups=0.59, wpb=59329.2, bsz=2027.5, num_updates=211500, lr=0.000217443, gnorm=1.403, loss_scale=8192, train_wall=169, wall=0
2023-02-20 01:11:55 | INFO | train_inner | epoch 107:   1974 / 1978 loss=3.008, nll_loss=0.87, word_ins=2.698, length=3.099, ppl=8.04, wps=35450.9, ups=0.59, wpb=59588.3, bsz=1974.3, num_updates=211600, lr=0.000217391, gnorm=1.361, loss_scale=8192, train_wall=168, wall=0
2023-02-20 01:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 01:12:17 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 4.088 | nll_loss 1.944 | word_ins 3.721 | length 3.671 | ppl 17 | wps 58428.4 | wpb 40242.5 | bsz 1500 | num_updates 211604 | best_loss 4.083
2023-02-20 01:12:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 01:12:23 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint107.pt (epoch 107 @ 211604 updates, score 4.088) (writing took 5.424179146997631 seconds)
2023-02-20 01:12:23 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2023-02-20 01:12:23 | INFO | train | epoch 107 | loss 3.005 | nll_loss 0.864 | word_ins 2.693 | length 3.117 | ppl 8.03 | wps 31390.5 | ups 0.53 | wpb 59282.5 | bsz 2002.6 | num_updates 211604 | lr 0.000217389 | gnorm 1.378 | loss_scale 8192 | train_wall 3687 | wall 0
2023-02-20 01:12:23 | INFO | fairseq.trainer | begin training epoch 108
2023-02-20 01:15:16 | INFO | train_inner | epoch 108:     96 / 1978 loss=3.001, nll_loss=0.858, word_ins=2.687, length=3.142, ppl=8.01, wps=29473, ups=0.5, wpb=58996.6, bsz=1910.7, num_updates=211700, lr=0.00021734, gnorm=1.358, loss_scale=8192, train_wall=170, wall=0
2023-02-20 01:18:07 | INFO | train_inner | epoch 108:    196 / 1978 loss=3.011, nll_loss=0.872, word_ins=2.7, length=3.113, ppl=8.06, wps=34427.3, ups=0.58, wpb=59127.8, bsz=1958.3, num_updates=211800, lr=0.000217289, gnorm=1.341, loss_scale=8192, train_wall=171, wall=0
2023-02-20 01:21:00 | INFO | train_inner | epoch 108:    296 / 1978 loss=2.995, nll_loss=0.861, word_ins=2.689, length=3.059, ppl=7.97, wps=34488.4, ups=0.58, wpb=59458, bsz=2028.9, num_updates=211900, lr=0.000217237, gnorm=1.38, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:23:54 | INFO | train_inner | epoch 108:    396 / 1978 loss=2.979, nll_loss=0.843, word_ins=2.674, length=3.056, ppl=7.89, wps=34306.2, ups=0.57, wpb=59712.7, bsz=2066, num_updates=212000, lr=0.000217186, gnorm=1.369, loss_scale=8192, train_wall=174, wall=0
2023-02-20 01:26:46 | INFO | train_inner | epoch 108:    496 / 1978 loss=3.01, nll_loss=0.87, word_ins=2.698, length=3.121, ppl=8.06, wps=34460.5, ups=0.58, wpb=59298, bsz=1975.8, num_updates=212100, lr=0.000217135, gnorm=1.379, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:29:38 | INFO | train_inner | epoch 108:    596 / 1978 loss=2.994, nll_loss=0.854, word_ins=2.683, length=3.105, ppl=7.97, wps=34454.1, ups=0.58, wpb=59390.3, bsz=1995.7, num_updates=212200, lr=0.000217084, gnorm=1.435, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:32:31 | INFO | train_inner | epoch 108:    696 / 1978 loss=2.993, nll_loss=0.854, word_ins=2.683, length=3.104, ppl=7.96, wps=34572.5, ups=0.58, wpb=59719.5, bsz=2059.2, num_updates=212300, lr=0.000217033, gnorm=1.36, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:35:24 | INFO | train_inner | epoch 108:    796 / 1978 loss=2.982, nll_loss=0.846, word_ins=2.677, length=3.053, ppl=7.9, wps=34274.3, ups=0.58, wpb=59146.7, bsz=2055.9, num_updates=212400, lr=0.000216982, gnorm=1.345, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:38:16 | INFO | train_inner | epoch 108:    896 / 1978 loss=3.021, nll_loss=0.883, word_ins=2.71, length=3.106, ppl=8.12, wps=34043.3, ups=0.58, wpb=58616.8, bsz=2021.7, num_updates=212500, lr=0.00021693, gnorm=1.385, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:41:07 | INFO | train_inner | epoch 108:    996 / 1978 loss=3, nll_loss=0.859, word_ins=2.688, length=3.119, ppl=8, wps=34889.1, ups=0.58, wpb=59776.2, bsz=1986.6, num_updates=212600, lr=0.000216879, gnorm=1.366, loss_scale=8192, train_wall=171, wall=0
2023-02-20 01:43:59 | INFO | train_inner | epoch 108:   1096 / 1978 loss=3.001, nll_loss=0.859, word_ins=2.688, length=3.121, ppl=8, wps=34391.8, ups=0.58, wpb=59011.2, bsz=1947.5, num_updates=212700, lr=0.000216828, gnorm=1.385, loss_scale=8192, train_wall=171, wall=0
2023-02-20 01:46:52 | INFO | train_inner | epoch 108:   1196 / 1978 loss=3.004, nll_loss=0.867, word_ins=2.696, length=3.087, ppl=8.02, wps=34447.2, ups=0.58, wpb=59553.9, bsz=1985.1, num_updates=212800, lr=0.000216777, gnorm=1.366, loss_scale=8192, train_wall=173, wall=0
2023-02-20 01:51:37 | INFO | train_inner | epoch 108:   1296 / 1978 loss=3.033, nll_loss=0.891, word_ins=2.717, length=3.161, ppl=8.18, wps=20729.8, ups=0.35, wpb=59175.2, bsz=1932.4, num_updates=212900, lr=0.000216727, gnorm=1.355, loss_scale=8192, train_wall=285, wall=0
2023-02-20 01:54:29 | INFO | train_inner | epoch 108:   1396 / 1978 loss=3, nll_loss=0.865, word_ins=2.693, length=3.071, ppl=8, wps=34628.2, ups=0.58, wpb=59579.8, bsz=1964.4, num_updates=213000, lr=0.000216676, gnorm=1.394, loss_scale=8192, train_wall=172, wall=0
2023-02-20 01:57:22 | INFO | train_inner | epoch 108:   1496 / 1978 loss=2.998, nll_loss=0.856, word_ins=2.685, length=3.133, ppl=7.99, wps=34644.6, ups=0.58, wpb=59711.2, bsz=2020.5, num_updates=213100, lr=0.000216625, gnorm=1.369, loss_scale=8192, train_wall=172, wall=0
2023-02-20 02:00:13 | INFO | train_inner | epoch 108:   1596 / 1978 loss=3.041, nll_loss=0.897, word_ins=2.723, length=3.185, ppl=8.23, wps=34314.1, ups=0.58, wpb=59006.8, bsz=1930.3, num_updates=213200, lr=0.000216574, gnorm=1.389, loss_scale=8192, train_wall=172, wall=0
2023-02-20 02:03:08 | INFO | train_inner | epoch 108:   1696 / 1978 loss=2.975, nll_loss=0.845, word_ins=2.675, length=3.003, ppl=7.86, wps=34109.2, ups=0.57, wpb=59474.6, bsz=2135.1, num_updates=213300, lr=0.000216523, gnorm=1.368, loss_scale=8192, train_wall=174, wall=0
2023-02-20 02:06:01 | INFO | train_inner | epoch 108:   1796 / 1978 loss=3.019, nll_loss=0.875, word_ins=2.703, length=3.165, ppl=8.11, wps=33909.2, ups=0.58, wpb=58692.7, bsz=2061.3, num_updates=213400, lr=0.000216473, gnorm=1.37, loss_scale=8192, train_wall=173, wall=0
2023-02-20 02:08:52 | INFO | train_inner | epoch 108:   1896 / 1978 loss=3.019, nll_loss=0.877, word_ins=2.705, length=3.14, ppl=8.11, wps=34272.7, ups=0.58, wpb=58689.1, bsz=1975.2, num_updates=213500, lr=0.000216422, gnorm=1.376, loss_scale=8192, train_wall=171, wall=0
2023-02-20 02:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 02:11:31 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 4.123 | nll_loss 1.979 | word_ins 3.751 | length 3.715 | ppl 17.43 | wps 58359.8 | wpb 40242.5 | bsz 1500 | num_updates 213582 | best_loss 4.083
2023-02-20 02:11:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 02:11:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint108.pt (epoch 108 @ 213582 updates, score 4.123) (writing took 5.6037153312936425 seconds)
2023-02-20 02:11:37 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2023-02-20 02:11:37 | INFO | train | epoch 108 | loss 3.004 | nll_loss 0.865 | word_ins 2.693 | length 3.108 | ppl 8.02 | wps 32992.4 | ups 0.56 | wpb 59284.3 | bsz 2002.6 | num_updates 213582 | lr 0.00021638 | gnorm 1.373 | loss_scale 8192 | train_wall 3517 | wall 0
2023-02-20 02:11:37 | INFO | fairseq.trainer | begin training epoch 109
2023-02-20 02:12:18 | INFO | train_inner | epoch 109:     18 / 1978 loss=3.001, nll_loss=0.861, word_ins=2.69, length=3.115, ppl=8.01, wps=28939.9, ups=0.49, wpb=59645.2, bsz=2035, num_updates=213600, lr=0.000216371, gnorm=1.383, loss_scale=8192, train_wall=173, wall=0
2023-02-20 02:15:13 | INFO | train_inner | epoch 109:    118 / 1978 loss=2.995, nll_loss=0.855, word_ins=2.685, length=3.102, ppl=7.97, wps=33971.8, ups=0.57, wpb=59411.1, bsz=1981, num_updates=213700, lr=0.000216321, gnorm=1.341, loss_scale=8192, train_wall=174, wall=0
2023-02-20 02:18:08 | INFO | train_inner | epoch 109:    218 / 1978 loss=2.982, nll_loss=0.844, word_ins=2.675, length=3.068, ppl=7.9, wps=33940.2, ups=0.57, wpb=59176.1, bsz=2079.9, num_updates=213800, lr=0.00021627, gnorm=1.365, loss_scale=8192, train_wall=174, wall=0
2023-02-20 02:21:00 | INFO | train_inner | epoch 109:    318 / 1978 loss=2.982, nll_loss=0.849, word_ins=2.678, length=3.041, ppl=7.9, wps=34766.5, ups=0.58, wpb=59970.8, bsz=2067.4, num_updates=213900, lr=0.000216219, gnorm=1.403, loss_scale=8192, train_wall=172, wall=0
2023-02-20 02:23:50 | INFO | train_inner | epoch 109:    418 / 1978 loss=3.035, nll_loss=0.884, word_ins=2.711, length=3.235, ppl=8.2, wps=34582.4, ups=0.59, wpb=58808.4, bsz=1898.2, num_updates=214000, lr=0.000216169, gnorm=1.403, loss_scale=8192, train_wall=170, wall=0
2023-02-20 02:26:42 | INFO | train_inner | epoch 109:    518 / 1978 loss=3.018, nll_loss=0.88, word_ins=2.708, length=3.099, ppl=8.1, wps=34311.4, ups=0.58, wpb=59079.4, bsz=1961.9, num_updates=214100, lr=0.000216118, gnorm=1.436, loss_scale=8192, train_wall=172, wall=0
2023-02-20 02:29:35 | INFO | train_inner | epoch 109:    618 / 1978 loss=2.98, nll_loss=0.846, word_ins=2.676, length=3.043, ppl=7.89, wps=34631.3, ups=0.58, wpb=59770.4, bsz=2031.8, num_updates=214200, lr=0.000216068, gnorm=1.347, loss_scale=16384, train_wall=172, wall=0
2023-02-20 02:32:27 | INFO | train_inner | epoch 109:    718 / 1978 loss=3.005, nll_loss=0.863, word_ins=2.692, length=3.126, ppl=8.03, wps=34394.1, ups=0.58, wpb=59051.6, bsz=1982, num_updates=214300, lr=0.000216017, gnorm=1.386, loss_scale=16384, train_wall=171, wall=0
2023-02-20 02:35:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 02:35:21 | INFO | train_inner | epoch 109:    819 / 1978 loss=2.978, nll_loss=0.843, word_ins=2.673, length=3.046, ppl=7.88, wps=33842.5, ups=0.57, wpb=59045.1, bsz=2092.8, num_updates=214400, lr=0.000215967, gnorm=1.332, loss_scale=8192, train_wall=174, wall=0
2023-02-20 02:38:14 | INFO | train_inner | epoch 109:    919 / 1978 loss=2.989, nll_loss=0.852, word_ins=2.681, length=3.076, ppl=7.94, wps=34612.4, ups=0.58, wpb=59904.8, bsz=2071.4, num_updates=214500, lr=0.000215917, gnorm=1.386, loss_scale=8192, train_wall=173, wall=0
2023-02-20 02:41:05 | INFO | train_inner | epoch 109:   1019 / 1978 loss=2.991, nll_loss=0.855, word_ins=2.684, length=3.073, ppl=7.95, wps=34495.3, ups=0.58, wpb=59077, bsz=2022.2, num_updates=214600, lr=0.000215866, gnorm=1.312, loss_scale=8192, train_wall=171, wall=0
2023-02-20 02:43:58 | INFO | train_inner | epoch 109:   1119 / 1978 loss=2.999, nll_loss=0.862, word_ins=2.69, length=3.09, ppl=7.99, wps=34538, ups=0.58, wpb=59628.6, bsz=1980.8, num_updates=214700, lr=0.000215816, gnorm=1.413, loss_scale=8192, train_wall=172, wall=0
2023-02-20 02:46:52 | INFO | train_inner | epoch 109:   1219 / 1978 loss=2.988, nll_loss=0.847, word_ins=2.677, length=3.111, ppl=7.93, wps=34042.4, ups=0.57, wpb=59352.5, bsz=2138.6, num_updates=214800, lr=0.000215766, gnorm=1.326, loss_scale=8192, train_wall=174, wall=0
2023-02-20 02:49:45 | INFO | train_inner | epoch 109:   1319 / 1978 loss=3.007, nll_loss=0.871, word_ins=2.698, length=3.091, ppl=8.04, wps=34605.1, ups=0.58, wpb=59876.5, bsz=1993, num_updates=214900, lr=0.000215716, gnorm=1.375, loss_scale=8192, train_wall=173, wall=0
2023-02-20 02:52:38 | INFO | train_inner | epoch 109:   1419 / 1978 loss=3.011, nll_loss=0.871, word_ins=2.699, length=3.119, ppl=8.06, wps=34167, ups=0.58, wpb=58804.6, bsz=1951.7, num_updates=215000, lr=0.000215666, gnorm=1.404, loss_scale=8192, train_wall=172, wall=0
2023-02-20 02:55:30 | INFO | train_inner | epoch 109:   1519 / 1978 loss=3.016, nll_loss=0.87, word_ins=2.698, length=3.186, ppl=8.09, wps=34495.7, ups=0.58, wpb=59635.9, bsz=1953.8, num_updates=215100, lr=0.000215615, gnorm=1.409, loss_scale=8192, train_wall=173, wall=0
2023-02-20 02:58:23 | INFO | train_inner | epoch 109:   1619 / 1978 loss=3.021, nll_loss=0.881, word_ins=2.708, length=3.134, ppl=8.12, wps=34291.7, ups=0.58, wpb=59032.4, bsz=1972, num_updates=215200, lr=0.000215565, gnorm=1.404, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:01:15 | INFO | train_inner | epoch 109:   1719 / 1978 loss=3.006, nll_loss=0.865, word_ins=2.694, length=3.121, ppl=8.03, wps=34414.7, ups=0.58, wpb=59399.3, bsz=2017.1, num_updates=215300, lr=0.000215515, gnorm=1.385, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:04:07 | INFO | train_inner | epoch 109:   1819 / 1978 loss=3.022, nll_loss=0.874, word_ins=2.702, length=3.202, ppl=8.12, wps=34149.1, ups=0.58, wpb=58713.3, bsz=1924.1, num_updates=215400, lr=0.000215465, gnorm=1.401, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:07:00 | INFO | train_inner | epoch 109:   1919 / 1978 loss=3.006, nll_loss=0.864, word_ins=2.693, length=3.131, ppl=8.03, wps=34073.9, ups=0.58, wpb=58881.3, bsz=1996.6, num_updates=215500, lr=0.000215415, gnorm=1.404, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 03:08:55 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 4.169 | nll_loss 1.965 | word_ins 3.738 | length 4.307 | ppl 17.98 | wps 58761.5 | wpb 40242.5 | bsz 1500 | num_updates 215559 | best_loss 4.083
2023-02-20 03:08:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 03:09:00 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint109.pt (epoch 109 @ 215559 updates, score 4.169) (writing took 5.443557881750166 seconds)
2023-02-20 03:09:00 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2023-02-20 03:09:00 | INFO | train | epoch 109 | loss 3.002 | nll_loss 0.862 | word_ins 2.691 | length 3.113 | ppl 8.01 | wps 34038.9 | ups 0.57 | wpb 59283.1 | bsz 2002.7 | num_updates 215559 | lr 0.000215386 | gnorm 1.38 | loss_scale 8192 | train_wall 3407 | wall 0
2023-02-20 03:09:00 | INFO | fairseq.trainer | begin training epoch 110
2023-02-20 03:10:20 | INFO | train_inner | epoch 110:     41 / 1978 loss=3.017, nll_loss=0.868, word_ins=2.697, length=3.202, ppl=8.09, wps=29428.3, ups=0.5, wpb=58825.1, bsz=1905.3, num_updates=215600, lr=0.000215365, gnorm=1.367, loss_scale=8192, train_wall=170, wall=0
2023-02-20 03:13:11 | INFO | train_inner | epoch 110:    141 / 1978 loss=3.012, nll_loss=0.872, word_ins=2.701, length=3.111, ppl=8.07, wps=34731.1, ups=0.58, wpb=59436.5, bsz=1951, num_updates=215700, lr=0.000215315, gnorm=1.342, loss_scale=8192, train_wall=171, wall=0
2023-02-20 03:16:04 | INFO | train_inner | epoch 110:    241 / 1978 loss=3.004, nll_loss=0.861, word_ins=2.69, length=3.138, ppl=8.02, wps=34116.7, ups=0.58, wpb=58906.4, bsz=1965.6, num_updates=215800, lr=0.000215265, gnorm=1.383, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:18:57 | INFO | train_inner | epoch 110:    341 / 1978 loss=3, nll_loss=0.859, word_ins=2.688, length=3.124, ppl=8, wps=34321.3, ups=0.58, wpb=59350, bsz=1967.9, num_updates=215900, lr=0.000215216, gnorm=1.448, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:21:49 | INFO | train_inner | epoch 110:    441 / 1978 loss=2.985, nll_loss=0.846, word_ins=2.676, length=3.095, ppl=7.92, wps=34396, ups=0.58, wpb=59239.1, bsz=2019.1, num_updates=216000, lr=0.000215166, gnorm=1.378, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:24:42 | INFO | train_inner | epoch 110:    541 / 1978 loss=2.996, nll_loss=0.854, word_ins=2.684, length=3.12, ppl=7.98, wps=34070.2, ups=0.58, wpb=59159.6, bsz=2051, num_updates=216100, lr=0.000215116, gnorm=1.374, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:27:36 | INFO | train_inner | epoch 110:    641 / 1978 loss=2.992, nll_loss=0.855, word_ins=2.684, length=3.076, ppl=7.95, wps=34345.1, ups=0.58, wpb=59549.2, bsz=2023.1, num_updates=216200, lr=0.000215066, gnorm=1.358, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:30:28 | INFO | train_inner | epoch 110:    741 / 1978 loss=2.995, nll_loss=0.861, word_ins=2.69, length=3.056, ppl=7.97, wps=34425.1, ups=0.58, wpb=59429.2, bsz=2037, num_updates=216300, lr=0.000215016, gnorm=1.387, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:33:22 | INFO | train_inner | epoch 110:    841 / 1978 loss=2.987, nll_loss=0.848, word_ins=2.678, length=3.095, ppl=7.93, wps=34729.8, ups=0.58, wpb=60093.8, bsz=2034.8, num_updates=216400, lr=0.000214967, gnorm=1.395, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:36:13 | INFO | train_inner | epoch 110:    941 / 1978 loss=2.999, nll_loss=0.861, word_ins=2.689, length=3.099, ppl=8, wps=34427.4, ups=0.58, wpb=59035.2, bsz=1966.8, num_updates=216500, lr=0.000214917, gnorm=1.334, loss_scale=8192, train_wall=171, wall=0
2023-02-20 03:39:06 | INFO | train_inner | epoch 110:   1041 / 1978 loss=3.006, nll_loss=0.864, word_ins=2.693, length=3.129, ppl=8.03, wps=34030.9, ups=0.58, wpb=58754.2, bsz=2005.4, num_updates=216600, lr=0.000214868, gnorm=1.35, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:41:57 | INFO | train_inner | epoch 110:   1141 / 1978 loss=3.017, nll_loss=0.871, word_ins=2.699, length=3.183, ppl=8.1, wps=34354.8, ups=0.58, wpb=58900.5, bsz=1951.8, num_updates=216700, lr=0.000214818, gnorm=1.37, loss_scale=8192, train_wall=171, wall=0
2023-02-20 03:44:51 | INFO | train_inner | epoch 110:   1241 / 1978 loss=2.985, nll_loss=0.849, word_ins=2.678, length=3.06, ppl=7.91, wps=34016.1, ups=0.57, wpb=59196.3, bsz=2085.6, num_updates=216800, lr=0.000214768, gnorm=1.388, loss_scale=8192, train_wall=174, wall=0
2023-02-20 03:47:44 | INFO | train_inner | epoch 110:   1341 / 1978 loss=2.986, nll_loss=0.847, word_ins=2.677, length=3.085, ppl=7.92, wps=34365, ups=0.58, wpb=59548.7, bsz=2089.8, num_updates=216900, lr=0.000214719, gnorm=1.35, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:50:36 | INFO | train_inner | epoch 110:   1441 / 1978 loss=3.017, nll_loss=0.878, word_ins=2.705, length=3.117, ppl=8.09, wps=34601.6, ups=0.58, wpb=59264.6, bsz=1938.3, num_updates=217000, lr=0.000214669, gnorm=1.351, loss_scale=8192, train_wall=171, wall=0
2023-02-20 03:53:29 | INFO | train_inner | epoch 110:   1541 / 1978 loss=3.001, nll_loss=0.861, word_ins=2.69, length=3.113, ppl=8.01, wps=34288.7, ups=0.58, wpb=59481.1, bsz=2008.3, num_updates=217100, lr=0.00021462, gnorm=1.392, loss_scale=8192, train_wall=173, wall=0
2023-02-20 03:56:22 | INFO | train_inner | epoch 110:   1641 / 1978 loss=3.013, nll_loss=0.871, word_ins=2.699, length=3.145, ppl=8.07, wps=34249.8, ups=0.58, wpb=59085.6, bsz=2006.5, num_updates=217200, lr=0.000214571, gnorm=1.334, loss_scale=8192, train_wall=172, wall=0
2023-02-20 03:59:14 | INFO | train_inner | epoch 110:   1741 / 1978 loss=2.999, nll_loss=0.861, word_ins=2.69, length=3.092, ppl=7.99, wps=34350, ups=0.58, wpb=59272.4, bsz=2006.7, num_updates=217300, lr=0.000214521, gnorm=1.348, loss_scale=8192, train_wall=172, wall=0
2023-02-20 04:02:06 | INFO | train_inner | epoch 110:   1841 / 1978 loss=3.019, nll_loss=0.876, word_ins=2.703, length=3.161, ppl=8.11, wps=34547.1, ups=0.58, wpb=59297.5, bsz=1955.7, num_updates=217400, lr=0.000214472, gnorm=1.366, loss_scale=8192, train_wall=171, wall=0
2023-02-20 04:04:59 | INFO | train_inner | epoch 110:   1941 / 1978 loss=3.003, nll_loss=0.862, word_ins=2.691, length=3.119, ppl=8.02, wps=34371.9, ups=0.58, wpb=59534.1, bsz=2010.6, num_updates=217500, lr=0.000214423, gnorm=1.413, loss_scale=8192, train_wall=173, wall=0
2023-02-20 04:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 04:06:20 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 4.163 | nll_loss 1.947 | word_ins 3.721 | length 4.411 | ppl 17.91 | wps 52194.7 | wpb 40242.5 | bsz 1500 | num_updates 217537 | best_loss 4.083
2023-02-20 04:06:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 04:06:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint110.pt (epoch 110 @ 217537 updates, score 4.163) (writing took 5.907286986708641 seconds)
2023-02-20 04:06:26 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2023-02-20 04:06:26 | INFO | train | epoch 110 | loss 3.001 | nll_loss 0.861 | word_ins 2.689 | length 3.112 | ppl 8 | wps 34026.6 | ups 0.57 | wpb 59284.3 | bsz 2002.6 | num_updates 217537 | lr 0.000214404 | gnorm 1.371 | loss_scale 8192 | train_wall 3408 | wall 0
2023-02-20 04:06:26 | INFO | fairseq.trainer | begin training epoch 111
2023-02-20 04:08:25 | INFO | train_inner | epoch 111:     63 / 1978 loss=2.996, nll_loss=0.853, word_ins=2.682, length=3.139, ppl=7.98, wps=28891.4, ups=0.49, wpb=59371, bsz=1912.7, num_updates=217600, lr=0.000214373, gnorm=1.381, loss_scale=8192, train_wall=171, wall=0
2023-02-20 04:11:19 | INFO | train_inner | epoch 111:    163 / 1978 loss=2.961, nll_loss=0.829, word_ins=2.66, length=3.008, ppl=7.79, wps=34237, ups=0.57, wpb=59546.5, bsz=2084.2, num_updates=217700, lr=0.000214324, gnorm=1.355, loss_scale=8192, train_wall=174, wall=0
2023-02-20 04:14:05 | INFO | train_inner | epoch 111:    263 / 1978 loss=2.993, nll_loss=0.854, word_ins=2.684, length=3.091, ppl=7.96, wps=35208.5, ups=0.6, wpb=58577.3, bsz=2017.9, num_updates=217800, lr=0.000214275, gnorm=1.358, loss_scale=8192, train_wall=166, wall=0
2023-02-20 04:16:54 | INFO | train_inner | epoch 111:    363 / 1978 loss=3.003, nll_loss=0.862, word_ins=2.691, length=3.12, ppl=8.01, wps=35129.3, ups=0.59, wpb=59331.6, bsz=1975.2, num_updates=217900, lr=0.000214226, gnorm=1.401, loss_scale=8192, train_wall=169, wall=0
2023-02-20 04:19:42 | INFO | train_inner | epoch 111:    463 / 1978 loss=2.987, nll_loss=0.855, word_ins=2.684, length=3.021, ppl=7.93, wps=35204.7, ups=0.59, wpb=59246.4, bsz=2071.4, num_updates=218000, lr=0.000214176, gnorm=1.351, loss_scale=8192, train_wall=168, wall=0
2023-02-20 04:22:30 | INFO | train_inner | epoch 111:    563 / 1978 loss=2.981, nll_loss=0.843, word_ins=2.673, length=3.078, ppl=7.9, wps=35442, ups=0.59, wpb=59627.1, bsz=2025.8, num_updates=218100, lr=0.000214127, gnorm=1.346, loss_scale=8192, train_wall=168, wall=0
2023-02-20 04:25:16 | INFO | train_inner | epoch 111:    663 / 1978 loss=2.994, nll_loss=0.856, word_ins=2.686, length=3.087, ppl=7.97, wps=35816.2, ups=0.6, wpb=59397.8, bsz=1987.9, num_updates=218200, lr=0.000214078, gnorm=1.408, loss_scale=8192, train_wall=166, wall=0
2023-02-20 04:28:03 | INFO | train_inner | epoch 111:    763 / 1978 loss=3.031, nll_loss=0.885, word_ins=2.712, length=3.185, ppl=8.17, wps=35196.1, ups=0.6, wpb=58640.5, bsz=1929.9, num_updates=218300, lr=0.000214029, gnorm=1.374, loss_scale=8192, train_wall=166, wall=0
2023-02-20 04:30:50 | INFO | train_inner | epoch 111:    863 / 1978 loss=2.984, nll_loss=0.846, word_ins=2.676, length=3.079, ppl=7.91, wps=35712.1, ups=0.6, wpb=59699.4, bsz=1982.3, num_updates=218400, lr=0.00021398, gnorm=1.367, loss_scale=8192, train_wall=167, wall=0
2023-02-20 04:33:37 | INFO | train_inner | epoch 111:    963 / 1978 loss=3, nll_loss=0.858, word_ins=2.686, length=3.14, ppl=8, wps=35599.7, ups=0.6, wpb=59503.8, bsz=1967.4, num_updates=218500, lr=0.000213931, gnorm=1.386, loss_scale=16384, train_wall=167, wall=0
2023-02-20 04:36:26 | INFO | train_inner | epoch 111:   1063 / 1978 loss=2.991, nll_loss=0.857, word_ins=2.687, length=3.04, ppl=7.95, wps=35034.5, ups=0.59, wpb=59073.4, bsz=2103.2, num_updates=218600, lr=0.000213882, gnorm=1.327, loss_scale=16384, train_wall=168, wall=0
2023-02-20 04:36:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 04:39:14 | INFO | train_inner | epoch 111:   1164 / 1978 loss=3.007, nll_loss=0.861, word_ins=2.69, length=3.173, ppl=8.04, wps=35159.4, ups=0.59, wpb=59331.2, bsz=1951.6, num_updates=218700, lr=0.000213833, gnorm=1.406, loss_scale=8192, train_wall=169, wall=0
2023-02-20 04:42:03 | INFO | train_inner | epoch 111:   1264 / 1978 loss=3.004, nll_loss=0.866, word_ins=2.694, length=3.098, ppl=8.02, wps=35108.1, ups=0.59, wpb=59117.7, bsz=2017.5, num_updates=218800, lr=0.000213785, gnorm=1.384, loss_scale=8192, train_wall=168, wall=0
2023-02-20 04:44:50 | INFO | train_inner | epoch 111:   1364 / 1978 loss=2.997, nll_loss=0.859, word_ins=2.688, length=3.092, ppl=7.98, wps=35221.4, ups=0.6, wpb=58889.6, bsz=2018.7, num_updates=218900, lr=0.000213736, gnorm=1.369, loss_scale=8192, train_wall=167, wall=0
2023-02-20 04:47:38 | INFO | train_inner | epoch 111:   1464 / 1978 loss=3.007, nll_loss=0.868, word_ins=2.696, length=3.111, ppl=8.04, wps=35345.8, ups=0.59, wpb=59465.2, bsz=2012.7, num_updates=219000, lr=0.000213687, gnorm=1.385, loss_scale=8192, train_wall=168, wall=0
2023-02-20 04:50:26 | INFO | train_inner | epoch 111:   1564 / 1978 loss=2.998, nll_loss=0.859, word_ins=2.687, length=3.105, ppl=7.99, wps=35523.9, ups=0.6, wpb=59520.2, bsz=1993.4, num_updates=219100, lr=0.000213638, gnorm=1.327, loss_scale=8192, train_wall=167, wall=0
2023-02-20 04:53:13 | INFO | train_inner | epoch 111:   1664 / 1978 loss=3.012, nll_loss=0.868, word_ins=2.696, length=3.164, ppl=8.07, wps=35369, ups=0.6, wpb=59032, bsz=1971.4, num_updates=219200, lr=0.000213589, gnorm=1.386, loss_scale=8192, train_wall=167, wall=0
2023-02-20 04:56:00 | INFO | train_inner | epoch 111:   1764 / 1978 loss=3.022, nll_loss=0.878, word_ins=2.705, length=3.162, ppl=8.12, wps=35227.6, ups=0.6, wpb=58861, bsz=1950.8, num_updates=219300, lr=0.000213541, gnorm=1.433, loss_scale=8192, train_wall=167, wall=0
2023-02-20 04:58:47 | INFO | train_inner | epoch 111:   1864 / 1978 loss=2.986, nll_loss=0.849, word_ins=2.678, length=3.08, ppl=7.93, wps=35689.8, ups=0.6, wpb=59762.5, bsz=2030.6, num_updates=219400, lr=0.000213492, gnorm=1.36, loss_scale=8192, train_wall=167, wall=0
2023-02-20 05:01:35 | INFO | train_inner | epoch 111:   1964 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.112, ppl=7.98, wps=35544.7, ups=0.6, wpb=59652.5, bsz=2031.5, num_updates=219500, lr=0.000213443, gnorm=1.381, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 05:02:22 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 4.119 | nll_loss 1.972 | word_ins 3.746 | length 3.731 | ppl 17.38 | wps 55265.2 | wpb 40242.5 | bsz 1500 | num_updates 219514 | best_loss 4.083
2023-02-20 05:02:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 05:02:28 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint111.pt (epoch 111 @ 219514 updates, score 4.119) (writing took 5.637966125272214 seconds)
2023-02-20 05:02:28 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2023-02-20 05:02:28 | INFO | train | epoch 111 | loss 2.997 | nll_loss 0.858 | word_ins 2.687 | length 3.103 | ppl 7.99 | wps 34869.5 | ups 0.59 | wpb 59287.6 | bsz 2002.8 | num_updates 219514 | lr 0.000213437 | gnorm 1.374 | loss_scale 8192 | train_wall 3317 | wall 0
2023-02-20 05:02:28 | INFO | fairseq.trainer | begin training epoch 112
2023-02-20 05:05:29 | INFO | train_inner | epoch 112:     86 / 1978 loss=2.97, nll_loss=0.839, word_ins=2.669, length=3.005, ppl=7.84, wps=25438.7, ups=0.43, wpb=59422, bsz=2155.6, num_updates=219600, lr=0.000213395, gnorm=1.403, loss_scale=8192, train_wall=169, wall=0
2023-02-20 05:08:18 | INFO | train_inner | epoch 112:    186 / 1978 loss=2.99, nll_loss=0.852, word_ins=2.682, length=3.087, ppl=7.95, wps=35075.3, ups=0.59, wpb=59444, bsz=2025, num_updates=219700, lr=0.000213346, gnorm=1.439, loss_scale=8192, train_wall=169, wall=0
2023-02-20 05:11:06 | INFO | train_inner | epoch 112:    286 / 1978 loss=2.993, nll_loss=0.855, word_ins=2.684, length=3.091, ppl=7.96, wps=35447.7, ups=0.6, wpb=59381.1, bsz=2024.3, num_updates=219800, lr=0.000213298, gnorm=1.336, loss_scale=8192, train_wall=167, wall=0
2023-02-20 05:13:54 | INFO | train_inner | epoch 112:    386 / 1978 loss=2.993, nll_loss=0.854, word_ins=2.684, length=3.094, ppl=7.96, wps=35369.3, ups=0.6, wpb=59424.8, bsz=1950.8, num_updates=219900, lr=0.000213249, gnorm=1.399, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:16:40 | INFO | train_inner | epoch 112:    486 / 1978 loss=3.018, nll_loss=0.875, word_ins=2.702, length=3.154, ppl=8.1, wps=35839.2, ups=0.6, wpb=59533.7, bsz=1886.4, num_updates=220000, lr=0.000213201, gnorm=1.366, loss_scale=8192, train_wall=166, wall=0
2023-02-20 05:19:29 | INFO | train_inner | epoch 112:    586 / 1978 loss=2.996, nll_loss=0.855, word_ins=2.684, length=3.115, ppl=7.98, wps=35317.7, ups=0.59, wpb=59582.6, bsz=2039.4, num_updates=220100, lr=0.000213152, gnorm=1.385, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:22:15 | INFO | train_inner | epoch 112:    686 / 1978 loss=3.01, nll_loss=0.866, word_ins=2.694, length=3.159, ppl=8.06, wps=35249.9, ups=0.6, wpb=58818.3, bsz=1941.3, num_updates=220200, lr=0.000213104, gnorm=1.378, loss_scale=8192, train_wall=167, wall=0
2023-02-20 05:25:04 | INFO | train_inner | epoch 112:    786 / 1978 loss=3, nll_loss=0.859, word_ins=2.687, length=3.122, ppl=8, wps=35013.8, ups=0.59, wpb=59156.2, bsz=1984.1, num_updates=220300, lr=0.000213056, gnorm=1.367, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:27:52 | INFO | train_inner | epoch 112:    886 / 1978 loss=2.997, nll_loss=0.855, word_ins=2.684, length=3.127, ppl=7.98, wps=35128.3, ups=0.6, wpb=58986, bsz=1975.8, num_updates=220400, lr=0.000213007, gnorm=1.364, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:30:41 | INFO | train_inner | epoch 112:    986 / 1978 loss=2.984, nll_loss=0.846, word_ins=2.677, length=3.074, ppl=7.91, wps=35099.3, ups=0.59, wpb=59175.4, bsz=2039, num_updates=220500, lr=0.000212959, gnorm=1.359, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:33:27 | INFO | train_inner | epoch 112:   1086 / 1978 loss=3.017, nll_loss=0.872, word_ins=2.7, length=3.164, ppl=8.09, wps=35831.5, ups=0.6, wpb=59338.6, bsz=1905.6, num_updates=220600, lr=0.000212911, gnorm=1.387, loss_scale=8192, train_wall=165, wall=0
2023-02-20 05:36:14 | INFO | train_inner | epoch 112:   1186 / 1978 loss=3.012, nll_loss=0.876, word_ins=2.703, length=3.09, ppl=8.07, wps=35485.5, ups=0.6, wpb=59490.1, bsz=1987.7, num_updates=220700, lr=0.000212862, gnorm=1.424, loss_scale=8192, train_wall=167, wall=0
2023-02-20 05:39:03 | INFO | train_inner | epoch 112:   1286 / 1978 loss=2.988, nll_loss=0.851, word_ins=2.68, length=3.075, ppl=7.93, wps=35509.1, ups=0.59, wpb=59832, bsz=2024.4, num_updates=220800, lr=0.000212814, gnorm=1.385, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:41:49 | INFO | train_inner | epoch 112:   1386 / 1978 loss=3.021, nll_loss=0.875, word_ins=2.702, length=3.182, ppl=8.11, wps=35403.3, ups=0.6, wpb=58919.6, bsz=1938.8, num_updates=220900, lr=0.000212766, gnorm=1.355, loss_scale=8192, train_wall=166, wall=0
2023-02-20 05:44:37 | INFO | train_inner | epoch 112:   1486 / 1978 loss=2.993, nll_loss=0.852, word_ins=2.682, length=3.117, ppl=7.96, wps=35041.3, ups=0.59, wpb=58973, bsz=2001, num_updates=221000, lr=0.000212718, gnorm=1.362, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:47:27 | INFO | train_inner | epoch 112:   1586 / 1978 loss=2.984, nll_loss=0.847, word_ins=2.676, length=3.076, ppl=7.91, wps=35032.6, ups=0.59, wpb=59380.8, bsz=2040.8, num_updates=221100, lr=0.00021267, gnorm=1.409, loss_scale=8192, train_wall=169, wall=0
2023-02-20 05:50:16 | INFO | train_inner | epoch 112:   1686 / 1978 loss=3, nll_loss=0.863, word_ins=2.691, length=3.086, ppl=8, wps=34981.6, ups=0.59, wpb=59083.2, bsz=2037.4, num_updates=221200, lr=0.000212622, gnorm=1.418, loss_scale=8192, train_wall=169, wall=0
2023-02-20 05:53:04 | INFO | train_inner | epoch 112:   1786 / 1978 loss=2.998, nll_loss=0.858, word_ins=2.687, length=3.109, ppl=7.99, wps=35324.4, ups=0.6, wpb=59230.7, bsz=2015.8, num_updates=221300, lr=0.000212574, gnorm=1.404, loss_scale=8192, train_wall=167, wall=0
2023-02-20 05:55:52 | INFO | train_inner | epoch 112:   1886 / 1978 loss=2.987, nll_loss=0.852, word_ins=2.682, length=3.05, ppl=7.93, wps=35365.9, ups=0.59, wpb=59489.6, bsz=2088, num_updates=221400, lr=0.000212526, gnorm=1.373, loss_scale=8192, train_wall=168, wall=0
2023-02-20 05:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 05:58:51 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 4.102 | nll_loss 1.958 | word_ins 3.73 | length 3.719 | ppl 17.17 | wps 55078.2 | wpb 40242.5 | bsz 1500 | num_updates 221492 | best_loss 4.083
2023-02-20 05:58:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 05:58:57 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint112.pt (epoch 112 @ 221492 updates, score 4.102) (writing took 5.503564881160855 seconds)
2023-02-20 05:58:57 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2023-02-20 05:58:57 | INFO | train | epoch 112 | loss 2.998 | nll_loss 0.858 | word_ins 2.687 | length 3.107 | ppl 7.99 | wps 34601.7 | ups 0.58 | wpb 59284.3 | bsz 2002.6 | num_updates 221492 | lr 0.000212481 | gnorm 1.383 | loss_scale 8192 | train_wall 3318 | wall 0
2023-02-20 05:58:57 | INFO | fairseq.trainer | begin training epoch 113
2023-02-20 05:59:28 | INFO | train_inner | epoch 113:      8 / 1978 loss=2.996, nll_loss=0.855, word_ins=2.684, length=3.114, ppl=7.98, wps=27357.6, ups=0.46, wpb=59115.3, bsz=2025.4, num_updates=221500, lr=0.000212478, gnorm=1.33, loss_scale=8192, train_wall=169, wall=0
2023-02-20 06:02:16 | INFO | train_inner | epoch 113:    108 / 1978 loss=3.006, nll_loss=0.865, word_ins=2.694, length=3.12, ppl=8.04, wps=34876.5, ups=0.6, wpb=58610.2, bsz=2016.6, num_updates=221600, lr=0.00021243, gnorm=1.37, loss_scale=8192, train_wall=168, wall=0
2023-02-20 06:05:05 | INFO | train_inner | epoch 113:    208 / 1978 loss=2.986, nll_loss=0.854, word_ins=2.683, length=3.028, ppl=7.92, wps=35409.5, ups=0.59, wpb=59761.7, bsz=2007.7, num_updates=221700, lr=0.000212382, gnorm=1.393, loss_scale=8192, train_wall=169, wall=0
2023-02-20 06:07:54 | INFO | train_inner | epoch 113:    308 / 1978 loss=2.971, nll_loss=0.834, word_ins=2.665, length=3.059, ppl=7.84, wps=34940.8, ups=0.59, wpb=59028.2, bsz=2111.8, num_updates=221800, lr=0.000212334, gnorm=1.355, loss_scale=8192, train_wall=169, wall=0
2023-02-20 06:10:42 | INFO | train_inner | epoch 113:    408 / 1978 loss=2.967, nll_loss=0.833, word_ins=2.664, length=3.035, ppl=7.82, wps=35423.5, ups=0.59, wpb=59733, bsz=2121.4, num_updates=221900, lr=0.000212286, gnorm=1.371, loss_scale=8192, train_wall=168, wall=0
2023-02-20 06:13:28 | INFO | train_inner | epoch 113:    508 / 1978 loss=3.001, nll_loss=0.858, word_ins=2.686, length=3.149, ppl=8.01, wps=35373.5, ups=0.6, wpb=58804.5, bsz=1957.7, num_updates=222000, lr=0.000212238, gnorm=1.399, loss_scale=8192, train_wall=166, wall=0
2023-02-20 06:16:15 | INFO | train_inner | epoch 113:    608 / 1978 loss=2.997, nll_loss=0.86, word_ins=2.689, length=3.081, ppl=7.98, wps=35366.7, ups=0.6, wpb=58944.9, bsz=1958.2, num_updates=222100, lr=0.00021219, gnorm=1.369, loss_scale=8192, train_wall=166, wall=0
2023-02-20 06:19:00 | INFO | train_inner | epoch 113:    708 / 1978 loss=3.017, nll_loss=0.874, word_ins=2.702, length=3.15, ppl=8.09, wps=35792.3, ups=0.6, wpb=59162.9, bsz=1874.5, num_updates=222200, lr=0.000212143, gnorm=1.38, loss_scale=8192, train_wall=165, wall=0
2023-02-20 06:21:47 | INFO | train_inner | epoch 113:    808 / 1978 loss=2.994, nll_loss=0.855, word_ins=2.684, length=3.101, ppl=7.97, wps=35470.1, ups=0.6, wpb=59181.3, bsz=1997.8, num_updates=222300, lr=0.000212095, gnorm=1.358, loss_scale=8192, train_wall=167, wall=0
2023-02-20 06:24:33 | INFO | train_inner | epoch 113:    908 / 1978 loss=2.996, nll_loss=0.855, word_ins=2.684, length=3.115, ppl=7.98, wps=35870.6, ups=0.6, wpb=59477.7, bsz=2008.7, num_updates=222400, lr=0.000212047, gnorm=1.407, loss_scale=8192, train_wall=166, wall=0
2023-02-20 06:27:16 | INFO | train_inner | epoch 113:   1008 / 1978 loss=3.014, nll_loss=0.87, word_ins=2.697, length=3.168, ppl=8.08, wps=36327.8, ups=0.61, wpb=59319.6, bsz=1897.4, num_updates=222500, lr=0.000212, gnorm=1.38, loss_scale=8192, train_wall=163, wall=0
2023-02-20 06:30:02 | INFO | train_inner | epoch 113:   1108 / 1978 loss=2.988, nll_loss=0.854, word_ins=2.683, length=3.048, ppl=7.93, wps=35618.1, ups=0.6, wpb=59149.4, bsz=2071, num_updates=222600, lr=0.000211952, gnorm=1.31, loss_scale=8192, train_wall=166, wall=0
2023-02-20 06:32:47 | INFO | train_inner | epoch 113:   1208 / 1978 loss=3.01, nll_loss=0.87, word_ins=2.698, length=3.126, ppl=8.06, wps=35971.6, ups=0.61, wpb=59324.5, bsz=1926.4, num_updates=222700, lr=0.000211904, gnorm=1.398, loss_scale=8192, train_wall=165, wall=0
2023-02-20 06:35:33 | INFO | train_inner | epoch 113:   1308 / 1978 loss=3.008, nll_loss=0.87, word_ins=2.698, length=3.105, ppl=8.05, wps=35882.1, ups=0.61, wpb=59240.4, bsz=1988.5, num_updates=222800, lr=0.000211857, gnorm=1.38, loss_scale=16384, train_wall=165, wall=0
2023-02-20 06:36:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 06:38:18 | INFO | train_inner | epoch 113:   1409 / 1978 loss=3.01, nll_loss=0.865, word_ins=2.693, length=3.175, ppl=8.06, wps=35766.8, ups=0.61, wpb=59117.1, bsz=1959, num_updates=222900, lr=0.000211809, gnorm=1.357, loss_scale=8192, train_wall=165, wall=0
2023-02-20 06:41:04 | INFO | train_inner | epoch 113:   1509 / 1978 loss=2.972, nll_loss=0.839, word_ins=2.669, length=3.032, ppl=7.85, wps=35997.7, ups=0.6, wpb=59779.3, bsz=2046.8, num_updates=223000, lr=0.000211762, gnorm=1.372, loss_scale=8192, train_wall=166, wall=0
2023-02-20 06:43:48 | INFO | train_inner | epoch 113:   1609 / 1978 loss=2.997, nll_loss=0.857, word_ins=2.686, length=3.107, ppl=7.98, wps=36314.5, ups=0.61, wpb=59684.9, bsz=1991.1, num_updates=223100, lr=0.000211714, gnorm=1.411, loss_scale=8192, train_wall=164, wall=0
2023-02-20 06:46:34 | INFO | train_inner | epoch 113:   1709 / 1978 loss=2.994, nll_loss=0.856, word_ins=2.685, length=3.091, ppl=7.97, wps=35651.6, ups=0.6, wpb=59086.3, bsz=2042.2, num_updates=223200, lr=0.000211667, gnorm=1.327, loss_scale=8192, train_wall=166, wall=0
2023-02-20 06:49:19 | INFO | train_inner | epoch 113:   1809 / 1978 loss=3.006, nll_loss=0.868, word_ins=2.696, length=3.101, ppl=8.03, wps=35890.2, ups=0.61, wpb=59266, bsz=2009.8, num_updates=223300, lr=0.000211619, gnorm=1.412, loss_scale=8192, train_wall=165, wall=0
2023-02-20 06:52:05 | INFO | train_inner | epoch 113:   1909 / 1978 loss=2.989, nll_loss=0.846, word_ins=2.676, length=3.127, ppl=7.94, wps=35756.1, ups=0.6, wpb=59150.6, bsz=2048, num_updates=223400, lr=0.000211572, gnorm=1.39, loss_scale=8192, train_wall=165, wall=0
2023-02-20 06:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 06:54:14 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 4.171 | nll_loss 1.958 | word_ins 3.734 | length 4.369 | ppl 18.01 | wps 60956.8 | wpb 40242.5 | bsz 1500 | num_updates 223469 | best_loss 4.083
2023-02-20 06:54:14 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 06:54:19 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint113.pt (epoch 113 @ 223469 updates, score 4.171) (writing took 5.28115008957684 seconds)
2023-02-20 06:54:19 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2023-02-20 06:54:19 | INFO | train | epoch 113 | loss 2.996 | nll_loss 0.857 | word_ins 2.686 | length 3.1 | ppl 7.98 | wps 35277.5 | ups 0.6 | wpb 59283.9 | bsz 2003 | num_updates 223469 | lr 0.000211539 | gnorm 1.378 | loss_scale 8192 | train_wall 3280 | wall 0
2023-02-20 06:54:19 | INFO | fairseq.trainer | begin training epoch 114
2023-02-20 06:55:20 | INFO | train_inner | epoch 114:     31 / 1978 loss=2.991, nll_loss=0.854, word_ins=2.683, length=3.087, ppl=7.95, wps=30761.3, ups=0.51, wpb=60047.8, bsz=2024.4, num_updates=223500, lr=0.000211525, gnorm=1.437, loss_scale=8192, train_wall=165, wall=0
2023-02-20 06:58:06 | INFO | train_inner | epoch 114:    131 / 1978 loss=2.984, nll_loss=0.848, word_ins=2.678, length=3.053, ppl=7.91, wps=35913.6, ups=0.6, wpb=59645.8, bsz=2008, num_updates=223600, lr=0.000211477, gnorm=1.379, loss_scale=8192, train_wall=166, wall=0
2023-02-20 07:00:51 | INFO | train_inner | epoch 114:    231 / 1978 loss=2.993, nll_loss=0.852, word_ins=2.681, length=3.12, ppl=7.96, wps=36065.1, ups=0.61, wpb=59599.4, bsz=2000.1, num_updates=223700, lr=0.00021143, gnorm=1.41, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:03:36 | INFO | train_inner | epoch 114:    331 / 1978 loss=3.008, nll_loss=0.864, word_ins=2.692, length=3.165, ppl=8.05, wps=36075.8, ups=0.61, wpb=59518.2, bsz=1934.3, num_updates=223800, lr=0.000211383, gnorm=1.418, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:06:21 | INFO | train_inner | epoch 114:    431 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.108, ppl=7.98, wps=36076.6, ups=0.61, wpb=59446.3, bsz=2006.9, num_updates=223900, lr=0.000211336, gnorm=1.388, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:09:06 | INFO | train_inner | epoch 114:    531 / 1978 loss=2.982, nll_loss=0.844, word_ins=2.674, length=3.086, ppl=7.9, wps=35593.1, ups=0.6, wpb=58868.2, bsz=2047, num_updates=224000, lr=0.000211289, gnorm=1.311, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:11:50 | INFO | train_inner | epoch 114:    631 / 1978 loss=2.99, nll_loss=0.851, word_ins=2.681, length=3.094, ppl=7.95, wps=36067.9, ups=0.61, wpb=59191.6, bsz=1989.2, num_updates=224100, lr=0.000211241, gnorm=1.389, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:14:34 | INFO | train_inner | epoch 114:    731 / 1978 loss=3.019, nll_loss=0.871, word_ins=2.699, length=3.2, ppl=8.11, wps=36000.6, ups=0.61, wpb=58732.2, bsz=1916.8, num_updates=224200, lr=0.000211194, gnorm=1.383, loss_scale=8192, train_wall=163, wall=0
2023-02-20 07:17:19 | INFO | train_inner | epoch 114:    831 / 1978 loss=2.98, nll_loss=0.847, word_ins=2.677, length=3.026, ppl=7.89, wps=35830.1, ups=0.6, wpb=59261.2, bsz=2094.6, num_updates=224300, lr=0.000211147, gnorm=1.337, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:20:04 | INFO | train_inner | epoch 114:    931 / 1978 loss=2.988, nll_loss=0.855, word_ins=2.684, length=3.048, ppl=7.94, wps=36034.2, ups=0.61, wpb=59393.4, bsz=2067, num_updates=224400, lr=0.0002111, gnorm=1.376, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:22:49 | INFO | train_inner | epoch 114:   1031 / 1978 loss=2.994, nll_loss=0.856, word_ins=2.685, length=3.093, ppl=7.97, wps=36015.8, ups=0.61, wpb=59470.6, bsz=2016.7, num_updates=224500, lr=0.000211053, gnorm=1.371, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:25:34 | INFO | train_inner | epoch 114:   1131 / 1978 loss=2.98, nll_loss=0.843, word_ins=2.673, length=3.066, ppl=7.89, wps=35984.1, ups=0.6, wpb=59494.9, bsz=2027.7, num_updates=224600, lr=0.000211006, gnorm=1.37, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:28:19 | INFO | train_inner | epoch 114:   1231 / 1978 loss=2.989, nll_loss=0.847, word_ins=2.676, length=3.13, ppl=7.94, wps=35916.2, ups=0.61, wpb=59182.4, bsz=1996.3, num_updates=224700, lr=0.000210959, gnorm=1.382, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:31:03 | INFO | train_inner | epoch 114:   1331 / 1978 loss=2.993, nll_loss=0.854, word_ins=2.683, length=3.106, ppl=7.96, wps=36187, ups=0.61, wpb=59351.7, bsz=1959.1, num_updates=224800, lr=0.000210912, gnorm=1.348, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:33:48 | INFO | train_inner | epoch 114:   1431 / 1978 loss=2.975, nll_loss=0.843, word_ins=2.673, length=3.027, ppl=7.86, wps=35768.7, ups=0.61, wpb=59060.5, bsz=2078.6, num_updates=224900, lr=0.000210865, gnorm=1.377, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:36:32 | INFO | train_inner | epoch 114:   1531 / 1978 loss=3.009, nll_loss=0.869, word_ins=2.697, length=3.122, ppl=8.05, wps=36235.3, ups=0.61, wpb=59386.1, bsz=1943.4, num_updates=225000, lr=0.000210819, gnorm=1.436, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:39:18 | INFO | train_inner | epoch 114:   1631 / 1978 loss=3.024, nll_loss=0.882, word_ins=2.708, length=3.16, ppl=8.14, wps=35622.6, ups=0.6, wpb=59102.4, bsz=1919.1, num_updates=225100, lr=0.000210772, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:42:03 | INFO | train_inner | epoch 114:   1731 / 1978 loss=3.007, nll_loss=0.868, word_ins=2.696, length=3.108, ppl=8.04, wps=35822.6, ups=0.61, wpb=58955.8, bsz=2008, num_updates=225200, lr=0.000210725, gnorm=1.411, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:44:49 | INFO | train_inner | epoch 114:   1831 / 1978 loss=2.985, nll_loss=0.851, word_ins=2.68, length=3.049, ppl=7.92, wps=36005.1, ups=0.6, wpb=59771.8, bsz=2077.1, num_updates=225300, lr=0.000210678, gnorm=1.34, loss_scale=8192, train_wall=166, wall=0
2023-02-20 07:47:33 | INFO | train_inner | epoch 114:   1931 / 1978 loss=3.016, nll_loss=0.872, word_ins=2.699, length=3.163, ppl=8.09, wps=35742.3, ups=0.61, wpb=58739, bsz=1940.5, num_updates=225400, lr=0.000210631, gnorm=1.389, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:48:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 07:49:05 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 4.13 | nll_loss 1.97 | word_ins 3.742 | length 3.878 | ppl 17.51 | wps 57830.5 | wpb 40242.5 | bsz 1500 | num_updates 225447 | best_loss 4.083
2023-02-20 07:49:05 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 07:49:10 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint114.pt (epoch 114 @ 225447 updates, score 4.13) (writing took 5.546780132688582 seconds)
2023-02-20 07:49:10 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2023-02-20 07:49:10 | INFO | train | epoch 114 | loss 2.995 | nll_loss 0.856 | word_ins 2.685 | length 3.101 | ppl 7.97 | wps 35631.8 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 225447 | lr 0.000210609 | gnorm 1.382 | loss_scale 8192 | train_wall 3257 | wall 0
2023-02-20 07:49:10 | INFO | fairseq.trainer | begin training epoch 115
2023-02-20 07:50:46 | INFO | train_inner | epoch 115:     53 / 1978 loss=2.973, nll_loss=0.838, word_ins=2.669, length=3.042, ppl=7.85, wps=30547.6, ups=0.52, wpb=59139.5, bsz=2043.4, num_updates=225500, lr=0.000210585, gnorm=1.414, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:53:31 | INFO | train_inner | epoch 115:    153 / 1978 loss=3.011, nll_loss=0.866, word_ins=2.695, length=3.161, ppl=8.06, wps=35839.2, ups=0.61, wpb=58860.4, bsz=1967, num_updates=225600, lr=0.000210538, gnorm=1.373, loss_scale=8192, train_wall=164, wall=0
2023-02-20 07:56:15 | INFO | train_inner | epoch 115:    253 / 1978 loss=2.973, nll_loss=0.834, word_ins=2.665, length=3.083, ppl=7.85, wps=36107.9, ups=0.61, wpb=59473.8, bsz=1985.4, num_updates=225700, lr=0.000210491, gnorm=1.391, loss_scale=8192, train_wall=165, wall=0
2023-02-20 07:59:00 | INFO | train_inner | epoch 115:    353 / 1978 loss=2.993, nll_loss=0.854, word_ins=2.683, length=3.106, ppl=7.96, wps=36161.2, ups=0.61, wpb=59476, bsz=1950.1, num_updates=225800, lr=0.000210445, gnorm=1.418, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:01:44 | INFO | train_inner | epoch 115:    453 / 1978 loss=2.98, nll_loss=0.846, word_ins=2.677, length=3.036, ppl=7.89, wps=36315.3, ups=0.61, wpb=59650.6, bsz=2002.1, num_updates=225900, lr=0.000210398, gnorm=1.402, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:04:28 | INFO | train_inner | epoch 115:    553 / 1978 loss=3.001, nll_loss=0.863, word_ins=2.691, length=3.09, ppl=8, wps=36572.9, ups=0.61, wpb=60019.6, bsz=1990, num_updates=226000, lr=0.000210352, gnorm=1.422, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:07:13 | INFO | train_inner | epoch 115:    653 / 1978 loss=2.997, nll_loss=0.856, word_ins=2.685, length=3.116, ppl=7.98, wps=35737.6, ups=0.61, wpb=58928.9, bsz=1956.8, num_updates=226100, lr=0.000210305, gnorm=1.362, loss_scale=8192, train_wall=165, wall=0
2023-02-20 08:10:00 | INFO | train_inner | epoch 115:    753 / 1978 loss=2.975, nll_loss=0.841, word_ins=2.671, length=3.043, ppl=7.86, wps=35909.8, ups=0.6, wpb=59846.2, bsz=2014, num_updates=226200, lr=0.000210259, gnorm=1.412, loss_scale=8192, train_wall=166, wall=0
2023-02-20 08:12:44 | INFO | train_inner | epoch 115:    853 / 1978 loss=3.019, nll_loss=0.877, word_ins=2.705, length=3.139, ppl=8.1, wps=35933.6, ups=0.61, wpb=58986.5, bsz=1898.4, num_updates=226300, lr=0.000210212, gnorm=1.369, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:15:30 | INFO | train_inner | epoch 115:    953 / 1978 loss=2.97, nll_loss=0.833, word_ins=2.664, length=3.061, ppl=7.84, wps=35807.5, ups=0.6, wpb=59463.9, bsz=2080.6, num_updates=226400, lr=0.000210166, gnorm=1.399, loss_scale=8192, train_wall=166, wall=0
2023-02-20 08:18:17 | INFO | train_inner | epoch 115:   1053 / 1978 loss=2.984, nll_loss=0.849, word_ins=2.679, length=3.056, ppl=7.91, wps=35870.6, ups=0.6, wpb=59702.4, bsz=2075.8, num_updates=226500, lr=0.000210119, gnorm=1.343, loss_scale=8192, train_wall=166, wall=0
2023-02-20 08:21:01 | INFO | train_inner | epoch 115:   1153 / 1978 loss=2.992, nll_loss=0.856, word_ins=2.685, length=3.075, ppl=7.96, wps=35768.1, ups=0.61, wpb=58926.8, bsz=2056.1, num_updates=226600, lr=0.000210073, gnorm=1.405, loss_scale=8192, train_wall=165, wall=0
2023-02-20 08:23:46 | INFO | train_inner | epoch 115:   1253 / 1978 loss=2.989, nll_loss=0.849, word_ins=2.678, length=3.113, ppl=7.94, wps=35899.4, ups=0.61, wpb=59297.8, bsz=2042, num_updates=226700, lr=0.000210027, gnorm=1.357, loss_scale=8192, train_wall=165, wall=0
2023-02-20 08:26:31 | INFO | train_inner | epoch 115:   1353 / 1978 loss=3.013, nll_loss=0.87, word_ins=2.698, length=3.153, ppl=8.07, wps=35844.1, ups=0.61, wpb=58933.9, bsz=1915.8, num_updates=226800, lr=0.00020998, gnorm=1.398, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:29:15 | INFO | train_inner | epoch 115:   1453 / 1978 loss=3.002, nll_loss=0.863, word_ins=2.692, length=3.105, ppl=8.01, wps=36069.8, ups=0.61, wpb=59366.1, bsz=1975.8, num_updates=226900, lr=0.000209934, gnorm=1.358, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:32:01 | INFO | train_inner | epoch 115:   1553 / 1978 loss=2.982, nll_loss=0.846, word_ins=2.675, length=3.064, ppl=7.9, wps=35986.5, ups=0.6, wpb=59553.8, bsz=2015.6, num_updates=227000, lr=0.000209888, gnorm=1.359, loss_scale=16384, train_wall=165, wall=0
2023-02-20 08:34:46 | INFO | train_inner | epoch 115:   1653 / 1978 loss=2.991, nll_loss=0.854, word_ins=2.683, length=3.08, ppl=7.95, wps=35843.7, ups=0.61, wpb=59235.3, bsz=2088.6, num_updates=227100, lr=0.000209842, gnorm=1.35, loss_scale=16384, train_wall=165, wall=0
2023-02-20 08:37:30 | INFO | train_inner | epoch 115:   1753 / 1978 loss=3.009, nll_loss=0.868, word_ins=2.696, length=3.131, ppl=8.05, wps=35776.9, ups=0.61, wpb=58650.8, bsz=2000.4, num_updates=227200, lr=0.000209795, gnorm=1.395, loss_scale=16384, train_wall=164, wall=0
2023-02-20 08:38:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 08:40:18 | INFO | train_inner | epoch 115:   1854 / 1978 loss=2.99, nll_loss=0.852, word_ins=2.681, length=3.091, ppl=7.94, wps=35297.4, ups=0.6, wpb=59162.9, bsz=2036.3, num_updates=227300, lr=0.000209749, gnorm=1.341, loss_scale=8192, train_wall=167, wall=0
2023-02-20 08:43:02 | INFO | train_inner | epoch 115:   1954 / 1978 loss=3.001, nll_loss=0.862, word_ins=2.69, length=3.11, ppl=8.01, wps=35966.4, ups=0.61, wpb=59118.5, bsz=1973, num_updates=227400, lr=0.000209703, gnorm=1.381, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 08:43:57 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 4.133 | nll_loss 1.922 | word_ins 3.699 | length 4.334 | ppl 17.54 | wps 58669.9 | wpb 40242.5 | bsz 1500 | num_updates 227424 | best_loss 4.083
2023-02-20 08:43:57 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 08:44:02 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint115.pt (epoch 115 @ 227424 updates, score 4.133) (writing took 5.491131897084415 seconds)
2023-02-20 08:44:02 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2023-02-20 08:44:02 | INFO | train | epoch 115 | loss 2.992 | nll_loss 0.854 | word_ins 2.683 | length 3.092 | ppl 7.96 | wps 35602.8 | ups 0.6 | wpb 59282.9 | bsz 2002.8 | num_updates 227424 | lr 0.000209692 | gnorm 1.38 | loss_scale 8192 | train_wall 3258 | wall 0
2023-02-20 08:44:02 | INFO | fairseq.trainer | begin training epoch 116
2023-02-20 08:46:17 | INFO | train_inner | epoch 116:     76 / 1978 loss=2.987, nll_loss=0.853, word_ins=2.682, length=3.049, ppl=7.93, wps=30413.4, ups=0.51, wpb=59135, bsz=2004, num_updates=227500, lr=0.000209657, gnorm=1.341, loss_scale=8192, train_wall=164, wall=0
2023-02-20 08:49:02 | INFO | train_inner | epoch 116:    176 / 1978 loss=2.968, nll_loss=0.834, word_ins=2.664, length=3.033, ppl=7.82, wps=36413.8, ups=0.61, wpb=60068.3, bsz=2010.5, num_updates=227600, lr=0.000209611, gnorm=1.371, loss_scale=8192, train_wall=165, wall=0
2023-02-20 08:51:47 | INFO | train_inner | epoch 116:    276 / 1978 loss=2.991, nll_loss=0.85, word_ins=2.68, length=3.108, ppl=7.95, wps=35529, ups=0.61, wpb=58634.3, bsz=1975.8, num_updates=227700, lr=0.000209565, gnorm=1.413, loss_scale=8192, train_wall=165, wall=0
2023-02-20 08:54:33 | INFO | train_inner | epoch 116:    376 / 1978 loss=2.985, nll_loss=0.852, word_ins=2.682, length=3.028, ppl=7.92, wps=35472.2, ups=0.6, wpb=58903.9, bsz=2054.6, num_updates=227800, lr=0.000209519, gnorm=1.332, loss_scale=8192, train_wall=166, wall=0
2023-02-20 08:59:37 | INFO | train_inner | epoch 116:    476 / 1978 loss=2.98, nll_loss=0.846, word_ins=2.676, length=3.037, ppl=7.89, wps=19434.3, ups=0.33, wpb=59137.6, bsz=2060.1, num_updates=227900, lr=0.000209473, gnorm=1.372, loss_scale=8192, train_wall=304, wall=0
2023-02-20 09:02:22 | INFO | train_inner | epoch 116:    576 / 1978 loss=2.996, nll_loss=0.857, word_ins=2.686, length=3.099, ppl=7.98, wps=36111.9, ups=0.61, wpb=59526, bsz=1997, num_updates=228000, lr=0.000209427, gnorm=1.393, loss_scale=8192, train_wall=165, wall=0
2023-02-20 09:05:06 | INFO | train_inner | epoch 116:    676 / 1978 loss=3.016, nll_loss=0.873, word_ins=2.701, length=3.154, ppl=8.09, wps=35855.4, ups=0.61, wpb=59042.6, bsz=1952.1, num_updates=228100, lr=0.000209381, gnorm=1.393, loss_scale=8192, train_wall=164, wall=0
2023-02-20 09:07:52 | INFO | train_inner | epoch 116:    776 / 1978 loss=2.97, nll_loss=0.835, word_ins=2.665, length=3.048, ppl=7.84, wps=35623.8, ups=0.6, wpb=59035.4, bsz=2091.8, num_updates=228200, lr=0.000209335, gnorm=1.347, loss_scale=8192, train_wall=166, wall=0
2023-02-20 09:10:41 | INFO | train_inner | epoch 116:    876 / 1978 loss=2.989, nll_loss=0.854, word_ins=2.683, length=3.059, ppl=7.94, wps=35193.6, ups=0.59, wpb=59351.8, bsz=2005.4, num_updates=228300, lr=0.000209289, gnorm=1.363, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:13:29 | INFO | train_inner | epoch 116:    976 / 1978 loss=3.006, nll_loss=0.862, word_ins=2.691, length=3.149, ppl=8.03, wps=35259.1, ups=0.6, wpb=59189.6, bsz=1923.9, num_updates=228400, lr=0.000209243, gnorm=1.383, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:16:17 | INFO | train_inner | epoch 116:   1076 / 1978 loss=2.974, nll_loss=0.839, word_ins=2.669, length=3.048, ppl=7.86, wps=35324.1, ups=0.59, wpb=59510.8, bsz=2046.7, num_updates=228500, lr=0.000209198, gnorm=1.359, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:19:05 | INFO | train_inner | epoch 116:   1176 / 1978 loss=2.973, nll_loss=0.835, word_ins=2.665, length=3.082, ppl=7.85, wps=35473, ups=0.6, wpb=59503.3, bsz=2081.4, num_updates=228600, lr=0.000209152, gnorm=1.361, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:21:52 | INFO | train_inner | epoch 116:   1276 / 1978 loss=2.996, nll_loss=0.857, word_ins=2.686, length=3.095, ppl=7.98, wps=35586.6, ups=0.6, wpb=59574.3, bsz=1980.9, num_updates=228700, lr=0.000209106, gnorm=1.406, loss_scale=8192, train_wall=167, wall=0
2023-02-20 09:24:39 | INFO | train_inner | epoch 116:   1376 / 1978 loss=2.994, nll_loss=0.859, word_ins=2.688, length=3.058, ppl=7.97, wps=35558.3, ups=0.6, wpb=59377.3, bsz=1986.3, num_updates=228800, lr=0.000209061, gnorm=1.389, loss_scale=8192, train_wall=167, wall=0
2023-02-20 09:27:28 | INFO | train_inner | epoch 116:   1476 / 1978 loss=2.993, nll_loss=0.854, word_ins=2.683, length=3.105, ppl=7.96, wps=35058.7, ups=0.59, wpb=58993.5, bsz=2032.6, num_updates=228900, lr=0.000209015, gnorm=1.347, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:30:14 | INFO | train_inner | epoch 116:   1576 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.116, ppl=7.98, wps=35780.6, ups=0.6, wpb=59597.9, bsz=1927.5, num_updates=229000, lr=0.000208969, gnorm=1.38, loss_scale=8192, train_wall=166, wall=0
2023-02-20 09:33:02 | INFO | train_inner | epoch 116:   1676 / 1978 loss=2.994, nll_loss=0.858, word_ins=2.687, length=3.068, ppl=7.97, wps=35153.4, ups=0.6, wpb=59018.5, bsz=2002.4, num_updates=229100, lr=0.000208924, gnorm=1.372, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:35:50 | INFO | train_inner | epoch 116:   1776 / 1978 loss=3.012, nll_loss=0.865, word_ins=2.692, length=3.194, ppl=8.07, wps=35350.6, ups=0.6, wpb=59323.2, bsz=1971.5, num_updates=229200, lr=0.000208878, gnorm=1.42, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:38:38 | INFO | train_inner | epoch 116:   1876 / 1978 loss=2.996, nll_loss=0.854, word_ins=2.683, length=3.131, ppl=7.98, wps=35362.9, ups=0.6, wpb=59302.6, bsz=1979.7, num_updates=229300, lr=0.000208832, gnorm=1.421, loss_scale=8192, train_wall=167, wall=0
2023-02-20 09:41:25 | INFO | train_inner | epoch 116:   1976 / 1978 loss=3.001, nll_loss=0.86, word_ins=2.688, length=3.126, ppl=8, wps=35628.4, ups=0.6, wpb=59490.6, bsz=1979.3, num_updates=229400, lr=0.000208787, gnorm=1.359, loss_scale=8192, train_wall=167, wall=0
2023-02-20 09:41:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 09:41:42 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 4.144 | nll_loss 1.946 | word_ins 3.723 | length 4.218 | ppl 17.68 | wps 57358.9 | wpb 40242.5 | bsz 1500 | num_updates 229402 | best_loss 4.083
2023-02-20 09:41:42 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 09:41:48 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint116.pt (epoch 116 @ 229402 updates, score 4.144) (writing took 5.563774973154068 seconds)
2023-02-20 09:41:48 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2023-02-20 09:41:48 | INFO | train | epoch 116 | loss 2.991 | nll_loss 0.853 | word_ins 2.682 | length 3.089 | ppl 7.95 | wps 33833.3 | ups 0.57 | wpb 59284.3 | bsz 2002.6 | num_updates 229402 | lr 0.000208786 | gnorm 1.377 | loss_scale 8192 | train_wall 3431 | wall 0
2023-02-20 09:41:48 | INFO | fairseq.trainer | begin training epoch 117
2023-02-20 09:44:40 | INFO | train_inner | epoch 117:     98 / 1978 loss=2.987, nll_loss=0.85, word_ins=2.679, length=3.075, ppl=7.93, wps=30217.8, ups=0.51, wpb=59103.4, bsz=1966.5, num_updates=229500, lr=0.000208741, gnorm=1.374, loss_scale=8192, train_wall=166, wall=0
2023-02-20 09:47:28 | INFO | train_inner | epoch 117:    198 / 1978 loss=2.99, nll_loss=0.849, word_ins=2.679, length=3.107, ppl=7.94, wps=35396.2, ups=0.59, wpb=59551.1, bsz=2013.8, num_updates=229600, lr=0.000208696, gnorm=1.371, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:50:15 | INFO | train_inner | epoch 117:    298 / 1978 loss=2.998, nll_loss=0.857, word_ins=2.687, length=3.107, ppl=7.99, wps=35502.4, ups=0.6, wpb=59296.8, bsz=1947.1, num_updates=229700, lr=0.000208651, gnorm=1.39, loss_scale=8192, train_wall=167, wall=0
2023-02-20 09:53:03 | INFO | train_inner | epoch 117:    398 / 1978 loss=2.987, nll_loss=0.85, word_ins=2.679, length=3.077, ppl=7.93, wps=35330.9, ups=0.6, wpb=59302.9, bsz=2030.2, num_updates=229800, lr=0.000208605, gnorm=1.387, loss_scale=8192, train_wall=168, wall=0
2023-02-20 09:55:50 | INFO | train_inner | epoch 117:    498 / 1978 loss=2.998, nll_loss=0.857, word_ins=2.686, length=3.116, ppl=7.99, wps=35335.7, ups=0.6, wpb=59015.8, bsz=1947.8, num_updates=229900, lr=0.00020856, gnorm=1.36, loss_scale=8192, train_wall=167, wall=0
2023-02-20 09:58:37 | INFO | train_inner | epoch 117:    598 / 1978 loss=2.996, nll_loss=0.855, word_ins=2.684, length=3.115, ppl=7.98, wps=35520.7, ups=0.6, wpb=59156.7, bsz=1938, num_updates=230000, lr=0.000208514, gnorm=1.396, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:01:23 | INFO | train_inner | epoch 117:    698 / 1978 loss=2.999, nll_loss=0.857, word_ins=2.686, length=3.135, ppl=8, wps=35518.4, ups=0.6, wpb=59185.7, bsz=1984.4, num_updates=230100, lr=0.000208469, gnorm=1.37, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:04:10 | INFO | train_inner | epoch 117:    798 / 1978 loss=2.985, nll_loss=0.844, word_ins=2.674, length=3.104, ppl=7.92, wps=35478, ups=0.6, wpb=59157.7, bsz=1977.4, num_updates=230200, lr=0.000208424, gnorm=1.35, loss_scale=8192, train_wall=167, wall=0
2023-02-20 10:06:58 | INFO | train_inner | epoch 117:    898 / 1978 loss=2.974, nll_loss=0.839, word_ins=2.669, length=3.046, ppl=7.86, wps=35602.3, ups=0.6, wpb=59769.3, bsz=2072.3, num_updates=230300, lr=0.000208379, gnorm=1.364, loss_scale=8192, train_wall=168, wall=0
2023-02-20 10:09:47 | INFO | train_inner | epoch 117:    998 / 1978 loss=2.962, nll_loss=0.831, word_ins=2.662, length=3.001, ppl=7.79, wps=35284.4, ups=0.59, wpb=59441.5, bsz=2110.5, num_updates=230400, lr=0.000208333, gnorm=1.381, loss_scale=8192, train_wall=168, wall=0
2023-02-20 10:12:34 | INFO | train_inner | epoch 117:   1098 / 1978 loss=2.971, nll_loss=0.84, word_ins=2.67, length=3.011, ppl=7.84, wps=35209.2, ups=0.6, wpb=59113.3, bsz=2084.2, num_updates=230500, lr=0.000208288, gnorm=1.426, loss_scale=8192, train_wall=168, wall=0
2023-02-20 10:15:23 | INFO | train_inner | epoch 117:   1198 / 1978 loss=2.994, nll_loss=0.853, word_ins=2.682, length=3.115, ppl=7.96, wps=35169.2, ups=0.59, wpb=59266.2, bsz=2040.4, num_updates=230600, lr=0.000208243, gnorm=1.343, loss_scale=8192, train_wall=168, wall=0
2023-02-20 10:18:09 | INFO | train_inner | epoch 117:   1298 / 1978 loss=2.999, nll_loss=0.863, word_ins=2.691, length=3.08, ppl=8, wps=35521.8, ups=0.6, wpb=58895, bsz=1978.2, num_updates=230700, lr=0.000208198, gnorm=1.387, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:20:57 | INFO | train_inner | epoch 117:   1398 / 1978 loss=3.005, nll_loss=0.865, word_ins=2.693, length=3.119, ppl=8.03, wps=34969.2, ups=0.6, wpb=58753.5, bsz=1937.8, num_updates=230800, lr=0.000208153, gnorm=1.381, loss_scale=8192, train_wall=168, wall=0
2023-02-20 10:23:46 | INFO | train_inner | epoch 117:   1498 / 1978 loss=2.982, nll_loss=0.846, word_ins=2.676, length=3.069, ppl=7.9, wps=35044, ups=0.59, wpb=59369.7, bsz=2051, num_updates=230900, lr=0.000208108, gnorm=1.372, loss_scale=8192, train_wall=169, wall=0
2023-02-20 10:26:33 | INFO | train_inner | epoch 117:   1598 / 1978 loss=3.003, nll_loss=0.862, word_ins=2.69, length=3.134, ppl=8.02, wps=35757.1, ups=0.6, wpb=59461, bsz=1939.2, num_updates=231000, lr=0.000208063, gnorm=1.427, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:29:19 | INFO | train_inner | epoch 117:   1698 / 1978 loss=2.976, nll_loss=0.843, word_ins=2.673, length=3.025, ppl=7.87, wps=35662.9, ups=0.6, wpb=59429.4, bsz=2036.6, num_updates=231100, lr=0.000208018, gnorm=1.375, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:32:06 | INFO | train_inner | epoch 117:   1798 / 1978 loss=3.014, nll_loss=0.868, word_ins=2.696, length=3.183, ppl=8.08, wps=35200.4, ups=0.6, wpb=58694.7, bsz=1951.2, num_updates=231200, lr=0.000207973, gnorm=1.4, loss_scale=8192, train_wall=167, wall=0
2023-02-20 10:34:54 | INFO | train_inner | epoch 117:   1898 / 1978 loss=2.987, nll_loss=0.85, word_ins=2.679, length=3.08, ppl=7.93, wps=35577.6, ups=0.6, wpb=59730.7, bsz=2003.7, num_updates=231300, lr=0.000207928, gnorm=1.378, loss_scale=8192, train_wall=168, wall=0
2023-02-20 10:35:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 10:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 10:37:24 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 4.076 | nll_loss 1.927 | word_ins 3.701 | length 3.751 | ppl 16.86 | wps 56002.4 | wpb 40242.5 | bsz 1500 | num_updates 231379 | best_loss 4.076
2023-02-20 10:37:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 10:37:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint117.pt (epoch 117 @ 231379 updates, score 4.076) (writing took 8.279332770965993 seconds)
2023-02-20 10:37:32 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2023-02-20 10:37:32 | INFO | train | epoch 117 | loss 2.989 | nll_loss 0.851 | word_ins 2.68 | length 3.087 | ppl 7.94 | wps 35049 | ups 0.59 | wpb 59283.3 | bsz 2002.8 | num_updates 231379 | lr 0.000207892 | gnorm 1.383 | loss_scale 8192 | train_wall 3306 | wall 0
2023-02-20 10:37:32 | INFO | fairseq.trainer | begin training epoch 118
2023-02-20 10:38:18 | INFO | train_inner | epoch 118:     21 / 1978 loss=2.968, nll_loss=0.83, word_ins=2.661, length=3.064, ppl=7.82, wps=29152.5, ups=0.49, wpb=59606.7, bsz=2039.4, num_updates=231400, lr=0.000207883, gnorm=1.408, loss_scale=8192, train_wall=169, wall=0
2023-02-20 10:41:06 | INFO | train_inner | epoch 118:    121 / 1978 loss=2.986, nll_loss=0.849, word_ins=2.679, length=3.067, ppl=7.92, wps=35100.3, ups=0.59, wpb=59015.4, bsz=2022.9, num_updates=231500, lr=0.000207838, gnorm=1.379, loss_scale=8192, train_wall=167, wall=0
2023-02-20 10:43:53 | INFO | train_inner | epoch 118:    221 / 1978 loss=3.026, nll_loss=0.882, word_ins=2.71, length=3.16, ppl=8.14, wps=35445.5, ups=0.6, wpb=58967.5, bsz=1826.8, num_updates=231600, lr=0.000207793, gnorm=1.424, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:46:40 | INFO | train_inner | epoch 118:    321 / 1978 loss=2.992, nll_loss=0.851, word_ins=2.681, length=3.114, ppl=7.96, wps=35551.6, ups=0.6, wpb=59456.4, bsz=1966.6, num_updates=231700, lr=0.000207748, gnorm=1.426, loss_scale=8192, train_wall=167, wall=0
2023-02-20 10:49:29 | INFO | train_inner | epoch 118:    421 / 1978 loss=2.953, nll_loss=0.819, word_ins=2.651, length=3.015, ppl=7.74, wps=35395.9, ups=0.59, wpb=59790.5, bsz=2129.4, num_updates=231800, lr=0.000207703, gnorm=1.322, loss_scale=8192, train_wall=169, wall=0
2023-02-20 10:52:15 | INFO | train_inner | epoch 118:    521 / 1978 loss=2.995, nll_loss=0.857, word_ins=2.686, length=3.09, ppl=7.97, wps=35961.9, ups=0.6, wpb=59647, bsz=1946, num_updates=231900, lr=0.000207658, gnorm=1.344, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:55:01 | INFO | train_inner | epoch 118:    621 / 1978 loss=2.981, nll_loss=0.843, word_ins=2.673, length=3.087, ppl=7.9, wps=35459.3, ups=0.6, wpb=58973.9, bsz=2051.6, num_updates=232000, lr=0.000207614, gnorm=1.32, loss_scale=8192, train_wall=166, wall=0
2023-02-20 10:57:47 | INFO | train_inner | epoch 118:    721 / 1978 loss=3.003, nll_loss=0.865, word_ins=2.693, length=3.092, ppl=8.01, wps=35566.6, ups=0.6, wpb=58877, bsz=1917.5, num_updates=232100, lr=0.000207569, gnorm=1.393, loss_scale=8192, train_wall=165, wall=0
2023-02-20 11:00:33 | INFO | train_inner | epoch 118:    821 / 1978 loss=2.978, nll_loss=0.844, word_ins=2.674, length=3.037, ppl=7.88, wps=35665.4, ups=0.6, wpb=59341.9, bsz=2027.7, num_updates=232200, lr=0.000207524, gnorm=1.383, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:03:19 | INFO | train_inner | epoch 118:    921 / 1978 loss=3, nll_loss=0.864, word_ins=2.692, length=3.08, ppl=8, wps=35881.8, ups=0.6, wpb=59558.9, bsz=1981.8, num_updates=232300, lr=0.00020748, gnorm=1.433, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:06:06 | INFO | train_inner | epoch 118:   1021 / 1978 loss=2.976, nll_loss=0.838, word_ins=2.668, length=3.082, ppl=7.87, wps=35595.4, ups=0.6, wpb=59451.9, bsz=2058.7, num_updates=232400, lr=0.000207435, gnorm=1.433, loss_scale=8192, train_wall=167, wall=0
2023-02-20 11:08:53 | INFO | train_inner | epoch 118:   1121 / 1978 loss=2.981, nll_loss=0.849, word_ins=2.678, length=3.023, ppl=7.89, wps=35593.6, ups=0.6, wpb=59262.3, bsz=2035.7, num_updates=232500, lr=0.00020739, gnorm=1.399, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:11:37 | INFO | train_inner | epoch 118:   1221 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.116, ppl=7.98, wps=35758.7, ups=0.61, wpb=58872, bsz=1932.9, num_updates=232600, lr=0.000207346, gnorm=1.384, loss_scale=8192, train_wall=164, wall=0
2023-02-20 11:14:23 | INFO | train_inner | epoch 118:   1321 / 1978 loss=2.989, nll_loss=0.848, word_ins=2.677, length=3.113, ppl=7.94, wps=36235.6, ups=0.6, wpb=60062.3, bsz=2006.2, num_updates=232700, lr=0.000207301, gnorm=1.384, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:17:10 | INFO | train_inner | epoch 118:   1421 / 1978 loss=2.985, nll_loss=0.849, word_ins=2.678, length=3.076, ppl=7.92, wps=35564.8, ups=0.6, wpb=59520.8, bsz=2047.4, num_updates=232800, lr=0.000207257, gnorm=1.374, loss_scale=8192, train_wall=167, wall=0
2023-02-20 11:19:57 | INFO | train_inner | epoch 118:   1521 / 1978 loss=2.977, nll_loss=0.845, word_ins=2.674, length=3.031, ppl=7.88, wps=35804.2, ups=0.6, wpb=59585.6, bsz=2060, num_updates=232900, lr=0.000207212, gnorm=1.348, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:22:42 | INFO | train_inner | epoch 118:   1621 / 1978 loss=3.01, nll_loss=0.864, word_ins=2.691, length=3.182, ppl=8.05, wps=35825.6, ups=0.61, wpb=59036.5, bsz=1924.9, num_updates=233000, lr=0.000207168, gnorm=1.389, loss_scale=8192, train_wall=165, wall=0
2023-02-20 11:25:28 | INFO | train_inner | epoch 118:   1721 / 1978 loss=2.994, nll_loss=0.854, word_ins=2.683, length=3.113, ppl=7.97, wps=35808.7, ups=0.6, wpb=59679.8, bsz=1994.9, num_updates=233100, lr=0.000207123, gnorm=1.36, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:28:15 | INFO | train_inner | epoch 118:   1821 / 1978 loss=2.976, nll_loss=0.841, word_ins=2.671, length=3.048, ppl=7.87, wps=35545.7, ups=0.6, wpb=59254.4, bsz=2093.9, num_updates=233200, lr=0.000207079, gnorm=1.363, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:31:01 | INFO | train_inner | epoch 118:   1921 / 1978 loss=2.973, nll_loss=0.838, word_ins=2.668, length=3.048, ppl=7.85, wps=35366.4, ups=0.6, wpb=58655.4, bsz=2010.3, num_updates=233300, lr=0.000207034, gnorm=1.333, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 11:32:50 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 4.114 | nll_loss 1.943 | word_ins 3.718 | length 3.963 | ppl 17.32 | wps 57935.9 | wpb 40242.5 | bsz 1500 | num_updates 233357 | best_loss 4.076
2023-02-20 11:32:50 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 11:32:55 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint118.pt (epoch 118 @ 233357 updates, score 4.114) (writing took 5.380298133008182 seconds)
2023-02-20 11:32:55 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2023-02-20 11:32:55 | INFO | train | epoch 118 | loss 2.988 | nll_loss 0.851 | word_ins 2.68 | length 3.085 | ppl 7.94 | wps 35288.4 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 233357 | lr 0.000207009 | gnorm 1.378 | loss_scale 8192 | train_wall 3286 | wall 0
2023-02-20 11:32:55 | INFO | fairseq.trainer | begin training epoch 119
2023-02-20 11:34:16 | INFO | train_inner | epoch 119:     43 / 1978 loss=2.998, nll_loss=0.859, word_ins=2.688, length=3.099, ppl=7.99, wps=30157.1, ups=0.51, wpb=58742.9, bsz=2014.4, num_updates=233400, lr=0.00020699, gnorm=1.364, loss_scale=8192, train_wall=164, wall=0
2023-02-20 11:37:01 | INFO | train_inner | epoch 119:    143 / 1978 loss=2.978, nll_loss=0.84, word_ins=2.671, length=3.073, ppl=7.88, wps=35889.1, ups=0.6, wpb=59422.2, bsz=1980.7, num_updates=233500, lr=0.000206946, gnorm=1.412, loss_scale=8192, train_wall=165, wall=0
2023-02-20 11:39:47 | INFO | train_inner | epoch 119:    243 / 1978 loss=2.979, nll_loss=0.838, word_ins=2.669, length=3.102, ppl=7.88, wps=35755.5, ups=0.6, wpb=59273.9, bsz=1975.2, num_updates=233600, lr=0.000206901, gnorm=1.397, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:42:34 | INFO | train_inner | epoch 119:    343 / 1978 loss=2.97, nll_loss=0.833, word_ins=2.664, length=3.064, ppl=7.84, wps=35700.5, ups=0.6, wpb=59558.3, bsz=2073.4, num_updates=233700, lr=0.000206857, gnorm=1.374, loss_scale=8192, train_wall=167, wall=0
2023-02-20 11:45:19 | INFO | train_inner | epoch 119:    443 / 1978 loss=2.994, nll_loss=0.855, word_ins=2.684, length=3.097, ppl=7.96, wps=35702.7, ups=0.6, wpb=59023.8, bsz=1996.4, num_updates=233800, lr=0.000206813, gnorm=1.391, loss_scale=8192, train_wall=165, wall=0
2023-02-20 11:48:04 | INFO | train_inner | epoch 119:    543 / 1978 loss=2.994, nll_loss=0.853, word_ins=2.682, length=3.118, ppl=7.97, wps=35739, ups=0.61, wpb=59066.2, bsz=1910.7, num_updates=233900, lr=0.000206769, gnorm=1.394, loss_scale=8192, train_wall=165, wall=0
2023-02-20 11:50:51 | INFO | train_inner | epoch 119:    643 / 1978 loss=2.994, nll_loss=0.857, word_ins=2.686, length=3.079, ppl=7.97, wps=35479.8, ups=0.6, wpb=59036.2, bsz=2048.2, num_updates=234000, lr=0.000206725, gnorm=1.369, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:53:36 | INFO | train_inner | epoch 119:    743 / 1978 loss=2.988, nll_loss=0.848, word_ins=2.678, length=3.108, ppl=7.94, wps=35973.2, ups=0.61, wpb=59418.4, bsz=1945.4, num_updates=234100, lr=0.00020668, gnorm=1.414, loss_scale=8192, train_wall=165, wall=0
2023-02-20 11:56:22 | INFO | train_inner | epoch 119:    843 / 1978 loss=2.979, nll_loss=0.845, word_ins=2.675, length=3.043, ppl=7.89, wps=35845, ups=0.6, wpb=59478.3, bsz=1979.2, num_updates=234200, lr=0.000206636, gnorm=1.351, loss_scale=8192, train_wall=166, wall=0
2023-02-20 11:59:08 | INFO | train_inner | epoch 119:    943 / 1978 loss=2.961, nll_loss=0.827, word_ins=2.658, length=3.031, ppl=7.79, wps=35819.4, ups=0.6, wpb=59415.2, bsz=2094.9, num_updates=234300, lr=0.000206592, gnorm=1.376, loss_scale=8192, train_wall=166, wall=0
2023-02-20 12:01:53 | INFO | train_inner | epoch 119:   1043 / 1978 loss=2.992, nll_loss=0.857, word_ins=2.685, length=3.066, ppl=7.95, wps=35738.7, ups=0.6, wpb=59176.1, bsz=1983, num_updates=234400, lr=0.000206548, gnorm=1.347, loss_scale=8192, train_wall=165, wall=0
2023-02-20 12:04:40 | INFO | train_inner | epoch 119:   1143 / 1978 loss=2.986, nll_loss=0.85, word_ins=2.68, length=3.06, ppl=7.92, wps=35386.4, ups=0.6, wpb=59061.9, bsz=2013.8, num_updates=234500, lr=0.000206504, gnorm=1.382, loss_scale=8192, train_wall=167, wall=0
2023-02-20 12:07:26 | INFO | train_inner | epoch 119:   1243 / 1978 loss=2.979, nll_loss=0.842, word_ins=2.672, length=3.078, ppl=7.89, wps=35971.8, ups=0.6, wpb=59648, bsz=2046.1, num_updates=234600, lr=0.00020646, gnorm=1.36, loss_scale=8192, train_wall=166, wall=0
2023-02-20 12:10:11 | INFO | train_inner | epoch 119:   1343 / 1978 loss=3.002, nll_loss=0.86, word_ins=2.688, length=3.14, ppl=8.01, wps=35808.2, ups=0.61, wpb=58924.7, bsz=1988.8, num_updates=234700, lr=0.000206416, gnorm=1.344, loss_scale=8192, train_wall=164, wall=0
2023-02-20 12:12:57 | INFO | train_inner | epoch 119:   1443 / 1978 loss=2.967, nll_loss=0.837, word_ins=2.667, length=3, ppl=7.82, wps=36023.8, ups=0.6, wpb=59878, bsz=2072.3, num_updates=234800, lr=0.000206372, gnorm=1.365, loss_scale=8192, train_wall=166, wall=0
2023-02-20 12:15:43 | INFO | train_inner | epoch 119:   1543 / 1978 loss=2.986, nll_loss=0.845, word_ins=2.675, length=3.118, ppl=7.93, wps=35597.5, ups=0.6, wpb=59223, bsz=2015.5, num_updates=234900, lr=0.000206328, gnorm=1.382, loss_scale=8192, train_wall=166, wall=0
2023-02-20 12:18:28 | INFO | train_inner | epoch 119:   1643 / 1978 loss=3.004, nll_loss=0.864, word_ins=2.692, length=3.119, ppl=8.02, wps=35868.6, ups=0.61, wpb=59251.3, bsz=1998.4, num_updates=235000, lr=0.000206284, gnorm=1.397, loss_scale=8192, train_wall=165, wall=0
2023-02-20 12:21:15 | INFO | train_inner | epoch 119:   1743 / 1978 loss=2.995, nll_loss=0.859, word_ins=2.687, length=3.083, ppl=7.97, wps=35564.1, ups=0.6, wpb=59294, bsz=2036.7, num_updates=235100, lr=0.00020624, gnorm=1.353, loss_scale=8192, train_wall=167, wall=0
2023-02-20 12:24:01 | INFO | train_inner | epoch 119:   1843 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.113, ppl=7.98, wps=36031.7, ups=0.6, wpb=59675.3, bsz=1938.8, num_updates=235200, lr=0.000206197, gnorm=1.439, loss_scale=8192, train_wall=165, wall=0
2023-02-20 12:26:46 | INFO | train_inner | epoch 119:   1943 / 1978 loss=2.998, nll_loss=0.86, word_ins=2.688, length=3.098, ppl=7.99, wps=35671.2, ups=0.6, wpb=59043.9, bsz=1989.3, num_updates=235300, lr=0.000206153, gnorm=1.399, loss_scale=8192, train_wall=165, wall=0
2023-02-20 12:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 12:28:01 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 4.101 | nll_loss 1.913 | word_ins 3.692 | length 4.09 | ppl 17.15 | wps 59206.7 | wpb 40242.5 | bsz 1500 | num_updates 235335 | best_loss 4.076
2023-02-20 12:28:01 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 12:28:06 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint119.pt (epoch 119 @ 235335 updates, score 4.101) (writing took 5.4039340410381556 seconds)
2023-02-20 12:28:06 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2023-02-20 12:28:06 | INFO | train | epoch 119 | loss 2.987 | nll_loss 0.849 | word_ins 2.678 | length 3.083 | ppl 7.93 | wps 35415.3 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 235335 | lr 0.000206137 | gnorm 1.381 | loss_scale 8192 | train_wall 3275 | wall 0
2023-02-20 12:28:06 | INFO | fairseq.trainer | begin training epoch 120
2023-02-20 12:30:05 | INFO | train_inner | epoch 120:     65 / 1978 loss=3.009, nll_loss=0.871, word_ins=2.698, length=3.105, ppl=8.05, wps=29764.4, ups=0.5, wpb=58983.3, bsz=1889.8, num_updates=235400, lr=0.000206109, gnorm=1.387, loss_scale=8192, train_wall=165, wall=0
2023-02-20 12:32:51 | INFO | train_inner | epoch 120:    165 / 1978 loss=2.948, nll_loss=0.817, word_ins=2.649, length=2.989, ppl=7.72, wps=35770.1, ups=0.6, wpb=59593.7, bsz=2107.1, num_updates=235500, lr=0.000206065, gnorm=1.338, loss_scale=16384, train_wall=166, wall=0
2023-02-20 12:35:37 | INFO | train_inner | epoch 120:    265 / 1978 loss=2.969, nll_loss=0.835, word_ins=2.666, length=3.028, ppl=7.83, wps=35834.5, ups=0.6, wpb=59481.3, bsz=2014.4, num_updates=235600, lr=0.000206021, gnorm=1.388, loss_scale=16384, train_wall=166, wall=0
2023-02-20 12:38:22 | INFO | train_inner | epoch 120:    365 / 1978 loss=2.974, nll_loss=0.839, word_ins=2.669, length=3.055, ppl=7.86, wps=36056.5, ups=0.61, wpb=59588.1, bsz=2014.3, num_updates=235700, lr=0.000205978, gnorm=1.32, loss_scale=16384, train_wall=165, wall=0
2023-02-20 12:41:08 | INFO | train_inner | epoch 120:    465 / 1978 loss=3.008, nll_loss=0.867, word_ins=2.695, length=3.132, ppl=8.05, wps=35697.3, ups=0.61, wpb=58965.7, bsz=1984.6, num_updates=235800, lr=0.000205934, gnorm=1.368, loss_scale=16384, train_wall=165, wall=0
2023-02-20 12:43:53 | INFO | train_inner | epoch 120:    565 / 1978 loss=2.985, nll_loss=0.845, word_ins=2.675, length=3.107, ppl=7.92, wps=35605.6, ups=0.6, wpb=58944.8, bsz=2002.5, num_updates=235900, lr=0.00020589, gnorm=1.378, loss_scale=16384, train_wall=165, wall=0
2023-02-20 12:44:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 12:46:43 | INFO | train_inner | epoch 120:    666 / 1978 loss=2.994, nll_loss=0.857, word_ins=2.686, length=3.089, ppl=7.97, wps=35046.5, ups=0.59, wpb=59678, bsz=1954.3, num_updates=236000, lr=0.000205847, gnorm=1.412, loss_scale=8192, train_wall=170, wall=0
2023-02-20 12:51:21 | INFO | train_inner | epoch 120:    766 / 1978 loss=2.963, nll_loss=0.825, word_ins=2.656, length=3.071, ppl=7.8, wps=21347.6, ups=0.36, wpb=59196.1, bsz=2091.9, num_updates=236100, lr=0.000205803, gnorm=1.385, loss_scale=8192, train_wall=277, wall=0
2023-02-20 12:54:05 | INFO | train_inner | epoch 120:    866 / 1978 loss=2.985, nll_loss=0.847, word_ins=2.676, length=3.095, ppl=7.92, wps=35981.2, ups=0.61, wpb=59245.9, bsz=1976.9, num_updates=236200, lr=0.00020576, gnorm=1.398, loss_scale=8192, train_wall=164, wall=0
2023-02-20 12:56:49 | INFO | train_inner | epoch 120:    966 / 1978 loss=3.024, nll_loss=0.88, word_ins=2.707, length=3.177, ppl=8.14, wps=35871.4, ups=0.61, wpb=58769, bsz=1891.8, num_updates=236300, lr=0.000205716, gnorm=1.399, loss_scale=8192, train_wall=164, wall=0
2023-02-20 12:59:34 | INFO | train_inner | epoch 120:   1066 / 1978 loss=2.994, nll_loss=0.86, word_ins=2.689, length=3.049, ppl=7.97, wps=35792.3, ups=0.61, wpb=59022.4, bsz=1968.9, num_updates=236400, lr=0.000205673, gnorm=1.377, loss_scale=8192, train_wall=165, wall=0
2023-02-20 13:02:20 | INFO | train_inner | epoch 120:   1166 / 1978 loss=2.973, nll_loss=0.835, word_ins=2.666, length=3.069, ppl=7.85, wps=35517.3, ups=0.6, wpb=58976.9, bsz=2038.9, num_updates=236500, lr=0.000205629, gnorm=1.391, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:05:06 | INFO | train_inner | epoch 120:   1266 / 1978 loss=2.996, nll_loss=0.855, word_ins=2.684, length=3.122, ppl=7.98, wps=35727.6, ups=0.6, wpb=59423.6, bsz=1972.6, num_updates=236600, lr=0.000205586, gnorm=1.378, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:07:54 | INFO | train_inner | epoch 120:   1366 / 1978 loss=2.997, nll_loss=0.858, word_ins=2.687, length=3.108, ppl=7.99, wps=34958.4, ups=0.6, wpb=58511, bsz=1940.3, num_updates=236700, lr=0.000205542, gnorm=1.396, loss_scale=8192, train_wall=167, wall=0
2023-02-20 13:10:43 | INFO | train_inner | epoch 120:   1466 / 1978 loss=2.985, nll_loss=0.845, word_ins=2.674, length=3.103, ppl=7.92, wps=35277.5, ups=0.59, wpb=59717.4, bsz=1989.9, num_updates=236800, lr=0.000205499, gnorm=1.407, loss_scale=8192, train_wall=169, wall=0
2023-02-20 13:13:31 | INFO | train_inner | epoch 120:   1566 / 1978 loss=2.981, nll_loss=0.842, word_ins=2.672, length=3.082, ppl=7.89, wps=35339.9, ups=0.59, wpb=59421.7, bsz=2012.1, num_updates=236900, lr=0.000205455, gnorm=1.391, loss_scale=8192, train_wall=168, wall=0
2023-02-20 13:16:19 | INFO | train_inner | epoch 120:   1666 / 1978 loss=3.009, nll_loss=0.869, word_ins=2.697, length=3.12, ppl=8.05, wps=35120.8, ups=0.6, wpb=59024.8, bsz=1966.5, num_updates=237000, lr=0.000205412, gnorm=1.356, loss_scale=8192, train_wall=168, wall=0
2023-02-20 13:19:06 | INFO | train_inner | epoch 120:   1766 / 1978 loss=2.98, nll_loss=0.839, word_ins=2.668, length=3.126, ppl=7.89, wps=35869.8, ups=0.6, wpb=59886.8, bsz=2035.6, num_updates=237100, lr=0.000205369, gnorm=1.38, loss_scale=8192, train_wall=167, wall=0
2023-02-20 13:21:52 | INFO | train_inner | epoch 120:   1866 / 1978 loss=2.961, nll_loss=0.828, word_ins=2.659, length=3.022, ppl=7.79, wps=36150.8, ups=0.6, wpb=59774.5, bsz=2124.9, num_updates=237200, lr=0.000205325, gnorm=1.388, loss_scale=8192, train_wall=165, wall=0
2023-02-20 13:24:38 | INFO | train_inner | epoch 120:   1966 / 1978 loss=2.973, nll_loss=0.84, word_ins=2.67, length=3.038, ppl=7.85, wps=35537.8, ups=0.6, wpb=59229.9, bsz=2051.4, num_updates=237300, lr=0.000205282, gnorm=1.398, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 13:25:14 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 4.147 | nll_loss 1.942 | word_ins 3.718 | length 4.293 | ppl 17.72 | wps 59412 | wpb 40242.5 | bsz 1500 | num_updates 237312 | best_loss 4.076
2023-02-20 13:25:14 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 13:25:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint120.pt (epoch 120 @ 237312 updates, score 4.147) (writing took 5.454251613467932 seconds)
2023-02-20 13:25:20 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2023-02-20 13:25:20 | INFO | train | epoch 120 | loss 2.985 | nll_loss 0.847 | word_ins 2.677 | length 3.084 | ppl 7.92 | wps 34136.2 | ups 0.58 | wpb 59283.9 | bsz 2002.8 | num_updates 237312 | lr 0.000205277 | gnorm 1.381 | loss_scale 8192 | train_wall 3396 | wall 0
2023-02-20 13:25:20 | INFO | fairseq.trainer | begin training epoch 121
2023-02-20 13:27:54 | INFO | train_inner | epoch 121:     88 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.107, ppl=7.98, wps=30068.4, ups=0.51, wpb=58961.5, bsz=1917.4, num_updates=237400, lr=0.000205239, gnorm=1.402, loss_scale=8192, train_wall=163, wall=0
2023-02-20 13:30:41 | INFO | train_inner | epoch 121:    188 / 1978 loss=2.964, nll_loss=0.831, word_ins=2.662, length=3.021, ppl=7.8, wps=35862.3, ups=0.6, wpb=59583.4, bsz=2044.8, num_updates=237500, lr=0.000205196, gnorm=1.356, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:33:27 | INFO | train_inner | epoch 121:    288 / 1978 loss=3.002, nll_loss=0.859, word_ins=2.687, length=3.15, ppl=8.01, wps=35588.7, ups=0.6, wpb=59143.2, bsz=1968.6, num_updates=237600, lr=0.000205152, gnorm=1.402, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:36:12 | INFO | train_inner | epoch 121:    388 / 1978 loss=2.988, nll_loss=0.845, word_ins=2.675, length=3.129, ppl=7.93, wps=35652.1, ups=0.6, wpb=58980.8, bsz=1953.6, num_updates=237700, lr=0.000205109, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-20 13:38:58 | INFO | train_inner | epoch 121:    488 / 1978 loss=2.984, nll_loss=0.843, word_ins=2.674, length=3.101, ppl=7.91, wps=35663, ups=0.6, wpb=59017.9, bsz=1955.6, num_updates=237800, lr=0.000205066, gnorm=1.355, loss_scale=8192, train_wall=165, wall=0
2023-02-20 13:41:44 | INFO | train_inner | epoch 121:    588 / 1978 loss=2.961, nll_loss=0.829, word_ins=2.66, length=3.007, ppl=7.79, wps=35841.5, ups=0.6, wpb=59604.9, bsz=2088.2, num_updates=237900, lr=0.000205023, gnorm=1.33, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:44:30 | INFO | train_inner | epoch 121:    688 / 1978 loss=2.985, nll_loss=0.845, word_ins=2.675, length=3.098, ppl=7.92, wps=35795.8, ups=0.6, wpb=59475.4, bsz=1942.7, num_updates=238000, lr=0.00020498, gnorm=1.379, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:47:16 | INFO | train_inner | epoch 121:    788 / 1978 loss=2.979, nll_loss=0.839, word_ins=2.67, length=3.09, ppl=7.88, wps=35570, ups=0.6, wpb=58970.3, bsz=2005.5, num_updates=238100, lr=0.000204937, gnorm=1.359, loss_scale=8192, train_wall=166, wall=0
2023-02-20 13:50:09 | INFO | train_inner | epoch 121:    888 / 1978 loss=2.979, nll_loss=0.845, word_ins=2.674, length=3.045, ppl=7.88, wps=34475.5, ups=0.58, wpb=59772, bsz=2023.9, num_updates=238200, lr=0.000204894, gnorm=1.389, loss_scale=8192, train_wall=173, wall=0
2023-02-20 13:53:04 | INFO | train_inner | epoch 121:    988 / 1978 loss=3.006, nll_loss=0.867, word_ins=2.696, length=3.108, ppl=8.04, wps=33671.9, ups=0.57, wpb=58749.7, bsz=1878.5, num_updates=238300, lr=0.000204851, gnorm=1.396, loss_scale=8192, train_wall=174, wall=0
2023-02-20 13:55:58 | INFO | train_inner | epoch 121:   1088 / 1978 loss=2.989, nll_loss=0.85, word_ins=2.679, length=3.104, ppl=7.94, wps=33887.6, ups=0.57, wpb=59141.5, bsz=1997.2, num_updates=238400, lr=0.000204808, gnorm=1.387, loss_scale=8192, train_wall=174, wall=0
2023-02-20 13:58:55 | INFO | train_inner | epoch 121:   1188 / 1978 loss=2.983, nll_loss=0.841, word_ins=2.672, length=3.113, ppl=7.91, wps=33700.4, ups=0.57, wpb=59399.9, bsz=2055.8, num_updates=238500, lr=0.000204765, gnorm=1.373, loss_scale=8192, train_wall=176, wall=0
2023-02-20 14:01:49 | INFO | train_inner | epoch 121:   1288 / 1978 loss=2.99, nll_loss=0.855, word_ins=2.684, length=3.064, ppl=7.95, wps=33855.7, ups=0.57, wpb=58940.3, bsz=1971.2, num_updates=238600, lr=0.000204722, gnorm=1.408, loss_scale=8192, train_wall=174, wall=0
2023-02-20 14:04:45 | INFO | train_inner | epoch 121:   1388 / 1978 loss=2.968, nll_loss=0.835, word_ins=2.665, length=3.026, ppl=7.82, wps=33485.4, ups=0.57, wpb=59072.8, bsz=2103.8, num_updates=238700, lr=0.000204679, gnorm=1.385, loss_scale=8192, train_wall=176, wall=0
2023-02-20 14:07:40 | INFO | train_inner | epoch 121:   1488 / 1978 loss=3.003, nll_loss=0.861, word_ins=2.689, length=3.134, ppl=8.02, wps=34027.6, ups=0.57, wpb=59597, bsz=1955.8, num_updates=238800, lr=0.000204636, gnorm=1.449, loss_scale=8192, train_wall=175, wall=0
2023-02-20 14:10:37 | INFO | train_inner | epoch 121:   1588 / 1978 loss=2.955, nll_loss=0.822, word_ins=2.653, length=3.017, ppl=7.75, wps=33937.4, ups=0.57, wpb=59825.1, bsz=2102.8, num_updates=238900, lr=0.000204594, gnorm=1.361, loss_scale=8192, train_wall=176, wall=0
2023-02-20 14:13:33 | INFO | train_inner | epoch 121:   1688 / 1978 loss=2.959, nll_loss=0.829, word_ins=2.66, length=2.989, ppl=7.77, wps=33863.6, ups=0.57, wpb=59835.2, bsz=2093.7, num_updates=239000, lr=0.000204551, gnorm=1.373, loss_scale=8192, train_wall=176, wall=0
2023-02-20 14:16:26 | INFO | train_inner | epoch 121:   1788 / 1978 loss=2.977, nll_loss=0.839, word_ins=2.669, length=3.087, ppl=7.88, wps=34342.5, ups=0.58, wpb=59433, bsz=2018.4, num_updates=239100, lr=0.000204508, gnorm=1.399, loss_scale=8192, train_wall=173, wall=0
2023-02-20 14:19:19 | INFO | train_inner | epoch 121:   1888 / 1978 loss=2.993, nll_loss=0.853, word_ins=2.681, length=3.115, ppl=7.96, wps=34159.7, ups=0.58, wpb=58971.3, bsz=2002, num_updates=239200, lr=0.000204465, gnorm=1.381, loss_scale=8192, train_wall=172, wall=0
2023-02-20 14:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 14:22:12 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 4.141 | nll_loss 1.946 | word_ins 3.717 | length 4.238 | ppl 17.64 | wps 48826.5 | wpb 40242.5 | bsz 1500 | num_updates 239290 | best_loss 4.076
2023-02-20 14:22:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 14:22:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint121.pt (epoch 121 @ 239290 updates, score 4.141) (writing took 5.634606051258743 seconds)
2023-02-20 14:22:17 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2023-02-20 14:22:17 | INFO | train | epoch 121 | loss 2.983 | nll_loss 0.845 | word_ins 2.674 | length 3.081 | ppl 7.9 | wps 34311.8 | ups 0.58 | wpb 59284.3 | bsz 2002.6 | num_updates 239290 | lr 0.000204427 | gnorm 1.383 | loss_scale 8192 | train_wall 3379 | wall 0
2023-02-20 14:22:17 | INFO | fairseq.trainer | begin training epoch 122
2023-02-20 14:22:47 | INFO | train_inner | epoch 122:     10 / 1978 loss=2.991, nll_loss=0.851, word_ins=2.681, length=3.106, ppl=7.95, wps=28476.3, ups=0.48, wpb=59143, bsz=1953.3, num_updates=239300, lr=0.000204422, gnorm=1.382, loss_scale=8192, train_wall=172, wall=0
2023-02-20 14:25:38 | INFO | train_inner | epoch 122:    110 / 1978 loss=2.985, nll_loss=0.843, word_ins=2.673, length=3.124, ppl=7.92, wps=34399.7, ups=0.58, wpb=58820, bsz=1919.8, num_updates=239400, lr=0.00020438, gnorm=1.405, loss_scale=8192, train_wall=171, wall=0
2023-02-20 14:28:29 | INFO | train_inner | epoch 122:    210 / 1978 loss=2.959, nll_loss=0.83, word_ins=2.661, length=2.981, ppl=7.78, wps=34668.1, ups=0.58, wpb=59418.7, bsz=2068.7, num_updates=239500, lr=0.000204337, gnorm=1.332, loss_scale=8192, train_wall=171, wall=0
2023-02-20 14:31:19 | INFO | train_inner | epoch 122:    310 / 1978 loss=2.988, nll_loss=0.846, word_ins=2.675, length=3.124, ppl=7.93, wps=34891.5, ups=0.59, wpb=59162.5, bsz=1910.3, num_updates=239600, lr=0.000204294, gnorm=1.363, loss_scale=8192, train_wall=169, wall=0
2023-02-20 14:34:09 | INFO | train_inner | epoch 122:    410 / 1978 loss=2.969, nll_loss=0.836, word_ins=2.667, length=3.02, ppl=7.83, wps=34933.3, ups=0.59, wpb=59482.5, bsz=2027.9, num_updates=239700, lr=0.000204252, gnorm=1.358, loss_scale=8192, train_wall=170, wall=0
2023-02-20 14:36:58 | INFO | train_inner | epoch 122:    510 / 1978 loss=2.982, nll_loss=0.842, word_ins=2.672, length=3.098, ppl=7.9, wps=35280.6, ups=0.59, wpb=59587, bsz=2035, num_updates=239800, lr=0.000204209, gnorm=1.376, loss_scale=8192, train_wall=169, wall=0
2023-02-20 14:39:46 | INFO | train_inner | epoch 122:    610 / 1978 loss=2.96, nll_loss=0.83, word_ins=2.661, length=2.987, ppl=7.78, wps=35562.7, ups=0.59, wpb=59773.6, bsz=2130.2, num_updates=239900, lr=0.000204167, gnorm=1.396, loss_scale=8192, train_wall=168, wall=0
2023-02-20 14:42:32 | INFO | train_inner | epoch 122:    710 / 1978 loss=2.982, nll_loss=0.842, word_ins=2.672, length=3.098, ppl=7.9, wps=35348.3, ups=0.6, wpb=58714.6, bsz=2014.5, num_updates=240000, lr=0.000204124, gnorm=1.394, loss_scale=8192, train_wall=166, wall=0
2023-02-20 14:45:18 | INFO | train_inner | epoch 122:    810 / 1978 loss=3.002, nll_loss=0.862, word_ins=2.691, length=3.117, ppl=8.01, wps=35491.9, ups=0.6, wpb=58945.9, bsz=1943.4, num_updates=240100, lr=0.000204082, gnorm=1.376, loss_scale=16384, train_wall=166, wall=0
2023-02-20 14:48:05 | INFO | train_inner | epoch 122:    910 / 1978 loss=2.984, nll_loss=0.846, word_ins=2.676, length=3.083, ppl=7.91, wps=35737.1, ups=0.6, wpb=59496.8, bsz=2013.6, num_updates=240200, lr=0.000204039, gnorm=1.403, loss_scale=16384, train_wall=166, wall=0
2023-02-20 14:50:50 | INFO | train_inner | epoch 122:   1010 / 1978 loss=2.995, nll_loss=0.855, word_ins=2.684, length=3.112, ppl=7.97, wps=35974.6, ups=0.6, wpb=59502.7, bsz=1918.3, num_updates=240300, lr=0.000203997, gnorm=1.438, loss_scale=16384, train_wall=165, wall=0
2023-02-20 14:52:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 14:53:37 | INFO | train_inner | epoch 122:   1111 / 1978 loss=2.978, nll_loss=0.838, word_ins=2.668, length=3.101, ppl=7.88, wps=35674.3, ups=0.6, wpb=59493.6, bsz=1973.5, num_updates=240400, lr=0.000203954, gnorm=1.436, loss_scale=8192, train_wall=167, wall=0
2023-02-20 14:56:23 | INFO | train_inner | epoch 122:   1211 / 1978 loss=2.974, nll_loss=0.841, word_ins=2.671, length=3.038, ppl=7.86, wps=35568.1, ups=0.6, wpb=59047.1, bsz=2065.9, num_updates=240500, lr=0.000203912, gnorm=1.363, loss_scale=8192, train_wall=166, wall=0
2023-02-20 14:59:10 | INFO | train_inner | epoch 122:   1311 / 1978 loss=2.97, nll_loss=0.834, word_ins=2.664, length=3.056, ppl=7.84, wps=35772.8, ups=0.6, wpb=59831.8, bsz=2049.6, num_updates=240600, lr=0.000203869, gnorm=1.417, loss_scale=8192, train_wall=167, wall=0
2023-02-20 15:01:56 | INFO | train_inner | epoch 122:   1411 / 1978 loss=2.999, nll_loss=0.856, word_ins=2.685, length=3.139, ppl=7.99, wps=35635.1, ups=0.6, wpb=59241.4, bsz=1967.2, num_updates=240700, lr=0.000203827, gnorm=1.434, loss_scale=8192, train_wall=166, wall=0
2023-02-20 15:04:41 | INFO | train_inner | epoch 122:   1511 / 1978 loss=2.989, nll_loss=0.853, word_ins=2.682, length=3.076, ppl=7.94, wps=35747.3, ups=0.61, wpb=59007.3, bsz=1984.3, num_updates=240800, lr=0.000203785, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:07:28 | INFO | train_inner | epoch 122:   1611 / 1978 loss=2.977, nll_loss=0.846, word_ins=2.675, length=3.023, ppl=7.88, wps=35492.2, ups=0.6, wpb=59264.2, bsz=2051.6, num_updates=240900, lr=0.000203742, gnorm=1.405, loss_scale=8192, train_wall=167, wall=0
2023-02-20 15:10:14 | INFO | train_inner | epoch 122:   1711 / 1978 loss=2.974, nll_loss=0.84, word_ins=2.67, length=3.042, ppl=7.86, wps=35978.3, ups=0.6, wpb=59666.3, bsz=2021, num_updates=241000, lr=0.0002037, gnorm=1.36, loss_scale=8192, train_wall=166, wall=0
2023-02-20 15:13:01 | INFO | train_inner | epoch 122:   1811 / 1978 loss=2.994, nll_loss=0.852, word_ins=2.681, length=3.128, ppl=7.97, wps=35560.8, ups=0.6, wpb=59173.3, bsz=1984, num_updates=241100, lr=0.000203658, gnorm=1.374, loss_scale=8192, train_wall=166, wall=0
2023-02-20 15:15:45 | INFO | train_inner | epoch 122:   1911 / 1978 loss=2.994, nll_loss=0.852, word_ins=2.68, length=3.136, ppl=7.96, wps=35983.5, ups=0.61, wpb=59155.7, bsz=1975.5, num_updates=241200, lr=0.000203616, gnorm=1.377, loss_scale=8192, train_wall=164, wall=0
2023-02-20 15:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 15:17:54 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 4.146 | nll_loss 1.969 | word_ins 3.741 | length 4.043 | ppl 17.7 | wps 53234.7 | wpb 40242.5 | bsz 1500 | num_updates 241267 | best_loss 4.076
2023-02-20 15:17:54 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 15:17:59 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint122.pt (epoch 122 @ 241267 updates, score 4.146) (writing took 5.620524022728205 seconds)
2023-02-20 15:17:59 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2023-02-20 15:17:59 | INFO | train | epoch 122 | loss 2.982 | nll_loss 0.845 | word_ins 2.674 | length 3.077 | ppl 7.9 | wps 35070.8 | ups 0.59 | wpb 59284 | bsz 2003 | num_updates 241267 | lr 0.000203587 | gnorm 1.391 | loss_scale 8192 | train_wall 3302 | wall 0
2023-02-20 15:17:59 | INFO | fairseq.trainer | begin training epoch 123
2023-02-20 15:19:05 | INFO | train_inner | epoch 123:     33 / 1978 loss=2.986, nll_loss=0.852, word_ins=2.681, length=3.05, ppl=7.92, wps=29482.8, ups=0.5, wpb=58830.9, bsz=1998.4, num_updates=241300, lr=0.000203574, gnorm=1.382, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:21:50 | INFO | train_inner | epoch 123:    133 / 1978 loss=2.979, nll_loss=0.839, word_ins=2.669, length=3.093, ppl=7.88, wps=35835.1, ups=0.61, wpb=59219.9, bsz=1980.6, num_updates=241400, lr=0.000203531, gnorm=1.374, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:24:36 | INFO | train_inner | epoch 123:    233 / 1978 loss=2.967, nll_loss=0.832, word_ins=2.663, length=3.042, ppl=7.82, wps=35795, ups=0.6, wpb=59508.4, bsz=2052.3, num_updates=241500, lr=0.000203489, gnorm=1.401, loss_scale=8192, train_wall=166, wall=0
2023-02-20 15:27:23 | INFO | train_inner | epoch 123:    333 / 1978 loss=2.971, nll_loss=0.834, word_ins=2.664, length=3.068, ppl=7.84, wps=35332.2, ups=0.6, wpb=58974.8, bsz=2021.7, num_updates=241600, lr=0.000203447, gnorm=1.38, loss_scale=8192, train_wall=167, wall=0
2023-02-20 15:30:09 | INFO | train_inner | epoch 123:    433 / 1978 loss=2.968, nll_loss=0.831, word_ins=2.661, length=3.062, ppl=7.82, wps=35978.1, ups=0.6, wpb=59771.2, bsz=2001.2, num_updates=241700, lr=0.000203405, gnorm=1.382, loss_scale=8192, train_wall=166, wall=0
2023-02-20 15:32:54 | INFO | train_inner | epoch 123:    533 / 1978 loss=2.985, nll_loss=0.85, word_ins=2.68, length=3.056, ppl=7.92, wps=35731.5, ups=0.61, wpb=59028.9, bsz=1897.5, num_updates=241800, lr=0.000203363, gnorm=1.397, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:35:40 | INFO | train_inner | epoch 123:    633 / 1978 loss=2.975, nll_loss=0.839, word_ins=2.669, length=3.063, ppl=7.86, wps=35541.6, ups=0.6, wpb=58779.6, bsz=2001.8, num_updates=241900, lr=0.000203321, gnorm=1.357, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:40:12 | INFO | train_inner | epoch 123:    733 / 1978 loss=2.958, nll_loss=0.822, word_ins=2.654, length=3.04, ppl=7.77, wps=21724.3, ups=0.37, wpb=59110.1, bsz=2096.1, num_updates=242000, lr=0.000203279, gnorm=1.367, loss_scale=8192, train_wall=167, wall=0
2023-02-20 15:42:59 | INFO | train_inner | epoch 123:    833 / 1978 loss=2.964, nll_loss=0.832, word_ins=2.662, length=3.018, ppl=7.8, wps=35502.4, ups=0.6, wpb=59252.6, bsz=2102.2, num_updates=242100, lr=0.000203237, gnorm=1.401, loss_scale=8192, train_wall=167, wall=0
2023-02-20 15:45:44 | INFO | train_inner | epoch 123:    933 / 1978 loss=3.011, nll_loss=0.87, word_ins=2.697, length=3.134, ppl=8.06, wps=35749.3, ups=0.61, wpb=59070.8, bsz=1888.4, num_updates=242200, lr=0.000203195, gnorm=1.412, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:48:29 | INFO | train_inner | epoch 123:   1033 / 1978 loss=2.982, nll_loss=0.843, word_ins=2.672, length=3.093, ppl=7.9, wps=35739.3, ups=0.61, wpb=58862.8, bsz=1994, num_updates=242300, lr=0.000203153, gnorm=1.381, loss_scale=8192, train_wall=164, wall=0
2023-02-20 15:51:15 | INFO | train_inner | epoch 123:   1133 / 1978 loss=2.991, nll_loss=0.853, word_ins=2.681, length=3.1, ppl=7.95, wps=35895.5, ups=0.6, wpb=59645.6, bsz=2004.6, num_updates=242400, lr=0.000203111, gnorm=1.413, loss_scale=8192, train_wall=166, wall=0
2023-02-20 15:54:02 | INFO | train_inner | epoch 123:   1233 / 1978 loss=2.954, nll_loss=0.822, word_ins=2.653, length=3.016, ppl=7.75, wps=35970.6, ups=0.6, wpb=60289.8, bsz=2096.8, num_updates=242500, lr=0.000203069, gnorm=1.367, loss_scale=8192, train_wall=167, wall=0
2023-02-20 15:56:47 | INFO | train_inner | epoch 123:   1333 / 1978 loss=3.004, nll_loss=0.867, word_ins=2.695, length=3.096, ppl=8.02, wps=35548, ups=0.61, wpb=58677.6, bsz=1951.1, num_updates=242600, lr=0.000203027, gnorm=1.393, loss_scale=8192, train_wall=165, wall=0
2023-02-20 15:59:33 | INFO | train_inner | epoch 123:   1433 / 1978 loss=2.982, nll_loss=0.848, word_ins=2.676, length=3.051, ppl=7.9, wps=36043.3, ups=0.6, wpb=59682.5, bsz=2041.1, num_updates=242700, lr=0.000202986, gnorm=1.371, loss_scale=8192, train_wall=165, wall=0
2023-02-20 16:02:20 | INFO | train_inner | epoch 123:   1533 / 1978 loss=2.97, nll_loss=0.838, word_ins=2.668, length=3.021, ppl=7.83, wps=35699.2, ups=0.6, wpb=59458.3, bsz=2045.9, num_updates=242800, lr=0.000202944, gnorm=1.364, loss_scale=8192, train_wall=166, wall=0
2023-02-20 16:05:05 | INFO | train_inner | epoch 123:   1633 / 1978 loss=3.023, nll_loss=0.878, word_ins=2.705, length=3.179, ppl=8.13, wps=35586.3, ups=0.61, wpb=58734.5, bsz=1911.4, num_updates=242900, lr=0.000202902, gnorm=1.44, loss_scale=8192, train_wall=165, wall=0
2023-02-20 16:07:51 | INFO | train_inner | epoch 123:   1733 / 1978 loss=2.975, nll_loss=0.836, word_ins=2.666, length=3.083, ppl=7.86, wps=35721.4, ups=0.6, wpb=59399.2, bsz=2036.2, num_updates=243000, lr=0.00020286, gnorm=1.419, loss_scale=8192, train_wall=166, wall=0
2023-02-20 16:10:38 | INFO | train_inner | epoch 123:   1833 / 1978 loss=2.985, nll_loss=0.849, word_ins=2.678, length=3.08, ppl=7.92, wps=35837.7, ups=0.6, wpb=59706.4, bsz=1995, num_updates=243100, lr=0.000202818, gnorm=1.414, loss_scale=8192, train_wall=166, wall=0
2023-02-20 16:13:22 | INFO | train_inner | epoch 123:   1933 / 1978 loss=3.008, nll_loss=0.865, word_ins=2.692, length=3.158, ppl=8.04, wps=35817.2, ups=0.61, wpb=59044.5, bsz=1910.4, num_updates=243200, lr=0.000202777, gnorm=1.456, loss_scale=8192, train_wall=165, wall=0
2023-02-20 16:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 16:14:55 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 4.131 | nll_loss 1.942 | word_ins 3.714 | length 4.166 | ppl 17.52 | wps 60086.5 | wpb 40242.5 | bsz 1500 | num_updates 243245 | best_loss 4.076
2023-02-20 16:14:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 16:15:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint123.pt (epoch 123 @ 243245 updates, score 4.131) (writing took 5.555945944041014 seconds)
2023-02-20 16:15:01 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2023-02-20 16:15:01 | INFO | train | epoch 123 | loss 2.981 | nll_loss 0.844 | word_ins 2.674 | length 3.074 | ppl 7.9 | wps 34274.1 | ups 0.58 | wpb 59284.3 | bsz 2002.6 | num_updates 243245 | lr 0.000202758 | gnorm 1.393 | loss_scale 8192 | train_wall 3278 | wall 0
2023-02-20 16:15:01 | INFO | fairseq.trainer | begin training epoch 124
2023-02-20 16:16:42 | INFO | train_inner | epoch 124:     55 / 1978 loss=2.985, nll_loss=0.851, word_ins=2.68, length=3.049, ppl=7.92, wps=29776.7, ups=0.5, wpb=59335.2, bsz=1941.2, num_updates=243300, lr=0.000202735, gnorm=1.391, loss_scale=8192, train_wall=165, wall=0
2023-02-20 16:19:27 | INFO | train_inner | epoch 124:    155 / 1978 loss=2.977, nll_loss=0.838, word_ins=2.669, length=3.081, ppl=7.87, wps=35465.6, ups=0.6, wpb=58623.6, bsz=2016.3, num_updates=243400, lr=0.000202693, gnorm=1.354, loss_scale=8192, train_wall=165, wall=0
2023-02-20 16:22:13 | INFO | train_inner | epoch 124:    255 / 1978 loss=2.958, nll_loss=0.824, word_ins=2.655, length=3.032, ppl=7.77, wps=35707.8, ups=0.6, wpb=59245.3, bsz=2085.2, num_updates=243500, lr=0.000202652, gnorm=1.356, loss_scale=8192, train_wall=166, wall=0
2023-02-20 16:25:00 | INFO | train_inner | epoch 124:    355 / 1978 loss=2.973, nll_loss=0.838, word_ins=2.668, length=3.051, ppl=7.85, wps=35625, ups=0.6, wpb=59692.8, bsz=2030, num_updates=243600, lr=0.00020261, gnorm=1.384, loss_scale=8192, train_wall=167, wall=0
2023-02-20 16:27:53 | INFO | train_inner | epoch 124:    455 / 1978 loss=2.992, nll_loss=0.851, word_ins=2.68, length=3.126, ppl=7.96, wps=34426.8, ups=0.58, wpb=59242.7, bsz=1933.6, num_updates=243700, lr=0.000202569, gnorm=1.458, loss_scale=8192, train_wall=172, wall=0
2023-02-20 16:30:40 | INFO | train_inner | epoch 124:    555 / 1978 loss=2.966, nll_loss=0.835, word_ins=2.665, length=3, ppl=7.81, wps=35527, ups=0.6, wpb=59357.6, bsz=2063, num_updates=243800, lr=0.000202527, gnorm=1.358, loss_scale=8192, train_wall=167, wall=0
2023-02-20 16:33:26 | INFO | train_inner | epoch 124:    655 / 1978 loss=2.973, nll_loss=0.838, word_ins=2.668, length=3.048, ppl=7.85, wps=35677.3, ups=0.6, wpb=59230.6, bsz=2065.6, num_updates=243900, lr=0.000202486, gnorm=1.359, loss_scale=8192, train_wall=166, wall=0
2023-02-20 16:36:17 | INFO | train_inner | epoch 124:    755 / 1978 loss=2.996, nll_loss=0.855, word_ins=2.683, length=3.121, ppl=7.98, wps=34538, ups=0.58, wpb=59161.3, bsz=1921.3, num_updates=244000, lr=0.000202444, gnorm=1.397, loss_scale=8192, train_wall=171, wall=0
2023-02-20 16:39:02 | INFO | train_inner | epoch 124:    855 / 1978 loss=2.959, nll_loss=0.831, word_ins=2.662, length=2.971, ppl=7.77, wps=36089.7, ups=0.61, wpb=59435.8, bsz=2048.5, num_updates=244100, lr=0.000202403, gnorm=1.341, loss_scale=8192, train_wall=165, wall=0
2023-02-20 16:41:46 | INFO | train_inner | epoch 124:    955 / 1978 loss=2.981, nll_loss=0.84, word_ins=2.67, length=3.113, ppl=7.9, wps=35916.7, ups=0.61, wpb=59111.3, bsz=1991.3, num_updates=244200, lr=0.000202361, gnorm=1.405, loss_scale=8192, train_wall=164, wall=0
2023-02-20 16:44:32 | INFO | train_inner | epoch 124:   1055 / 1978 loss=2.987, nll_loss=0.849, word_ins=2.678, length=3.085, ppl=7.93, wps=35513.4, ups=0.6, wpb=58899.5, bsz=2026.3, num_updates=244300, lr=0.00020232, gnorm=1.388, loss_scale=8192, train_wall=166, wall=0
2023-02-20 16:47:21 | INFO | train_inner | epoch 124:   1155 / 1978 loss=2.961, nll_loss=0.825, word_ins=2.656, length=3.053, ppl=7.79, wps=35182.2, ups=0.59, wpb=59477.8, bsz=2081.4, num_updates=244400, lr=0.000202278, gnorm=1.397, loss_scale=8192, train_wall=169, wall=0
2023-02-20 16:50:08 | INFO | train_inner | epoch 124:   1255 / 1978 loss=2.999, nll_loss=0.863, word_ins=2.691, length=3.087, ppl=8, wps=35798.4, ups=0.6, wpb=59575.8, bsz=1897.9, num_updates=244500, lr=0.000202237, gnorm=1.376, loss_scale=16384, train_wall=166, wall=0
2023-02-20 16:52:54 | INFO | train_inner | epoch 124:   1355 / 1978 loss=2.969, nll_loss=0.831, word_ins=2.662, length=3.076, ppl=7.83, wps=35535.8, ups=0.6, wpb=59214, bsz=2045.3, num_updates=244600, lr=0.000202196, gnorm=1.416, loss_scale=16384, train_wall=166, wall=0
2023-02-20 16:55:41 | INFO | train_inner | epoch 124:   1455 / 1978 loss=2.984, nll_loss=0.844, word_ins=2.673, length=3.108, ppl=7.91, wps=35629.8, ups=0.6, wpb=59304.2, bsz=2006.3, num_updates=244700, lr=0.000202154, gnorm=1.431, loss_scale=16384, train_wall=166, wall=0
2023-02-20 16:58:27 | INFO | train_inner | epoch 124:   1555 / 1978 loss=2.973, nll_loss=0.838, word_ins=2.668, length=3.049, ppl=7.85, wps=35823.5, ups=0.6, wpb=59467, bsz=2036.9, num_updates=244800, lr=0.000202113, gnorm=1.405, loss_scale=16384, train_wall=166, wall=0
2023-02-20 17:01:15 | INFO | train_inner | epoch 124:   1655 / 1978 loss=2.985, nll_loss=0.844, word_ins=2.673, length=3.117, ppl=7.92, wps=35242.6, ups=0.59, wpb=59285.5, bsz=2023, num_updates=244900, lr=0.000202072, gnorm=1.378, loss_scale=16384, train_wall=168, wall=0
2023-02-20 17:04:10 | INFO | train_inner | epoch 124:   1755 / 1978 loss=2.981, nll_loss=0.844, word_ins=2.673, length=3.078, ppl=7.9, wps=34047.7, ups=0.57, wpb=59458.2, bsz=1982.9, num_updates=245000, lr=0.000202031, gnorm=1.385, loss_scale=16384, train_wall=174, wall=0
2023-02-20 17:07:05 | INFO | train_inner | epoch 124:   1855 / 1978 loss=2.959, nll_loss=0.825, word_ins=2.656, length=3.027, ppl=7.78, wps=34283.2, ups=0.57, wpb=60132.3, bsz=2081, num_updates=245100, lr=0.000201989, gnorm=1.444, loss_scale=16384, train_wall=175, wall=0
2023-02-20 17:09:59 | INFO | train_inner | epoch 124:   1955 / 1978 loss=3.021, nll_loss=0.878, word_ins=2.705, length=3.158, ppl=8.11, wps=33772.5, ups=0.57, wpb=58851.6, bsz=1880.6, num_updates=245200, lr=0.000201948, gnorm=1.43, loss_scale=16384, train_wall=174, wall=0
2023-02-20 17:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 17:10:55 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 4.108 | nll_loss 1.931 | word_ins 3.705 | length 4.023 | ppl 17.24 | wps 49462.1 | wpb 40242.5 | bsz 1500 | num_updates 245223 | best_loss 4.076
2023-02-20 17:10:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 17:11:00 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint124.pt (epoch 124 @ 245223 updates, score 4.108) (writing took 5.502302059903741 seconds)
2023-02-20 17:11:00 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2023-02-20 17:11:00 | INFO | train | epoch 124 | loss 2.98 | nll_loss 0.843 | word_ins 2.672 | length 3.075 | ppl 7.89 | wps 34902.4 | ups 0.59 | wpb 59284.3 | bsz 2002.6 | num_updates 245223 | lr 0.000201939 | gnorm 1.393 | loss_scale 16384 | train_wall 3322 | wall 0
2023-02-20 17:11:00 | INFO | fairseq.trainer | begin training epoch 125
2023-02-20 17:13:24 | INFO | train_inner | epoch 125:     77 / 1978 loss=2.978, nll_loss=0.84, word_ins=2.671, length=3.076, ppl=7.88, wps=28606, ups=0.49, wpb=58623.9, bsz=1928.9, num_updates=245300, lr=0.000201907, gnorm=1.34, loss_scale=16384, train_wall=173, wall=0
2023-02-20 17:16:18 | INFO | train_inner | epoch 125:    177 / 1978 loss=2.975, nll_loss=0.838, word_ins=2.669, length=3.064, ppl=7.86, wps=33838.8, ups=0.57, wpb=58939.9, bsz=1989.3, num_updates=245400, lr=0.000201866, gnorm=1.381, loss_scale=16384, train_wall=174, wall=0
2023-02-20 17:19:12 | INFO | train_inner | epoch 125:    277 / 1978 loss=2.981, nll_loss=0.845, word_ins=2.675, length=3.059, ppl=7.9, wps=34216.1, ups=0.58, wpb=59274.7, bsz=1957.1, num_updates=245500, lr=0.000201825, gnorm=1.384, loss_scale=16384, train_wall=173, wall=0
2023-02-20 17:19:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 17:22:09 | INFO | train_inner | epoch 125:    378 / 1978 loss=2.96, nll_loss=0.823, word_ins=2.655, length=3.049, ppl=7.78, wps=33302.2, ups=0.56, wpb=59028.4, bsz=2077, num_updates=245600, lr=0.000201784, gnorm=1.385, loss_scale=8192, train_wall=177, wall=0
2023-02-20 17:24:59 | INFO | train_inner | epoch 125:    478 / 1978 loss=2.986, nll_loss=0.85, word_ins=2.679, length=3.066, ppl=7.92, wps=34595.4, ups=0.59, wpb=59024.9, bsz=1983.8, num_updates=245700, lr=0.000201743, gnorm=1.357, loss_scale=8192, train_wall=170, wall=0
2023-02-20 17:27:50 | INFO | train_inner | epoch 125:    578 / 1978 loss=2.967, nll_loss=0.83, word_ins=2.661, length=3.057, ppl=7.82, wps=34800.1, ups=0.59, wpb=59288.6, bsz=1991.7, num_updates=245800, lr=0.000201701, gnorm=1.406, loss_scale=8192, train_wall=170, wall=0
2023-02-20 17:30:41 | INFO | train_inner | epoch 125:    678 / 1978 loss=2.968, nll_loss=0.834, word_ins=2.664, length=3.034, ppl=7.82, wps=34832.9, ups=0.59, wpb=59457.2, bsz=1989.7, num_updates=245900, lr=0.00020166, gnorm=1.406, loss_scale=8192, train_wall=170, wall=0
2023-02-20 17:33:30 | INFO | train_inner | epoch 125:    778 / 1978 loss=2.996, nll_loss=0.856, word_ins=2.685, length=3.113, ppl=7.98, wps=34855.5, ups=0.59, wpb=59149.1, bsz=1905.3, num_updates=246000, lr=0.000201619, gnorm=1.395, loss_scale=8192, train_wall=169, wall=0
2023-02-20 17:36:21 | INFO | train_inner | epoch 125:    878 / 1978 loss=2.98, nll_loss=0.847, word_ins=2.676, length=3.041, ppl=7.89, wps=34972.1, ups=0.59, wpb=59662.3, bsz=2010.4, num_updates=246100, lr=0.000201578, gnorm=1.452, loss_scale=8192, train_wall=170, wall=0
2023-02-20 17:39:11 | INFO | train_inner | epoch 125:    978 / 1978 loss=2.988, nll_loss=0.845, word_ins=2.674, length=3.135, ppl=7.93, wps=34680.2, ups=0.59, wpb=59104.5, bsz=1936.2, num_updates=246200, lr=0.000201538, gnorm=1.341, loss_scale=8192, train_wall=170, wall=0
2023-02-20 17:41:59 | INFO | train_inner | epoch 125:   1078 / 1978 loss=2.984, nll_loss=0.841, word_ins=2.671, length=3.129, ppl=7.91, wps=35573.4, ups=0.6, wpb=59718.9, bsz=1958.4, num_updates=246300, lr=0.000201497, gnorm=1.424, loss_scale=8192, train_wall=168, wall=0
2023-02-20 17:44:46 | INFO | train_inner | epoch 125:   1178 / 1978 loss=2.973, nll_loss=0.84, word_ins=2.67, length=3.032, ppl=7.85, wps=35426.1, ups=0.6, wpb=59008.5, bsz=2068.4, num_updates=246400, lr=0.000201456, gnorm=1.415, loss_scale=8192, train_wall=166, wall=0
2023-02-20 17:47:33 | INFO | train_inner | epoch 125:   1278 / 1978 loss=2.968, nll_loss=0.833, word_ins=2.664, length=3.046, ppl=7.83, wps=35429.6, ups=0.6, wpb=59294.3, bsz=2093.5, num_updates=246500, lr=0.000201415, gnorm=1.408, loss_scale=8192, train_wall=167, wall=0
2023-02-20 17:50:19 | INFO | train_inner | epoch 125:   1378 / 1978 loss=2.997, nll_loss=0.853, word_ins=2.682, length=3.152, ppl=7.98, wps=35246.4, ups=0.6, wpb=58476.7, bsz=1995.2, num_updates=246600, lr=0.000201374, gnorm=1.399, loss_scale=8192, train_wall=166, wall=0
2023-02-20 17:53:04 | INFO | train_inner | epoch 125:   1478 / 1978 loss=2.999, nll_loss=0.862, word_ins=2.69, length=3.09, ppl=7.99, wps=35690.1, ups=0.61, wpb=58982.6, bsz=2054, num_updates=246700, lr=0.000201333, gnorm=1.431, loss_scale=8192, train_wall=165, wall=0
2023-02-20 17:55:51 | INFO | train_inner | epoch 125:   1578 / 1978 loss=2.971, nll_loss=0.835, word_ins=2.665, length=3.064, ppl=7.84, wps=35723.6, ups=0.6, wpb=59485.5, bsz=2047.5, num_updates=246800, lr=0.000201292, gnorm=1.384, loss_scale=8192, train_wall=166, wall=0
2023-02-20 17:58:37 | INFO | train_inner | epoch 125:   1678 / 1978 loss=2.97, nll_loss=0.832, word_ins=2.662, length=3.076, ppl=7.83, wps=35907.4, ups=0.6, wpb=59594.4, bsz=2061.3, num_updates=246900, lr=0.000201252, gnorm=1.402, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:01:22 | INFO | train_inner | epoch 125:   1778 / 1978 loss=2.985, nll_loss=0.847, word_ins=2.676, length=3.089, ppl=7.92, wps=36339.5, ups=0.61, wpb=59921.1, bsz=1883.4, num_updates=247000, lr=0.000201211, gnorm=1.417, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:04:09 | INFO | train_inner | epoch 125:   1878 / 1978 loss=2.984, nll_loss=0.848, word_ins=2.678, length=3.068, ppl=7.91, wps=35746.8, ups=0.6, wpb=59658.8, bsz=1990.2, num_updates=247100, lr=0.00020117, gnorm=1.41, loss_scale=8192, train_wall=167, wall=0
2023-02-20 18:06:55 | INFO | train_inner | epoch 125:   1978 / 1978 loss=2.967, nll_loss=0.831, word_ins=2.661, length=3.063, ppl=7.82, wps=35874, ups=0.6, wpb=59802.3, bsz=2067.6, num_updates=247200, lr=0.000201129, gnorm=1.446, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 18:07:09 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 4.104 | nll_loss 1.939 | word_ins 3.712 | length 3.921 | ppl 17.2 | wps 58308 | wpb 40242.5 | bsz 1500 | num_updates 247200 | best_loss 4.076
2023-02-20 18:07:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 18:07:15 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint125.pt (epoch 125 @ 247200 updates, score 4.104) (writing took 5.51334940828383 seconds)
2023-02-20 18:07:15 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2023-02-20 18:07:15 | INFO | train | epoch 125 | loss 2.978 | nll_loss 0.841 | word_ins 2.671 | length 3.074 | ppl 7.88 | wps 34733.8 | ups 0.59 | wpb 59285.2 | bsz 2002.5 | num_updates 247200 | lr 0.000201129 | gnorm 1.399 | loss_scale 8192 | train_wall 3340 | wall 0
2023-02-20 18:07:15 | INFO | fairseq.trainer | begin training epoch 126
2023-02-20 18:10:10 | INFO | train_inner | epoch 126:    100 / 1978 loss=2.958, nll_loss=0.828, word_ins=2.659, length=2.986, ppl=7.77, wps=30542.8, ups=0.51, wpb=59481.1, bsz=1999.4, num_updates=247300, lr=0.000201089, gnorm=1.381, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:12:54 | INFO | train_inner | epoch 126:    200 / 1978 loss=2.985, nll_loss=0.846, word_ins=2.676, length=3.093, ppl=7.92, wps=35979.4, ups=0.61, wpb=59113.1, bsz=1922.2, num_updates=247400, lr=0.000201048, gnorm=1.43, loss_scale=8192, train_wall=164, wall=0
2023-02-20 18:15:39 | INFO | train_inner | epoch 126:    300 / 1978 loss=2.984, nll_loss=0.843, word_ins=2.673, length=3.108, ppl=7.91, wps=35945.6, ups=0.61, wpb=59161.2, bsz=1907, num_updates=247500, lr=0.000201008, gnorm=1.391, loss_scale=8192, train_wall=164, wall=0
2023-02-20 18:18:26 | INFO | train_inner | epoch 126:    400 / 1978 loss=2.949, nll_loss=0.816, word_ins=2.648, length=3.008, ppl=7.72, wps=35455.9, ups=0.6, wpb=59274.3, bsz=2084.6, num_updates=247600, lr=0.000200967, gnorm=1.424, loss_scale=8192, train_wall=167, wall=0
2023-02-20 18:21:13 | INFO | train_inner | epoch 126:    500 / 1978 loss=2.966, nll_loss=0.83, word_ins=2.661, length=3.058, ppl=7.82, wps=35478.3, ups=0.6, wpb=59259.6, bsz=2099.9, num_updates=247700, lr=0.000200926, gnorm=1.38, loss_scale=8192, train_wall=167, wall=0
2023-02-20 18:24:00 | INFO | train_inner | epoch 126:    600 / 1978 loss=2.975, nll_loss=0.839, word_ins=2.669, length=3.064, ppl=7.87, wps=35923.8, ups=0.6, wpb=59803.5, bsz=2063.2, num_updates=247800, lr=0.000200886, gnorm=1.383, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:26:46 | INFO | train_inner | epoch 126:    700 / 1978 loss=2.97, nll_loss=0.834, word_ins=2.664, length=3.061, ppl=7.84, wps=35606.9, ups=0.6, wpb=59381.2, bsz=2016.2, num_updates=247900, lr=0.000200845, gnorm=1.405, loss_scale=8192, train_wall=167, wall=0
2023-02-20 18:29:31 | INFO | train_inner | epoch 126:    800 / 1978 loss=2.985, nll_loss=0.846, word_ins=2.676, length=3.099, ppl=7.92, wps=35952.8, ups=0.61, wpb=59123.8, bsz=1944.6, num_updates=248000, lr=0.000200805, gnorm=1.425, loss_scale=8192, train_wall=164, wall=0
2023-02-20 18:32:16 | INFO | train_inner | epoch 126:    900 / 1978 loss=2.975, nll_loss=0.841, word_ins=2.67, length=3.047, ppl=7.86, wps=35954, ups=0.61, wpb=59330.8, bsz=2004.7, num_updates=248100, lr=0.000200764, gnorm=1.438, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:35:01 | INFO | train_inner | epoch 126:   1000 / 1978 loss=2.957, nll_loss=0.824, word_ins=2.655, length=3.021, ppl=7.76, wps=36142.7, ups=0.6, wpb=59848.8, bsz=1964.6, num_updates=248200, lr=0.000200724, gnorm=1.441, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:37:48 | INFO | train_inner | epoch 126:   1100 / 1978 loss=2.975, nll_loss=0.831, word_ins=2.662, length=3.13, ppl=7.86, wps=35537.3, ups=0.6, wpb=59182.6, bsz=2025.7, num_updates=248300, lr=0.000200683, gnorm=1.415, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:40:34 | INFO | train_inner | epoch 126:   1200 / 1978 loss=2.964, nll_loss=0.831, word_ins=2.662, length=3.028, ppl=7.8, wps=35754.6, ups=0.6, wpb=59285.5, bsz=2016.6, num_updates=248400, lr=0.000200643, gnorm=1.414, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:43:21 | INFO | train_inner | epoch 126:   1300 / 1978 loss=2.98, nll_loss=0.841, word_ins=2.671, length=3.094, ppl=7.89, wps=35363.4, ups=0.6, wpb=59274.6, bsz=2059.2, num_updates=248500, lr=0.000200603, gnorm=1.372, loss_scale=8192, train_wall=167, wall=0
2023-02-20 18:46:08 | INFO | train_inner | epoch 126:   1400 / 1978 loss=2.974, nll_loss=0.837, word_ins=2.667, length=3.068, ppl=7.86, wps=35327.1, ups=0.6, wpb=58731.3, bsz=2028.6, num_updates=248600, lr=0.000200562, gnorm=1.382, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:48:54 | INFO | train_inner | epoch 126:   1500 / 1978 loss=2.986, nll_loss=0.845, word_ins=2.674, length=3.116, ppl=7.92, wps=35634.7, ups=0.6, wpb=59225.9, bsz=1983.9, num_updates=248700, lr=0.000200522, gnorm=1.399, loss_scale=8192, train_wall=166, wall=0
2023-02-20 18:51:39 | INFO | train_inner | epoch 126:   1600 / 1978 loss=3, nll_loss=0.859, word_ins=2.687, length=3.126, ppl=8, wps=35983.5, ups=0.61, wpb=59372.4, bsz=1926.8, num_updates=248800, lr=0.000200482, gnorm=1.454, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:54:24 | INFO | train_inner | epoch 126:   1700 / 1978 loss=3.009, nll_loss=0.873, word_ins=2.7, length=3.092, ppl=8.05, wps=35598.6, ups=0.61, wpb=58761, bsz=2002.6, num_updates=248900, lr=0.000200441, gnorm=1.423, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:57:09 | INFO | train_inner | epoch 126:   1800 / 1978 loss=2.989, nll_loss=0.853, word_ins=2.681, length=3.075, ppl=7.94, wps=36050.4, ups=0.61, wpb=59458.4, bsz=1933.6, num_updates=249000, lr=0.000200401, gnorm=1.437, loss_scale=8192, train_wall=165, wall=0
2023-02-20 18:59:55 | INFO | train_inner | epoch 126:   1900 / 1978 loss=2.971, nll_loss=0.833, word_ins=2.663, length=3.075, ppl=7.84, wps=35868.6, ups=0.6, wpb=59768.8, bsz=2066.2, num_updates=249100, lr=0.000200361, gnorm=1.385, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 19:02:20 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 4.195 | nll_loss 1.95 | word_ins 3.726 | length 4.678 | ppl 18.31 | wps 55683.7 | wpb 40242.5 | bsz 1500 | num_updates 249178 | best_loss 4.076
2023-02-20 19:02:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 19:02:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint126.pt (epoch 126 @ 249178 updates, score 4.195) (writing took 5.582437559962273 seconds)
2023-02-20 19:02:26 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2023-02-20 19:02:26 | INFO | train | epoch 126 | loss 2.977 | nll_loss 0.84 | word_ins 2.67 | length 3.072 | ppl 7.87 | wps 35417.5 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 249178 | lr 0.00020033 | gnorm 1.409 | loss_scale 8192 | train_wall 3275 | wall 0
2023-02-20 19:02:26 | INFO | fairseq.trainer | begin training epoch 127
2023-02-20 19:03:13 | INFO | train_inner | epoch 127:     22 / 1978 loss=2.976, nll_loss=0.838, word_ins=2.668, length=3.073, ppl=7.87, wps=29762.7, ups=0.51, wpb=58825.1, bsz=2035.4, num_updates=249200, lr=0.000200321, gnorm=1.377, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:06:00 | INFO | train_inner | epoch 127:    122 / 1978 loss=2.952, nll_loss=0.818, word_ins=2.65, length=3.024, ppl=7.74, wps=35632.3, ups=0.6, wpb=59524, bsz=2062.5, num_updates=249300, lr=0.000200281, gnorm=1.386, loss_scale=8192, train_wall=167, wall=0
2023-02-20 19:08:46 | INFO | train_inner | epoch 127:    222 / 1978 loss=2.983, nll_loss=0.846, word_ins=2.675, length=3.08, ppl=7.91, wps=35649.8, ups=0.6, wpb=59077.7, bsz=1978.8, num_updates=249400, lr=0.00020024, gnorm=1.406, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:11:31 | INFO | train_inner | epoch 127:    322 / 1978 loss=2.977, nll_loss=0.84, word_ins=2.671, length=3.066, ppl=7.88, wps=35208.5, ups=0.61, wpb=58192.4, bsz=1976.6, num_updates=249500, lr=0.0002002, gnorm=1.359, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:14:17 | INFO | train_inner | epoch 127:    422 / 1978 loss=2.961, nll_loss=0.822, word_ins=2.654, length=3.072, ppl=7.79, wps=35988.9, ups=0.6, wpb=59586.6, bsz=2009.4, num_updates=249600, lr=0.00020016, gnorm=1.417, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:17:03 | INFO | train_inner | epoch 127:    522 / 1978 loss=2.965, nll_loss=0.831, word_ins=2.662, length=3.036, ppl=7.81, wps=35845.9, ups=0.6, wpb=59553.1, bsz=2059.9, num_updates=249700, lr=0.00020012, gnorm=1.42, loss_scale=16384, train_wall=166, wall=0
2023-02-20 19:19:49 | INFO | train_inner | epoch 127:    622 / 1978 loss=2.949, nll_loss=0.817, word_ins=2.649, length=2.998, ppl=7.72, wps=35860.3, ups=0.6, wpb=59495.9, bsz=2051.8, num_updates=249800, lr=0.00020008, gnorm=1.356, loss_scale=16384, train_wall=166, wall=0
2023-02-20 19:22:34 | INFO | train_inner | epoch 127:    722 / 1978 loss=2.969, nll_loss=0.827, word_ins=2.658, length=3.105, ppl=7.83, wps=36012.9, ups=0.61, wpb=59410.9, bsz=1985.5, num_updates=249900, lr=0.00020004, gnorm=1.403, loss_scale=16384, train_wall=165, wall=0
2023-02-20 19:23:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 19:25:21 | INFO | train_inner | epoch 127:    823 / 1978 loss=2.987, nll_loss=0.852, word_ins=2.681, length=3.066, ppl=7.93, wps=35343.6, ups=0.6, wpb=59196.3, bsz=1983, num_updates=250000, lr=0.0002, gnorm=1.463, loss_scale=8192, train_wall=167, wall=0
2023-02-20 19:28:08 | INFO | train_inner | epoch 127:    923 / 1978 loss=2.968, nll_loss=0.827, word_ins=2.658, length=3.098, ppl=7.82, wps=35583.3, ups=0.6, wpb=59233.8, bsz=2044.2, num_updates=250100, lr=0.00019996, gnorm=1.413, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:30:54 | INFO | train_inner | epoch 127:   1023 / 1978 loss=2.983, nll_loss=0.843, word_ins=2.673, length=3.104, ppl=7.91, wps=35473.3, ups=0.6, wpb=58849.9, bsz=1975.8, num_updates=250200, lr=0.00019992, gnorm=1.416, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:33:40 | INFO | train_inner | epoch 127:   1123 / 1978 loss=2.968, nll_loss=0.842, word_ins=2.671, length=2.977, ppl=7.83, wps=36197.5, ups=0.6, wpb=60031.5, bsz=1997.3, num_updates=250300, lr=0.00019988, gnorm=1.414, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:36:26 | INFO | train_inner | epoch 127:   1223 / 1978 loss=2.984, nll_loss=0.851, word_ins=2.679, length=3.048, ppl=7.91, wps=35672.1, ups=0.6, wpb=59338.2, bsz=1986.2, num_updates=250400, lr=0.00019984, gnorm=1.404, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:39:11 | INFO | train_inner | epoch 127:   1323 / 1978 loss=2.993, nll_loss=0.85, word_ins=2.679, length=3.142, ppl=7.96, wps=35772, ups=0.61, wpb=58969.7, bsz=1931.3, num_updates=250500, lr=0.0001998, gnorm=1.392, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:41:56 | INFO | train_inner | epoch 127:   1423 / 1978 loss=2.98, nll_loss=0.846, word_ins=2.675, length=3.05, ppl=7.89, wps=35963.5, ups=0.61, wpb=59413.4, bsz=1997.4, num_updates=250600, lr=0.00019976, gnorm=1.399, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:44:42 | INFO | train_inner | epoch 127:   1523 / 1978 loss=2.968, nll_loss=0.835, word_ins=2.665, length=3.025, ppl=7.82, wps=35523.2, ups=0.6, wpb=58977.5, bsz=2066.3, num_updates=250700, lr=0.000199721, gnorm=1.372, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:47:28 | INFO | train_inner | epoch 127:   1623 / 1978 loss=2.988, nll_loss=0.854, word_ins=2.683, length=3.055, ppl=7.93, wps=35900.6, ups=0.6, wpb=59514.4, bsz=1951.5, num_updates=250800, lr=0.000199681, gnorm=1.435, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:50:13 | INFO | train_inner | epoch 127:   1723 / 1978 loss=3.001, nll_loss=0.862, word_ins=2.69, length=3.11, ppl=8, wps=35707.6, ups=0.61, wpb=58882, bsz=1984.6, num_updates=250900, lr=0.000199641, gnorm=1.371, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:52:59 | INFO | train_inner | epoch 127:   1823 / 1978 loss=2.986, nll_loss=0.851, word_ins=2.679, length=3.069, ppl=7.92, wps=35993.4, ups=0.6, wpb=59700.2, bsz=2002.6, num_updates=251000, lr=0.000199601, gnorm=1.445, loss_scale=8192, train_wall=166, wall=0
2023-02-20 19:55:44 | INFO | train_inner | epoch 127:   1923 / 1978 loss=2.973, nll_loss=0.838, word_ins=2.668, length=3.051, ppl=7.85, wps=36081.5, ups=0.6, wpb=59764.4, bsz=1979, num_updates=251100, lr=0.000199561, gnorm=1.409, loss_scale=8192, train_wall=165, wall=0
2023-02-20 19:57:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 19:57:31 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 4.142 | nll_loss 1.94 | word_ins 3.714 | length 4.275 | ppl 17.65 | wps 57478 | wpb 40242.5 | bsz 1500 | num_updates 251155 | best_loss 4.076
2023-02-20 19:57:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 19:57:36 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint127.pt (epoch 127 @ 251155 updates, score 4.142) (writing took 5.413876861333847 seconds)
2023-02-20 19:57:36 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2023-02-20 19:57:36 | INFO | train | epoch 127 | loss 2.975 | nll_loss 0.839 | word_ins 2.669 | length 3.063 | ppl 7.86 | wps 35402.2 | ups 0.6 | wpb 59282.6 | bsz 2002.5 | num_updates 251155 | lr 0.00019954 | gnorm 1.403 | loss_scale 8192 | train_wall 3274 | wall 0
2023-02-20 19:57:36 | INFO | fairseq.trainer | begin training epoch 128
2023-02-20 19:59:01 | INFO | train_inner | epoch 128:     45 / 1978 loss=2.973, nll_loss=0.831, word_ins=2.662, length=3.113, ppl=7.85, wps=29889.4, ups=0.51, wpb=58920.8, bsz=1949.8, num_updates=251200, lr=0.000199522, gnorm=1.405, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:01:47 | INFO | train_inner | epoch 128:    145 / 1978 loss=2.957, nll_loss=0.826, word_ins=2.657, length=2.997, ppl=7.77, wps=35845.3, ups=0.6, wpb=59490.5, bsz=2014.3, num_updates=251300, lr=0.000199482, gnorm=1.428, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:04:33 | INFO | train_inner | epoch 128:    245 / 1978 loss=2.974, nll_loss=0.839, word_ins=2.669, length=3.045, ppl=7.85, wps=35579.7, ups=0.6, wpb=59086.1, bsz=1994.2, num_updates=251400, lr=0.000199442, gnorm=1.429, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:07:20 | INFO | train_inner | epoch 128:    345 / 1978 loss=2.975, nll_loss=0.837, word_ins=2.667, length=3.071, ppl=7.86, wps=35363.2, ups=0.6, wpb=58814.3, bsz=2022.7, num_updates=251500, lr=0.000199403, gnorm=1.372, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:10:04 | INFO | train_inner | epoch 128:    445 / 1978 loss=2.976, nll_loss=0.839, word_ins=2.669, length=3.067, ppl=7.87, wps=36166.2, ups=0.61, wpb=59377.7, bsz=1949, num_updates=251600, lr=0.000199363, gnorm=1.409, loss_scale=8192, train_wall=164, wall=0
2023-02-20 20:12:50 | INFO | train_inner | epoch 128:    545 / 1978 loss=2.949, nll_loss=0.811, word_ins=2.643, length=3.06, ppl=7.72, wps=35694.1, ups=0.6, wpb=59135.8, bsz=2071.1, num_updates=251700, lr=0.000199323, gnorm=1.399, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:15:35 | INFO | train_inner | epoch 128:    645 / 1978 loss=2.964, nll_loss=0.826, word_ins=2.656, length=3.073, ppl=7.8, wps=35756.3, ups=0.6, wpb=59339.8, bsz=1985, num_updates=251800, lr=0.000199284, gnorm=1.347, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:18:21 | INFO | train_inner | epoch 128:    745 / 1978 loss=2.978, nll_loss=0.841, word_ins=2.67, length=3.075, ppl=7.88, wps=35989.3, ups=0.6, wpb=59638.9, bsz=1940.7, num_updates=251900, lr=0.000199244, gnorm=1.448, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:21:07 | INFO | train_inner | epoch 128:    845 / 1978 loss=2.962, nll_loss=0.826, word_ins=2.657, length=3.052, ppl=7.79, wps=35785, ups=0.6, wpb=59431.6, bsz=2045.6, num_updates=252000, lr=0.000199205, gnorm=1.378, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:23:52 | INFO | train_inner | epoch 128:    945 / 1978 loss=2.98, nll_loss=0.844, word_ins=2.673, length=3.062, ppl=7.89, wps=36009.1, ups=0.61, wpb=59325.4, bsz=1971.7, num_updates=252100, lr=0.000199165, gnorm=1.401, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:26:38 | INFO | train_inner | epoch 128:   1045 / 1978 loss=3, nll_loss=0.861, word_ins=2.689, length=3.109, ppl=8, wps=35478.4, ups=0.6, wpb=58954.3, bsz=1970.6, num_updates=252200, lr=0.000199126, gnorm=1.412, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:29:24 | INFO | train_inner | epoch 128:   1145 / 1978 loss=2.975, nll_loss=0.84, word_ins=2.67, length=3.053, ppl=7.86, wps=35946.2, ups=0.6, wpb=59464.8, bsz=2003.8, num_updates=252300, lr=0.000199086, gnorm=1.416, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:32:10 | INFO | train_inner | epoch 128:   1245 / 1978 loss=2.957, nll_loss=0.827, word_ins=2.658, length=2.989, ppl=7.77, wps=35714.5, ups=0.6, wpb=59501.4, bsz=2057.9, num_updates=252400, lr=0.000199047, gnorm=1.397, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:34:56 | INFO | train_inner | epoch 128:   1345 / 1978 loss=2.97, nll_loss=0.832, word_ins=2.662, length=3.081, ppl=7.84, wps=35880.3, ups=0.6, wpb=59383.9, bsz=2009, num_updates=252500, lr=0.000199007, gnorm=1.383, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:37:42 | INFO | train_inner | epoch 128:   1445 / 1978 loss=2.979, nll_loss=0.841, word_ins=2.671, length=3.083, ppl=7.88, wps=35792.6, ups=0.6, wpb=59510.5, bsz=2043.4, num_updates=252600, lr=0.000198968, gnorm=1.44, loss_scale=8192, train_wall=166, wall=0
2023-02-20 20:40:27 | INFO | train_inner | epoch 128:   1545 / 1978 loss=3.012, nll_loss=0.864, word_ins=2.692, length=3.2, ppl=8.07, wps=35574.1, ups=0.61, wpb=58556, bsz=1926.9, num_updates=252700, lr=0.000198929, gnorm=1.439, loss_scale=8192, train_wall=164, wall=0
2023-02-20 20:43:13 | INFO | train_inner | epoch 128:   1645 / 1978 loss=2.976, nll_loss=0.839, word_ins=2.669, length=3.068, ppl=7.87, wps=35342.2, ups=0.6, wpb=58942.7, bsz=2057.9, num_updates=252800, lr=0.000198889, gnorm=1.402, loss_scale=8192, train_wall=167, wall=0
2023-02-20 20:45:58 | INFO | train_inner | epoch 128:   1745 / 1978 loss=2.975, nll_loss=0.835, word_ins=2.665, length=3.104, ppl=7.87, wps=35750.3, ups=0.61, wpb=58889.1, bsz=1980.8, num_updates=252900, lr=0.00019885, gnorm=1.391, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:48:43 | INFO | train_inner | epoch 128:   1845 / 1978 loss=2.977, nll_loss=0.835, word_ins=2.665, length=3.126, ppl=7.88, wps=36258.2, ups=0.61, wpb=59804.4, bsz=1944.4, num_updates=253000, lr=0.000198811, gnorm=1.421, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:51:30 | INFO | train_inner | epoch 128:   1945 / 1978 loss=2.976, nll_loss=0.843, word_ins=2.672, length=3.038, ppl=7.87, wps=35689.8, ups=0.6, wpb=59620.8, bsz=2065.4, num_updates=253100, lr=0.000198771, gnorm=1.378, loss_scale=8192, train_wall=167, wall=0
2023-02-20 20:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 20:52:42 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 4.114 | nll_loss 1.951 | word_ins 3.724 | length 3.886 | ppl 17.31 | wps 56579.1 | wpb 40242.5 | bsz 1500 | num_updates 253133 | best_loss 4.076
2023-02-20 20:52:42 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 20:52:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint128.pt (epoch 128 @ 253133 updates, score 4.114) (writing took 5.493572758510709 seconds)
2023-02-20 20:52:47 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2023-02-20 20:52:47 | INFO | train | epoch 128 | loss 2.973 | nll_loss 0.836 | word_ins 2.667 | length 3.07 | ppl 7.85 | wps 35417.3 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 253133 | lr 0.000198758 | gnorm 1.405 | loss_scale 8192 | train_wall 3273 | wall 0
2023-02-20 20:52:47 | INFO | fairseq.trainer | begin training epoch 129
2023-02-20 20:54:48 | INFO | train_inner | epoch 129:     67 / 1978 loss=2.928, nll_loss=0.799, word_ins=2.632, length=2.954, ppl=7.61, wps=29962.4, ups=0.51, wpb=59329.9, bsz=2128.1, num_updates=253200, lr=0.000198732, gnorm=1.378, loss_scale=8192, train_wall=165, wall=0
2023-02-20 20:57:33 | INFO | train_inner | epoch 129:    167 / 1978 loss=2.962, nll_loss=0.826, word_ins=2.658, length=3.039, ppl=7.79, wps=36025.6, ups=0.61, wpb=59472.3, bsz=1961.7, num_updates=253300, lr=0.000198693, gnorm=1.424, loss_scale=8192, train_wall=165, wall=0
2023-02-20 21:00:18 | INFO | train_inner | epoch 129:    267 / 1978 loss=2.986, nll_loss=0.849, word_ins=2.679, length=3.072, ppl=7.93, wps=35624.5, ups=0.61, wpb=58724.9, bsz=1951.4, num_updates=253400, lr=0.000198654, gnorm=1.428, loss_scale=8192, train_wall=165, wall=0
2023-02-20 21:03:04 | INFO | train_inner | epoch 129:    367 / 1978 loss=2.963, nll_loss=0.827, word_ins=2.658, length=3.049, ppl=7.8, wps=35212.9, ups=0.6, wpb=58361.3, bsz=2015.8, num_updates=253500, lr=0.000198615, gnorm=1.345, loss_scale=8192, train_wall=166, wall=0
2023-02-20 21:05:50 | INFO | train_inner | epoch 129:    467 / 1978 loss=2.962, nll_loss=0.829, word_ins=2.66, length=3.018, ppl=7.79, wps=35554.6, ups=0.6, wpb=59037.3, bsz=2055, num_updates=253600, lr=0.000198575, gnorm=1.382, loss_scale=8192, train_wall=166, wall=0
2023-02-20 21:08:35 | INFO | train_inner | epoch 129:    567 / 1978 loss=2.98, nll_loss=0.844, word_ins=2.673, length=3.067, ppl=7.89, wps=35674.1, ups=0.61, wpb=58875, bsz=1958, num_updates=253700, lr=0.000198536, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-20 21:11:22 | INFO | train_inner | epoch 129:    667 / 1978 loss=2.958, nll_loss=0.822, word_ins=2.653, length=3.046, ppl=7.77, wps=35780.4, ups=0.6, wpb=59771.2, bsz=2020.5, num_updates=253800, lr=0.000198497, gnorm=1.432, loss_scale=8192, train_wall=167, wall=0
2023-02-20 21:14:07 | INFO | train_inner | epoch 129:    767 / 1978 loss=2.96, nll_loss=0.824, word_ins=2.655, length=3.058, ppl=7.78, wps=36053.9, ups=0.6, wpb=59624.4, bsz=1976.6, num_updates=253900, lr=0.000198458, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-20 21:16:52 | INFO | train_inner | epoch 129:    867 / 1978 loss=2.991, nll_loss=0.848, word_ins=2.677, length=3.144, ppl=7.95, wps=36033.3, ups=0.61, wpb=59403.1, bsz=1959.4, num_updates=254000, lr=0.000198419, gnorm=1.451, loss_scale=8192, train_wall=165, wall=0
2023-02-20 21:19:38 | INFO | train_inner | epoch 129:    967 / 1978 loss=2.973, nll_loss=0.837, word_ins=2.667, length=3.062, ppl=7.85, wps=35576.8, ups=0.6, wpb=59138, bsz=2024.6, num_updates=254100, lr=0.00019838, gnorm=1.355, loss_scale=16384, train_wall=166, wall=0
2023-02-20 21:22:24 | INFO | train_inner | epoch 129:   1067 / 1978 loss=2.99, nll_loss=0.855, word_ins=2.683, length=3.069, ppl=7.95, wps=35783.8, ups=0.6, wpb=59186.1, bsz=1917.9, num_updates=254200, lr=0.000198341, gnorm=1.399, loss_scale=16384, train_wall=165, wall=0
2023-02-20 21:25:10 | INFO | train_inner | epoch 129:   1167 / 1978 loss=2.966, nll_loss=0.83, word_ins=2.66, length=3.064, ppl=7.81, wps=35714.4, ups=0.6, wpb=59367.2, bsz=2016.8, num_updates=254300, lr=0.000198302, gnorm=1.439, loss_scale=16384, train_wall=166, wall=0
2023-02-20 21:27:57 | INFO | train_inner | epoch 129:   1267 / 1978 loss=2.963, nll_loss=0.831, word_ins=2.661, length=3.022, ppl=7.8, wps=35955.9, ups=0.6, wpb=59952.1, bsz=2056.9, num_updates=254400, lr=0.000198263, gnorm=1.421, loss_scale=16384, train_wall=167, wall=0
2023-02-20 21:30:42 | INFO | train_inner | epoch 129:   1367 / 1978 loss=2.973, nll_loss=0.837, word_ins=2.667, length=3.063, ppl=7.85, wps=36020, ups=0.6, wpb=59577.7, bsz=2064.4, num_updates=254500, lr=0.000198224, gnorm=1.39, loss_scale=16384, train_wall=165, wall=0
2023-02-20 21:33:29 | INFO | train_inner | epoch 129:   1467 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.658, length=3.054, ppl=7.8, wps=35760.1, ups=0.6, wpb=59672.8, bsz=2056.5, num_updates=254600, lr=0.000198185, gnorm=1.427, loss_scale=16384, train_wall=167, wall=0
2023-02-20 21:36:15 | INFO | train_inner | epoch 129:   1567 / 1978 loss=2.969, nll_loss=0.833, word_ins=2.663, length=3.061, ppl=7.83, wps=35605.1, ups=0.6, wpb=59105.8, bsz=2081.4, num_updates=254700, lr=0.000198146, gnorm=1.429, loss_scale=16384, train_wall=166, wall=0
2023-02-20 21:39:01 | INFO | train_inner | epoch 129:   1667 / 1978 loss=2.967, nll_loss=0.835, word_ins=2.665, length=3.024, ppl=7.82, wps=35813.2, ups=0.6, wpb=59414.6, bsz=2061.7, num_updates=254800, lr=0.000198107, gnorm=1.387, loss_scale=16384, train_wall=166, wall=0
2023-02-20 21:41:47 | INFO | train_inner | epoch 129:   1767 / 1978 loss=2.984, nll_loss=0.843, word_ins=2.672, length=3.115, ppl=7.91, wps=35815.4, ups=0.6, wpb=59423.3, bsz=1953.8, num_updates=254900, lr=0.000198068, gnorm=1.395, loss_scale=16384, train_wall=166, wall=0
2023-02-20 21:44:32 | INFO | train_inner | epoch 129:   1867 / 1978 loss=2.992, nll_loss=0.854, word_ins=2.682, length=3.094, ppl=7.95, wps=36040.1, ups=0.61, wpb=59454.7, bsz=1951, num_updates=255000, lr=0.00019803, gnorm=1.447, loss_scale=16384, train_wall=165, wall=0
2023-02-20 21:47:16 | INFO | train_inner | epoch 129:   1967 / 1978 loss=2.994, nll_loss=0.855, word_ins=2.683, length=3.11, ppl=7.97, wps=35970.8, ups=0.61, wpb=59088.7, bsz=1888.8, num_updates=255100, lr=0.000197991, gnorm=1.403, loss_scale=16384, train_wall=164, wall=0
2023-02-20 21:47:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 21:47:53 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 4.139 | nll_loss 1.965 | word_ins 3.737 | length 4.02 | ppl 17.61 | wps 56933.5 | wpb 40242.5 | bsz 1500 | num_updates 255111 | best_loss 4.076
2023-02-20 21:47:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 21:47:59 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint129.pt (epoch 129 @ 255111 updates, score 4.139) (writing took 5.793288832530379 seconds)
2023-02-20 21:47:59 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2023-02-20 21:47:59 | INFO | train | epoch 129 | loss 2.972 | nll_loss 0.836 | word_ins 2.666 | length 3.06 | ppl 7.85 | wps 35411 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 255111 | lr 0.000197986 | gnorm 1.407 | loss_scale 16384 | train_wall 3272 | wall 0
2023-02-20 21:47:59 | INFO | fairseq.trainer | begin training epoch 130
2023-02-20 21:50:40 | INFO | train_inner | epoch 130:     89 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.659, length=3.044, ppl=7.8, wps=28735.9, ups=0.49, wpb=58443.2, bsz=2012.9, num_updates=255200, lr=0.000197952, gnorm=1.388, loss_scale=16384, train_wall=166, wall=0
2023-02-20 21:53:24 | INFO | train_inner | epoch 130:    189 / 1978 loss=2.965, nll_loss=0.828, word_ins=2.659, length=3.059, ppl=7.81, wps=35984.9, ups=0.61, wpb=59303.1, bsz=2002.3, num_updates=255300, lr=0.000197913, gnorm=1.363, loss_scale=16384, train_wall=165, wall=0
2023-02-20 21:56:10 | INFO | train_inner | epoch 130:    289 / 1978 loss=2.97, nll_loss=0.837, word_ins=2.668, length=3.024, ppl=7.84, wps=35898.8, ups=0.6, wpb=59407.7, bsz=1952.5, num_updates=255400, lr=0.000197874, gnorm=1.431, loss_scale=16384, train_wall=165, wall=0
2023-02-20 21:58:56 | INFO | train_inner | epoch 130:    389 / 1978 loss=2.967, nll_loss=0.834, word_ins=2.664, length=3.028, ppl=7.82, wps=35687.4, ups=0.6, wpb=59366.3, bsz=2064.8, num_updates=255500, lr=0.000197836, gnorm=1.387, loss_scale=16384, train_wall=166, wall=0
2023-02-20 22:01:42 | INFO | train_inner | epoch 130:    489 / 1978 loss=2.977, nll_loss=0.841, word_ins=2.671, length=3.06, ppl=7.87, wps=35785.9, ups=0.6, wpb=59178.8, bsz=2033.4, num_updates=255600, lr=0.000197797, gnorm=1.421, loss_scale=16384, train_wall=165, wall=0
2023-02-20 22:04:27 | INFO | train_inner | epoch 130:    589 / 1978 loss=2.952, nll_loss=0.817, word_ins=2.649, length=3.024, ppl=7.74, wps=35936.1, ups=0.6, wpb=59541, bsz=2053.1, num_updates=255700, lr=0.000197758, gnorm=1.375, loss_scale=16384, train_wall=165, wall=0
2023-02-20 22:07:14 | INFO | train_inner | epoch 130:    689 / 1978 loss=2.939, nll_loss=0.808, word_ins=2.641, length=2.978, ppl=7.67, wps=35597.3, ups=0.6, wpb=59337.6, bsz=2108.6, num_updates=255800, lr=0.00019772, gnorm=1.388, loss_scale=16384, train_wall=166, wall=0
2023-02-20 22:09:58 | INFO | train_inner | epoch 130:    789 / 1978 loss=2.982, nll_loss=0.845, word_ins=2.675, length=3.071, ppl=7.9, wps=35633.6, ups=0.61, wpb=58440.5, bsz=1984.2, num_updates=255900, lr=0.000197681, gnorm=1.406, loss_scale=16384, train_wall=164, wall=0
2023-02-20 22:12:43 | INFO | train_inner | epoch 130:    889 / 1978 loss=2.984, nll_loss=0.85, word_ins=2.678, length=3.056, ppl=7.91, wps=36028, ups=0.61, wpb=59507, bsz=1958.2, num_updates=256000, lr=0.000197642, gnorm=1.398, loss_scale=16384, train_wall=165, wall=0
2023-02-20 22:15:29 | INFO | train_inner | epoch 130:    989 / 1978 loss=2.962, nll_loss=0.827, word_ins=2.657, length=3.048, ppl=7.79, wps=36111.2, ups=0.6, wpb=59750.4, bsz=1978.3, num_updates=256100, lr=0.000197604, gnorm=1.446, loss_scale=16384, train_wall=165, wall=0
2023-02-20 22:18:15 | INFO | train_inner | epoch 130:   1089 / 1978 loss=2.968, nll_loss=0.831, word_ins=2.661, length=3.07, ppl=7.82, wps=35342.9, ups=0.6, wpb=58690.1, bsz=2020, num_updates=256200, lr=0.000197565, gnorm=1.416, loss_scale=16384, train_wall=166, wall=0
2023-02-20 22:21:01 | INFO | train_inner | epoch 130:   1189 / 1978 loss=2.968, nll_loss=0.834, word_ins=2.664, length=3.031, ppl=7.82, wps=35554, ups=0.6, wpb=59236.4, bsz=2101, num_updates=256300, lr=0.000197527, gnorm=1.389, loss_scale=16384, train_wall=166, wall=0
2023-02-20 22:23:47 | INFO | train_inner | epoch 130:   1289 / 1978 loss=2.99, nll_loss=0.854, word_ins=2.682, length=3.073, ppl=7.94, wps=35912.5, ups=0.6, wpb=59495.4, bsz=1925, num_updates=256400, lr=0.000197488, gnorm=1.469, loss_scale=16384, train_wall=165, wall=0
2023-02-20 22:26:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-20 22:26:34 | INFO | train_inner | epoch 130:   1390 / 1978 loss=2.979, nll_loss=0.841, word_ins=2.67, length=3.082, ppl=7.88, wps=35850.9, ups=0.6, wpb=59749.7, bsz=1951.6, num_updates=256500, lr=0.00019745, gnorm=1.424, loss_scale=8192, train_wall=166, wall=0
2023-02-20 22:29:19 | INFO | train_inner | epoch 130:   1490 / 1978 loss=2.995, nll_loss=0.855, word_ins=2.684, length=3.115, ppl=7.97, wps=35909.1, ups=0.6, wpb=59517.8, bsz=1946.2, num_updates=256600, lr=0.000197411, gnorm=1.441, loss_scale=8192, train_wall=166, wall=0
2023-02-20 22:32:05 | INFO | train_inner | epoch 130:   1590 / 1978 loss=2.975, nll_loss=0.836, word_ins=2.666, length=3.082, ppl=7.86, wps=35992.8, ups=0.61, wpb=59418.6, bsz=1957.6, num_updates=256700, lr=0.000197373, gnorm=1.418, loss_scale=8192, train_wall=165, wall=0
2023-02-20 22:34:50 | INFO | train_inner | epoch 130:   1690 / 1978 loss=2.966, nll_loss=0.828, word_ins=2.659, length=3.071, ppl=7.81, wps=35757.3, ups=0.6, wpb=59325.7, bsz=2021.4, num_updates=256800, lr=0.000197334, gnorm=1.433, loss_scale=8192, train_wall=166, wall=0
2023-02-20 22:37:35 | INFO | train_inner | epoch 130:   1790 / 1978 loss=2.982, nll_loss=0.841, word_ins=2.671, length=3.113, ppl=7.9, wps=35869.6, ups=0.61, wpb=59190.3, bsz=1966.6, num_updates=256900, lr=0.000197296, gnorm=1.392, loss_scale=8192, train_wall=165, wall=0
2023-02-20 22:40:20 | INFO | train_inner | epoch 130:   1890 / 1978 loss=2.957, nll_loss=0.821, word_ins=2.652, length=3.056, ppl=7.77, wps=36153.7, ups=0.61, wpb=59448.6, bsz=2036, num_updates=257000, lr=0.000197257, gnorm=1.383, loss_scale=8192, train_wall=164, wall=0
2023-02-20 22:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 22:43:01 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 4.136 | nll_loss 1.956 | word_ins 3.731 | length 4.051 | ppl 17.58 | wps 57324.9 | wpb 40242.5 | bsz 1500 | num_updates 257088 | best_loss 4.076
2023-02-20 22:43:01 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 22:43:07 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint130.pt (epoch 130 @ 257088 updates, score 4.136) (writing took 5.468634110875428 seconds)
2023-02-20 22:43:07 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2023-02-20 22:43:07 | INFO | train | epoch 130 | loss 2.971 | nll_loss 0.834 | word_ins 2.665 | length 3.059 | ppl 7.84 | wps 35431.9 | ups 0.6 | wpb 59285 | bsz 2003.1 | num_updates 257088 | lr 0.000197224 | gnorm 1.408 | loss_scale 8192 | train_wall 3270 | wall 0
2023-02-20 22:43:07 | INFO | fairseq.trainer | begin training epoch 131
2023-02-20 22:43:38 | INFO | train_inner | epoch 131:     12 / 1978 loss=2.977, nll_loss=0.841, word_ins=2.671, length=3.066, ppl=7.87, wps=30014.7, ups=0.51, wpb=59335.6, bsz=1954.2, num_updates=257100, lr=0.000197219, gnorm=1.405, loss_scale=8192, train_wall=164, wall=0
2023-02-20 22:46:25 | INFO | train_inner | epoch 131:    112 / 1978 loss=2.972, nll_loss=0.838, word_ins=2.668, length=3.039, ppl=7.85, wps=35211.9, ups=0.6, wpb=58950.3, bsz=1966.1, num_updates=257200, lr=0.000197181, gnorm=1.433, loss_scale=8192, train_wall=167, wall=0
2023-02-20 22:49:11 | INFO | train_inner | epoch 131:    212 / 1978 loss=2.966, nll_loss=0.83, word_ins=2.66, length=3.053, ppl=7.81, wps=35747.9, ups=0.6, wpb=59409.8, bsz=2008.6, num_updates=257300, lr=0.000197142, gnorm=1.406, loss_scale=8192, train_wall=166, wall=0
2023-02-20 22:51:57 | INFO | train_inner | epoch 131:    312 / 1978 loss=2.958, nll_loss=0.822, word_ins=2.654, length=3.041, ppl=7.77, wps=35995.9, ups=0.6, wpb=59533.6, bsz=1957.6, num_updates=257400, lr=0.000197104, gnorm=1.425, loss_scale=8192, train_wall=165, wall=0
2023-02-20 22:54:43 | INFO | train_inner | epoch 131:    412 / 1978 loss=2.967, nll_loss=0.832, word_ins=2.662, length=3.05, ppl=7.82, wps=35658.3, ups=0.6, wpb=59337.9, bsz=2051, num_updates=257500, lr=0.000197066, gnorm=1.419, loss_scale=8192, train_wall=166, wall=0
2023-02-20 22:57:30 | INFO | train_inner | epoch 131:    512 / 1978 loss=2.934, nll_loss=0.805, word_ins=2.638, length=2.964, ppl=7.64, wps=35742.7, ups=0.6, wpb=59558.6, bsz=2103.4, num_updates=257600, lr=0.000197028, gnorm=1.342, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:00:15 | INFO | train_inner | epoch 131:    612 / 1978 loss=2.965, nll_loss=0.829, word_ins=2.66, length=3.05, ppl=7.81, wps=35527.2, ups=0.6, wpb=58794.1, bsz=2014, num_updates=257700, lr=0.000196989, gnorm=1.438, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:03:01 | INFO | train_inner | epoch 131:    712 / 1978 loss=2.988, nll_loss=0.85, word_ins=2.679, length=3.091, ppl=7.94, wps=35759, ups=0.6, wpb=59193.7, bsz=1958.7, num_updates=257800, lr=0.000196951, gnorm=1.418, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:05:47 | INFO | train_inner | epoch 131:    812 / 1978 loss=2.962, nll_loss=0.827, word_ins=2.658, length=3.042, ppl=7.79, wps=35553.6, ups=0.6, wpb=59162.8, bsz=2039, num_updates=257900, lr=0.000196913, gnorm=1.396, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:08:33 | INFO | train_inner | epoch 131:    912 / 1978 loss=2.946, nll_loss=0.812, word_ins=2.644, length=3.013, ppl=7.7, wps=35761.5, ups=0.6, wpb=59473.6, bsz=2137.6, num_updates=258000, lr=0.000196875, gnorm=1.396, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:11:24 | INFO | train_inner | epoch 131:   1012 / 1978 loss=2.978, nll_loss=0.84, word_ins=2.67, length=3.082, ppl=7.88, wps=34621.4, ups=0.58, wpb=59209.5, bsz=1955.9, num_updates=258100, lr=0.000196837, gnorm=1.406, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:14:11 | INFO | train_inner | epoch 131:   1112 / 1978 loss=2.973, nll_loss=0.835, word_ins=2.665, length=3.082, ppl=7.85, wps=35704.7, ups=0.6, wpb=59527.7, bsz=2039.4, num_updates=258200, lr=0.000196799, gnorm=1.394, loss_scale=8192, train_wall=167, wall=0
2023-02-20 23:16:56 | INFO | train_inner | epoch 131:   1212 / 1978 loss=2.991, nll_loss=0.857, word_ins=2.685, length=3.063, ppl=7.95, wps=35518.8, ups=0.61, wpb=58699.5, bsz=1935.6, num_updates=258300, lr=0.00019676, gnorm=1.384, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:19:43 | INFO | train_inner | epoch 131:   1312 / 1978 loss=2.976, nll_loss=0.842, word_ins=2.671, length=3.043, ppl=7.87, wps=35458.9, ups=0.6, wpb=59211.8, bsz=1999.5, num_updates=258400, lr=0.000196722, gnorm=1.416, loss_scale=8192, train_wall=167, wall=0
2023-02-20 23:22:29 | INFO | train_inner | epoch 131:   1412 / 1978 loss=2.969, nll_loss=0.83, word_ins=2.66, length=3.085, ppl=7.83, wps=35776.4, ups=0.6, wpb=59279.5, bsz=2045.7, num_updates=258500, lr=0.000196684, gnorm=1.426, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:25:17 | INFO | train_inner | epoch 131:   1512 / 1978 loss=2.962, nll_loss=0.828, word_ins=2.659, length=3.03, ppl=7.79, wps=35809.5, ups=0.6, wpb=60002.5, bsz=2043.5, num_updates=258600, lr=0.000196646, gnorm=1.381, loss_scale=8192, train_wall=167, wall=0
2023-02-20 23:28:01 | INFO | train_inner | epoch 131:   1612 / 1978 loss=3, nll_loss=0.854, word_ins=2.682, length=3.184, ppl=8, wps=35740.1, ups=0.61, wpb=58672.6, bsz=1875.5, num_updates=258700, lr=0.000196608, gnorm=1.449, loss_scale=8192, train_wall=164, wall=0
2023-02-20 23:30:46 | INFO | train_inner | epoch 131:   1712 / 1978 loss=2.958, nll_loss=0.822, word_ins=2.652, length=3.058, ppl=7.77, wps=35866.3, ups=0.6, wpb=59363.8, bsz=2014, num_updates=258800, lr=0.00019657, gnorm=1.402, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:33:31 | INFO | train_inner | epoch 131:   1812 / 1978 loss=2.973, nll_loss=0.834, word_ins=2.665, length=3.08, ppl=7.85, wps=35947.4, ups=0.61, wpb=59207.1, bsz=1968.8, num_updates=258900, lr=0.000196532, gnorm=1.394, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:36:16 | INFO | train_inner | epoch 131:   1912 / 1978 loss=2.968, nll_loss=0.829, word_ins=2.659, length=3.097, ppl=7.83, wps=35973.3, ups=0.6, wpb=59492.2, bsz=1953, num_updates=259000, lr=0.000196494, gnorm=1.424, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-20 23:38:24 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 4.168 | nll_loss 1.964 | word_ins 3.734 | length 4.346 | ppl 17.97 | wps 57461.8 | wpb 40242.5 | bsz 1500 | num_updates 259066 | best_loss 4.076
2023-02-20 23:38:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-20 23:38:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint131.pt (epoch 131 @ 259066 updates, score 4.168) (writing took 5.676981911063194 seconds)
2023-02-20 23:38:30 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2023-02-20 23:38:30 | INFO | train | epoch 131 | loss 2.969 | nll_loss 0.833 | word_ins 2.663 | length 3.06 | ppl 7.83 | wps 35286.1 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 259066 | lr 0.000196469 | gnorm 1.411 | loss_scale 8192 | train_wall 3278 | wall 0
2023-02-20 23:38:30 | INFO | fairseq.trainer | begin training epoch 132
2023-02-20 23:39:37 | INFO | train_inner | epoch 132:     34 / 1978 loss=2.979, nll_loss=0.845, word_ins=2.674, length=3.048, ppl=7.88, wps=29675.5, ups=0.5, wpb=59474.7, bsz=1969.2, num_updates=259100, lr=0.000196456, gnorm=1.465, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:42:23 | INFO | train_inner | epoch 132:    134 / 1978 loss=2.962, nll_loss=0.831, word_ins=2.662, length=3.005, ppl=7.79, wps=35435.8, ups=0.6, wpb=58808.8, bsz=2047.4, num_updates=259200, lr=0.000196419, gnorm=1.41, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:45:08 | INFO | train_inner | epoch 132:    234 / 1978 loss=2.974, nll_loss=0.836, word_ins=2.667, length=3.068, ppl=7.85, wps=35570.5, ups=0.61, wpb=58740, bsz=1984, num_updates=259300, lr=0.000196381, gnorm=1.413, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:47:53 | INFO | train_inner | epoch 132:    334 / 1978 loss=2.979, nll_loss=0.842, word_ins=2.671, length=3.079, ppl=7.89, wps=36078.2, ups=0.61, wpb=59613.3, bsz=1941.5, num_updates=259400, lr=0.000196343, gnorm=1.441, loss_scale=8192, train_wall=165, wall=0
2023-02-20 23:50:40 | INFO | train_inner | epoch 132:    434 / 1978 loss=2.93, nll_loss=0.801, word_ins=2.634, length=2.957, ppl=7.62, wps=35683.6, ups=0.6, wpb=59450.3, bsz=2117, num_updates=259500, lr=0.000196305, gnorm=1.357, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:53:27 | INFO | train_inner | epoch 132:    534 / 1978 loss=2.962, nll_loss=0.829, word_ins=2.66, length=3.024, ppl=7.79, wps=35619.5, ups=0.6, wpb=59497.9, bsz=2060.3, num_updates=259600, lr=0.000196267, gnorm=1.398, loss_scale=8192, train_wall=167, wall=0
2023-02-20 23:56:13 | INFO | train_inner | epoch 132:    634 / 1978 loss=2.973, nll_loss=0.831, word_ins=2.662, length=3.109, ppl=7.85, wps=35713.6, ups=0.6, wpb=59201.5, bsz=1970.6, num_updates=259700, lr=0.000196229, gnorm=1.422, loss_scale=8192, train_wall=166, wall=0
2023-02-20 23:59:00 | INFO | train_inner | epoch 132:    734 / 1978 loss=2.957, nll_loss=0.821, word_ins=2.653, length=3.041, ppl=7.76, wps=35183.5, ups=0.6, wpb=58863.7, bsz=2042.6, num_updates=259800, lr=0.000196192, gnorm=1.435, loss_scale=8192, train_wall=167, wall=0
2023-02-21 00:01:48 | INFO | train_inner | epoch 132:    834 / 1978 loss=2.955, nll_loss=0.826, word_ins=2.657, length=2.973, ppl=7.75, wps=35376.2, ups=0.6, wpb=59420.2, bsz=2060.4, num_updates=259900, lr=0.000196154, gnorm=1.383, loss_scale=8192, train_wall=168, wall=0
2023-02-21 00:04:33 | INFO | train_inner | epoch 132:    934 / 1978 loss=2.976, nll_loss=0.838, word_ins=2.667, length=3.085, ppl=7.87, wps=36020.7, ups=0.61, wpb=59286.5, bsz=1938.9, num_updates=260000, lr=0.000196116, gnorm=1.473, loss_scale=8192, train_wall=164, wall=0
2023-02-21 00:07:18 | INFO | train_inner | epoch 132:   1034 / 1978 loss=2.972, nll_loss=0.831, word_ins=2.661, length=3.105, ppl=7.84, wps=36041.5, ups=0.6, wpb=59607.7, bsz=1975.5, num_updates=260100, lr=0.000196078, gnorm=1.427, loss_scale=8192, train_wall=165, wall=0
2023-02-21 00:10:03 | INFO | train_inner | epoch 132:   1134 / 1978 loss=2.976, nll_loss=0.836, word_ins=2.666, length=3.096, ppl=7.87, wps=35664.9, ups=0.61, wpb=58916.9, bsz=1958, num_updates=260200, lr=0.000196041, gnorm=1.388, loss_scale=8192, train_wall=165, wall=0
2023-02-21 00:12:50 | INFO | train_inner | epoch 132:   1234 / 1978 loss=2.966, nll_loss=0.833, word_ins=2.663, length=3.029, ppl=7.81, wps=35740.7, ups=0.6, wpb=59524.5, bsz=2083.8, num_updates=260300, lr=0.000196003, gnorm=1.369, loss_scale=8192, train_wall=166, wall=0
2023-02-21 00:15:35 | INFO | train_inner | epoch 132:   1334 / 1978 loss=2.975, nll_loss=0.84, word_ins=2.67, length=3.049, ppl=7.86, wps=35601.8, ups=0.6, wpb=58892.1, bsz=1990.1, num_updates=260400, lr=0.000195965, gnorm=1.427, loss_scale=8192, train_wall=165, wall=0
2023-02-21 00:18:20 | INFO | train_inner | epoch 132:   1434 / 1978 loss=2.997, nll_loss=0.858, word_ins=2.686, length=3.108, ppl=7.98, wps=36188, ups=0.61, wpb=59598.2, bsz=1875, num_updates=260500, lr=0.000195928, gnorm=1.472, loss_scale=8192, train_wall=164, wall=0
2023-02-21 00:21:04 | INFO | train_inner | epoch 132:   1534 / 1978 loss=2.982, nll_loss=0.843, word_ins=2.672, length=3.104, ppl=7.9, wps=35968.4, ups=0.61, wpb=59200.2, bsz=1959.8, num_updates=260600, lr=0.00019589, gnorm=1.437, loss_scale=16384, train_wall=164, wall=0
2023-02-21 00:23:51 | INFO | train_inner | epoch 132:   1634 / 1978 loss=2.949, nll_loss=0.815, word_ins=2.646, length=3.033, ppl=7.72, wps=35862.1, ups=0.6, wpb=59712.2, bsz=2066.5, num_updates=260700, lr=0.000195853, gnorm=1.441, loss_scale=16384, train_wall=166, wall=0
2023-02-21 00:26:36 | INFO | train_inner | epoch 132:   1734 / 1978 loss=2.982, nll_loss=0.844, word_ins=2.673, length=3.084, ppl=7.9, wps=35940.4, ups=0.61, wpb=59282.5, bsz=1929.1, num_updates=260800, lr=0.000195815, gnorm=1.43, loss_scale=16384, train_wall=165, wall=0
2023-02-21 00:29:22 | INFO | train_inner | epoch 132:   1834 / 1978 loss=2.967, nll_loss=0.832, word_ins=2.661, length=3.059, ppl=7.82, wps=36101.5, ups=0.6, wpb=59840.3, bsz=1998, num_updates=260900, lr=0.000195778, gnorm=1.382, loss_scale=16384, train_wall=166, wall=0
2023-02-21 00:32:08 | INFO | train_inner | epoch 132:   1934 / 1978 loss=2.959, nll_loss=0.824, word_ins=2.655, length=3.041, ppl=7.78, wps=35772.6, ups=0.6, wpb=59380.2, bsz=2062.1, num_updates=261000, lr=0.00019574, gnorm=1.367, loss_scale=16384, train_wall=166, wall=0
2023-02-21 00:33:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 00:33:41 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 4.11 | nll_loss 1.935 | word_ins 3.713 | length 3.97 | ppl 17.27 | wps 57442.6 | wpb 40242.5 | bsz 1500 | num_updates 261044 | best_loss 4.076
2023-02-21 00:33:41 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 00:33:46 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint132.pt (epoch 132 @ 261044 updates, score 4.11) (writing took 5.409258422441781 seconds)
2023-02-21 00:33:46 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2023-02-21 00:33:46 | INFO | train | epoch 132 | loss 2.968 | nll_loss 0.833 | word_ins 2.663 | length 3.053 | ppl 7.83 | wps 35361.4 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 261044 | lr 0.000195724 | gnorm 1.415 | loss_scale 16384 | train_wall 3276 | wall 0
2023-02-21 00:33:46 | INFO | fairseq.trainer | begin training epoch 133
2023-02-21 00:35:29 | INFO | train_inner | epoch 133:     56 / 1978 loss=2.96, nll_loss=0.831, word_ins=2.662, length=2.98, ppl=7.78, wps=29110.4, ups=0.5, wpb=58758, bsz=2046.5, num_updates=261100, lr=0.000195703, gnorm=1.45, loss_scale=16384, train_wall=166, wall=0
2023-02-21 00:38:20 | INFO | train_inner | epoch 133:    156 / 1978 loss=2.964, nll_loss=0.827, word_ins=2.658, length=3.061, ppl=7.81, wps=34535.6, ups=0.59, wpb=58882.9, bsz=2002.6, num_updates=261200, lr=0.000195665, gnorm=1.407, loss_scale=16384, train_wall=170, wall=0
2023-02-21 00:41:06 | INFO | train_inner | epoch 133:    256 / 1978 loss=2.97, nll_loss=0.832, word_ins=2.662, length=3.085, ppl=7.84, wps=35648.4, ups=0.6, wpb=59046.9, bsz=1992.2, num_updates=261300, lr=0.000195628, gnorm=1.418, loss_scale=16384, train_wall=165, wall=0
2023-02-21 00:43:50 | INFO | train_inner | epoch 133:    356 / 1978 loss=2.973, nll_loss=0.833, word_ins=2.663, length=3.099, ppl=7.85, wps=36523, ups=0.61, wpb=59993.6, bsz=1935, num_updates=261400, lr=0.00019559, gnorm=1.423, loss_scale=16384, train_wall=164, wall=0
2023-02-21 00:46:37 | INFO | train_inner | epoch 133:    456 / 1978 loss=2.952, nll_loss=0.819, word_ins=2.651, length=3.013, ppl=7.74, wps=35815.7, ups=0.6, wpb=59687.3, bsz=2070, num_updates=261500, lr=0.000195553, gnorm=1.393, loss_scale=16384, train_wall=166, wall=0
2023-02-21 00:49:25 | INFO | train_inner | epoch 133:    556 / 1978 loss=2.953, nll_loss=0.821, word_ins=2.652, length=3.009, ppl=7.75, wps=34794.7, ups=0.59, wpb=58565.7, bsz=2131.1, num_updates=261600, lr=0.000195515, gnorm=1.397, loss_scale=16384, train_wall=168, wall=0
2023-02-21 00:52:15 | INFO | train_inner | epoch 133:    656 / 1978 loss=2.966, nll_loss=0.836, word_ins=2.665, length=3.008, ppl=7.82, wps=35075.2, ups=0.59, wpb=59821.5, bsz=2006.4, num_updates=261700, lr=0.000195478, gnorm=1.435, loss_scale=16384, train_wall=170, wall=0
2023-02-21 00:55:01 | INFO | train_inner | epoch 133:    756 / 1978 loss=2.972, nll_loss=0.833, word_ins=2.663, length=3.088, ppl=7.85, wps=35793.3, ups=0.6, wpb=59240, bsz=2017.8, num_updates=261800, lr=0.000195441, gnorm=1.438, loss_scale=16384, train_wall=165, wall=0
2023-02-21 00:57:47 | INFO | train_inner | epoch 133:    856 / 1978 loss=2.972, nll_loss=0.836, word_ins=2.666, length=3.06, ppl=7.84, wps=35697.8, ups=0.6, wpb=59265.8, bsz=2012.6, num_updates=261900, lr=0.000195403, gnorm=1.491, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:00:32 | INFO | train_inner | epoch 133:    956 / 1978 loss=3.001, nll_loss=0.858, word_ins=2.686, length=3.142, ppl=8, wps=35630.9, ups=0.61, wpb=58659.3, bsz=1882.6, num_updates=262000, lr=0.000195366, gnorm=1.466, loss_scale=16384, train_wall=164, wall=0
2023-02-21 01:03:17 | INFO | train_inner | epoch 133:   1056 / 1978 loss=2.967, nll_loss=0.829, word_ins=2.659, length=3.074, ppl=7.82, wps=35914.6, ups=0.6, wpb=59481.2, bsz=1992.6, num_updates=262100, lr=0.000195329, gnorm=1.383, loss_scale=16384, train_wall=165, wall=0
2023-02-21 01:06:09 | INFO | train_inner | epoch 133:   1156 / 1978 loss=2.974, nll_loss=0.835, word_ins=2.665, length=3.088, ppl=7.86, wps=34623.9, ups=0.58, wpb=59327.6, bsz=1950.8, num_updates=262200, lr=0.000195292, gnorm=1.386, loss_scale=16384, train_wall=171, wall=0
2023-02-21 01:08:55 | INFO | train_inner | epoch 133:   1256 / 1978 loss=2.955, nll_loss=0.824, word_ins=2.655, length=2.999, ppl=7.75, wps=35572.9, ups=0.6, wpb=59269.5, bsz=2016.4, num_updates=262300, lr=0.000195254, gnorm=1.38, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:13:26 | INFO | train_inner | epoch 133:   1356 / 1978 loss=2.961, nll_loss=0.825, word_ins=2.656, length=3.05, ppl=7.78, wps=21610.2, ups=0.37, wpb=58535.5, bsz=2039.1, num_updates=262400, lr=0.000195217, gnorm=1.4, loss_scale=16384, train_wall=271, wall=0
2023-02-21 01:16:24 | INFO | train_inner | epoch 133:   1456 / 1978 loss=2.964, nll_loss=0.833, word_ins=2.663, length=3.017, ppl=7.81, wps=33413.6, ups=0.56, wpb=59428, bsz=1991.5, num_updates=262500, lr=0.00019518, gnorm=1.495, loss_scale=16384, train_wall=176, wall=0
2023-02-21 01:19:10 | INFO | train_inner | epoch 133:   1556 / 1978 loss=2.981, nll_loss=0.84, word_ins=2.67, length=3.113, ppl=7.9, wps=35622.4, ups=0.6, wpb=59266.3, bsz=1973.3, num_updates=262600, lr=0.000195143, gnorm=1.414, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:23:27 | INFO | train_inner | epoch 133:   1656 / 1978 loss=2.969, nll_loss=0.833, word_ins=2.663, length=3.058, ppl=7.83, wps=23241.9, ups=0.39, wpb=59559, bsz=2006.2, num_updates=262700, lr=0.000195106, gnorm=1.427, loss_scale=16384, train_wall=256, wall=0
2023-02-21 01:26:12 | INFO | train_inner | epoch 133:   1756 / 1978 loss=2.946, nll_loss=0.815, word_ins=2.646, length=3.004, ppl=7.71, wps=36058.1, ups=0.6, wpb=59768.3, bsz=2066.2, num_updates=262800, lr=0.000195069, gnorm=1.414, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:29:00 | INFO | train_inner | epoch 133:   1856 / 1978 loss=2.965, nll_loss=0.829, word_ins=2.66, length=3.056, ppl=7.81, wps=35320.4, ups=0.6, wpb=59299, bsz=1981.3, num_updates=262900, lr=0.000195031, gnorm=1.372, loss_scale=16384, train_wall=165, wall=0
2023-02-21 01:31:46 | INFO | train_inner | epoch 133:   1956 / 1978 loss=2.97, nll_loss=0.832, word_ins=2.663, length=3.067, ppl=7.83, wps=35896.7, ups=0.6, wpb=59413.3, bsz=1979.5, num_updates=263000, lr=0.000194994, gnorm=1.387, loss_scale=16384, train_wall=165, wall=0
2023-02-21 01:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 01:32:50 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 4.108 | nll_loss 1.945 | word_ins 3.721 | length 3.873 | ppl 17.25 | wps 55116.5 | wpb 40242.5 | bsz 1500 | num_updates 263022 | best_loss 4.076
2023-02-21 01:32:50 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 01:32:55 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint133.pt (epoch 133 @ 263022 updates, score 4.108) (writing took 5.540018707513809 seconds)
2023-02-21 01:32:55 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2023-02-21 01:32:55 | INFO | train | epoch 133 | loss 2.966 | nll_loss 0.83 | word_ins 2.661 | length 3.055 | ppl 7.82 | wps 33040.9 | ups 0.56 | wpb 59284.3 | bsz 2002.6 | num_updates 263022 | lr 0.000194986 | gnorm 1.419 | loss_scale 16384 | train_wall 3497 | wall 0
2023-02-21 01:32:55 | INFO | fairseq.trainer | begin training epoch 134
2023-02-21 01:35:15 | INFO | train_inner | epoch 134:     78 / 1978 loss=2.943, nll_loss=0.813, word_ins=2.645, length=2.977, ppl=7.69, wps=28165.2, ups=0.48, wpb=58977.1, bsz=2043.8, num_updates=263100, lr=0.000194957, gnorm=1.421, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:38:03 | INFO | train_inner | epoch 134:    178 / 1978 loss=2.948, nll_loss=0.816, word_ins=2.648, length=3.002, ppl=7.72, wps=35178, ups=0.6, wpb=59093.7, bsz=2052.2, num_updates=263200, lr=0.00019492, gnorm=1.409, loss_scale=16384, train_wall=168, wall=0
2023-02-21 01:40:49 | INFO | train_inner | epoch 134:    278 / 1978 loss=2.967, nll_loss=0.833, word_ins=2.663, length=3.037, ppl=7.82, wps=35633.1, ups=0.61, wpb=58896.2, bsz=1979.7, num_updates=263300, lr=0.000194883, gnorm=1.421, loss_scale=16384, train_wall=165, wall=0
2023-02-21 01:43:34 | INFO | train_inner | epoch 134:    378 / 1978 loss=2.962, nll_loss=0.823, word_ins=2.654, length=3.084, ppl=7.79, wps=35738.7, ups=0.6, wpb=59254.5, bsz=1973.7, num_updates=263400, lr=0.000194846, gnorm=1.408, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:46:22 | INFO | train_inner | epoch 134:    478 / 1978 loss=2.943, nll_loss=0.815, word_ins=2.647, length=2.96, ppl=7.69, wps=35786.7, ups=0.6, wpb=59817.1, bsz=2120.8, num_updates=263500, lr=0.000194809, gnorm=1.388, loss_scale=16384, train_wall=167, wall=0
2023-02-21 01:49:11 | INFO | train_inner | epoch 134:    578 / 1978 loss=2.964, nll_loss=0.825, word_ins=2.656, length=3.078, ppl=7.8, wps=34787.6, ups=0.59, wpb=58954.9, bsz=2017.9, num_updates=263600, lr=0.000194772, gnorm=1.367, loss_scale=16384, train_wall=169, wall=0
2023-02-21 01:51:57 | INFO | train_inner | epoch 134:    678 / 1978 loss=2.953, nll_loss=0.817, word_ins=2.649, length=3.045, ppl=7.74, wps=35904, ups=0.6, wpb=59620, bsz=2032.5, num_updates=263700, lr=0.000194735, gnorm=1.412, loss_scale=16384, train_wall=166, wall=0
2023-02-21 01:54:48 | INFO | train_inner | epoch 134:    778 / 1978 loss=2.974, nll_loss=0.839, word_ins=2.669, length=3.047, ppl=7.86, wps=35006.3, ups=0.59, wpb=59714.4, bsz=1925.1, num_updates=263800, lr=0.000194698, gnorm=1.469, loss_scale=16384, train_wall=170, wall=0
2023-02-21 01:57:35 | INFO | train_inner | epoch 134:    878 / 1978 loss=2.966, nll_loss=0.832, word_ins=2.662, length=3.042, ppl=7.81, wps=35771.8, ups=0.6, wpb=59724.3, bsz=2059.3, num_updates=263900, lr=0.000194662, gnorm=1.448, loss_scale=16384, train_wall=167, wall=0
2023-02-21 02:00:20 | INFO | train_inner | epoch 134:    978 / 1978 loss=2.965, nll_loss=0.826, word_ins=2.657, length=3.08, ppl=7.81, wps=36179.8, ups=0.6, wpb=59870.3, bsz=1984.3, num_updates=264000, lr=0.000194625, gnorm=1.441, loss_scale=16384, train_wall=165, wall=0
2023-02-21 02:05:12 | INFO | train_inner | epoch 134:   1078 / 1978 loss=2.958, nll_loss=0.823, word_ins=2.654, length=3.044, ppl=7.77, wps=30138.8, ups=0.51, wpb=59306.5, bsz=2059.3, num_updates=264100, lr=0.000194588, gnorm=1.395, loss_scale=16384, train_wall=197, wall=0
2023-02-21 02:07:58 | INFO | train_inner | epoch 134:   1178 / 1978 loss=2.967, nll_loss=0.83, word_ins=2.661, length=3.059, ppl=7.82, wps=35565.5, ups=0.6, wpb=58877.8, bsz=1964.7, num_updates=264200, lr=0.000194551, gnorm=1.452, loss_scale=16384, train_wall=165, wall=0
2023-02-21 02:10:43 | INFO | train_inner | epoch 134:   1278 / 1978 loss=2.975, nll_loss=0.841, word_ins=2.67, length=3.046, ppl=7.86, wps=35585.8, ups=0.6, wpb=58866.4, bsz=1997.7, num_updates=264300, lr=0.000194514, gnorm=1.412, loss_scale=16384, train_wall=165, wall=0
2023-02-21 02:13:30 | INFO | train_inner | epoch 134:   1378 / 1978 loss=2.944, nll_loss=0.813, word_ins=2.644, length=3.001, ppl=7.7, wps=35954.3, ups=0.6, wpb=59916.8, bsz=2048.4, num_updates=264400, lr=0.000194477, gnorm=1.403, loss_scale=16384, train_wall=166, wall=0
2023-02-21 02:16:14 | INFO | train_inner | epoch 134:   1478 / 1978 loss=2.995, nll_loss=0.852, word_ins=2.681, length=3.133, ppl=7.97, wps=35811.8, ups=0.61, wpb=58978.1, bsz=1886.6, num_updates=264500, lr=0.000194441, gnorm=1.43, loss_scale=16384, train_wall=164, wall=0
2023-02-21 02:20:29 | INFO | train_inner | epoch 134:   1578 / 1978 loss=2.993, nll_loss=0.855, word_ins=2.683, length=3.104, ppl=7.96, wps=23188.1, ups=0.39, wpb=58912.7, bsz=1909, num_updates=264600, lr=0.000194404, gnorm=1.456, loss_scale=16384, train_wall=254, wall=0
2023-02-21 02:23:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-02-21 02:23:26 | INFO | train_inner | epoch 134:   1679 / 1978 loss=2.983, nll_loss=0.841, word_ins=2.671, length=3.125, ppl=7.91, wps=33097.1, ups=0.56, wpb=58851.2, bsz=1961.8, num_updates=264700, lr=0.000194367, gnorm=1.448, loss_scale=16384, train_wall=176, wall=0
2023-02-21 02:26:13 | INFO | train_inner | epoch 134:   1779 / 1978 loss=2.966, nll_loss=0.834, word_ins=2.664, length=3.018, ppl=7.81, wps=35525.7, ups=0.6, wpb=59213.3, bsz=2054.8, num_updates=264800, lr=0.000194331, gnorm=1.44, loss_scale=16384, train_wall=166, wall=0
2023-02-21 02:28:58 | INFO | train_inner | epoch 134:   1879 / 1978 loss=2.969, nll_loss=0.832, word_ins=2.662, length=3.072, ppl=7.83, wps=36083.2, ups=0.61, wpb=59463.5, bsz=1992.8, num_updates=264900, lr=0.000194294, gnorm=1.421, loss_scale=16384, train_wall=165, wall=0
2023-02-21 02:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 02:33:45 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 4.102 | nll_loss 1.932 | word_ins 3.707 | length 3.955 | ppl 17.18 | wps 56521.5 | wpb 40242.5 | bsz 1500 | num_updates 264999 | best_loss 4.076
2023-02-21 02:33:45 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 02:33:50 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint134.pt (epoch 134 @ 264999 updates, score 4.102) (writing took 5.429550313390791 seconds)
2023-02-21 02:33:50 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2023-02-21 02:33:50 | INFO | train | epoch 134 | loss 2.965 | nll_loss 0.829 | word_ins 2.66 | length 3.051 | ppl 7.81 | wps 32067.4 | ups 0.54 | wpb 59285 | bsz 2002.7 | num_updates 264999 | lr 0.000194258 | gnorm 1.425 | loss_scale 16384 | train_wall 3517 | wall 0
2023-02-21 02:33:50 | INFO | fairseq.trainer | begin training epoch 135
2023-02-21 02:34:01 | INFO | train_inner | epoch 135:      1 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.658, length=3.061, ppl=7.8, wps=19586.4, ups=0.33, wpb=59395.9, bsz=1977.3, num_updates=265000, lr=0.000194257, gnorm=1.474, loss_scale=16384, train_wall=267, wall=0
2023-02-21 02:36:59 | INFO | train_inner | epoch 135:    101 / 1978 loss=2.96, nll_loss=0.827, word_ins=2.658, length=3.016, ppl=7.78, wps=33382.5, ups=0.56, wpb=59392.6, bsz=1957.4, num_updates=265100, lr=0.000194221, gnorm=1.423, loss_scale=16384, train_wall=178, wall=0
2023-02-21 02:40:39 | INFO | train_inner | epoch 135:    201 / 1978 loss=2.95, nll_loss=0.814, word_ins=2.646, length=3.039, ppl=7.73, wps=26967.5, ups=0.45, wpb=59338.5, bsz=2023.9, num_updates=265200, lr=0.000194184, gnorm=1.47, loss_scale=16384, train_wall=220, wall=0
2023-02-21 02:43:24 | INFO | train_inner | epoch 135:    301 / 1978 loss=2.958, nll_loss=0.824, word_ins=2.655, length=3.033, ppl=7.77, wps=35943.5, ups=0.61, wpb=59372.4, bsz=1996.3, num_updates=265300, lr=0.000194147, gnorm=1.469, loss_scale=16384, train_wall=165, wall=0
2023-02-21 02:46:23 | INFO | train_inner | epoch 135:    401 / 1978 loss=2.946, nll_loss=0.813, word_ins=2.645, length=3.017, ppl=7.71, wps=33486.1, ups=0.56, wpb=59871.6, bsz=2049.1, num_updates=265400, lr=0.000194111, gnorm=1.436, loss_scale=16384, train_wall=167, wall=0
2023-02-21 02:49:10 | INFO | train_inner | epoch 135:    501 / 1978 loss=2.979, nll_loss=0.841, word_ins=2.671, length=3.083, ppl=7.89, wps=35303.4, ups=0.6, wpb=59047.5, bsz=1980.7, num_updates=265500, lr=0.000194074, gnorm=1.427, loss_scale=16384, train_wall=167, wall=0
2023-02-21 02:52:18 | INFO | train_inner | epoch 135:    601 / 1978 loss=2.979, nll_loss=0.842, word_ins=2.672, length=3.071, ppl=7.89, wps=31604.5, ups=0.53, wpb=59193.8, bsz=1948.2, num_updates=265600, lr=0.000194038, gnorm=1.435, loss_scale=16384, train_wall=176, wall=0
2023-02-21 02:55:03 | INFO | train_inner | epoch 135:    701 / 1978 loss=2.967, nll_loss=0.832, word_ins=2.662, length=3.048, ppl=7.82, wps=35627.7, ups=0.6, wpb=58934.6, bsz=1975.9, num_updates=265700, lr=0.000194001, gnorm=1.409, loss_scale=16384, train_wall=165, wall=0
2023-02-21 02:58:09 | INFO | train_inner | epoch 135:    801 / 1978 loss=2.974, nll_loss=0.836, word_ins=2.666, length=3.08, ppl=7.86, wps=31850.5, ups=0.54, wpb=59348.7, bsz=1976.2, num_updates=265800, lr=0.000193965, gnorm=1.483, loss_scale=16384, train_wall=171, wall=0
2023-02-21 03:01:00 | INFO | train_inner | epoch 135:    901 / 1978 loss=2.97, nll_loss=0.837, word_ins=2.667, length=3.032, ppl=7.84, wps=34656.7, ups=0.59, wpb=59029.4, bsz=2008.4, num_updates=265900, lr=0.000193928, gnorm=1.405, loss_scale=16384, train_wall=170, wall=0
2023-02-21 03:03:47 | INFO | train_inner | epoch 135:   1001 / 1978 loss=2.958, nll_loss=0.824, word_ins=2.655, length=3.037, ppl=7.77, wps=35723.5, ups=0.6, wpb=59625, bsz=2046.1, num_updates=266000, lr=0.000193892, gnorm=1.432, loss_scale=16384, train_wall=167, wall=0
2023-02-21 03:06:36 | INFO | train_inner | epoch 135:   1101 / 1978 loss=2.963, nll_loss=0.825, word_ins=2.655, length=3.074, ppl=7.8, wps=35294.3, ups=0.59, wpb=59763.1, bsz=1976.7, num_updates=266100, lr=0.000193855, gnorm=1.443, loss_scale=16384, train_wall=169, wall=0
2023-02-21 03:11:00 | INFO | train_inner | epoch 135:   1201 / 1978 loss=2.98, nll_loss=0.836, word_ins=2.666, length=3.143, ppl=7.89, wps=22340.2, ups=0.38, wpb=58998.6, bsz=1951.7, num_updates=266200, lr=0.000193819, gnorm=1.476, loss_scale=16384, train_wall=168, wall=0
2023-02-21 03:13:48 | INFO | train_inner | epoch 135:   1301 / 1978 loss=2.956, nll_loss=0.823, word_ins=2.654, length=3.029, ppl=7.76, wps=35416.7, ups=0.59, wpb=59619, bsz=1972.1, num_updates=266300, lr=0.000193782, gnorm=1.446, loss_scale=16384, train_wall=168, wall=0
2023-02-21 03:16:37 | INFO | train_inner | epoch 135:   1401 / 1978 loss=2.945, nll_loss=0.816, word_ins=2.647, length=2.978, ppl=7.7, wps=35414.2, ups=0.59, wpb=59588.9, bsz=2144.9, num_updates=266400, lr=0.000193746, gnorm=1.412, loss_scale=16384, train_wall=168, wall=0
2023-02-21 03:19:21 | INFO | train_inner | epoch 135:   1501 / 1978 loss=2.982, nll_loss=0.843, word_ins=2.672, length=3.1, ppl=7.9, wps=35781.9, ups=0.61, wpb=58955.7, bsz=1974.5, num_updates=266500, lr=0.00019371, gnorm=1.45, loss_scale=16384, train_wall=165, wall=0
2023-02-21 03:22:17 | INFO | train_inner | epoch 135:   1601 / 1978 loss=2.963, nll_loss=0.833, word_ins=2.664, length=2.999, ppl=7.8, wps=33824.4, ups=0.57, wpb=59482.7, bsz=1976, num_updates=266600, lr=0.000193673, gnorm=1.436, loss_scale=16384, train_wall=166, wall=0
2023-02-21 03:25:08 | INFO | train_inner | epoch 135:   1701 / 1978 loss=2.958, nll_loss=0.822, word_ins=2.652, length=3.059, ppl=7.77, wps=34648.4, ups=0.59, wpb=59167.3, bsz=2073.3, num_updates=266700, lr=0.000193637, gnorm=1.411, loss_scale=16384, train_wall=171, wall=0
2023-02-21 03:27:53 | INFO | train_inner | epoch 135:   1801 / 1978 loss=2.972, nll_loss=0.836, word_ins=2.665, length=3.063, ppl=7.84, wps=35625.4, ups=0.61, wpb=58814.8, bsz=1991, num_updates=266800, lr=0.000193601, gnorm=1.381, loss_scale=16384, train_wall=165, wall=0
2023-02-21 03:30:40 | INFO | train_inner | epoch 135:   1901 / 1978 loss=2.952, nll_loss=0.817, word_ins=2.648, length=3.033, ppl=7.74, wps=35478.4, ups=0.6, wpb=59202, bsz=2121.4, num_updates=266900, lr=0.000193565, gnorm=1.471, loss_scale=16384, train_wall=167, wall=0
2023-02-21 03:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 03:33:05 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 4.124 | nll_loss 1.956 | word_ins 3.729 | length 3.952 | ppl 17.43 | wps 56967.8 | wpb 40242.5 | bsz 1500 | num_updates 266977 | best_loss 4.076
2023-02-21 03:33:05 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 03:33:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint135.pt (epoch 135 @ 266977 updates, score 4.124) (writing took 5.414315551519394 seconds)
2023-02-21 03:33:11 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2023-02-21 03:33:11 | INFO | train | epoch 135 | loss 2.966 | nll_loss 0.83 | word_ins 2.66 | length 3.052 | ppl 7.81 | wps 32932.1 | ups 0.56 | wpb 59284.3 | bsz 2002.6 | num_updates 266977 | lr 0.000193537 | gnorm 1.44 | loss_scale 16384 | train_wall 3380 | wall 0
2023-02-21 03:33:11 | INFO | fairseq.trainer | begin training epoch 136
2023-02-21 03:33:59 | INFO | train_inner | epoch 136:     23 / 1978 loss=3.007, nll_loss=0.863, word_ins=2.692, length=3.157, ppl=8.04, wps=29567.5, ups=0.5, wpb=58704.7, bsz=1861, num_updates=267000, lr=0.000193528, gnorm=1.49, loss_scale=16384, train_wall=164, wall=0
2023-02-21 03:36:45 | INFO | train_inner | epoch 136:    123 / 1978 loss=2.95, nll_loss=0.821, word_ins=2.652, length=2.978, ppl=7.73, wps=35717, ups=0.6, wpb=59494.2, bsz=2039.2, num_updates=267100, lr=0.000193492, gnorm=1.408, loss_scale=16384, train_wall=166, wall=0
2023-02-21 03:39:30 | INFO | train_inner | epoch 136:    223 / 1978 loss=2.951, nll_loss=0.816, word_ins=2.647, length=3.04, ppl=7.74, wps=36107.4, ups=0.61, wpb=59626.1, bsz=1947.8, num_updates=267200, lr=0.000193456, gnorm=1.403, loss_scale=16384, train_wall=165, wall=0
2023-02-21 03:42:16 | INFO | train_inner | epoch 136:    323 / 1978 loss=2.961, nll_loss=0.82, word_ins=2.652, length=3.088, ppl=7.78, wps=35846.7, ups=0.6, wpb=59274.8, bsz=1969.8, num_updates=267300, lr=0.00019342, gnorm=1.462, loss_scale=16384, train_wall=165, wall=0
2023-02-21 03:45:01 | INFO | train_inner | epoch 136:    423 / 1978 loss=2.971, nll_loss=0.836, word_ins=2.667, length=3.045, ppl=7.84, wps=35634.3, ups=0.61, wpb=58806.3, bsz=1980.8, num_updates=267400, lr=0.000193383, gnorm=1.43, loss_scale=16384, train_wall=165, wall=0
2023-02-21 03:47:48 | INFO | train_inner | epoch 136:    523 / 1978 loss=2.966, nll_loss=0.831, word_ins=2.662, length=3.047, ppl=7.82, wps=35366.6, ups=0.6, wpb=59060.1, bsz=2054.2, num_updates=267500, lr=0.000193347, gnorm=1.417, loss_scale=16384, train_wall=167, wall=0
2023-02-21 03:50:33 | INFO | train_inner | epoch 136:    623 / 1978 loss=2.989, nll_loss=0.844, word_ins=2.674, length=3.148, ppl=7.94, wps=35807.9, ups=0.6, wpb=59230.5, bsz=1905.8, num_updates=267600, lr=0.000193311, gnorm=1.478, loss_scale=16384, train_wall=165, wall=0
2023-02-21 03:53:19 | INFO | train_inner | epoch 136:    723 / 1978 loss=2.974, nll_loss=0.844, word_ins=2.674, length=3.002, ppl=7.86, wps=35517.8, ups=0.6, wpb=58905.8, bsz=1984.4, num_updates=267700, lr=0.000193275, gnorm=1.416, loss_scale=16384, train_wall=166, wall=0
2023-02-21 03:56:05 | INFO | train_inner | epoch 136:    823 / 1978 loss=2.945, nll_loss=0.811, word_ins=2.643, length=3.02, ppl=7.7, wps=35761.1, ups=0.6, wpb=59356.1, bsz=2129.1, num_updates=267800, lr=0.000193239, gnorm=1.414, loss_scale=16384, train_wall=166, wall=0
2023-02-21 03:58:51 | INFO | train_inner | epoch 136:    923 / 1978 loss=2.981, nll_loss=0.846, word_ins=2.676, length=3.051, ppl=7.89, wps=35388.1, ups=0.6, wpb=58679.6, bsz=2005, num_updates=267900, lr=0.000193203, gnorm=1.443, loss_scale=16384, train_wall=166, wall=0
2023-02-21 04:01:37 | INFO | train_inner | epoch 136:   1023 / 1978 loss=2.968, nll_loss=0.828, word_ins=2.658, length=3.105, ppl=7.83, wps=35881.1, ups=0.6, wpb=59572, bsz=1951.8, num_updates=268000, lr=0.000193167, gnorm=1.434, loss_scale=16384, train_wall=166, wall=0
2023-02-21 04:04:23 | INFO | train_inner | epoch 136:   1123 / 1978 loss=2.958, nll_loss=0.825, word_ins=2.655, length=3.026, ppl=7.77, wps=35492.4, ups=0.6, wpb=59057.3, bsz=2048, num_updates=268100, lr=0.000193131, gnorm=1.405, loss_scale=16384, train_wall=166, wall=0
2023-02-21 04:07:08 | INFO | train_inner | epoch 136:   1223 / 1978 loss=2.974, nll_loss=0.835, word_ins=2.664, length=3.095, ppl=7.86, wps=36071.3, ups=0.61, wpb=59566.8, bsz=1920.2, num_updates=268200, lr=0.000193095, gnorm=1.462, loss_scale=16384, train_wall=165, wall=0
2023-02-21 04:09:53 | INFO | train_inner | epoch 136:   1323 / 1978 loss=2.977, nll_loss=0.838, word_ins=2.668, length=3.09, ppl=7.87, wps=35884.8, ups=0.61, wpb=59266.8, bsz=1927.2, num_updates=268300, lr=0.000193059, gnorm=1.465, loss_scale=16384, train_wall=165, wall=0
2023-02-21 04:11:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 04:12:42 | INFO | train_inner | epoch 136:   1424 / 1978 loss=2.945, nll_loss=0.814, word_ins=2.645, length=2.991, ppl=7.7, wps=35478.8, ups=0.59, wpb=59723.3, bsz=2077.3, num_updates=268400, lr=0.000193023, gnorm=1.446, loss_scale=8192, train_wall=168, wall=0
2023-02-21 04:15:27 | INFO | train_inner | epoch 136:   1524 / 1978 loss=2.971, nll_loss=0.832, word_ins=2.662, length=3.088, ppl=7.84, wps=35880.5, ups=0.61, wpb=59287, bsz=1968.9, num_updates=268500, lr=0.000192987, gnorm=1.465, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:18:13 | INFO | train_inner | epoch 136:   1624 / 1978 loss=2.97, nll_loss=0.834, word_ins=2.663, length=3.062, ppl=7.83, wps=35668.1, ups=0.6, wpb=59330.5, bsz=2021.9, num_updates=268600, lr=0.000192951, gnorm=1.466, loss_scale=8192, train_wall=166, wall=0
2023-02-21 04:21:00 | INFO | train_inner | epoch 136:   1724 / 1978 loss=2.938, nll_loss=0.809, word_ins=2.641, length=2.976, ppl=7.67, wps=35645.2, ups=0.6, wpb=59524.8, bsz=2139.8, num_updates=268700, lr=0.000192915, gnorm=1.424, loss_scale=8192, train_wall=167, wall=0
2023-02-21 04:23:46 | INFO | train_inner | epoch 136:   1824 / 1978 loss=2.957, nll_loss=0.822, word_ins=2.653, length=3.043, ppl=7.77, wps=35665.9, ups=0.6, wpb=59030.2, bsz=2066.3, num_updates=268800, lr=0.000192879, gnorm=1.463, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:26:32 | INFO | train_inner | epoch 136:   1924 / 1978 loss=2.971, nll_loss=0.837, word_ins=2.667, length=3.041, ppl=7.84, wps=35857.8, ups=0.6, wpb=59489.4, bsz=1989.4, num_updates=268900, lr=0.000192843, gnorm=1.437, loss_scale=8192, train_wall=166, wall=0
2023-02-21 04:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 04:28:19 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 4.132 | nll_loss 1.942 | word_ins 3.716 | length 4.164 | ppl 17.54 | wps 56580.8 | wpb 40242.5 | bsz 1500 | num_updates 268954 | best_loss 4.076
2023-02-21 04:28:19 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 04:28:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint136.pt (epoch 136 @ 268954 updates, score 4.132) (writing took 5.452435124665499 seconds)
2023-02-21 04:28:24 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2023-02-21 04:28:24 | INFO | train | epoch 136 | loss 2.964 | nll_loss 0.829 | word_ins 2.659 | length 3.05 | ppl 7.8 | wps 35373.4 | ups 0.6 | wpb 59283.4 | bsz 2002.8 | num_updates 268954 | lr 0.000192824 | gnorm 1.441 | loss_scale 8192 | train_wall 3275 | wall 0
2023-02-21 04:28:24 | INFO | fairseq.trainer | begin training epoch 137
2023-02-21 04:29:50 | INFO | train_inner | epoch 137:     46 / 1978 loss=2.953, nll_loss=0.824, word_ins=2.655, length=2.98, ppl=7.74, wps=30060.2, ups=0.5, wpb=59579.9, bsz=1993.8, num_updates=269000, lr=0.000192807, gnorm=1.527, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:32:37 | INFO | train_inner | epoch 137:    146 / 1978 loss=2.94, nll_loss=0.81, word_ins=2.642, length=2.975, ppl=7.67, wps=35579, ups=0.6, wpb=59542.8, bsz=2059.7, num_updates=269100, lr=0.000192772, gnorm=1.411, loss_scale=8192, train_wall=167, wall=0
2023-02-21 04:35:22 | INFO | train_inner | epoch 137:    246 / 1978 loss=2.984, nll_loss=0.847, word_ins=2.677, length=3.078, ppl=7.91, wps=35938.1, ups=0.61, wpb=59207.8, bsz=1909.3, num_updates=269200, lr=0.000192736, gnorm=1.47, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:38:08 | INFO | train_inner | epoch 137:    346 / 1978 loss=2.968, nll_loss=0.834, word_ins=2.664, length=3.038, ppl=7.82, wps=35948.3, ups=0.6, wpb=59567, bsz=1952.4, num_updates=269300, lr=0.0001927, gnorm=1.426, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:40:53 | INFO | train_inner | epoch 137:    446 / 1978 loss=2.949, nll_loss=0.819, word_ins=2.651, length=2.983, ppl=7.72, wps=35867.7, ups=0.61, wpb=59254.9, bsz=2063.4, num_updates=269400, lr=0.000192664, gnorm=1.443, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:43:39 | INFO | train_inner | epoch 137:    546 / 1978 loss=2.959, nll_loss=0.824, word_ins=2.656, length=3.035, ppl=7.78, wps=35847, ups=0.6, wpb=59400.2, bsz=1980.5, num_updates=269500, lr=0.000192629, gnorm=1.424, loss_scale=8192, train_wall=165, wall=0
2023-02-21 04:46:25 | INFO | train_inner | epoch 137:    646 / 1978 loss=2.954, nll_loss=0.822, word_ins=2.653, length=3.01, ppl=7.75, wps=35896.2, ups=0.6, wpb=59697.7, bsz=2049.6, num_updates=269600, lr=0.000192593, gnorm=1.447, loss_scale=8192, train_wall=166, wall=0
2023-02-21 04:49:10 | INFO | train_inner | epoch 137:    746 / 1978 loss=2.982, nll_loss=0.839, word_ins=2.669, length=3.128, ppl=7.9, wps=35464.2, ups=0.61, wpb=58389.9, bsz=1932.3, num_updates=269700, lr=0.000192557, gnorm=1.414, loss_scale=8192, train_wall=164, wall=0
2023-02-21 04:51:56 | INFO | train_inner | epoch 137:    846 / 1978 loss=2.95, nll_loss=0.814, word_ins=2.645, length=3.044, ppl=7.73, wps=35758.2, ups=0.6, wpb=59293.2, bsz=2042.2, num_updates=269800, lr=0.000192521, gnorm=1.422, loss_scale=8192, train_wall=166, wall=0
2023-02-21 04:54:43 | INFO | train_inner | epoch 137:    946 / 1978 loss=2.954, nll_loss=0.824, word_ins=2.654, length=2.994, ppl=7.75, wps=35749.3, ups=0.6, wpb=59907, bsz=2092.7, num_updates=269900, lr=0.000192486, gnorm=1.468, loss_scale=8192, train_wall=167, wall=0
2023-02-21 04:57:29 | INFO | train_inner | epoch 137:   1046 / 1978 loss=2.976, nll_loss=0.832, word_ins=2.662, length=3.136, ppl=7.87, wps=35616.4, ups=0.6, wpb=58975.4, bsz=1981, num_updates=270000, lr=0.00019245, gnorm=1.425, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:00:14 | INFO | train_inner | epoch 137:   1146 / 1978 loss=2.954, nll_loss=0.821, word_ins=2.652, length=3.016, ppl=7.75, wps=35966.8, ups=0.61, wpb=59443.6, bsz=1998.7, num_updates=270100, lr=0.000192414, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:02:59 | INFO | train_inner | epoch 137:   1246 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.659, length=3.058, ppl=7.81, wps=35875.2, ups=0.61, wpb=59133.5, bsz=1958.2, num_updates=270200, lr=0.000192379, gnorm=1.461, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:05:46 | INFO | train_inner | epoch 137:   1346 / 1978 loss=2.967, nll_loss=0.833, word_ins=2.663, length=3.045, ppl=7.82, wps=35526.8, ups=0.6, wpb=59224.1, bsz=2027.4, num_updates=270300, lr=0.000192343, gnorm=1.446, loss_scale=8192, train_wall=166, wall=0
2023-02-21 05:08:31 | INFO | train_inner | epoch 137:   1446 / 1978 loss=2.955, nll_loss=0.82, word_ins=2.651, length=3.044, ppl=7.76, wps=35735.1, ups=0.6, wpb=59066.4, bsz=1997.6, num_updates=270400, lr=0.000192308, gnorm=1.421, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:11:17 | INFO | train_inner | epoch 137:   1546 / 1978 loss=2.957, nll_loss=0.822, word_ins=2.653, length=3.037, ppl=7.76, wps=35934.3, ups=0.6, wpb=59612.5, bsz=2033, num_updates=270500, lr=0.000192272, gnorm=1.409, loss_scale=8192, train_wall=166, wall=0
2023-02-21 05:14:03 | INFO | train_inner | epoch 137:   1646 / 1978 loss=2.96, nll_loss=0.823, word_ins=2.653, length=3.067, ppl=7.78, wps=35539, ups=0.6, wpb=58970.2, bsz=2080.3, num_updates=270600, lr=0.000192237, gnorm=1.387, loss_scale=8192, train_wall=166, wall=0
2023-02-21 05:16:48 | INFO | train_inner | epoch 137:   1746 / 1978 loss=2.982, nll_loss=0.843, word_ins=2.672, length=3.099, ppl=7.9, wps=35851.5, ups=0.6, wpb=59286.1, bsz=1994.6, num_updates=270700, lr=0.000192201, gnorm=1.443, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:19:33 | INFO | train_inner | epoch 137:   1846 / 1978 loss=2.966, nll_loss=0.826, word_ins=2.656, length=3.098, ppl=7.81, wps=36085.2, ups=0.61, wpb=59549.5, bsz=1951.5, num_updates=270800, lr=0.000192166, gnorm=1.474, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:22:18 | INFO | train_inner | epoch 137:   1946 / 1978 loss=2.992, nll_loss=0.849, word_ins=2.678, length=3.143, ppl=7.96, wps=35820.1, ups=0.61, wpb=58954.6, bsz=1895.4, num_updates=270900, lr=0.00019213, gnorm=1.462, loss_scale=8192, train_wall=164, wall=0
2023-02-21 05:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 05:23:29 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 4.127 | nll_loss 1.936 | word_ins 3.709 | length 4.175 | ppl 17.47 | wps 58114.2 | wpb 40242.5 | bsz 1500 | num_updates 270932 | best_loss 4.076
2023-02-21 05:23:29 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 05:23:34 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint137.pt (epoch 137 @ 270932 updates, score 4.127) (writing took 5.357157916761935 seconds)
2023-02-21 05:23:34 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2023-02-21 05:23:34 | INFO | train | epoch 137 | loss 2.963 | nll_loss 0.828 | word_ins 2.658 | length 3.05 | ppl 7.8 | wps 35426.5 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 270932 | lr 0.000192119 | gnorm 1.437 | loss_scale 8192 | train_wall 3273 | wall 0
2023-02-21 05:23:34 | INFO | fairseq.trainer | begin training epoch 138
2023-02-21 05:25:41 | INFO | train_inner | epoch 138:     68 / 1978 loss=2.96, nll_loss=0.825, word_ins=2.656, length=3.047, ppl=7.78, wps=29012.3, ups=0.49, wpb=59057.4, bsz=2004.2, num_updates=271000, lr=0.000192095, gnorm=1.49, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:28:26 | INFO | train_inner | epoch 138:    168 / 1978 loss=2.96, nll_loss=0.824, word_ins=2.655, length=3.052, ppl=7.78, wps=36215.4, ups=0.61, wpb=59557.1, bsz=1970.5, num_updates=271100, lr=0.000192059, gnorm=1.465, loss_scale=8192, train_wall=164, wall=0
2023-02-21 05:31:12 | INFO | train_inner | epoch 138:    268 / 1978 loss=2.953, nll_loss=0.817, word_ins=2.648, length=3.048, ppl=7.74, wps=35566.2, ups=0.6, wpb=59008.7, bsz=2024.8, num_updates=271200, lr=0.000192024, gnorm=1.401, loss_scale=8192, train_wall=166, wall=0
2023-02-21 05:33:57 | INFO | train_inner | epoch 138:    368 / 1978 loss=2.956, nll_loss=0.822, word_ins=2.653, length=3.037, ppl=7.76, wps=35798.9, ups=0.6, wpb=59300.3, bsz=1985.6, num_updates=271300, lr=0.000191988, gnorm=1.43, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:36:44 | INFO | train_inner | epoch 138:    468 / 1978 loss=2.95, nll_loss=0.816, word_ins=2.648, length=3.022, ppl=7.73, wps=35527.5, ups=0.6, wpb=59268.3, bsz=2035.3, num_updates=271400, lr=0.000191953, gnorm=1.445, loss_scale=8192, train_wall=167, wall=0
2023-02-21 05:39:29 | INFO | train_inner | epoch 138:    568 / 1978 loss=2.988, nll_loss=0.851, word_ins=2.679, length=3.087, ppl=7.93, wps=35737.8, ups=0.61, wpb=58900.8, bsz=1924.5, num_updates=271500, lr=0.000191918, gnorm=1.504, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:42:14 | INFO | train_inner | epoch 138:    668 / 1978 loss=2.965, nll_loss=0.828, word_ins=2.659, length=3.066, ppl=7.81, wps=35898.2, ups=0.61, wpb=59183, bsz=1957.1, num_updates=271600, lr=0.000191882, gnorm=1.408, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:44:59 | INFO | train_inner | epoch 138:    768 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.658, length=3.054, ppl=7.8, wps=35780.9, ups=0.6, wpb=59293.8, bsz=1973.1, num_updates=271700, lr=0.000191847, gnorm=1.445, loss_scale=8192, train_wall=166, wall=0
2023-02-21 05:47:46 | INFO | train_inner | epoch 138:    868 / 1978 loss=2.959, nll_loss=0.824, word_ins=2.655, length=3.045, ppl=7.78, wps=35672.9, ups=0.6, wpb=59419.2, bsz=2022, num_updates=271800, lr=0.000191812, gnorm=1.454, loss_scale=8192, train_wall=166, wall=0
2023-02-21 05:50:33 | INFO | train_inner | epoch 138:    968 / 1978 loss=2.954, nll_loss=0.819, word_ins=2.65, length=3.04, ppl=7.75, wps=35692.7, ups=0.6, wpb=59625.2, bsz=2099.3, num_updates=271900, lr=0.000191777, gnorm=1.471, loss_scale=8192, train_wall=167, wall=0
2023-02-21 05:53:18 | INFO | train_inner | epoch 138:   1068 / 1978 loss=2.985, nll_loss=0.846, word_ins=2.675, length=3.097, ppl=7.92, wps=35852, ups=0.61, wpb=59102.6, bsz=1994.9, num_updates=272000, lr=0.000191741, gnorm=1.446, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:56:03 | INFO | train_inner | epoch 138:   1168 / 1978 loss=2.961, nll_loss=0.826, word_ins=2.657, length=3.043, ppl=7.79, wps=35994.6, ups=0.61, wpb=59318.8, bsz=1951.9, num_updates=272100, lr=0.000191706, gnorm=1.424, loss_scale=8192, train_wall=165, wall=0
2023-02-21 05:58:48 | INFO | train_inner | epoch 138:   1268 / 1978 loss=2.989, nll_loss=0.849, word_ins=2.678, length=3.118, ppl=7.94, wps=35960.2, ups=0.6, wpb=59535.8, bsz=1962, num_updates=272200, lr=0.000191671, gnorm=1.502, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:01:35 | INFO | train_inner | epoch 138:   1368 / 1978 loss=2.939, nll_loss=0.808, word_ins=2.64, length=2.987, ppl=7.67, wps=35469.3, ups=0.6, wpb=59224.5, bsz=2075.4, num_updates=272300, lr=0.000191636, gnorm=1.407, loss_scale=8192, train_wall=167, wall=0
2023-02-21 06:04:21 | INFO | train_inner | epoch 138:   1468 / 1978 loss=2.946, nll_loss=0.814, word_ins=2.646, length=2.999, ppl=7.7, wps=35902.6, ups=0.6, wpb=59632.9, bsz=2034.7, num_updates=272400, lr=0.0001916, gnorm=1.426, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:06:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 06:07:09 | INFO | train_inner | epoch 138:   1569 / 1978 loss=2.95, nll_loss=0.817, word_ins=2.649, length=3.017, ppl=7.73, wps=35487.4, ups=0.6, wpb=59535.8, bsz=2022.3, num_updates=272500, lr=0.000191565, gnorm=1.412, loss_scale=8192, train_wall=168, wall=0
2023-02-21 06:09:55 | INFO | train_inner | epoch 138:   1669 / 1978 loss=2.962, nll_loss=0.826, word_ins=2.656, length=3.06, ppl=7.79, wps=35814.3, ups=0.6, wpb=59393.2, bsz=2005.6, num_updates=272600, lr=0.00019153, gnorm=1.451, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:12:41 | INFO | train_inner | epoch 138:   1769 / 1978 loss=2.964, nll_loss=0.837, word_ins=2.667, length=2.97, ppl=7.8, wps=35795.6, ups=0.6, wpb=59310, bsz=2009.2, num_updates=272700, lr=0.000191495, gnorm=1.465, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:15:27 | INFO | train_inner | epoch 138:   1869 / 1978 loss=2.963, nll_loss=0.828, word_ins=2.658, length=3.047, ppl=7.8, wps=35472.6, ups=0.6, wpb=59048.3, bsz=2069.4, num_updates=272800, lr=0.00019146, gnorm=1.432, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:18:13 | INFO | train_inner | epoch 138:   1969 / 1978 loss=2.978, nll_loss=0.842, word_ins=2.671, length=3.067, ppl=7.88, wps=35512.8, ups=0.6, wpb=59036.2, bsz=1975.1, num_updates=272900, lr=0.000191425, gnorm=1.425, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 06:18:45 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 4.104 | nll_loss 1.935 | word_ins 3.712 | length 3.928 | ppl 17.2 | wps 55666.4 | wpb 40242.5 | bsz 1500 | num_updates 272909 | best_loss 4.076
2023-02-21 06:18:45 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 06:18:50 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint138.pt (epoch 138 @ 272909 updates, score 4.104) (writing took 5.42689695302397 seconds)
2023-02-21 06:18:50 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2023-02-21 06:18:50 | INFO | train | epoch 138 | loss 2.963 | nll_loss 0.828 | word_ins 2.658 | length 3.046 | ppl 7.8 | wps 35346.6 | ups 0.6 | wpb 59284.2 | bsz 2003 | num_updates 272909 | lr 0.000191422 | gnorm 1.447 | loss_scale 8192 | train_wall 3275 | wall 0
2023-02-21 06:18:50 | INFO | fairseq.trainer | begin training epoch 139
2023-02-21 06:21:31 | INFO | train_inner | epoch 139:     91 / 1978 loss=2.939, nll_loss=0.811, word_ins=2.643, length=2.967, ppl=7.67, wps=30179.4, ups=0.51, wpb=59578.3, bsz=2042.3, num_updates=273000, lr=0.00019139, gnorm=1.488, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:24:16 | INFO | train_inner | epoch 139:    191 / 1978 loss=2.946, nll_loss=0.812, word_ins=2.643, length=3.03, ppl=7.71, wps=36213.7, ups=0.6, wpb=59969.3, bsz=2045.6, num_updates=273100, lr=0.000191355, gnorm=1.448, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:27:02 | INFO | train_inner | epoch 139:    291 / 1978 loss=2.969, nll_loss=0.833, word_ins=2.664, length=3.053, ppl=7.83, wps=35700.3, ups=0.61, wpb=58992.2, bsz=1976.9, num_updates=273200, lr=0.00019132, gnorm=1.475, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:29:48 | INFO | train_inner | epoch 139:    391 / 1978 loss=2.951, nll_loss=0.817, word_ins=2.648, length=3.029, ppl=7.73, wps=35695.7, ups=0.6, wpb=59332.8, bsz=2013, num_updates=273300, lr=0.000191285, gnorm=1.425, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:32:33 | INFO | train_inner | epoch 139:    491 / 1978 loss=2.979, nll_loss=0.838, word_ins=2.668, length=3.106, ppl=7.88, wps=35778.1, ups=0.6, wpb=59165.7, bsz=1945.9, num_updates=273400, lr=0.00019125, gnorm=1.459, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:35:20 | INFO | train_inner | epoch 139:    591 / 1978 loss=2.96, nll_loss=0.825, word_ins=2.656, length=3.041, ppl=7.78, wps=35783.6, ups=0.6, wpb=59540.1, bsz=2004.5, num_updates=273500, lr=0.000191215, gnorm=1.446, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:38:05 | INFO | train_inner | epoch 139:    691 / 1978 loss=2.974, nll_loss=0.838, word_ins=2.668, length=3.058, ppl=7.86, wps=35660.4, ups=0.6, wpb=58998.8, bsz=1982.4, num_updates=273600, lr=0.00019118, gnorm=1.5, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:40:51 | INFO | train_inner | epoch 139:    791 / 1978 loss=2.972, nll_loss=0.834, word_ins=2.664, length=3.082, ppl=7.85, wps=36195.2, ups=0.6, wpb=59966.9, bsz=1927.1, num_updates=273700, lr=0.000191145, gnorm=1.45, loss_scale=8192, train_wall=165, wall=0
2023-02-21 06:43:37 | INFO | train_inner | epoch 139:    891 / 1978 loss=2.943, nll_loss=0.813, word_ins=2.644, length=2.991, ppl=7.69, wps=35609.6, ups=0.6, wpb=59232, bsz=2109.8, num_updates=273800, lr=0.00019111, gnorm=1.425, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:46:23 | INFO | train_inner | epoch 139:    991 / 1978 loss=2.954, nll_loss=0.819, word_ins=2.65, length=3.036, ppl=7.75, wps=35761.2, ups=0.6, wpb=59383.4, bsz=2028.2, num_updates=273900, lr=0.000191075, gnorm=1.416, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:49:10 | INFO | train_inner | epoch 139:   1091 / 1978 loss=2.939, nll_loss=0.807, word_ins=2.639, length=3.002, ppl=7.67, wps=35434.8, ups=0.6, wpb=59166.7, bsz=2053.1, num_updates=274000, lr=0.00019104, gnorm=1.402, loss_scale=8192, train_wall=167, wall=0
2023-02-21 06:51:56 | INFO | train_inner | epoch 139:   1191 / 1978 loss=2.958, nll_loss=0.82, word_ins=2.651, length=3.072, ppl=7.77, wps=35731, ups=0.6, wpb=59307.1, bsz=2028.1, num_updates=274100, lr=0.000191005, gnorm=1.444, loss_scale=8192, train_wall=166, wall=0
2023-02-21 06:54:41 | INFO | train_inner | epoch 139:   1291 / 1978 loss=2.961, nll_loss=0.824, word_ins=2.655, length=3.058, ppl=7.79, wps=35955.8, ups=0.61, wpb=59204.9, bsz=1945.8, num_updates=274200, lr=0.00019097, gnorm=1.45, loss_scale=8192, train_wall=164, wall=0
2023-02-21 06:57:27 | INFO | train_inner | epoch 139:   1391 / 1978 loss=2.968, nll_loss=0.83, word_ins=2.66, length=3.073, ppl=7.82, wps=35602.7, ups=0.6, wpb=59008.6, bsz=2030.6, num_updates=274300, lr=0.000190936, gnorm=1.424, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:00:11 | INFO | train_inner | epoch 139:   1491 / 1978 loss=2.98, nll_loss=0.844, word_ins=2.673, length=3.066, ppl=7.89, wps=36080.7, ups=0.61, wpb=59241.6, bsz=1922.8, num_updates=274400, lr=0.000190901, gnorm=1.488, loss_scale=8192, train_wall=164, wall=0
2023-02-21 07:02:56 | INFO | train_inner | epoch 139:   1591 / 1978 loss=2.958, nll_loss=0.823, word_ins=2.654, length=3.045, ppl=7.77, wps=35748.4, ups=0.6, wpb=59119.3, bsz=2015.7, num_updates=274500, lr=0.000190866, gnorm=1.425, loss_scale=8192, train_wall=165, wall=0
2023-02-21 07:05:42 | INFO | train_inner | epoch 139:   1691 / 1978 loss=2.96, nll_loss=0.824, word_ins=2.655, length=3.049, ppl=7.78, wps=35632.6, ups=0.6, wpb=59057.8, bsz=2004.4, num_updates=274600, lr=0.000190831, gnorm=1.433, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:08:28 | INFO | train_inner | epoch 139:   1791 / 1978 loss=2.978, nll_loss=0.838, word_ins=2.668, length=3.098, ppl=7.88, wps=35550.6, ups=0.6, wpb=59074.4, bsz=1987, num_updates=274700, lr=0.000190797, gnorm=1.441, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:11:14 | INFO | train_inner | epoch 139:   1891 / 1978 loss=2.964, nll_loss=0.826, word_ins=2.657, length=3.072, ppl=7.8, wps=35804.4, ups=0.6, wpb=59391.6, bsz=1992.8, num_updates=274800, lr=0.000190762, gnorm=1.497, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 07:13:51 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 4.142 | nll_loss 1.957 | word_ins 3.729 | length 4.135 | ppl 17.66 | wps 56205.7 | wpb 40242.5 | bsz 1500 | num_updates 274887 | best_loss 4.076
2023-02-21 07:13:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 07:13:57 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint139.pt (epoch 139 @ 274887 updates, score 4.142) (writing took 5.146673632785678 seconds)
2023-02-21 07:13:57 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2023-02-21 07:13:57 | INFO | train | epoch 139 | loss 2.961 | nll_loss 0.826 | word_ins 2.656 | length 3.049 | ppl 7.79 | wps 35465.4 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 274887 | lr 0.000190732 | gnorm 1.449 | loss_scale 8192 | train_wall 3274 | wall 0
2023-02-21 07:13:57 | INFO | fairseq.trainer | begin training epoch 140
2023-02-21 07:14:27 | INFO | train_inner | epoch 140:     13 / 1978 loss=2.973, nll_loss=0.839, word_ins=2.668, length=3.046, ppl=7.85, wps=30554, ups=0.52, wpb=58985.2, bsz=1983, num_updates=274900, lr=0.000190727, gnorm=1.48, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:17:13 | INFO | train_inner | epoch 140:    113 / 1978 loss=2.954, nll_loss=0.82, word_ins=2.651, length=3.024, ppl=7.75, wps=35725.8, ups=0.6, wpb=59199.1, bsz=2014.5, num_updates=275000, lr=0.000190693, gnorm=1.437, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:19:59 | INFO | train_inner | epoch 140:    213 / 1978 loss=2.942, nll_loss=0.811, word_ins=2.643, length=2.994, ppl=7.69, wps=35818.4, ups=0.6, wpb=59614.7, bsz=2079.6, num_updates=275100, lr=0.000190658, gnorm=1.473, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:22:44 | INFO | train_inner | epoch 140:    313 / 1978 loss=2.967, nll_loss=0.828, word_ins=2.658, length=3.084, ppl=7.82, wps=35834.9, ups=0.6, wpb=59249.7, bsz=1932.7, num_updates=275200, lr=0.000190623, gnorm=1.465, loss_scale=8192, train_wall=165, wall=0
2023-02-21 07:25:30 | INFO | train_inner | epoch 140:    413 / 1978 loss=2.937, nll_loss=0.801, word_ins=2.634, length=3.038, ppl=7.66, wps=36049.8, ups=0.6, wpb=59822.7, bsz=2018.2, num_updates=275300, lr=0.000190589, gnorm=1.444, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:28:15 | INFO | train_inner | epoch 140:    513 / 1978 loss=2.957, nll_loss=0.823, word_ins=2.654, length=3.028, ppl=7.76, wps=35957.8, ups=0.61, wpb=59204.8, bsz=1959.6, num_updates=275400, lr=0.000190554, gnorm=1.412, loss_scale=8192, train_wall=164, wall=0
2023-02-21 07:31:01 | INFO | train_inner | epoch 140:    613 / 1978 loss=2.959, nll_loss=0.825, word_ins=2.656, length=3.028, ppl=7.78, wps=35908.6, ups=0.6, wpb=59524.7, bsz=1971.4, num_updates=275500, lr=0.000190519, gnorm=1.483, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:33:46 | INFO | train_inner | epoch 140:    713 / 1978 loss=2.972, nll_loss=0.834, word_ins=2.664, length=3.078, ppl=7.84, wps=35767.5, ups=0.6, wpb=59125.2, bsz=1923.4, num_updates=275600, lr=0.000190485, gnorm=1.487, loss_scale=8192, train_wall=165, wall=0
2023-02-21 07:36:32 | INFO | train_inner | epoch 140:    813 / 1978 loss=2.952, nll_loss=0.816, word_ins=2.647, length=3.049, ppl=7.74, wps=35717.4, ups=0.6, wpb=59234.9, bsz=2027.3, num_updates=275700, lr=0.00019045, gnorm=1.406, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:39:17 | INFO | train_inner | epoch 140:    913 / 1978 loss=2.966, nll_loss=0.829, word_ins=2.66, length=3.056, ppl=7.81, wps=35202.7, ups=0.61, wpb=58146.2, bsz=2025.2, num_updates=275800, lr=0.000190416, gnorm=1.437, loss_scale=8192, train_wall=165, wall=0
2023-02-21 07:42:02 | INFO | train_inner | epoch 140:   1013 / 1978 loss=2.955, nll_loss=0.819, word_ins=2.649, length=3.062, ppl=7.76, wps=36183.7, ups=0.61, wpb=59802.8, bsz=2016.3, num_updates=275900, lr=0.000190381, gnorm=1.443, loss_scale=8192, train_wall=165, wall=0
2023-02-21 07:44:50 | INFO | train_inner | epoch 140:   1113 / 1978 loss=2.941, nll_loss=0.811, word_ins=2.643, length=2.978, ppl=7.68, wps=35351.5, ups=0.6, wpb=59133, bsz=2123.2, num_updates=276000, lr=0.000190347, gnorm=1.423, loss_scale=8192, train_wall=167, wall=0
2023-02-21 07:47:36 | INFO | train_inner | epoch 140:   1213 / 1978 loss=2.963, nll_loss=0.833, word_ins=2.663, length=2.997, ppl=7.8, wps=35765.1, ups=0.6, wpb=59363.7, bsz=2009.4, num_updates=276100, lr=0.000190312, gnorm=1.446, loss_scale=8192, train_wall=166, wall=0
2023-02-21 07:50:21 | INFO | train_inner | epoch 140:   1313 / 1978 loss=2.95, nll_loss=0.81, word_ins=2.642, length=3.081, ppl=7.73, wps=36096.8, ups=0.61, wpb=59564.5, bsz=2020, num_updates=276200, lr=0.000190278, gnorm=1.463, loss_scale=8192, train_wall=165, wall=0
2023-02-21 07:53:09 | INFO | train_inner | epoch 140:   1413 / 1978 loss=2.94, nll_loss=0.812, word_ins=2.644, length=2.963, ppl=7.67, wps=35438.5, ups=0.6, wpb=59460.2, bsz=2105.4, num_updates=276300, lr=0.000190243, gnorm=1.442, loss_scale=8192, train_wall=168, wall=0
2023-02-21 07:55:53 | INFO | train_inner | epoch 140:   1513 / 1978 loss=2.986, nll_loss=0.853, word_ins=2.682, length=3.041, ppl=7.92, wps=35950.7, ups=0.61, wpb=58963, bsz=1889.6, num_updates=276400, lr=0.000190209, gnorm=1.543, loss_scale=8192, train_wall=164, wall=0
2023-02-21 07:58:39 | INFO | train_inner | epoch 140:   1613 / 1978 loss=2.968, nll_loss=0.834, word_ins=2.664, length=3.043, ppl=7.82, wps=35533.8, ups=0.6, wpb=59089.8, bsz=2044.9, num_updates=276500, lr=0.000190175, gnorm=1.508, loss_scale=8192, train_wall=166, wall=0
2023-02-21 08:01:25 | INFO | train_inner | epoch 140:   1713 / 1978 loss=2.97, nll_loss=0.833, word_ins=2.663, length=3.071, ppl=7.84, wps=35831.2, ups=0.6, wpb=59348.5, bsz=1984.1, num_updates=276600, lr=0.00019014, gnorm=1.48, loss_scale=16384, train_wall=165, wall=0
2023-02-21 08:04:10 | INFO | train_inner | epoch 140:   1813 / 1978 loss=2.954, nll_loss=0.821, word_ins=2.652, length=3.024, ppl=7.75, wps=36105.6, ups=0.6, wpb=59736.4, bsz=1995, num_updates=276700, lr=0.000190106, gnorm=1.436, loss_scale=16384, train_wall=165, wall=0
2023-02-21 08:06:55 | INFO | train_inner | epoch 140:   1913 / 1978 loss=2.975, nll_loss=0.837, word_ins=2.667, length=3.083, ppl=7.86, wps=35781.8, ups=0.61, wpb=58906.6, bsz=1929.1, num_updates=276800, lr=0.000190071, gnorm=1.499, loss_scale=16384, train_wall=164, wall=0
2023-02-21 08:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 08:08:56 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 4.135 | nll_loss 1.959 | word_ins 3.73 | length 4.047 | ppl 17.57 | wps 57580.8 | wpb 40242.5 | bsz 1500 | num_updates 276865 | best_loss 4.076
2023-02-21 08:08:56 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 08:09:02 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint140.pt (epoch 140 @ 276865 updates, score 4.135) (writing took 5.4156929878517985 seconds)
2023-02-21 08:09:02 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2023-02-21 08:09:02 | INFO | train | epoch 140 | loss 2.959 | nll_loss 0.824 | word_ins 2.655 | length 3.04 | ppl 7.78 | wps 35482 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 276865 | lr 0.000190049 | gnorm 1.458 | loss_scale 16384 | train_wall 3272 | wall 0
2023-02-21 08:09:02 | INFO | fairseq.trainer | begin training epoch 141
2023-02-21 08:09:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 08:10:10 | INFO | train_inner | epoch 141:     36 / 1978 loss=2.956, nll_loss=0.818, word_ins=2.649, length=3.065, ppl=7.76, wps=30566.4, ups=0.51, wpb=59623.5, bsz=1997.1, num_updates=276900, lr=0.000190037, gnorm=1.443, loss_scale=8192, train_wall=166, wall=0
2023-02-21 08:12:55 | INFO | train_inner | epoch 141:    136 / 1978 loss=2.954, nll_loss=0.818, word_ins=2.65, length=3.044, ppl=7.75, wps=35463.9, ups=0.6, wpb=58685, bsz=1983.4, num_updates=277000, lr=0.000190003, gnorm=1.445, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:15:40 | INFO | train_inner | epoch 141:    236 / 1978 loss=2.941, nll_loss=0.808, word_ins=2.64, length=3.013, ppl=7.68, wps=36004.2, ups=0.61, wpb=59333.3, bsz=2021.7, num_updates=277100, lr=0.000189969, gnorm=1.415, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:18:25 | INFO | train_inner | epoch 141:    336 / 1978 loss=2.934, nll_loss=0.805, word_ins=2.638, length=2.966, ppl=7.64, wps=36059.3, ups=0.6, wpb=59632, bsz=2049.2, num_updates=277200, lr=0.000189934, gnorm=1.455, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:21:12 | INFO | train_inner | epoch 141:    436 / 1978 loss=2.933, nll_loss=0.804, word_ins=2.637, length=2.966, ppl=7.64, wps=35881.7, ups=0.6, wpb=59836, bsz=2110.2, num_updates=277300, lr=0.0001899, gnorm=1.419, loss_scale=8192, train_wall=167, wall=0
2023-02-21 08:23:57 | INFO | train_inner | epoch 141:    536 / 1978 loss=2.961, nll_loss=0.826, word_ins=2.657, length=3.043, ppl=7.79, wps=35863.8, ups=0.61, wpb=59069.3, bsz=2016.2, num_updates=277400, lr=0.000189866, gnorm=1.489, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:26:41 | INFO | train_inner | epoch 141:    636 / 1978 loss=2.976, nll_loss=0.839, word_ins=2.669, length=3.071, ppl=7.87, wps=36029, ups=0.61, wpb=59281.1, bsz=1899.5, num_updates=277500, lr=0.000189832, gnorm=1.516, loss_scale=8192, train_wall=164, wall=0
2023-02-21 08:29:26 | INFO | train_inner | epoch 141:    736 / 1978 loss=2.959, nll_loss=0.826, word_ins=2.656, length=3.027, ppl=7.78, wps=35983.3, ups=0.61, wpb=59340.2, bsz=1980.8, num_updates=277600, lr=0.000189797, gnorm=1.498, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:32:13 | INFO | train_inner | epoch 141:    836 / 1978 loss=2.935, nll_loss=0.803, word_ins=2.635, length=2.992, ppl=7.65, wps=35959.5, ups=0.6, wpb=59870.3, bsz=2066.8, num_updates=277700, lr=0.000189763, gnorm=1.399, loss_scale=8192, train_wall=166, wall=0
2023-02-21 08:34:57 | INFO | train_inner | epoch 141:    936 / 1978 loss=2.962, nll_loss=0.828, word_ins=2.658, length=3.04, ppl=7.79, wps=36004.4, ups=0.61, wpb=59089, bsz=2003.6, num_updates=277800, lr=0.000189729, gnorm=1.467, loss_scale=8192, train_wall=164, wall=0
2023-02-21 08:37:42 | INFO | train_inner | epoch 141:   1036 / 1978 loss=2.966, nll_loss=0.836, word_ins=2.666, length=2.998, ppl=7.81, wps=35501.9, ups=0.61, wpb=58578.3, bsz=1999.5, num_updates=277900, lr=0.000189695, gnorm=1.506, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:40:28 | INFO | train_inner | epoch 141:   1136 / 1978 loss=2.95, nll_loss=0.812, word_ins=2.644, length=3.057, ppl=7.73, wps=35702.2, ups=0.6, wpb=59189.2, bsz=2055.8, num_updates=278000, lr=0.000189661, gnorm=1.465, loss_scale=8192, train_wall=166, wall=0
2023-02-21 08:43:15 | INFO | train_inner | epoch 141:   1236 / 1978 loss=2.951, nll_loss=0.816, word_ins=2.648, length=3.029, ppl=7.73, wps=35420.6, ups=0.6, wpb=59133.2, bsz=2079, num_updates=278100, lr=0.000189627, gnorm=1.44, loss_scale=8192, train_wall=167, wall=0
2023-02-21 08:46:00 | INFO | train_inner | epoch 141:   1336 / 1978 loss=2.972, nll_loss=0.833, word_ins=2.663, length=3.087, ppl=7.85, wps=36033.1, ups=0.61, wpb=59537.9, bsz=1933.8, num_updates=278200, lr=0.000189593, gnorm=1.445, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:48:45 | INFO | train_inner | epoch 141:   1436 / 1978 loss=2.962, nll_loss=0.827, word_ins=2.658, length=3.042, ppl=7.79, wps=36197.1, ups=0.61, wpb=59808.8, bsz=1989.7, num_updates=278300, lr=0.000189559, gnorm=1.457, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:51:32 | INFO | train_inner | epoch 141:   1536 / 1978 loss=2.955, nll_loss=0.822, word_ins=2.653, length=3.024, ppl=7.75, wps=35580.7, ups=0.6, wpb=59315.3, bsz=2075.9, num_updates=278400, lr=0.000189525, gnorm=1.445, loss_scale=8192, train_wall=167, wall=0
2023-02-21 08:54:15 | INFO | train_inner | epoch 141:   1636 / 1978 loss=3.01, nll_loss=0.871, word_ins=2.698, length=3.121, ppl=8.06, wps=35962.7, ups=0.61, wpb=58789.8, bsz=1813.8, num_updates=278500, lr=0.00018949, gnorm=1.479, loss_scale=8192, train_wall=163, wall=0
2023-02-21 08:57:00 | INFO | train_inner | epoch 141:   1736 / 1978 loss=2.947, nll_loss=0.809, word_ins=2.64, length=3.069, ppl=7.71, wps=35997.9, ups=0.61, wpb=59410.7, bsz=2063.2, num_updates=278600, lr=0.000189456, gnorm=1.437, loss_scale=8192, train_wall=165, wall=0
2023-02-21 08:59:45 | INFO | train_inner | epoch 141:   1836 / 1978 loss=2.962, nll_loss=0.823, word_ins=2.653, length=3.089, ppl=7.79, wps=35979.2, ups=0.61, wpb=59287.7, bsz=2004, num_updates=278700, lr=0.000189422, gnorm=1.469, loss_scale=8192, train_wall=165, wall=0
2023-02-21 09:02:30 | INFO | train_inner | epoch 141:   1936 / 1978 loss=2.977, nll_loss=0.842, word_ins=2.671, length=3.064, ppl=7.88, wps=35716.3, ups=0.61, wpb=58824, bsz=1977.5, num_updates=278800, lr=0.000189389, gnorm=1.466, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:03:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 09:03:54 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 4.186 | nll_loss 1.953 | word_ins 3.723 | length 4.636 | ppl 18.2 | wps 58701.6 | wpb 40242.5 | bsz 1500 | num_updates 278842 | best_loss 4.076
2023-02-21 09:03:54 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 09:03:59 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint141.pt (epoch 141 @ 278842 updates, score 4.186) (writing took 5.458129719831049 seconds)
2023-02-21 09:03:59 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2023-02-21 09:03:59 | INFO | train | epoch 141 | loss 2.959 | nll_loss 0.824 | word_ins 2.655 | length 3.041 | ppl 7.78 | wps 35543 | ups 0.6 | wpb 59283 | bsz 2002.6 | num_updates 278842 | lr 0.000189374 | gnorm 1.461 | loss_scale 8192 | train_wall 3263 | wall 0
2023-02-21 09:03:59 | INFO | fairseq.trainer | begin training epoch 142
2023-02-21 09:05:43 | INFO | train_inner | epoch 142:     58 / 1978 loss=2.978, nll_loss=0.838, word_ins=2.668, length=3.104, ppl=7.88, wps=30476.8, ups=0.52, wpb=58746.3, bsz=1885.6, num_updates=278900, lr=0.000189355, gnorm=1.474, loss_scale=8192, train_wall=163, wall=0
2023-02-21 09:08:28 | INFO | train_inner | epoch 142:    158 / 1978 loss=2.937, nll_loss=0.805, word_ins=2.638, length=2.993, ppl=7.66, wps=35793.3, ups=0.6, wpb=59211, bsz=2094.9, num_updates=279000, lr=0.000189321, gnorm=1.429, loss_scale=8192, train_wall=165, wall=0
2023-02-21 09:11:13 | INFO | train_inner | epoch 142:    258 / 1978 loss=2.966, nll_loss=0.828, word_ins=2.659, length=3.071, ppl=7.81, wps=36002.1, ups=0.61, wpb=59466.6, bsz=1940.6, num_updates=279100, lr=0.000189287, gnorm=1.474, loss_scale=8192, train_wall=165, wall=0
2023-02-21 09:13:59 | INFO | train_inner | epoch 142:    358 / 1978 loss=2.955, nll_loss=0.821, word_ins=2.653, length=3.024, ppl=7.76, wps=35262.1, ups=0.6, wpb=58421.9, bsz=2014.6, num_updates=279200, lr=0.000189253, gnorm=1.462, loss_scale=8192, train_wall=165, wall=0
2023-02-21 09:16:46 | INFO | train_inner | epoch 142:    458 / 1978 loss=2.949, nll_loss=0.814, word_ins=2.645, length=3.039, ppl=7.72, wps=35563.5, ups=0.6, wpb=59614.4, bsz=2012, num_updates=279300, lr=0.000189219, gnorm=1.481, loss_scale=8192, train_wall=167, wall=0
2023-02-21 09:19:39 | INFO | train_inner | epoch 142:    558 / 1978 loss=2.941, nll_loss=0.807, word_ins=2.639, length=3.021, ppl=7.68, wps=34528.6, ups=0.58, wpb=59595.6, bsz=2057.8, num_updates=279400, lr=0.000189185, gnorm=1.484, loss_scale=8192, train_wall=172, wall=0
2023-02-21 09:22:32 | INFO | train_inner | epoch 142:    658 / 1978 loss=2.934, nll_loss=0.805, word_ins=2.638, length=2.963, ppl=7.64, wps=34589.4, ups=0.58, wpb=59681.2, bsz=2092.9, num_updates=279500, lr=0.000189151, gnorm=1.429, loss_scale=8192, train_wall=172, wall=0
2023-02-21 09:25:19 | INFO | train_inner | epoch 142:    758 / 1978 loss=2.965, nll_loss=0.825, word_ins=2.656, length=3.087, ppl=7.81, wps=35305.2, ups=0.6, wpb=59031.3, bsz=1973.8, num_updates=279600, lr=0.000189117, gnorm=1.522, loss_scale=8192, train_wall=167, wall=0
2023-02-21 09:28:03 | INFO | train_inner | epoch 142:    858 / 1978 loss=2.96, nll_loss=0.826, word_ins=2.657, length=3.034, ppl=7.78, wps=36466.9, ups=0.61, wpb=59891.9, bsz=1985.8, num_updates=279700, lr=0.000189084, gnorm=1.506, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:30:48 | INFO | train_inner | epoch 142:    958 / 1978 loss=2.958, nll_loss=0.824, word_ins=2.654, length=3.034, ppl=7.77, wps=35985.2, ups=0.6, wpb=59514.4, bsz=1972.6, num_updates=279800, lr=0.00018905, gnorm=1.453, loss_scale=8192, train_wall=165, wall=0
2023-02-21 09:33:33 | INFO | train_inner | epoch 142:   1058 / 1978 loss=2.977, nll_loss=0.842, word_ins=2.671, length=3.057, ppl=7.87, wps=35855.8, ups=0.61, wpb=59060.1, bsz=1998.8, num_updates=279900, lr=0.000189016, gnorm=1.445, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:36:18 | INFO | train_inner | epoch 142:   1158 / 1978 loss=2.937, nll_loss=0.807, word_ins=2.639, length=2.988, ppl=7.66, wps=35954.7, ups=0.61, wpb=59393.3, bsz=2114.1, num_updates=280000, lr=0.000188982, gnorm=1.431, loss_scale=8192, train_wall=165, wall=0
2023-02-21 09:39:03 | INFO | train_inner | epoch 142:   1258 / 1978 loss=2.97, nll_loss=0.833, word_ins=2.663, length=3.072, ppl=7.84, wps=36071.4, ups=0.61, wpb=59336.9, bsz=1960, num_updates=280100, lr=0.000188948, gnorm=1.46, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:41:47 | INFO | train_inner | epoch 142:   1358 / 1978 loss=2.964, nll_loss=0.826, word_ins=2.656, length=3.078, ppl=7.8, wps=36200.7, ups=0.61, wpb=59401.2, bsz=1973.3, num_updates=280200, lr=0.000188915, gnorm=1.445, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:44:30 | INFO | train_inner | epoch 142:   1458 / 1978 loss=2.977, nll_loss=0.842, word_ins=2.671, length=3.06, ppl=7.88, wps=36108.1, ups=0.61, wpb=59033.1, bsz=1933.8, num_updates=280300, lr=0.000188881, gnorm=1.441, loss_scale=8192, train_wall=163, wall=0
2023-02-21 09:47:14 | INFO | train_inner | epoch 142:   1558 / 1978 loss=2.982, nll_loss=0.841, word_ins=2.67, length=3.116, ppl=7.9, wps=36359, ups=0.61, wpb=59445.8, bsz=1896.1, num_updates=280400, lr=0.000188847, gnorm=1.525, loss_scale=8192, train_wall=163, wall=0
2023-02-21 09:50:00 | INFO | train_inner | epoch 142:   1658 / 1978 loss=2.938, nll_loss=0.81, word_ins=2.641, length=2.966, ppl=7.66, wps=35879.2, ups=0.6, wpb=59738.7, bsz=2083.1, num_updates=280500, lr=0.000188814, gnorm=1.427, loss_scale=8192, train_wall=166, wall=0
2023-02-21 09:52:45 | INFO | train_inner | epoch 142:   1758 / 1978 loss=2.961, nll_loss=0.823, word_ins=2.654, length=3.065, ppl=7.78, wps=35914.7, ups=0.61, wpb=59129.1, bsz=1990.7, num_updates=280600, lr=0.00018878, gnorm=1.529, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:55:29 | INFO | train_inner | epoch 142:   1858 / 1978 loss=2.974, nll_loss=0.838, word_ins=2.668, length=3.065, ppl=7.86, wps=35745.5, ups=0.61, wpb=58579.3, bsz=1936.4, num_updates=280700, lr=0.000188746, gnorm=1.399, loss_scale=8192, train_wall=164, wall=0
2023-02-21 09:58:15 | INFO | train_inner | epoch 142:   1958 / 1978 loss=2.962, nll_loss=0.828, word_ins=2.659, length=3.036, ppl=7.79, wps=35547.7, ups=0.6, wpb=59147.6, bsz=2032.2, num_updates=280800, lr=0.000188713, gnorm=1.464, loss_scale=8192, train_wall=166, wall=0
2023-02-21 09:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 09:59:02 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 4.158 | nll_loss 1.948 | word_ins 3.722 | length 4.369 | ppl 17.86 | wps 55723.6 | wpb 40242.5 | bsz 1500 | num_updates 280820 | best_loss 4.076
2023-02-21 09:59:02 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 09:59:08 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint142.pt (epoch 142 @ 280820 updates, score 4.158) (writing took 5.441360615193844 seconds)
2023-02-21 09:59:08 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2023-02-21 09:59:08 | INFO | train | epoch 142 | loss 2.957 | nll_loss 0.823 | word_ins 2.654 | length 3.038 | ppl 7.77 | wps 35441.4 | ups 0.6 | wpb 59284.3 | bsz 2002.6 | num_updates 280820 | lr 0.000188706 | gnorm 1.462 | loss_scale 8192 | train_wall 3276 | wall 0
2023-02-21 09:59:08 | INFO | fairseq.trainer | begin training epoch 143
2023-02-21 10:01:32 | INFO | train_inner | epoch 143:     80 / 1978 loss=2.924, nll_loss=0.797, word_ins=2.63, length=2.938, ppl=7.59, wps=30116.6, ups=0.51, wpb=59075.6, bsz=2100.7, num_updates=280900, lr=0.000188679, gnorm=1.412, loss_scale=8192, train_wall=168, wall=0
2023-02-21 10:04:20 | INFO | train_inner | epoch 143:    180 / 1978 loss=2.952, nll_loss=0.819, word_ins=2.652, length=3.006, ppl=7.74, wps=35083.4, ups=0.6, wpb=58931.1, bsz=2074.5, num_updates=281000, lr=0.000188646, gnorm=1.411, loss_scale=16384, train_wall=168, wall=0
2023-02-21 10:05:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 10:07:07 | INFO | train_inner | epoch 143:    281 / 1978 loss=2.946, nll_loss=0.816, word_ins=2.648, length=2.985, ppl=7.71, wps=35498.7, ups=0.6, wpb=59488, bsz=2032.9, num_updates=281100, lr=0.000188612, gnorm=1.492, loss_scale=8192, train_wall=167, wall=0
2023-02-21 10:09:55 | INFO | train_inner | epoch 143:    381 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.659, length=3.055, ppl=7.8, wps=35759.1, ups=0.6, wpb=59979.7, bsz=1963.5, num_updates=281200, lr=0.000188579, gnorm=1.53, loss_scale=8192, train_wall=168, wall=0
2023-02-21 10:12:42 | INFO | train_inner | epoch 143:    481 / 1978 loss=2.971, nll_loss=0.833, word_ins=2.663, length=3.077, ppl=7.84, wps=35350.2, ups=0.6, wpb=59000.7, bsz=1918.6, num_updates=281300, lr=0.000188545, gnorm=1.463, loss_scale=8192, train_wall=167, wall=0
2023-02-21 10:15:29 | INFO | train_inner | epoch 143:    581 / 1978 loss=2.96, nll_loss=0.829, word_ins=2.66, length=3.008, ppl=7.78, wps=35635.9, ups=0.6, wpb=59538.8, bsz=2019.8, num_updates=281400, lr=0.000188512, gnorm=1.452, loss_scale=8192, train_wall=167, wall=0
2023-02-21 10:18:14 | INFO | train_inner | epoch 143:    681 / 1978 loss=2.952, nll_loss=0.817, word_ins=2.648, length=3.034, ppl=7.74, wps=36028.7, ups=0.61, wpb=59432.6, bsz=2028.8, num_updates=281500, lr=0.000188478, gnorm=1.48, loss_scale=8192, train_wall=165, wall=0
2023-02-21 10:20:58 | INFO | train_inner | epoch 143:    781 / 1978 loss=2.984, nll_loss=0.845, word_ins=2.674, length=3.104, ppl=7.91, wps=35846.3, ups=0.61, wpb=58701.6, bsz=1950.2, num_updates=281600, lr=0.000188445, gnorm=1.535, loss_scale=8192, train_wall=164, wall=0
2023-02-21 10:23:43 | INFO | train_inner | epoch 143:    881 / 1978 loss=2.932, nll_loss=0.803, word_ins=2.635, length=2.974, ppl=7.63, wps=36405.5, ups=0.61, wpb=60117.2, bsz=2001.5, num_updates=281700, lr=0.000188411, gnorm=1.46, loss_scale=8192, train_wall=165, wall=0
2023-02-21 10:26:27 | INFO | train_inner | epoch 143:    981 / 1978 loss=2.947, nll_loss=0.811, word_ins=2.643, length=3.047, ppl=7.71, wps=35840.5, ups=0.61, wpb=59022.3, bsz=2010.1, num_updates=281800, lr=0.000188378, gnorm=1.424, loss_scale=8192, train_wall=164, wall=0
2023-02-21 10:29:11 | INFO | train_inner | epoch 143:   1081 / 1978 loss=2.96, nll_loss=0.823, word_ins=2.653, length=3.069, ppl=7.78, wps=36275.9, ups=0.61, wpb=59449.5, bsz=1918.7, num_updates=281900, lr=0.000188344, gnorm=1.447, loss_scale=8192, train_wall=164, wall=0
2023-02-21 10:31:55 | INFO | train_inner | epoch 143:   1181 / 1978 loss=2.955, nll_loss=0.82, word_ins=2.651, length=3.044, ppl=7.76, wps=36233.2, ups=0.61, wpb=59473.6, bsz=1992.9, num_updates=282000, lr=0.000188311, gnorm=1.476, loss_scale=8192, train_wall=164, wall=0
2023-02-21 10:34:42 | INFO | train_inner | epoch 143:   1281 / 1978 loss=2.96, nll_loss=0.822, word_ins=2.653, length=3.074, ppl=7.78, wps=35747.7, ups=0.6, wpb=59419.8, bsz=2001, num_updates=282100, lr=0.000188278, gnorm=1.506, loss_scale=8192, train_wall=166, wall=0
2023-02-21 10:37:31 | INFO | train_inner | epoch 143:   1381 / 1978 loss=2.955, nll_loss=0.82, word_ins=2.651, length=3.038, ppl=7.75, wps=34785.4, ups=0.59, wpb=58917.2, bsz=2043.8, num_updates=282200, lr=0.000188244, gnorm=1.487, loss_scale=8192, train_wall=169, wall=0
2023-02-21 10:40:20 | INFO | train_inner | epoch 143:   1481 / 1978 loss=2.954, nll_loss=0.819, word_ins=2.65, length=3.039, ppl=7.75, wps=34840.5, ups=0.59, wpb=58698.2, bsz=1957.5, num_updates=282300, lr=0.000188211, gnorm=1.473, loss_scale=8192, train_wall=168, wall=0
2023-02-21 10:43:11 | INFO | train_inner | epoch 143:   1581 / 1978 loss=2.961, nll_loss=0.826, word_ins=2.656, length=3.054, ppl=7.79, wps=34334.4, ups=0.58, wpb=59022.4, bsz=2017.3, num_updates=282400, lr=0.000188177, gnorm=1.466, loss_scale=8192, train_wall=172, wall=0
2023-02-21 10:46:10 | INFO | train_inner | epoch 143:   1681 / 1978 loss=2.959, nll_loss=0.826, word_ins=2.656, length=3.034, ppl=7.78, wps=33026.2, ups=0.56, wpb=59025.7, bsz=2015.1, num_updates=282500, lr=0.000188144, gnorm=1.48, loss_scale=8192, train_wall=178, wall=0
2023-02-21 10:49:09 | INFO | train_inner | epoch 143:   1781 / 1978 loss=2.954, nll_loss=0.82, word_ins=2.651, length=3.031, ppl=7.75, wps=32869.8, ups=0.56, wpb=58896.4, bsz=2078.9, num_updates=282600, lr=0.000188111, gnorm=1.482, loss_scale=8192, train_wall=179, wall=0
2023-02-21 10:52:08 | INFO | train_inner | epoch 143:   1881 / 1978 loss=2.948, nll_loss=0.813, word_ins=2.644, length=3.038, ppl=7.72, wps=33631.9, ups=0.56, wpb=60047.5, bsz=2008.9, num_updates=282700, lr=0.000188078, gnorm=1.543, loss_scale=8192, train_wall=178, wall=0
2023-02-21 10:55:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 10:55:17 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 4.116 | nll_loss 1.934 | word_ins 3.706 | length 4.093 | ppl 17.34 | wps 48037.3 | wpb 40242.5 | bsz 1500 | num_updates 282797 | best_loss 4.076
2023-02-21 10:55:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 10:55:23 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint143.pt (epoch 143 @ 282797 updates, score 4.116) (writing took 6.057003489695489 seconds)
2023-02-21 10:55:23 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2023-02-21 10:55:23 | INFO | train | epoch 143 | loss 2.956 | nll_loss 0.821 | word_ins 2.652 | length 3.039 | ppl 7.76 | wps 34721.6 | ups 0.59 | wpb 59284.2 | bsz 2002.6 | num_updates 282797 | lr 0.000188045 | gnorm 1.475 | loss_scale 8192 | train_wall 3340 | wall 0
2023-02-21 10:55:23 | INFO | fairseq.trainer | begin training epoch 144
2023-02-21 10:55:40 | INFO | train_inner | epoch 144:      3 / 1978 loss=2.97, nll_loss=0.83, word_ins=2.66, length=3.092, ppl=7.83, wps=28071.2, ups=0.47, wpb=59445.8, bsz=1947.9, num_updates=282800, lr=0.000188044, gnorm=1.475, loss_scale=8192, train_wall=178, wall=0
2023-02-21 10:58:40 | INFO | train_inner | epoch 144:    103 / 1978 loss=2.935, nll_loss=0.804, word_ins=2.637, length=2.989, ppl=7.65, wps=33230.4, ups=0.56, wpb=59769.6, bsz=2057.5, num_updates=282900, lr=0.000188011, gnorm=1.485, loss_scale=8192, train_wall=180, wall=0
2023-02-21 11:01:38 | INFO | train_inner | epoch 144:    203 / 1978 loss=2.952, nll_loss=0.82, word_ins=2.651, length=3.01, ppl=7.74, wps=33028.5, ups=0.56, wpb=59029.2, bsz=2026.3, num_updates=283000, lr=0.000187978, gnorm=1.467, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:04:38 | INFO | train_inner | epoch 144:    303 / 1978 loss=2.948, nll_loss=0.814, word_ins=2.645, length=3.026, ppl=7.72, wps=33051.8, ups=0.56, wpb=59310, bsz=2009, num_updates=283100, lr=0.000187945, gnorm=1.486, loss_scale=8192, train_wall=179, wall=0
2023-02-21 11:07:39 | INFO | train_inner | epoch 144:    403 / 1978 loss=2.938, nll_loss=0.805, word_ins=2.637, length=3.008, ppl=7.66, wps=33027.2, ups=0.55, wpb=59736.5, bsz=2088.2, num_updates=283200, lr=0.000187912, gnorm=1.459, loss_scale=8192, train_wall=179, wall=0
2023-02-21 11:10:37 | INFO | train_inner | epoch 144:    503 / 1978 loss=2.948, nll_loss=0.816, word_ins=2.648, length=3.008, ppl=7.72, wps=33223.8, ups=0.56, wpb=59158, bsz=1990.2, num_updates=283300, lr=0.000187878, gnorm=1.424, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:13:34 | INFO | train_inner | epoch 144:    603 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.658, length=3.06, ppl=7.8, wps=33356.4, ups=0.56, wpb=59175.7, bsz=1930.2, num_updates=283400, lr=0.000187845, gnorm=1.515, loss_scale=8192, train_wall=177, wall=0
2023-02-21 11:16:32 | INFO | train_inner | epoch 144:    703 / 1978 loss=2.953, nll_loss=0.817, word_ins=2.648, length=3.051, ppl=7.74, wps=33149.2, ups=0.56, wpb=59050.2, bsz=1990.8, num_updates=283500, lr=0.000187812, gnorm=1.48, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:19:30 | INFO | train_inner | epoch 144:    803 / 1978 loss=2.955, nll_loss=0.818, word_ins=2.649, length=3.062, ppl=7.76, wps=33477.1, ups=0.56, wpb=59526.4, bsz=1965.6, num_updates=283600, lr=0.000187779, gnorm=1.508, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:22:28 | INFO | train_inner | epoch 144:    903 / 1978 loss=2.953, nll_loss=0.818, word_ins=2.649, length=3.039, ppl=7.75, wps=33272.7, ups=0.56, wpb=59135.6, bsz=2000.6, num_updates=283700, lr=0.000187746, gnorm=1.475, loss_scale=8192, train_wall=177, wall=0
2023-02-21 11:25:44 | INFO | train_inner | epoch 144:   1003 / 1978 loss=2.951, nll_loss=0.815, word_ins=2.646, length=3.045, ppl=7.73, wps=30202.1, ups=0.51, wpb=59238.6, bsz=2045.9, num_updates=283800, lr=0.000187713, gnorm=1.441, loss_scale=8192, train_wall=179, wall=0
2023-02-21 11:28:42 | INFO | train_inner | epoch 144:   1103 / 1978 loss=2.95, nll_loss=0.819, word_ins=2.65, length=2.996, ppl=7.73, wps=33114.4, ups=0.56, wpb=58950.9, bsz=2050.6, num_updates=283900, lr=0.00018768, gnorm=1.424, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:31:39 | INFO | train_inner | epoch 144:   1203 / 1978 loss=2.959, nll_loss=0.823, word_ins=2.653, length=3.06, ppl=7.78, wps=33523.4, ups=0.56, wpb=59435.5, bsz=2000.9, num_updates=284000, lr=0.000187647, gnorm=1.486, loss_scale=8192, train_wall=177, wall=0
2023-02-21 11:34:37 | INFO | train_inner | epoch 144:   1303 / 1978 loss=2.976, nll_loss=0.841, word_ins=2.67, length=3.061, ppl=7.87, wps=33253, ups=0.56, wpb=59041.2, bsz=1915.2, num_updates=284100, lr=0.000187614, gnorm=1.539, loss_scale=8192, train_wall=177, wall=0
2023-02-21 11:37:35 | INFO | train_inner | epoch 144:   1403 / 1978 loss=2.953, nll_loss=0.82, word_ins=2.651, length=3.016, ppl=7.74, wps=33484.3, ups=0.56, wpb=59662, bsz=1978.6, num_updates=284200, lr=0.000187581, gnorm=1.506, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:40:32 | INFO | train_inner | epoch 144:   1503 / 1978 loss=2.96, nll_loss=0.828, word_ins=2.658, length=3.024, ppl=7.78, wps=33222, ups=0.57, wpb=58746.2, bsz=2000, num_updates=284300, lr=0.000187548, gnorm=1.472, loss_scale=8192, train_wall=177, wall=0
2023-02-21 11:43:31 | INFO | train_inner | epoch 144:   1603 / 1978 loss=2.949, nll_loss=0.814, word_ins=2.645, length=3.038, ppl=7.72, wps=33118, ups=0.56, wpb=59396, bsz=2060.4, num_updates=284400, lr=0.000187515, gnorm=1.439, loss_scale=8192, train_wall=179, wall=0
2023-02-21 11:46:31 | INFO | train_inner | epoch 144:   1703 / 1978 loss=2.963, nll_loss=0.827, word_ins=2.657, length=3.058, ppl=7.8, wps=32863.6, ups=0.56, wpb=58992.5, bsz=2009, num_updates=284500, lr=0.000187482, gnorm=1.549, loss_scale=8192, train_wall=179, wall=0
2023-02-21 11:49:27 | INFO | train_inner | epoch 144:   1803 / 1978 loss=2.97, nll_loss=0.835, word_ins=2.664, length=3.057, ppl=7.84, wps=33733.3, ups=0.57, wpb=59562, bsz=1956.6, num_updates=284600, lr=0.000187449, gnorm=1.504, loss_scale=8192, train_wall=176, wall=0
2023-02-21 11:52:25 | INFO | train_inner | epoch 144:   1903 / 1978 loss=2.974, nll_loss=0.837, word_ins=2.666, length=3.075, ppl=7.86, wps=33430.7, ups=0.56, wpb=59455.4, bsz=1967.9, num_updates=284700, lr=0.000187416, gnorm=1.508, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:54:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 11:54:55 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 4.073 | nll_loss 1.926 | word_ins 3.702 | length 3.706 | ppl 16.83 | wps 48713.9 | wpb 40242.5 | bsz 1500 | num_updates 284775 | best_loss 4.073
2023-02-21 11:54:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 11:55:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint144.pt (epoch 144 @ 284775 updates, score 4.073) (writing took 8.998542150482535 seconds)
2023-02-21 11:55:04 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2023-02-21 11:55:04 | INFO | train | epoch 144 | loss 2.956 | nll_loss 0.821 | word_ins 2.652 | length 3.04 | ppl 7.76 | wps 32749.5 | ups 0.55 | wpb 59284.3 | bsz 2002.6 | num_updates 284775 | lr 0.000187391 | gnorm 1.484 | loss_scale 8192 | train_wall 3521 | wall 0
2023-02-21 11:55:04 | INFO | fairseq.trainer | begin training epoch 145
2023-02-21 11:56:01 | INFO | train_inner | epoch 145:     25 / 1978 loss=2.952, nll_loss=0.812, word_ins=2.644, length=3.084, ppl=7.74, wps=27599.6, ups=0.46, wpb=59474, bsz=2046.7, num_updates=284800, lr=0.000187383, gnorm=1.491, loss_scale=8192, train_wall=178, wall=0
2023-02-21 11:59:02 | INFO | train_inner | epoch 145:    125 / 1978 loss=2.919, nll_loss=0.792, word_ins=2.626, length=2.935, ppl=7.56, wps=33108.6, ups=0.55, wpb=60128.7, bsz=2147.8, num_updates=284900, lr=0.00018735, gnorm=1.478, loss_scale=8192, train_wall=181, wall=0
2023-02-21 12:02:00 | INFO | train_inner | epoch 145:    225 / 1978 loss=2.952, nll_loss=0.816, word_ins=2.648, length=3.046, ppl=7.74, wps=33301.6, ups=0.56, wpb=59149.8, bsz=1950.9, num_updates=285000, lr=0.000187317, gnorm=1.531, loss_scale=8192, train_wall=177, wall=0
2023-02-21 12:04:59 | INFO | train_inner | epoch 145:    325 / 1978 loss=2.932, nll_loss=0.797, word_ins=2.63, length=3.021, ppl=7.63, wps=33270, ups=0.56, wpb=59534.1, bsz=2061, num_updates=285100, lr=0.000187284, gnorm=1.434, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:06:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 12:07:58 | INFO | train_inner | epoch 145:    426 / 1978 loss=2.97, nll_loss=0.834, word_ins=2.664, length=3.059, ppl=7.84, wps=32745.5, ups=0.56, wpb=58848.8, bsz=2075.3, num_updates=285200, lr=0.000187251, gnorm=1.472, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:10:56 | INFO | train_inner | epoch 145:    526 / 1978 loss=2.951, nll_loss=0.817, word_ins=2.649, length=3.026, ppl=7.73, wps=33340.1, ups=0.56, wpb=59336.8, bsz=1992.5, num_updates=285300, lr=0.000187219, gnorm=1.486, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:13:55 | INFO | train_inner | epoch 145:    626 / 1978 loss=2.956, nll_loss=0.823, word_ins=2.654, length=3.014, ppl=7.76, wps=32978.6, ups=0.56, wpb=58867.2, bsz=2023.4, num_updates=285400, lr=0.000187186, gnorm=1.486, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:16:55 | INFO | train_inner | epoch 145:    726 / 1978 loss=2.95, nll_loss=0.814, word_ins=2.645, length=3.048, ppl=7.73, wps=33236.9, ups=0.56, wpb=59698.1, bsz=1949.8, num_updates=285500, lr=0.000187153, gnorm=1.504, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:19:54 | INFO | train_inner | epoch 145:    826 / 1978 loss=2.946, nll_loss=0.813, word_ins=2.645, length=3.017, ppl=7.71, wps=33046, ups=0.56, wpb=59273.6, bsz=2026.7, num_updates=285600, lr=0.00018712, gnorm=1.439, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:22:51 | INFO | train_inner | epoch 145:    926 / 1978 loss=2.973, nll_loss=0.835, word_ins=2.665, length=3.086, ppl=7.85, wps=33472.8, ups=0.56, wpb=59341.4, bsz=1923.4, num_updates=285700, lr=0.000187088, gnorm=1.459, loss_scale=8192, train_wall=177, wall=0
2023-02-21 12:25:50 | INFO | train_inner | epoch 145:   1026 / 1978 loss=2.945, nll_loss=0.811, word_ins=2.642, length=3.028, ppl=7.7, wps=33056, ups=0.56, wpb=59200.1, bsz=2040.5, num_updates=285800, lr=0.000187055, gnorm=1.469, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:28:49 | INFO | train_inner | epoch 145:   1126 / 1978 loss=2.967, nll_loss=0.836, word_ins=2.665, length=3.019, ppl=7.82, wps=33138, ups=0.56, wpb=59152.1, bsz=1997.9, num_updates=285900, lr=0.000187022, gnorm=1.569, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:31:47 | INFO | train_inner | epoch 145:   1226 / 1978 loss=2.96, nll_loss=0.825, word_ins=2.655, length=3.047, ppl=7.78, wps=33639.6, ups=0.56, wpb=59873.7, bsz=1913.5, num_updates=286000, lr=0.000186989, gnorm=1.485, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:34:45 | INFO | train_inner | epoch 145:   1326 / 1978 loss=2.962, nll_loss=0.825, word_ins=2.655, length=3.066, ppl=7.79, wps=33609.8, ups=0.56, wpb=59748.5, bsz=1942.2, num_updates=286100, lr=0.000186957, gnorm=1.529, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:37:41 | INFO | train_inner | epoch 145:   1426 / 1978 loss=2.969, nll_loss=0.829, word_ins=2.66, length=3.089, ppl=7.83, wps=33130.8, ups=0.57, wpb=58365.8, bsz=1960.6, num_updates=286200, lr=0.000186924, gnorm=1.499, loss_scale=8192, train_wall=176, wall=0
2023-02-21 12:40:38 | INFO | train_inner | epoch 145:   1526 / 1978 loss=2.972, nll_loss=0.834, word_ins=2.663, length=3.09, ppl=7.85, wps=33664.8, ups=0.57, wpb=59506.8, bsz=1905, num_updates=286300, lr=0.000186891, gnorm=1.446, loss_scale=8192, train_wall=177, wall=0
2023-02-21 12:43:37 | INFO | train_inner | epoch 145:   1626 / 1978 loss=2.93, nll_loss=0.797, word_ins=2.631, length=2.996, ppl=7.62, wps=32708.6, ups=0.56, wpb=58665.7, bsz=2111, num_updates=286400, lr=0.000186859, gnorm=1.435, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:46:35 | INFO | train_inner | epoch 145:   1726 / 1978 loss=2.961, nll_loss=0.828, word_ins=2.658, length=3.03, ppl=7.79, wps=33514.6, ups=0.56, wpb=59555.8, bsz=1954.6, num_updates=286500, lr=0.000186826, gnorm=1.45, loss_scale=8192, train_wall=177, wall=0
2023-02-21 12:49:33 | INFO | train_inner | epoch 145:   1826 / 1978 loss=2.965, nll_loss=0.827, word_ins=2.658, length=3.068, ppl=7.81, wps=33190, ups=0.56, wpb=59108.4, bsz=1967.1, num_updates=286600, lr=0.000186794, gnorm=1.471, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:52:31 | INFO | train_inner | epoch 145:   1926 / 1978 loss=2.971, nll_loss=0.839, word_ins=2.668, length=3.024, ppl=7.84, wps=33108.1, ups=0.56, wpb=59074, bsz=1999.3, num_updates=286700, lr=0.000186761, gnorm=1.467, loss_scale=8192, train_wall=178, wall=0
2023-02-21 12:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 12:54:22 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 4.152 | nll_loss 1.943 | word_ins 3.717 | length 4.347 | ppl 17.78 | wps 47571.7 | wpb 40242.5 | bsz 1500 | num_updates 286752 | best_loss 4.073
2023-02-21 12:54:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 12:54:28 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint145.pt (epoch 145 @ 286752 updates, score 4.152) (writing took 5.921434501186013 seconds)
2023-02-21 12:54:28 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2023-02-21 12:54:28 | INFO | train | epoch 145 | loss 2.954 | nll_loss 0.82 | word_ins 2.651 | length 3.035 | ppl 7.75 | wps 32884.8 | ups 0.55 | wpb 59283.1 | bsz 2002.4 | num_updates 286752 | lr 0.000186744 | gnorm 1.479 | loss_scale 8192 | train_wall 3523 | wall 0
2023-02-21 12:54:28 | INFO | fairseq.trainer | begin training epoch 146
2023-02-21 12:56:06 | INFO | train_inner | epoch 146:     48 / 1978 loss=2.939, nll_loss=0.81, word_ins=2.642, length=2.971, ppl=7.67, wps=27694.9, ups=0.47, wpb=59386, bsz=2079.5, num_updates=286800, lr=0.000186728, gnorm=1.522, loss_scale=8192, train_wall=179, wall=0
2023-02-21 12:59:05 | INFO | train_inner | epoch 146:    148 / 1978 loss=2.959, nll_loss=0.825, word_ins=2.656, length=3.027, ppl=7.77, wps=33325.2, ups=0.56, wpb=59628.9, bsz=1980.5, num_updates=286900, lr=0.000186696, gnorm=1.513, loss_scale=8192, train_wall=179, wall=0
2023-02-21 13:02:03 | INFO | train_inner | epoch 146:    248 / 1978 loss=2.981, nll_loss=0.842, word_ins=2.672, length=3.083, ppl=7.89, wps=32789, ups=0.56, wpb=58492.1, bsz=1916.6, num_updates=287000, lr=0.000186663, gnorm=1.546, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:05:00 | INFO | train_inner | epoch 146:    348 / 1978 loss=2.966, nll_loss=0.825, word_ins=2.656, length=3.098, ppl=7.81, wps=33581.9, ups=0.57, wpb=59394.6, bsz=1916.2, num_updates=287100, lr=0.000186631, gnorm=1.52, loss_scale=8192, train_wall=177, wall=0
2023-02-21 13:07:58 | INFO | train_inner | epoch 146:    448 / 1978 loss=2.948, nll_loss=0.816, word_ins=2.647, length=3.011, ppl=7.72, wps=33473.3, ups=0.56, wpb=59603.1, bsz=1989.6, num_updates=287200, lr=0.000186598, gnorm=1.543, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:10:55 | INFO | train_inner | epoch 146:    548 / 1978 loss=2.962, nll_loss=0.828, word_ins=2.658, length=3.042, ppl=7.79, wps=33406.5, ups=0.56, wpb=59242.1, bsz=1957.4, num_updates=287300, lr=0.000186566, gnorm=1.501, loss_scale=8192, train_wall=177, wall=0
2023-02-21 13:13:53 | INFO | train_inner | epoch 146:    648 / 1978 loss=2.957, nll_loss=0.824, word_ins=2.654, length=3.029, ppl=7.77, wps=33616.9, ups=0.56, wpb=59833, bsz=1940.4, num_updates=287400, lr=0.000186533, gnorm=1.519, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:16:52 | INFO | train_inner | epoch 146:    748 / 1978 loss=2.942, nll_loss=0.811, word_ins=2.643, length=2.992, ppl=7.68, wps=33092.2, ups=0.56, wpb=59265.8, bsz=2040.1, num_updates=287500, lr=0.000186501, gnorm=1.453, loss_scale=8192, train_wall=179, wall=0
2023-02-21 13:19:51 | INFO | train_inner | epoch 146:    848 / 1978 loss=2.952, nll_loss=0.818, word_ins=2.65, length=3.024, ppl=7.74, wps=32874.9, ups=0.56, wpb=58682.5, bsz=2095.8, num_updates=287600, lr=0.000186469, gnorm=1.448, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:22:48 | INFO | train_inner | epoch 146:    948 / 1978 loss=2.939, nll_loss=0.806, word_ins=2.638, length=3.006, ppl=7.67, wps=33420.4, ups=0.56, wpb=59378.8, bsz=1986.6, num_updates=287700, lr=0.000186436, gnorm=1.446, loss_scale=8192, train_wall=177, wall=0
2023-02-21 13:25:47 | INFO | train_inner | epoch 146:   1048 / 1978 loss=2.935, nll_loss=0.804, word_ins=2.637, length=2.981, ppl=7.65, wps=33031.1, ups=0.56, wpb=59094.3, bsz=2130, num_updates=287800, lr=0.000186404, gnorm=1.481, loss_scale=8192, train_wall=179, wall=0
2023-02-21 13:28:51 | INFO | train_inner | epoch 146:   1148 / 1978 loss=2.932, nll_loss=0.801, word_ins=2.633, length=2.993, ppl=7.63, wps=32538.9, ups=0.54, wpb=59784.8, bsz=2095.2, num_updates=287900, lr=0.000186371, gnorm=1.49, loss_scale=8192, train_wall=179, wall=0
2023-02-21 13:31:49 | INFO | train_inner | epoch 146:   1248 / 1978 loss=2.951, nll_loss=0.821, word_ins=2.652, length=2.992, ppl=7.73, wps=33338.1, ups=0.56, wpb=59325, bsz=1981.7, num_updates=288000, lr=0.000186339, gnorm=1.54, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:34:47 | INFO | train_inner | epoch 146:   1348 / 1978 loss=2.967, nll_loss=0.835, word_ins=2.665, length=3.022, ppl=7.82, wps=33194.2, ups=0.56, wpb=58931.8, bsz=1966.8, num_updates=288100, lr=0.000186307, gnorm=1.507, loss_scale=8192, train_wall=177, wall=0
2023-02-21 13:37:45 | INFO | train_inner | epoch 146:   1448 / 1978 loss=2.944, nll_loss=0.807, word_ins=2.639, length=3.053, ppl=7.7, wps=33022.9, ups=0.56, wpb=58901.8, bsz=2042, num_updates=288200, lr=0.000186274, gnorm=1.488, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:40:44 | INFO | train_inner | epoch 146:   1548 / 1978 loss=2.958, nll_loss=0.826, word_ins=2.655, length=3.025, ppl=7.77, wps=33411.9, ups=0.56, wpb=59799.9, bsz=2046.1, num_updates=288300, lr=0.000186242, gnorm=1.464, loss_scale=8192, train_wall=179, wall=0
2023-02-21 13:43:42 | INFO | train_inner | epoch 146:   1648 / 1978 loss=2.965, nll_loss=0.826, word_ins=2.656, length=3.083, ppl=7.81, wps=33482.7, ups=0.56, wpb=59495.2, bsz=1935.4, num_updates=288400, lr=0.00018621, gnorm=1.557, loss_scale=8192, train_wall=177, wall=0
2023-02-21 13:46:40 | INFO | train_inner | epoch 146:   1748 / 1978 loss=2.966, nll_loss=0.83, word_ins=2.66, length=3.057, ppl=7.81, wps=33169.8, ups=0.56, wpb=59037.1, bsz=2000.9, num_updates=288500, lr=0.000186177, gnorm=1.468, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:49:34 | INFO | train_inner | epoch 146:   1848 / 1978 loss=2.969, nll_loss=0.828, word_ins=2.658, length=3.11, ppl=7.83, wps=33970.1, ups=0.57, wpb=59225.5, bsz=1977.6, num_updates=288600, lr=0.000186145, gnorm=1.529, loss_scale=8192, train_wall=174, wall=0
2023-02-21 13:52:32 | INFO | train_inner | epoch 146:   1948 / 1978 loss=2.941, nll_loss=0.807, word_ins=2.64, length=3.012, ppl=7.68, wps=33244.2, ups=0.56, wpb=59277.7, bsz=2016.7, num_updates=288700, lr=0.000186113, gnorm=1.461, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 13:53:43 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 4.12 | nll_loss 1.943 | word_ins 3.718 | length 4.028 | ppl 17.39 | wps 48193.3 | wpb 40242.5 | bsz 1500 | num_updates 288730 | best_loss 4.073
2023-02-21 13:53:43 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 13:53:49 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint146.pt (epoch 146 @ 288730 updates, score 4.12) (writing took 5.9530704990029335 seconds)
2023-02-21 13:53:49 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2023-02-21 13:53:49 | INFO | train | epoch 146 | loss 2.954 | nll_loss 0.819 | word_ins 2.65 | length 3.032 | ppl 7.75 | wps 32931.6 | ups 0.56 | wpb 59284.3 | bsz 2002.6 | num_updates 288730 | lr 0.000186103 | gnorm 1.5 | loss_scale 8192 | train_wall 3517 | wall 0
2023-02-21 13:53:49 | INFO | fairseq.trainer | begin training epoch 147
2023-02-21 13:56:05 | INFO | train_inner | epoch 147:     70 / 1978 loss=2.94, nll_loss=0.807, word_ins=2.639, length=3.012, ppl=7.68, wps=27735.5, ups=0.47, wpb=58975.2, bsz=2044.6, num_updates=288800, lr=0.000186081, gnorm=1.47, loss_scale=8192, train_wall=178, wall=0
2023-02-21 13:59:02 | INFO | train_inner | epoch 147:    170 / 1978 loss=2.961, nll_loss=0.825, word_ins=2.655, length=3.061, ppl=7.79, wps=33586.7, ups=0.56, wpb=59495.8, bsz=1901.4, num_updates=288900, lr=0.000186049, gnorm=1.555, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:01:59 | INFO | train_inner | epoch 147:    270 / 1978 loss=2.933, nll_loss=0.8, word_ins=2.633, length=3.002, ppl=7.64, wps=33619.7, ups=0.56, wpb=59595.2, bsz=2034.5, num_updates=289000, lr=0.000186016, gnorm=1.472, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:04:54 | INFO | train_inner | epoch 147:    370 / 1978 loss=2.947, nll_loss=0.814, word_ins=2.646, length=3.016, ppl=7.71, wps=34206.7, ups=0.57, wpb=59591.5, bsz=1971.8, num_updates=289100, lr=0.000185984, gnorm=1.523, loss_scale=8192, train_wall=174, wall=0
2023-02-21 14:07:51 | INFO | train_inner | epoch 147:    470 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.658, length=3.058, ppl=7.8, wps=33176.3, ups=0.56, wpb=58764, bsz=1936.5, num_updates=289200, lr=0.000185952, gnorm=1.475, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:08:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 14:10:50 | INFO | train_inner | epoch 147:    571 / 1978 loss=2.951, nll_loss=0.816, word_ins=2.647, length=3.042, ppl=7.73, wps=33053, ups=0.56, wpb=59312.6, bsz=1969.8, num_updates=289300, lr=0.00018592, gnorm=1.511, loss_scale=8192, train_wall=179, wall=0
2023-02-21 14:13:48 | INFO | train_inner | epoch 147:    671 / 1978 loss=2.949, nll_loss=0.811, word_ins=2.643, length=3.063, ppl=7.72, wps=33219, ups=0.56, wpb=59146.2, bsz=1997.4, num_updates=289400, lr=0.000185888, gnorm=1.473, loss_scale=8192, train_wall=178, wall=0
2023-02-21 14:16:47 | INFO | train_inner | epoch 147:    771 / 1978 loss=2.942, nll_loss=0.812, word_ins=2.643, length=2.985, ppl=7.68, wps=33239.8, ups=0.56, wpb=59497.8, bsz=2064.8, num_updates=289500, lr=0.000185856, gnorm=1.496, loss_scale=8192, train_wall=179, wall=0
2023-02-21 14:19:46 | INFO | train_inner | epoch 147:    871 / 1978 loss=2.958, nll_loss=0.823, word_ins=2.654, length=3.036, ppl=7.77, wps=33187.1, ups=0.56, wpb=59244.3, bsz=1992.7, num_updates=289600, lr=0.000185824, gnorm=1.495, loss_scale=8192, train_wall=178, wall=0
2023-02-21 14:22:44 | INFO | train_inner | epoch 147:    971 / 1978 loss=2.957, nll_loss=0.82, word_ins=2.651, length=3.059, ppl=7.77, wps=33208.7, ups=0.56, wpb=59309.2, bsz=2007, num_updates=289700, lr=0.000185791, gnorm=1.513, loss_scale=8192, train_wall=178, wall=0
2023-02-21 14:25:43 | INFO | train_inner | epoch 147:   1071 / 1978 loss=2.935, nll_loss=0.803, word_ins=2.635, length=3, ppl=7.65, wps=33189.2, ups=0.56, wpb=59367.5, bsz=2095, num_updates=289800, lr=0.000185759, gnorm=1.534, loss_scale=8192, train_wall=179, wall=0
2023-02-21 14:28:42 | INFO | train_inner | epoch 147:   1171 / 1978 loss=2.942, nll_loss=0.806, word_ins=2.638, length=3.038, ppl=7.68, wps=33234.7, ups=0.56, wpb=59435.3, bsz=2014.7, num_updates=289900, lr=0.000185727, gnorm=1.472, loss_scale=8192, train_wall=179, wall=0
2023-02-21 14:31:40 | INFO | train_inner | epoch 147:   1271 / 1978 loss=2.945, nll_loss=0.813, word_ins=2.645, length=2.999, ppl=7.7, wps=33030.2, ups=0.56, wpb=58760.4, bsz=2074.6, num_updates=290000, lr=0.000185695, gnorm=1.44, loss_scale=8192, train_wall=178, wall=0
2023-02-21 14:34:39 | INFO | train_inner | epoch 147:   1371 / 1978 loss=2.949, nll_loss=0.816, word_ins=2.647, length=3.013, ppl=7.72, wps=33199.4, ups=0.56, wpb=59435.2, bsz=2067.5, num_updates=290100, lr=0.000185663, gnorm=1.486, loss_scale=8192, train_wall=179, wall=0
2023-02-21 14:37:36 | INFO | train_inner | epoch 147:   1471 / 1978 loss=2.955, nll_loss=0.822, word_ins=2.652, length=3.028, ppl=7.75, wps=33593, ups=0.56, wpb=59554.6, bsz=1940.9, num_updates=290200, lr=0.000185631, gnorm=1.505, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:40:33 | INFO | train_inner | epoch 147:   1571 / 1978 loss=2.978, nll_loss=0.835, word_ins=2.665, length=3.131, ppl=7.88, wps=33299.4, ups=0.56, wpb=58970.2, bsz=1911.8, num_updates=290300, lr=0.000185599, gnorm=1.545, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:43:32 | INFO | train_inner | epoch 147:   1671 / 1978 loss=2.98, nll_loss=0.844, word_ins=2.673, length=3.069, ppl=7.89, wps=32628, ups=0.56, wpb=58236, bsz=2000.1, num_updates=290400, lr=0.000185567, gnorm=1.443, loss_scale=8192, train_wall=178, wall=0
2023-02-21 14:46:31 | INFO | train_inner | epoch 147:   1771 / 1978 loss=2.945, nll_loss=0.817, word_ins=2.648, length=2.975, ppl=7.7, wps=33183.1, ups=0.56, wpb=59493.9, bsz=2096.8, num_updates=290500, lr=0.000185535, gnorm=1.465, loss_scale=8192, train_wall=179, wall=0
2023-02-21 14:49:29 | INFO | train_inner | epoch 147:   1871 / 1978 loss=2.965, nll_loss=0.823, word_ins=2.653, length=3.112, ppl=7.81, wps=33634.2, ups=0.56, wpb=59707.2, bsz=1929.4, num_updates=290600, lr=0.000185504, gnorm=1.543, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:52:27 | INFO | train_inner | epoch 147:   1971 / 1978 loss=2.945, nll_loss=0.811, word_ins=2.642, length=3.022, ppl=7.7, wps=33509.5, ups=0.56, wpb=59750.6, bsz=1999.6, num_updates=290700, lr=0.000185472, gnorm=1.514, loss_scale=8192, train_wall=178, wall=0
2023-02-21 14:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 14:52:58 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 4.125 | nll_loss 1.937 | word_ins 3.712 | length 4.126 | ppl 17.44 | wps 49205.9 | wpb 40242.5 | bsz 1500 | num_updates 290707 | best_loss 4.073
2023-02-21 14:52:58 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 14:53:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint147.pt (epoch 147 @ 290707 updates, score 4.125) (writing took 5.9278385285288095 seconds)
2023-02-21 14:53:04 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2023-02-21 14:53:04 | INFO | train | epoch 147 | loss 2.952 | nll_loss 0.818 | word_ins 2.649 | length 3.035 | ppl 7.74 | wps 32967.3 | ups 0.56 | wpb 59283 | bsz 2003.1 | num_updates 290707 | lr 0.000185469 | gnorm 1.497 | loss_scale 8192 | train_wall 3515 | wall 0
2023-02-21 14:53:04 | INFO | fairseq.trainer | begin training epoch 148
2023-02-21 14:56:00 | INFO | train_inner | epoch 148:     93 / 1978 loss=2.947, nll_loss=0.815, word_ins=2.646, length=3.009, ppl=7.71, wps=27477.9, ups=0.47, wpb=58640.8, bsz=1976.3, num_updates=290800, lr=0.00018544, gnorm=1.455, loss_scale=8192, train_wall=177, wall=0
2023-02-21 14:58:59 | INFO | train_inner | epoch 148:    193 / 1978 loss=2.937, nll_loss=0.808, word_ins=2.64, length=2.969, ppl=7.66, wps=32960.3, ups=0.56, wpb=58897.7, bsz=2072.1, num_updates=290900, lr=0.000185408, gnorm=1.484, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:01:58 | INFO | train_inner | epoch 148:    293 / 1978 loss=2.945, nll_loss=0.81, word_ins=2.642, length=3.029, ppl=7.7, wps=33068.7, ups=0.56, wpb=59056.9, bsz=2041.5, num_updates=291000, lr=0.000185376, gnorm=1.525, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:04:56 | INFO | train_inner | epoch 148:    393 / 1978 loss=2.948, nll_loss=0.81, word_ins=2.642, length=3.065, ppl=7.72, wps=33207.3, ups=0.56, wpb=59202.3, bsz=1998.6, num_updates=291100, lr=0.000185344, gnorm=1.499, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:07:55 | INFO | train_inner | epoch 148:    493 / 1978 loss=2.942, nll_loss=0.809, word_ins=2.641, length=3.014, ppl=7.69, wps=33307.5, ups=0.56, wpb=59501.1, bsz=2047.5, num_updates=291200, lr=0.000185312, gnorm=1.514, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:10:52 | INFO | train_inner | epoch 148:    593 / 1978 loss=2.954, nll_loss=0.821, word_ins=2.652, length=3.023, ppl=7.75, wps=33367.3, ups=0.56, wpb=59181.6, bsz=1945.4, num_updates=291300, lr=0.000185281, gnorm=1.456, loss_scale=8192, train_wall=177, wall=0
2023-02-21 15:13:50 | INFO | train_inner | epoch 148:    693 / 1978 loss=2.953, nll_loss=0.817, word_ins=2.648, length=3.047, ppl=7.74, wps=33499.8, ups=0.56, wpb=59694.5, bsz=1958.1, num_updates=291400, lr=0.000185249, gnorm=1.526, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:16:48 | INFO | train_inner | epoch 148:    793 / 1978 loss=2.935, nll_loss=0.8, word_ins=2.633, length=3.018, ppl=7.65, wps=33328.8, ups=0.56, wpb=59392, bsz=2039.4, num_updates=291500, lr=0.000185217, gnorm=1.479, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:19:46 | INFO | train_inner | epoch 148:    893 / 1978 loss=2.951, nll_loss=0.817, word_ins=2.648, length=3.031, ppl=7.73, wps=33267.2, ups=0.56, wpb=59165.5, bsz=2035.8, num_updates=291600, lr=0.000185185, gnorm=1.498, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:22:45 | INFO | train_inner | epoch 148:    993 / 1978 loss=2.965, nll_loss=0.833, word_ins=2.663, length=3.017, ppl=7.81, wps=32814.8, ups=0.56, wpb=58758.4, bsz=2028.8, num_updates=291700, lr=0.000185153, gnorm=1.439, loss_scale=8192, train_wall=179, wall=0
2023-02-21 15:25:56 | INFO | train_inner | epoch 148:   1093 / 1978 loss=2.935, nll_loss=0.797, word_ins=2.63, length=3.047, ppl=7.65, wps=31053.6, ups=0.52, wpb=59254.9, bsz=2039.1, num_updates=291800, lr=0.000185122, gnorm=1.452, loss_scale=8192, train_wall=191, wall=0
2023-02-21 15:28:54 | INFO | train_inner | epoch 148:   1193 / 1978 loss=2.953, nll_loss=0.819, word_ins=2.65, length=3.031, ppl=7.74, wps=33648.1, ups=0.56, wpb=59993.7, bsz=2011.6, num_updates=291900, lr=0.00018509, gnorm=1.557, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:31:53 | INFO | train_inner | epoch 148:   1293 / 1978 loss=2.951, nll_loss=0.817, word_ins=2.648, length=3.039, ppl=7.74, wps=33442.6, ups=0.56, wpb=59644.8, bsz=1984.6, num_updates=292000, lr=0.000185058, gnorm=1.524, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:34:53 | INFO | train_inner | epoch 148:   1393 / 1978 loss=2.974, nll_loss=0.839, word_ins=2.668, length=3.059, ppl=7.85, wps=32913, ups=0.55, wpb=59368.6, bsz=1889.1, num_updates=292100, lr=0.000185027, gnorm=1.55, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:37:52 | INFO | train_inner | epoch 148:   1493 / 1978 loss=2.946, nll_loss=0.811, word_ins=2.643, length=3.029, ppl=7.7, wps=33086.5, ups=0.56, wpb=59247.4, bsz=2030.4, num_updates=292200, lr=0.000184995, gnorm=1.539, loss_scale=8192, train_wall=179, wall=0
2023-02-21 15:40:51 | INFO | train_inner | epoch 148:   1593 / 1978 loss=2.965, nll_loss=0.826, word_ins=2.657, length=3.073, ppl=7.81, wps=32916.8, ups=0.56, wpb=58723.3, bsz=2007, num_updates=292300, lr=0.000184963, gnorm=1.525, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:43:49 | INFO | train_inner | epoch 148:   1693 / 1978 loss=2.956, nll_loss=0.822, word_ins=2.652, length=3.04, ppl=7.76, wps=33310, ups=0.56, wpb=59466.8, bsz=2014.9, num_updates=292400, lr=0.000184932, gnorm=1.503, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:46:52 | INFO | train_inner | epoch 148:   1793 / 1978 loss=2.948, nll_loss=0.816, word_ins=2.648, length=3.001, ppl=7.72, wps=32585.3, ups=0.55, wpb=59416.4, bsz=2065, num_updates=292500, lr=0.0001849, gnorm=1.463, loss_scale=8192, train_wall=182, wall=0
2023-02-21 15:49:50 | INFO | train_inner | epoch 148:   1893 / 1978 loss=2.963, nll_loss=0.827, word_ins=2.657, length=3.06, ppl=7.8, wps=33253.6, ups=0.56, wpb=59492.8, bsz=1937.2, num_updates=292600, lr=0.000184868, gnorm=1.545, loss_scale=8192, train_wall=179, wall=0
2023-02-21 15:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 15:52:41 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 4.126 | nll_loss 1.949 | word_ins 3.72 | length 4.065 | ppl 17.46 | wps 48441.5 | wpb 40242.5 | bsz 1500 | num_updates 292685 | best_loss 4.073
2023-02-21 15:52:41 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 15:52:48 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint148.pt (epoch 148 @ 292685 updates, score 4.126) (writing took 7.176277465187013 seconds)
2023-02-21 15:52:48 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2023-02-21 15:52:48 | INFO | train | epoch 148 | loss 2.952 | nll_loss 0.817 | word_ins 2.648 | length 3.034 | ppl 7.74 | wps 32720.7 | ups 0.55 | wpb 59284.3 | bsz 2002.6 | num_updates 292685 | lr 0.000184842 | gnorm 1.505 | loss_scale 8192 | train_wall 3540 | wall 0
2023-02-21 15:52:48 | INFO | fairseq.trainer | begin training epoch 149
2023-02-21 15:53:26 | INFO | train_inner | epoch 149:     15 / 1978 loss=2.959, nll_loss=0.823, word_ins=2.654, length=3.053, ppl=7.78, wps=27489.9, ups=0.46, wpb=59291.6, bsz=1936.3, num_updates=292700, lr=0.000184837, gnorm=1.559, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:56:25 | INFO | train_inner | epoch 149:    115 / 1978 loss=2.945, nll_loss=0.813, word_ins=2.644, length=3.003, ppl=7.7, wps=33328, ups=0.56, wpb=59468.3, bsz=2023.9, num_updates=292800, lr=0.000184805, gnorm=1.488, loss_scale=8192, train_wall=178, wall=0
2023-02-21 15:59:22 | INFO | train_inner | epoch 149:    215 / 1978 loss=2.956, nll_loss=0.822, word_ins=2.653, length=3.034, ppl=7.76, wps=33238.1, ups=0.56, wpb=59004.8, bsz=1958.2, num_updates=292900, lr=0.000184774, gnorm=1.498, loss_scale=8192, train_wall=177, wall=0
2023-02-21 16:02:21 | INFO | train_inner | epoch 149:    315 / 1978 loss=2.967, nll_loss=0.832, word_ins=2.662, length=3.055, ppl=7.82, wps=32972.2, ups=0.56, wpb=59021.8, bsz=1969.4, num_updates=293000, lr=0.000184742, gnorm=1.547, loss_scale=8192, train_wall=179, wall=0
2023-02-21 16:05:19 | INFO | train_inner | epoch 149:    415 / 1978 loss=2.95, nll_loss=0.813, word_ins=2.645, length=3.057, ppl=7.73, wps=33414.3, ups=0.56, wpb=59483.8, bsz=1945.4, num_updates=293100, lr=0.000184711, gnorm=1.514, loss_scale=8192, train_wall=178, wall=0
2023-02-21 16:10:03 | INFO | train_inner | epoch 149:    515 / 1978 loss=2.905, nll_loss=0.781, word_ins=2.615, length=2.898, ppl=7.49, wps=21113.6, ups=0.35, wpb=59880.1, bsz=2145.7, num_updates=293200, lr=0.000184679, gnorm=1.482, loss_scale=8192, train_wall=184, wall=0
2023-02-21 16:13:01 | INFO | train_inner | epoch 149:    615 / 1978 loss=2.957, nll_loss=0.822, word_ins=2.653, length=3.042, ppl=7.77, wps=33201.4, ups=0.56, wpb=59018.5, bsz=2010.2, num_updates=293300, lr=0.000184648, gnorm=1.521, loss_scale=8192, train_wall=178, wall=0
2023-02-21 16:14:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 16:16:01 | INFO | train_inner | epoch 149:    716 / 1978 loss=2.948, nll_loss=0.813, word_ins=2.644, length=3.04, ppl=7.72, wps=32903.5, ups=0.55, wpb=59357, bsz=2012.7, num_updates=293400, lr=0.000184616, gnorm=1.505, loss_scale=8192, train_wall=180, wall=0
2023-02-21 16:18:58 | INFO | train_inner | epoch 149:    816 / 1978 loss=2.939, nll_loss=0.802, word_ins=2.635, length=3.039, ppl=7.67, wps=33148.1, ups=0.56, wpb=58712.7, bsz=2013.6, num_updates=293500, lr=0.000184585, gnorm=1.48, loss_scale=8192, train_wall=177, wall=0
2023-02-21 16:21:56 | INFO | train_inner | epoch 149:    916 / 1978 loss=2.953, nll_loss=0.817, word_ins=2.648, length=3.049, ppl=7.75, wps=33269.6, ups=0.56, wpb=59188.3, bsz=1969.5, num_updates=293600, lr=0.000184553, gnorm=1.526, loss_scale=8192, train_wall=177, wall=0
2023-02-21 16:24:56 | INFO | train_inner | epoch 149:   1016 / 1978 loss=2.977, nll_loss=0.844, word_ins=2.673, length=3.039, ppl=7.88, wps=33002.1, ups=0.56, wpb=59266, bsz=1979, num_updates=293700, lr=0.000184522, gnorm=1.534, loss_scale=8192, train_wall=179, wall=0
2023-02-21 16:27:53 | INFO | train_inner | epoch 149:   1116 / 1978 loss=2.965, nll_loss=0.827, word_ins=2.657, length=3.077, ppl=7.81, wps=33684.3, ups=0.56, wpb=59732.8, bsz=1941, num_updates=293800, lr=0.000184491, gnorm=1.518, loss_scale=8192, train_wall=177, wall=0
2023-02-21 16:30:53 | INFO | train_inner | epoch 149:   1216 / 1978 loss=2.953, nll_loss=0.823, word_ins=2.653, length=3.003, ppl=7.75, wps=33044.5, ups=0.55, wpb=59552.7, bsz=1965.4, num_updates=293900, lr=0.000184459, gnorm=1.548, loss_scale=8192, train_wall=177, wall=0
2023-02-21 16:33:51 | INFO | train_inner | epoch 149:   1316 / 1978 loss=2.939, nll_loss=0.808, word_ins=2.64, length=2.989, ppl=7.67, wps=33505.2, ups=0.56, wpb=59692, bsz=2021.6, num_updates=294000, lr=0.000184428, gnorm=1.497, loss_scale=8192, train_wall=178, wall=0
2023-02-21 16:36:53 | INFO | train_inner | epoch 149:   1416 / 1978 loss=2.962, nll_loss=0.825, word_ins=2.656, length=3.068, ppl=7.79, wps=32249.4, ups=0.55, wpb=58693.4, bsz=1960.2, num_updates=294100, lr=0.000184396, gnorm=1.47, loss_scale=8192, train_wall=182, wall=0
2023-02-21 16:39:53 | INFO | train_inner | epoch 149:   1516 / 1978 loss=2.95, nll_loss=0.816, word_ins=2.647, length=3.038, ppl=7.73, wps=33112.4, ups=0.56, wpb=59453, bsz=1978.8, num_updates=294200, lr=0.000184365, gnorm=1.487, loss_scale=8192, train_wall=179, wall=0
2023-02-21 16:42:52 | INFO | train_inner | epoch 149:   1616 / 1978 loss=2.959, nll_loss=0.825, word_ins=2.656, length=3.03, ppl=7.78, wps=32999.6, ups=0.56, wpb=59014.1, bsz=1985.2, num_updates=294300, lr=0.000184334, gnorm=1.507, loss_scale=8192, train_wall=179, wall=0
2023-02-21 16:45:52 | INFO | train_inner | epoch 149:   1716 / 1978 loss=2.949, nll_loss=0.816, word_ins=2.647, length=3.017, ppl=7.72, wps=32715, ups=0.55, wpb=58948.2, bsz=2071.9, num_updates=294400, lr=0.000184302, gnorm=1.47, loss_scale=8192, train_wall=180, wall=0
2023-02-21 16:48:53 | INFO | train_inner | epoch 149:   1816 / 1978 loss=2.951, nll_loss=0.814, word_ins=2.645, length=3.061, ppl=7.73, wps=32748.5, ups=0.55, wpb=59207, bsz=2031, num_updates=294500, lr=0.000184271, gnorm=1.464, loss_scale=8192, train_wall=181, wall=0
2023-02-21 16:51:53 | INFO | train_inner | epoch 149:   1916 / 1978 loss=2.942, nll_loss=0.808, word_ins=2.64, length=3.021, ppl=7.68, wps=33067.1, ups=0.56, wpb=59566.9, bsz=2025.7, num_updates=294600, lr=0.00018424, gnorm=1.52, loss_scale=8192, train_wall=179, wall=0
2023-02-21 16:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 16:54:03 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 4.106 | nll_loss 1.934 | word_ins 3.71 | length 3.966 | ppl 17.22 | wps 47911.8 | wpb 40242.5 | bsz 1500 | num_updates 294662 | best_loss 4.073
2023-02-21 16:54:03 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 16:54:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint149.pt (epoch 149 @ 294662 updates, score 4.106) (writing took 6.293887156993151 seconds)
2023-02-21 16:54:09 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2023-02-21 16:54:09 | INFO | train | epoch 149 | loss 2.95 | nll_loss 0.816 | word_ins 2.647 | length 3.026 | ppl 7.73 | wps 31840 | ups 0.54 | wpb 59284.8 | bsz 2002.7 | num_updates 294662 | lr 0.00018422 | gnorm 1.503 | loss_scale 8192 | train_wall 3538 | wall 0
2023-02-21 16:54:09 | INFO | fairseq.trainer | begin training epoch 150
2023-02-21 16:55:28 | INFO | train_inner | epoch 150:     38 / 1978 loss=2.924, nll_loss=0.797, word_ins=2.63, length=2.944, ppl=7.59, wps=27642.8, ups=0.46, wpb=59519.4, bsz=2073.7, num_updates=294700, lr=0.000184209, gnorm=1.487, loss_scale=8192, train_wall=181, wall=0
2023-02-21 16:58:31 | INFO | train_inner | epoch 150:    138 / 1978 loss=2.915, nll_loss=0.787, word_ins=2.621, length=2.94, ppl=7.54, wps=32636.7, ups=0.55, wpb=59692.7, bsz=2066.4, num_updates=294800, lr=0.000184177, gnorm=1.497, loss_scale=8192, train_wall=180, wall=0
2023-02-21 17:03:34 | INFO | train_inner | epoch 150:    238 / 1978 loss=2.927, nll_loss=0.801, word_ins=2.633, length=2.935, ppl=7.6, wps=19581.3, ups=0.33, wpb=59259.8, bsz=2063.9, num_updates=294900, lr=0.000184146, gnorm=1.46, loss_scale=8192, train_wall=302, wall=0
2023-02-21 17:08:19 | INFO | train_inner | epoch 150:    338 / 1978 loss=2.939, nll_loss=0.81, word_ins=2.642, length=2.966, ppl=7.67, wps=20856, ups=0.35, wpb=59511.4, bsz=2015.3, num_updates=295000, lr=0.000184115, gnorm=1.46, loss_scale=8192, train_wall=285, wall=0
2023-02-21 17:11:18 | INFO | train_inner | epoch 150:    438 / 1978 loss=2.938, nll_loss=0.809, word_ins=2.641, length=2.968, ppl=7.66, wps=33134.2, ups=0.56, wpb=59392, bsz=2023.8, num_updates=295100, lr=0.000184084, gnorm=1.505, loss_scale=8192, train_wall=179, wall=0
2023-02-21 17:16:13 | INFO | train_inner | epoch 150:    538 / 1978 loss=2.955, nll_loss=0.817, word_ins=2.648, length=3.068, ppl=7.76, wps=20026.7, ups=0.34, wpb=59029.1, bsz=1986.7, num_updates=295200, lr=0.000184053, gnorm=1.482, loss_scale=8192, train_wall=185, wall=0
2023-02-21 17:19:12 | INFO | train_inner | epoch 150:    638 / 1978 loss=2.963, nll_loss=0.825, word_ins=2.656, length=3.072, ppl=7.8, wps=33109.9, ups=0.56, wpb=59154.9, bsz=1941.7, num_updates=295300, lr=0.000184021, gnorm=1.519, loss_scale=8192, train_wall=178, wall=0
2023-02-21 17:22:10 | INFO | train_inner | epoch 150:    738 / 1978 loss=2.959, nll_loss=0.821, word_ins=2.652, length=3.074, ppl=7.78, wps=33113.3, ups=0.56, wpb=58882, bsz=1933.3, num_updates=295400, lr=0.00018399, gnorm=1.512, loss_scale=8192, train_wall=178, wall=0
2023-02-21 17:25:09 | INFO | train_inner | epoch 150:    838 / 1978 loss=2.941, nll_loss=0.808, word_ins=2.64, length=3.01, ppl=7.68, wps=32787.5, ups=0.56, wpb=58867.6, bsz=2076, num_updates=295500, lr=0.000183959, gnorm=1.48, loss_scale=8192, train_wall=179, wall=0
2023-02-21 17:28:07 | INFO | train_inner | epoch 150:    938 / 1978 loss=2.954, nll_loss=0.818, word_ins=2.649, length=3.053, ppl=7.75, wps=33206.9, ups=0.56, wpb=59233.5, bsz=1946.3, num_updates=295600, lr=0.000183928, gnorm=1.494, loss_scale=8192, train_wall=178, wall=0
2023-02-21 17:31:06 | INFO | train_inner | epoch 150:   1038 / 1978 loss=2.958, nll_loss=0.827, word_ins=2.657, length=3.003, ppl=7.77, wps=33256.8, ups=0.56, wpb=59394.6, bsz=1994.5, num_updates=295700, lr=0.000183897, gnorm=1.545, loss_scale=8192, train_wall=178, wall=0
2023-02-21 17:34:07 | INFO | train_inner | epoch 150:   1138 / 1978 loss=2.933, nll_loss=0.803, word_ins=2.635, length=2.98, ppl=7.64, wps=32779.6, ups=0.55, wpb=59374.1, bsz=2111.7, num_updates=295800, lr=0.000183866, gnorm=1.514, loss_scale=8192, train_wall=181, wall=0
2023-02-21 17:37:12 | INFO | train_inner | epoch 150:   1238 / 1978 loss=2.967, nll_loss=0.828, word_ins=2.658, length=3.083, ppl=7.82, wps=31678.2, ups=0.54, wpb=58594.5, bsz=1991.8, num_updates=295900, lr=0.000183835, gnorm=1.547, loss_scale=8192, train_wall=185, wall=0
2023-02-21 17:40:12 | INFO | train_inner | epoch 150:   1338 / 1978 loss=2.954, nll_loss=0.82, word_ins=2.651, length=3.03, ppl=7.75, wps=33072.6, ups=0.56, wpb=59557.5, bsz=1989.5, num_updates=296000, lr=0.000183804, gnorm=1.542, loss_scale=8192, train_wall=180, wall=0
2023-02-21 17:43:12 | INFO | train_inner | epoch 150:   1438 / 1978 loss=2.949, nll_loss=0.817, word_ins=2.648, length=3.008, ppl=7.72, wps=33026.1, ups=0.56, wpb=59474.1, bsz=2015.5, num_updates=296100, lr=0.000183773, gnorm=1.477, loss_scale=8192, train_wall=180, wall=0
2023-02-21 17:46:10 | INFO | train_inner | epoch 150:   1538 / 1978 loss=2.965, nll_loss=0.824, word_ins=2.654, length=3.107, ppl=7.81, wps=33083.2, ups=0.56, wpb=58832.7, bsz=1958.6, num_updates=296200, lr=0.000183742, gnorm=1.53, loss_scale=8192, train_wall=178, wall=0
2023-02-21 17:49:12 | INFO | train_inner | epoch 150:   1638 / 1978 loss=2.94, nll_loss=0.806, word_ins=2.638, length=3.017, ppl=7.67, wps=32738.5, ups=0.55, wpb=59558.7, bsz=2078.5, num_updates=296300, lr=0.000183711, gnorm=1.502, loss_scale=8192, train_wall=182, wall=0
2023-02-21 17:52:17 | INFO | train_inner | epoch 150:   1738 / 1978 loss=2.968, nll_loss=0.833, word_ins=2.663, length=3.05, ppl=7.82, wps=32299.6, ups=0.54, wpb=59568.1, bsz=1883.4, num_updates=296400, lr=0.00018368, gnorm=1.525, loss_scale=8192, train_wall=184, wall=0
2023-02-21 17:55:17 | INFO | train_inner | epoch 150:   1838 / 1978 loss=2.955, nll_loss=0.823, word_ins=2.653, length=3.018, ppl=7.76, wps=33057.1, ups=0.55, wpb=59622.3, bsz=1958.8, num_updates=296500, lr=0.000183649, gnorm=1.53, loss_scale=8192, train_wall=180, wall=0
2023-02-21 17:58:17 | INFO | train_inner | epoch 150:   1938 / 1978 loss=2.951, nll_loss=0.815, word_ins=2.646, length=3.052, ppl=7.73, wps=32873.1, ups=0.55, wpb=59321.4, bsz=2046.4, num_updates=296600, lr=0.000183618, gnorm=1.457, loss_scale=8192, train_wall=180, wall=0
2023-02-21 17:59:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 17:59:46 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 4.117 | nll_loss 1.937 | word_ins 3.711 | length 4.057 | ppl 17.35 | wps 48088 | wpb 40242.5 | bsz 1500 | num_updates 296640 | best_loss 4.073
2023-02-21 17:59:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 17:59:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint150.pt (epoch 150 @ 296640 updates, score 4.117) (writing took 6.167751749046147 seconds)
2023-02-21 17:59:53 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2023-02-21 17:59:53 | INFO | train | epoch 150 | loss 2.949 | nll_loss 0.815 | word_ins 2.647 | length 3.024 | ppl 7.72 | wps 29734.1 | ups 0.5 | wpb 59284.3 | bsz 2002.6 | num_updates 296640 | lr 0.000183605 | gnorm 1.505 | loss_scale 8192 | train_wall 3791 | wall 0
2023-02-21 17:59:53 | INFO | fairseq.trainer | begin training epoch 151
2023-02-21 18:01:55 | INFO | train_inner | epoch 151:     60 / 1978 loss=2.934, nll_loss=0.803, word_ins=2.635, length=2.997, ppl=7.64, wps=27280.1, ups=0.46, wpb=59398.7, bsz=2030.2, num_updates=296700, lr=0.000183587, gnorm=1.503, loss_scale=8192, train_wall=180, wall=0
2023-02-21 18:04:58 | INFO | train_inner | epoch 151:    160 / 1978 loss=2.938, nll_loss=0.808, word_ins=2.64, length=2.974, ppl=7.66, wps=32484.4, ups=0.55, wpb=59275, bsz=2050.6, num_updates=296800, lr=0.000183556, gnorm=1.488, loss_scale=8192, train_wall=182, wall=0
2023-02-21 18:08:02 | INFO | train_inner | epoch 151:    260 / 1978 loss=2.959, nll_loss=0.822, word_ins=2.653, length=3.058, ppl=7.77, wps=32145.7, ups=0.54, wpb=59314.9, bsz=1936.6, num_updates=296900, lr=0.000183525, gnorm=1.525, loss_scale=8192, train_wall=184, wall=0
2023-02-21 18:11:03 | INFO | train_inner | epoch 151:    360 / 1978 loss=2.935, nll_loss=0.807, word_ins=2.639, length=2.962, ppl=7.65, wps=33000.2, ups=0.55, wpb=59602.8, bsz=2025, num_updates=297000, lr=0.000183494, gnorm=1.541, loss_scale=8192, train_wall=180, wall=0
2023-02-21 18:14:04 | INFO | train_inner | epoch 151:    460 / 1978 loss=2.933, nll_loss=0.803, word_ins=2.635, length=2.976, ppl=7.64, wps=32896.6, ups=0.55, wpb=59563.4, bsz=2029.6, num_updates=297100, lr=0.000183463, gnorm=1.527, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:17:03 | INFO | train_inner | epoch 151:    560 / 1978 loss=2.966, nll_loss=0.831, word_ins=2.661, length=3.048, ppl=7.81, wps=32838.9, ups=0.56, wpb=58868.9, bsz=1954, num_updates=297200, lr=0.000183432, gnorm=1.478, loss_scale=8192, train_wall=179, wall=0
2023-02-21 18:20:03 | INFO | train_inner | epoch 151:    660 / 1978 loss=2.959, nll_loss=0.825, word_ins=2.655, length=3.036, ppl=7.78, wps=32784.7, ups=0.55, wpb=59125.3, bsz=2016.6, num_updates=297300, lr=0.000183401, gnorm=1.501, loss_scale=8192, train_wall=180, wall=0
2023-02-21 18:23:03 | INFO | train_inner | epoch 151:    760 / 1978 loss=2.948, nll_loss=0.818, word_ins=2.649, length=2.991, ppl=7.72, wps=33227.2, ups=0.56, wpb=59663.8, bsz=1976.6, num_updates=297400, lr=0.000183371, gnorm=1.536, loss_scale=8192, train_wall=179, wall=0
2023-02-21 18:24:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-02-21 18:26:04 | INFO | train_inner | epoch 151:    861 / 1978 loss=2.937, nll_loss=0.8, word_ins=2.632, length=3.045, ppl=7.66, wps=33006.7, ups=0.55, wpb=59721.4, bsz=2022.8, num_updates=297500, lr=0.00018334, gnorm=1.532, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:29:09 | INFO | train_inner | epoch 151:    961 / 1978 loss=2.929, nll_loss=0.802, word_ins=2.634, length=2.951, ppl=7.62, wps=32322.9, ups=0.54, wpb=59657.6, bsz=2079.6, num_updates=297600, lr=0.000183309, gnorm=1.466, loss_scale=8192, train_wall=184, wall=0
2023-02-21 18:32:10 | INFO | train_inner | epoch 151:   1061 / 1978 loss=2.937, nll_loss=0.804, word_ins=2.636, length=3.013, ppl=7.66, wps=32701.7, ups=0.55, wpb=59237, bsz=2039, num_updates=297700, lr=0.000183278, gnorm=1.517, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:35:11 | INFO | train_inner | epoch 151:   1161 / 1978 loss=2.955, nll_loss=0.821, word_ins=2.652, length=3.029, ppl=7.75, wps=32642.6, ups=0.55, wpb=59224.6, bsz=1955.9, num_updates=297800, lr=0.000183247, gnorm=1.482, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:38:09 | INFO | train_inner | epoch 151:   1261 / 1978 loss=2.964, nll_loss=0.828, word_ins=2.659, length=3.057, ppl=7.8, wps=33170.8, ups=0.56, wpb=59166.9, bsz=1974.2, num_updates=297900, lr=0.000183217, gnorm=1.495, loss_scale=8192, train_wall=178, wall=0
2023-02-21 18:41:11 | INFO | train_inner | epoch 151:   1361 / 1978 loss=2.964, nll_loss=0.826, word_ins=2.657, length=3.079, ppl=7.81, wps=32259.2, ups=0.55, wpb=58715.1, bsz=1918.6, num_updates=298000, lr=0.000183186, gnorm=1.478, loss_scale=8192, train_wall=182, wall=0
2023-02-21 18:44:13 | INFO | train_inner | epoch 151:   1461 / 1978 loss=2.954, nll_loss=0.821, word_ins=2.652, length=3.028, ppl=7.75, wps=32640.9, ups=0.55, wpb=59204.9, bsz=2023.8, num_updates=298100, lr=0.000183155, gnorm=1.507, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:47:15 | INFO | train_inner | epoch 151:   1561 / 1978 loss=2.929, nll_loss=0.801, word_ins=2.633, length=2.951, ppl=7.61, wps=32716.2, ups=0.55, wpb=59507.2, bsz=2111.5, num_updates=298200, lr=0.000183124, gnorm=1.546, loss_scale=8192, train_wall=182, wall=0
2023-02-21 18:50:16 | INFO | train_inner | epoch 151:   1661 / 1978 loss=2.96, nll_loss=0.822, word_ins=2.652, length=3.078, ppl=7.78, wps=32857.1, ups=0.55, wpb=59490.7, bsz=1915.4, num_updates=298300, lr=0.000183094, gnorm=1.533, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:53:18 | INFO | train_inner | epoch 151:   1761 / 1978 loss=2.946, nll_loss=0.814, word_ins=2.646, length=3.005, ppl=7.71, wps=32453.7, ups=0.55, wpb=59149.6, bsz=2021.9, num_updates=298400, lr=0.000183063, gnorm=1.514, loss_scale=8192, train_wall=182, wall=0
2023-02-21 18:56:18 | INFO | train_inner | epoch 151:   1861 / 1978 loss=2.974, nll_loss=0.833, word_ins=2.663, length=3.111, ppl=7.86, wps=32867, ups=0.56, wpb=59064.6, bsz=1915.8, num_updates=298500, lr=0.000183032, gnorm=1.502, loss_scale=8192, train_wall=179, wall=0
2023-02-21 18:59:19 | INFO | train_inner | epoch 151:   1961 / 1978 loss=2.936, nll_loss=0.807, word_ins=2.639, length=2.969, ppl=7.65, wps=32640.3, ups=0.55, wpb=59129.7, bsz=2058.8, num_updates=298600, lr=0.000183002, gnorm=1.517, loss_scale=8192, train_wall=181, wall=0
2023-02-21 18:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 19:00:07 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 4.119 | nll_loss 1.95 | word_ins 3.722 | length 3.968 | ppl 17.37 | wps 46995.3 | wpb 40242.5 | bsz 1500 | num_updates 298617 | best_loss 4.073
2023-02-21 19:00:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 19:00:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint151.pt (epoch 151 @ 298617 updates, score 4.119) (writing took 6.129227740690112 seconds)
2023-02-21 19:00:13 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2023-02-21 19:00:13 | INFO | train | epoch 151 | loss 2.948 | nll_loss 0.815 | word_ins 2.646 | length 3.019 | ppl 7.72 | wps 32374.5 | ups 0.55 | wpb 59285.4 | bsz 2002.9 | num_updates 298617 | lr 0.000182996 | gnorm 1.509 | loss_scale 8192 | train_wall 3577 | wall 0
2023-02-21 19:00:13 | INFO | fairseq.trainer | begin training epoch 152
2023-02-21 19:02:54 | INFO | train_inner | epoch 152:     83 / 1978 loss=2.955, nll_loss=0.816, word_ins=2.647, length=3.082, ppl=7.76, wps=27384.1, ups=0.47, wpb=58861.6, bsz=2012.5, num_updates=298700, lr=0.000182971, gnorm=1.511, loss_scale=8192, train_wall=179, wall=0
2023-02-21 19:05:55 | INFO | train_inner | epoch 152:    183 / 1978 loss=2.94, nll_loss=0.809, word_ins=2.641, length=2.993, ppl=7.68, wps=32917.9, ups=0.55, wpb=59469.1, bsz=1954.1, num_updates=298800, lr=0.00018294, gnorm=1.54, loss_scale=8192, train_wall=180, wall=0
2023-02-21 19:08:55 | INFO | train_inner | epoch 152:    283 / 1978 loss=2.948, nll_loss=0.813, word_ins=2.645, length=3.033, ppl=7.72, wps=33049.1, ups=0.56, wpb=59476.2, bsz=1995.7, num_updates=298900, lr=0.00018291, gnorm=1.56, loss_scale=8192, train_wall=180, wall=0
2023-02-21 19:11:55 | INFO | train_inner | epoch 152:    383 / 1978 loss=2.93, nll_loss=0.799, word_ins=2.631, length=2.982, ppl=7.62, wps=32736, ups=0.55, wpb=59160.9, bsz=2085.3, num_updates=299000, lr=0.000182879, gnorm=1.508, loss_scale=8192, train_wall=180, wall=0
2023-02-21 19:14:59 | INFO | train_inner | epoch 152:    483 / 1978 loss=2.959, nll_loss=0.823, word_ins=2.654, length=3.051, ppl=7.77, wps=32272.9, ups=0.54, wpb=59217.7, bsz=1901.2, num_updates=299100, lr=0.000182849, gnorm=1.516, loss_scale=8192, train_wall=183, wall=0
2023-02-21 19:17:58 | INFO | train_inner | epoch 152:    583 / 1978 loss=2.943, nll_loss=0.808, word_ins=2.64, length=3.035, ppl=7.69, wps=32767.5, ups=0.56, wpb=58798, bsz=2008.5, num_updates=299200, lr=0.000182818, gnorm=1.455, loss_scale=8192, train_wall=179, wall=0
2023-02-21 19:20:59 | INFO | train_inner | epoch 152:    683 / 1978 loss=2.938, nll_loss=0.806, word_ins=2.639, length=2.994, ppl=7.66, wps=32656.5, ups=0.55, wpb=59118.7, bsz=2023.5, num_updates=299300, lr=0.000182788, gnorm=1.489, loss_scale=8192, train_wall=181, wall=0
2023-02-21 19:24:02 | INFO | train_inner | epoch 152:    783 / 1978 loss=2.949, nll_loss=0.816, word_ins=2.647, length=3.021, ppl=7.72, wps=32459.4, ups=0.55, wpb=59335.3, bsz=2003.5, num_updates=299400, lr=0.000182757, gnorm=1.569, loss_scale=8192, train_wall=183, wall=0
2023-02-21 19:27:07 | INFO | train_inner | epoch 152:    883 / 1978 loss=2.942, nll_loss=0.808, word_ins=2.639, length=3.028, ppl=7.68, wps=32316.5, ups=0.54, wpb=59606.5, bsz=2040.6, num_updates=299500, lr=0.000182727, gnorm=1.545, loss_scale=8192, train_wall=184, wall=0
2023-02-21 19:30:21 | INFO | train_inner | epoch 152:    983 / 1978 loss=2.955, nll_loss=0.824, word_ins=2.655, length=3.005, ppl=7.76, wps=30141.2, ups=0.51, wpb=58690.8, bsz=1953.7, num_updates=299600, lr=0.000182696, gnorm=1.476, loss_scale=8192, train_wall=194, wall=0
2023-02-21 19:33:22 | INFO | train_inner | epoch 152:   1083 / 1978 loss=2.946, nll_loss=0.807, word_ins=2.639, length=3.066, ppl=7.71, wps=32779.9, ups=0.55, wpb=59378.5, bsz=1994.2, num_updates=299700, lr=0.000182666, gnorm=1.46, loss_scale=8192, train_wall=181, wall=0
2023-02-21 19:36:24 | INFO | train_inner | epoch 152:   1183 / 1978 loss=2.936, nll_loss=0.807, word_ins=2.639, length=2.974, ppl=7.65, wps=32856, ups=0.55, wpb=59502.1, bsz=2025.4, num_updates=299800, lr=0.000182635, gnorm=1.496, loss_scale=8192, train_wall=181, wall=0
2023-02-21 19:39:24 | INFO | train_inner | epoch 152:   1283 / 1978 loss=2.965, nll_loss=0.828, word_ins=2.659, length=3.06, ppl=7.81, wps=32692.4, ups=0.55, wpb=59158.9, bsz=1967.2, num_updates=299900, lr=0.000182605, gnorm=1.548, loss_scale=8192, train_wall=181, wall=0
2023-02-21 19:42:26 | INFO | train_inner | epoch 152:   1383 / 1978 loss=2.957, nll_loss=0.824, word_ins=2.654, length=3.031, ppl=7.77, wps=32742.2, ups=0.55, wpb=59349.5, bsz=2017, num_updates=300000, lr=0.000182574, gnorm=1.523, loss_scale=8192, train_wall=181, wall=0
2023-02-21 19:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-02-21 19:42:43 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 4.199 | nll_loss 1.947 | word_ins 3.721 | length 4.775 | ppl 18.36 | wps 46420 | wpb 40242.5 | bsz 1500 | num_updates 300000 | best_loss 4.073
2023-02-21 19:42:43 | INFO | fairseq_cli.train | begin save checkpoint
2023-02-21 19:42:46 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTdeen_distill_CMLMC_L5D3_300k_amlpseq_ema99_scale_c5/checkpoint_last.pt (epoch 152 @ 300000 updates, score 4.199) (writing took 2.7631884375587106 seconds)
2023-02-21 19:42:46 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2023-02-21 19:42:46 | INFO | train | epoch 152 | loss 2.947 | nll_loss 0.813 | word_ins 2.644 | length 3.022 | ppl 7.71 | wps 32093.8 | ups 0.54 | wpb 59244.1 | bsz 2001.4 | num_updates 300000 | lr 0.000182574 | gnorm 1.512 | loss_scale 8192 | train_wall 2517 | wall 0
2023-02-21 19:42:46 | INFO | fairseq_cli.train | done training in 163603.1 seconds
