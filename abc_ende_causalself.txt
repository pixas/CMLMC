2023-03-01 21:44:34 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:12133
2023-03-01 21:44:34 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:12133
2023-03-01 21:44:34 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:12133
2023-03-01 21:44:34 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:12133
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for 4 nodes.
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for 4 nodes.
2023-03-01 21:44:35 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-81 as rank 0
2023-03-01 21:44:35 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-81 as rank 2
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for 4 nodes.
2023-03-01 21:44:35 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for 4 nodes.
2023-03-01 21:44:35 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-81 as rank 1
2023-03-01 21:44:35 | INFO | fairseq.distributed_utils | initialized host SH-IDC1-10-140-1-81 as rank 3
2023-03-01 21:44:41 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_ema=None, all_gather_list_size=16384, amlp_activation='softmax', apply_bert_init=True, arch='cmlm_transformer_wmt_en_de', attention_dropout=0.0, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, concatPE=True, cpu=False, criterion='nat_loss', cross_self_attention=False, curriculum=0, data='/mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_cross_attention_type='abc', decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=512, decoder_self_attention_type='abc', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:12133', distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dont_use_layernorm=False, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, encoder_self_attention_type='mha', eval_bleu=True, eval_bleu_args='{"iter_decode_max_iter": 0, "iter_decode_with_beam": 1}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, insertCausalSelfAttn=True, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=20, label_smoothing=0.1, landmarks=16, left_pad_source='True', left_pad_target='False', length_loss_factor=0.1, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', maskdistshiftpower=1.0, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=16384, max_tokens_valid=16384, max_update=300000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, ngram_predictor=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=True, no_token_positional_embeddings=False, noise='random_mask', nprocs_per_node=4, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=None, pipeline_devices=None, pipeline_model_parallel=False, pred_length_offset=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, replacefactor=0.3, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, selfcorrection=0, sentence_avg=False, sg_length_pred=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', src_embedding_copy=False, stop_time_hours=0, target_lang='de', task='translation_lev', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=40000, weight_decay=0.01, zero_sharding='none')
2023-03-01 21:44:41 | INFO | fairseq.tasks.translation | [en] dictionary: 39840 types
2023-03-01 21:44:41 | INFO | fairseq.tasks.translation | [de] dictionary: 39840 types
2023-03-01 21:44:41 | INFO | fairseq.data.data_utils | loaded 3000 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict/valid.en-de.en
2023-03-01 21:44:41 | INFO | fairseq.data.data_utils | loaded 3000 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict/valid.en-de.de
2023-03-01 21:44:41 | INFO | fairseq.tasks.translation | /mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict valid en-de 3000 examples
2023-03-01 21:44:41 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:41 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:41 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:41 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:41 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:41 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention MultiheadAttention
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | root | Using efficient attention FSABC
2023-03-01 21:44:42 | INFO | fairseq_cli.train | CMLMNATransformerModel(
  (encoder): FairseqNATEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39840, 512, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (PEfc): Linear(in_features=1024, out_features=512, bias=True)
  )
  (decoder): NATransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39840, 512, padding_idx=1)
    (PEfc): Linear(in_features=1024, out_features=512, bias=True)
    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn_unmasked): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (self_attn_unmasked_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn_unmasked): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (self_attn_unmasked_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn_unmasked): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (self_attn_unmasked_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn_unmasked): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (self_attn_unmasked_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn_unmasked): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (self_attn_unmasked_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn_unmasked): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (self_attn_unmasked_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): FSCls(
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39840, bias=False)
    (embed_length): Embedding(256, 512)
  )
)
2023-03-01 21:44:42 | INFO | fairseq_cli.train | task: translation_lev (TranslationLevenshteinTask)
2023-03-01 21:44:42 | INFO | fairseq_cli.train | model: cmlm_transformer_wmt_en_de (CMLMNATransformerModel)
2023-03-01 21:44:42 | INFO | fairseq_cli.train | criterion: nat_loss (LabelSmoothedDualImitationCriterion)
2023-03-01 21:44:42 | INFO | fairseq_cli.train | num. model params: 73102336 (num. trained: 73102336)
2023-03-01 21:44:42 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-03-01 21:44:42 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-03-01 21:44:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-03-01 21:44:43 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-03-01 21:44:43 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-03-01 21:44:43 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-03-01 21:44:43 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 79.347 GB ; name = NVIDIA A100-SXM4-80GB                   
2023-03-01 21:44:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-03-01 21:44:43 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-03-01 21:44:43 | INFO | fairseq_cli.train | max tokens per GPU = 16384 and max sentences per GPU = None
2023-03-01 21:44:46 | INFO | fairseq.trainer | loaded checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint_last.pt (epoch 22 @ 41642 updates)
2023-03-01 21:44:46 | INFO | fairseq.trainer | loading train data for epoch 22
2023-03-01 21:44:47 | INFO | fairseq.data.data_utils | loaded 3961179 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict/train.en-de.en
2023-03-01 21:44:48 | INFO | fairseq.data.data_utils | loaded 3961179 examples from: /mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict/train.en-de.de
2023-03-01 21:44:48 | INFO | fairseq.tasks.translation | /mnt/petrelfs/jiangshuyang/data-bin/wmt14_ende_distill_jointdict train en-de 3961179 examples
2023-03-01 21:44:51 | INFO | fairseq.trainer | begin training epoch 22
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
/mnt/petrelfs/jiangshuyang/.local/lib/python3.7/site-packages/torch/nn/parallel/distributed.py:468: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  "The `check_reduction` argument in `DistributedDataParallel` "
2023-03-01 21:45:07 | INFO | root | Reducer buckets have been rebuilt in this iteration.
2023-03-01 21:45:24 | INFO | train_inner | epoch 022:     58 / 1983 loss=3.822, nll_loss=1.66, word_ins=3.445, length=3.761, ppl=14.14, wps=95572.7, ups=1.56, wpb=61377, bsz=1997.4, num_updates=41700, lr=0.000489702, gnorm=1, loss_scale=16384, train_wall=30, wall=0
2023-03-01 21:45:53 | INFO | train_inner | epoch 022:    158 / 1983 loss=3.843, nll_loss=1.679, word_ins=3.463, length=3.802, ppl=14.35, wps=209657, ups=3.42, wpb=61368.7, bsz=2011.3, num_updates=41800, lr=0.000489116, gnorm=1.008, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:46:22 | INFO | train_inner | epoch 022:    258 / 1983 loss=3.806, nll_loss=1.643, word_ins=3.431, length=3.756, ppl=13.99, wps=212776, ups=3.42, wpb=62271.2, bsz=2019, num_updates=41900, lr=0.000488532, gnorm=0.994, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:46:52 | INFO | train_inner | epoch 022:    358 / 1983 loss=3.797, nll_loss=1.638, word_ins=3.426, length=3.712, ppl=13.9, wps=210166, ups=3.4, wpb=61879.2, bsz=2042.7, num_updates=42000, lr=0.00048795, gnorm=0.992, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:47:21 | INFO | train_inner | epoch 022:    458 / 1983 loss=3.795, nll_loss=1.638, word_ins=3.426, length=3.69, ppl=13.88, wps=209204, ups=3.41, wpb=61412.1, bsz=2018, num_updates=42100, lr=0.00048737, gnorm=0.997, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:47:50 | INFO | train_inner | epoch 022:    558 / 1983 loss=3.853, nll_loss=1.689, word_ins=3.471, length=3.821, ppl=14.45, wps=210282, ups=3.42, wpb=61474.3, bsz=1976.5, num_updates=42200, lr=0.000486792, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:48:20 | INFO | train_inner | epoch 022:    658 / 1983 loss=3.813, nll_loss=1.651, word_ins=3.438, length=3.757, ppl=14.06, wps=212743, ups=3.43, wpb=61973.1, bsz=1976.9, num_updates=42300, lr=0.000486217, gnorm=0.988, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:48:49 | INFO | train_inner | epoch 022:    758 / 1983 loss=3.825, nll_loss=1.662, word_ins=3.446, length=3.786, ppl=14.17, wps=210658, ups=3.44, wpb=61290.2, bsz=1999.3, num_updates=42400, lr=0.000485643, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:49:18 | INFO | train_inner | epoch 022:    858 / 1983 loss=3.789, nll_loss=1.63, word_ins=3.418, length=3.714, ppl=13.82, wps=211292, ups=3.41, wpb=61951.1, bsz=2087, num_updates=42500, lr=0.000485071, gnorm=0.973, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:49:47 | INFO | train_inner | epoch 022:    958 / 1983 loss=3.798, nll_loss=1.637, word_ins=3.425, length=3.731, ppl=13.91, wps=210209, ups=3.41, wpb=61716.6, bsz=2032.7, num_updates=42600, lr=0.000484502, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:50:16 | INFO | train_inner | epoch 022:   1058 / 1983 loss=3.784, nll_loss=1.631, word_ins=3.418, length=3.658, ppl=13.78, wps=212549, ups=3.43, wpb=62014.6, bsz=2038.2, num_updates=42700, lr=0.000483934, gnorm=0.988, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:50:46 | INFO | train_inner | epoch 022:   1158 / 1983 loss=3.792, nll_loss=1.631, word_ins=3.419, length=3.737, ppl=13.86, wps=212297, ups=3.43, wpb=61983.8, bsz=1945.4, num_updates=42800, lr=0.000483368, gnorm=0.973, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:51:15 | INFO | train_inner | epoch 022:   1258 / 1983 loss=3.87, nll_loss=1.709, word_ins=3.489, length=3.816, ppl=14.62, wps=208532, ups=3.39, wpb=61495.4, bsz=1970.5, num_updates=42900, lr=0.000482805, gnorm=1.042, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:51:44 | INFO | train_inner | epoch 022:   1358 / 1983 loss=3.809, nll_loss=1.649, word_ins=3.435, length=3.736, ppl=14.01, wps=211584, ups=3.43, wpb=61712.7, bsz=1966.8, num_updates=43000, lr=0.000482243, gnorm=0.983, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:52:14 | INFO | train_inner | epoch 022:   1458 / 1983 loss=3.782, nll_loss=1.624, word_ins=3.412, length=3.701, ppl=13.76, wps=209442, ups=3.41, wpb=61499.2, bsz=2071.4, num_updates=43100, lr=0.000481683, gnorm=0.971, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:52:43 | INFO | train_inner | epoch 022:   1558 / 1983 loss=3.802, nll_loss=1.639, word_ins=3.425, length=3.764, ppl=13.95, wps=211656, ups=3.43, wpb=61768.4, bsz=1992.6, num_updates=43200, lr=0.000481125, gnorm=0.981, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:53:12 | INFO | train_inner | epoch 022:   1658 / 1983 loss=3.82, nll_loss=1.659, word_ins=3.444, length=3.77, ppl=14.13, wps=210428, ups=3.43, wpb=61338.6, bsz=1965.1, num_updates=43300, lr=0.000480569, gnorm=0.996, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:53:41 | INFO | train_inner | epoch 022:   1758 / 1983 loss=3.842, nll_loss=1.677, word_ins=3.46, length=3.829, ppl=14.34, wps=208928, ups=3.43, wpb=60929.8, bsz=1951.6, num_updates=43400, lr=0.000480015, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:54:10 | INFO | train_inner | epoch 022:   1858 / 1983 loss=3.825, nll_loss=1.668, word_ins=3.451, length=3.739, ppl=14.18, wps=210678, ups=3.42, wpb=61541.9, bsz=1942.3, num_updates=43500, lr=0.000479463, gnorm=0.977, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:54:39 | INFO | train_inner | epoch 022:   1958 / 1983 loss=3.811, nll_loss=1.649, word_ins=3.434, length=3.767, ppl=14.03, wps=213736, ups=3.46, wpb=61838.9, bsz=1881.2, num_updates=43600, lr=0.000478913, gnorm=0.988, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
/mnt/petrelfs/jiangshuyang/repo/efficient-attention/efficient_attention/abc.py:139: UserWarning: `attn_mask` arguments make no sense in `ABC`
  warnings.warn("`attn_mask` arguments make no sense in `ABC`")
/mnt/petrelfs/jiangshuyang/repo/efficient-attention/efficient_attention/abc.py:139: UserWarning: `attn_mask` arguments make no sense in `ABC`
  warnings.warn("`attn_mask` arguments make no sense in `ABC`")
/mnt/petrelfs/jiangshuyang/repo/efficient-attention/efficient_attention/abc.py:139: UserWarning: `attn_mask` arguments make no sense in `ABC`
  warnings.warn("`attn_mask` arguments make no sense in `ABC`")
/mnt/petrelfs/jiangshuyang/repo/efficient-attention/efficient_attention/abc.py:139: UserWarning: `attn_mask` arguments make no sense in `ABC`
  warnings.warn("`attn_mask` arguments make no sense in `ABC`")
2023-03-01 21:55:00 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.703 | nll_loss 1.45 | word_ins 3.333 | length 3.696 | ppl 13.02 | wps 85220.1 | wpb 41551 | bsz 1500 | num_updates 43625 | best_loss 3.703
2023-03-01 21:55:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 21:55:14 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint22.pt (epoch 22 @ 43625 updates, score 3.703) (writing took 13.631625268026255 seconds)
2023-03-01 21:55:14 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-03-01 21:55:14 | INFO | train | epoch 022 | loss 3.833 | nll_loss 1.672 | word_ins 3.456 | length 3.769 | ppl 14.25 | wps 196186 | ups 3.18 | wpb 61628.5 | bsz 1997.6 | num_updates 43625 | lr 0.000478776 | gnorm 1.002 | loss_scale 16384 | train_wall 1164 | wall 0
2023-03-01 21:55:14 | INFO | fairseq.trainer | begin training epoch 23
2023-03-01 21:55:47 | INFO | train_inner | epoch 023:     75 / 1983 loss=3.752, nll_loss=1.592, word_ins=3.383, length=3.69, ppl=13.47, wps=90145.8, ups=1.47, wpb=61281.2, bsz=2096.6, num_updates=43700, lr=0.000478365, gnorm=0.968, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:56:17 | INFO | train_inner | epoch 023:    175 / 1983 loss=3.82, nll_loss=1.656, word_ins=3.441, length=3.788, ppl=14.12, wps=210927, ups=3.41, wpb=61805.2, bsz=1946.7, num_updates=43800, lr=0.000477818, gnorm=0.99, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:56:46 | INFO | train_inner | epoch 023:    275 / 1983 loss=3.751, nll_loss=1.588, word_ins=3.379, length=3.721, ppl=13.47, wps=211240, ups=3.42, wpb=61824.1, bsz=2064.7, num_updates=43900, lr=0.000477274, gnorm=0.957, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:57:15 | INFO | train_inner | epoch 023:    375 / 1983 loss=3.827, nll_loss=1.656, word_ins=3.441, length=3.856, ppl=14.19, wps=209932, ups=3.41, wpb=61494.7, bsz=1948.1, num_updates=44000, lr=0.000476731, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:57:44 | INFO | train_inner | epoch 023:    475 / 1983 loss=3.802, nll_loss=1.639, word_ins=3.425, length=3.768, ppl=13.95, wps=211025, ups=3.43, wpb=61511, bsz=1945.4, num_updates=44100, lr=0.00047619, gnorm=0.974, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:58:14 | INFO | train_inner | epoch 023:    575 / 1983 loss=3.712, nll_loss=1.558, word_ins=3.352, length=3.595, ppl=13.1, wps=211519, ups=3.42, wpb=61924.7, bsz=2102.9, num_updates=44200, lr=0.000475651, gnorm=0.955, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:58:43 | INFO | train_inner | epoch 023:    675 / 1983 loss=3.797, nll_loss=1.637, word_ins=3.423, length=3.735, ppl=13.9, wps=211212, ups=3.41, wpb=61953.2, bsz=1956.7, num_updates=44300, lr=0.000475114, gnorm=0.987, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:59:13 | INFO | train_inner | epoch 023:    775 / 1983 loss=3.808, nll_loss=1.647, word_ins=3.433, length=3.751, ppl=14, wps=210000, ups=3.39, wpb=61981.7, bsz=1912.9, num_updates=44400, lr=0.000474579, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-01 21:59:42 | INFO | train_inner | epoch 023:    875 / 1983 loss=3.785, nll_loss=1.624, word_ins=3.412, length=3.728, ppl=13.78, wps=210820, ups=3.43, wpb=61472.1, bsz=2014.2, num_updates=44500, lr=0.000474045, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:00:11 | INFO | train_inner | epoch 023:    975 / 1983 loss=3.77, nll_loss=1.61, word_ins=3.399, length=3.719, ppl=13.65, wps=210346, ups=3.43, wpb=61346, bsz=1977.2, num_updates=44600, lr=0.000473514, gnorm=0.95, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:00:40 | INFO | train_inner | epoch 023:   1075 / 1983 loss=3.793, nll_loss=1.634, word_ins=3.42, length=3.726, ppl=13.86, wps=211102, ups=3.41, wpb=61866, bsz=1975.7, num_updates=44700, lr=0.000472984, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:01:09 | INFO | train_inner | epoch 023:   1175 / 1983 loss=3.771, nll_loss=1.609, word_ins=3.398, length=3.729, ppl=13.65, wps=212013, ups=3.43, wpb=61824.2, bsz=1989.9, num_updates=44800, lr=0.000472456, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:01:39 | INFO | train_inner | epoch 023:   1275 / 1983 loss=3.712, nll_loss=1.557, word_ins=3.351, length=3.614, ppl=13.1, wps=210376, ups=3.41, wpb=61773.5, bsz=2131.1, num_updates=44900, lr=0.000471929, gnorm=0.954, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:02:08 | INFO | train_inner | epoch 023:   1375 / 1983 loss=3.758, nll_loss=1.597, word_ins=3.387, length=3.715, ppl=13.53, wps=211675, ups=3.42, wpb=61871.2, bsz=2012.6, num_updates=45000, lr=0.000471405, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:02:37 | INFO | train_inner | epoch 023:   1475 / 1983 loss=3.755, nll_loss=1.601, word_ins=3.39, length=3.651, ppl=13.5, wps=211320, ups=3.44, wpb=61408.5, bsz=2008.9, num_updates=45100, lr=0.000470882, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:03:06 | INFO | train_inner | epoch 023:   1575 / 1983 loss=3.792, nll_loss=1.627, word_ins=3.414, length=3.783, ppl=13.85, wps=209658, ups=3.44, wpb=61025.5, bsz=1938.6, num_updates=45200, lr=0.00047036, gnorm=1.014, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:03:35 | INFO | train_inner | epoch 023:   1675 / 1983 loss=3.788, nll_loss=1.623, word_ins=3.41, length=3.788, ppl=13.82, wps=210374, ups=3.43, wpb=61395, bsz=1970.8, num_updates=45300, lr=0.000469841, gnorm=0.966, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:04:05 | INFO | train_inner | epoch 023:   1775 / 1983 loss=3.802, nll_loss=1.646, word_ins=3.43, length=3.72, ppl=13.94, wps=209764, ups=3.41, wpb=61444.5, bsz=2038.1, num_updates=45400, lr=0.000469323, gnorm=0.987, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:04:34 | INFO | train_inner | epoch 023:   1875 / 1983 loss=3.783, nll_loss=1.619, word_ins=3.406, length=3.767, ppl=13.76, wps=209254, ups=3.43, wpb=61058.6, bsz=1963.8, num_updates=45500, lr=0.000468807, gnorm=0.954, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:05:03 | INFO | train_inner | epoch 023:   1975 / 1983 loss=3.755, nll_loss=1.59, word_ins=3.38, length=3.753, ppl=13.5, wps=211723, ups=3.41, wpb=62100.5, bsz=2005.7, num_updates=45600, lr=0.000468293, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 22:05:20 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.661 | nll_loss 1.418 | word_ins 3.299 | length 3.613 | ppl 12.65 | wps 95990.2 | wpb 41551 | bsz 1500 | num_updates 45608 | best_loss 3.661
2023-03-01 22:05:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 22:05:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint23.pt (epoch 23 @ 45608 updates, score 3.661) (writing took 11.394384467974305 seconds)
2023-03-01 22:05:32 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-03-01 22:05:32 | INFO | train | epoch 023 | loss 3.776 | nll_loss 1.615 | word_ins 3.403 | length 3.73 | ppl 13.7 | wps 197818 | ups 3.21 | wpb 61628.5 | bsz 1997.6 | num_updates 45608 | lr 0.000468252 | gnorm 0.976 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 22:05:32 | INFO | fairseq.trainer | begin training epoch 24
2023-03-01 22:06:10 | INFO | train_inner | epoch 024:     92 / 1983 loss=3.809, nll_loss=1.644, word_ins=3.43, length=3.794, ppl=14.02, wps=90548.9, ups=1.49, wpb=60636.4, bsz=1870.6, num_updates=45700, lr=0.00046778, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:06:40 | INFO | train_inner | epoch 024:    192 / 1983 loss=3.73, nll_loss=1.572, word_ins=3.364, length=3.66, ppl=13.27, wps=208285, ups=3.4, wpb=61327, bsz=2013.8, num_updates=45800, lr=0.000467269, gnorm=0.954, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:07:09 | INFO | train_inner | epoch 024:    292 / 1983 loss=3.707, nll_loss=1.55, word_ins=3.344, length=3.625, ppl=13.06, wps=209762, ups=3.39, wpb=61786.7, bsz=2089.8, num_updates=45900, lr=0.00046676, gnorm=0.945, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:07:38 | INFO | train_inner | epoch 024:    392 / 1983 loss=3.727, nll_loss=1.564, word_ins=3.357, length=3.697, ppl=13.24, wps=211166, ups=3.4, wpb=62142.1, bsz=2094.2, num_updates=46000, lr=0.000466252, gnorm=0.983, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:08:08 | INFO | train_inner | epoch 024:    492 / 1983 loss=3.739, nll_loss=1.582, word_ins=3.372, length=3.665, ppl=13.35, wps=210514, ups=3.42, wpb=61597.1, bsz=1991.1, num_updates=46100, lr=0.000465746, gnorm=0.946, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:08:37 | INFO | train_inner | epoch 024:    592 / 1983 loss=3.713, nll_loss=1.553, word_ins=3.346, length=3.661, ppl=13.11, wps=209725, ups=3.39, wpb=61844, bsz=2109.9, num_updates=46200, lr=0.000465242, gnorm=0.949, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:09:06 | INFO | train_inner | epoch 024:    692 / 1983 loss=3.758, nll_loss=1.598, word_ins=3.387, length=3.715, ppl=13.53, wps=211704, ups=3.42, wpb=61826.9, bsz=1943.8, num_updates=46300, lr=0.000464739, gnorm=0.964, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:09:36 | INFO | train_inner | epoch 024:    792 / 1983 loss=3.746, nll_loss=1.593, word_ins=3.382, length=3.64, ppl=13.42, wps=209345, ups=3.39, wpb=61697.2, bsz=2041.2, num_updates=46400, lr=0.000464238, gnorm=0.956, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:10:05 | INFO | train_inner | epoch 024:    892 / 1983 loss=3.742, nll_loss=1.587, word_ins=3.377, length=3.648, ppl=13.38, wps=209881, ups=3.4, wpb=61769.3, bsz=2019, num_updates=46500, lr=0.000463739, gnorm=0.953, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:10:34 | INFO | train_inner | epoch 024:    992 / 1983 loss=3.727, nll_loss=1.566, word_ins=3.358, length=3.697, ppl=13.24, wps=210953, ups=3.43, wpb=61525.3, bsz=2019.1, num_updates=46600, lr=0.000463241, gnorm=0.959, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:11:04 | INFO | train_inner | epoch 024:   1092 / 1983 loss=3.741, nll_loss=1.578, word_ins=3.368, length=3.733, ppl=13.37, wps=210671, ups=3.43, wpb=61434.9, bsz=2011.4, num_updates=46700, lr=0.000462745, gnorm=0.953, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:11:33 | INFO | train_inner | epoch 024:   1192 / 1983 loss=3.745, nll_loss=1.584, word_ins=3.374, length=3.71, ppl=13.41, wps=210809, ups=3.43, wpb=61486.4, bsz=1931.4, num_updates=46800, lr=0.00046225, gnorm=0.955, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:12:02 | INFO | train_inner | epoch 024:   1292 / 1983 loss=3.742, nll_loss=1.578, word_ins=3.368, length=3.737, ppl=13.38, wps=209838, ups=3.43, wpb=61175.1, bsz=2011.6, num_updates=46900, lr=0.000461757, gnorm=0.944, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:12:31 | INFO | train_inner | epoch 024:   1392 / 1983 loss=3.763, nll_loss=1.604, word_ins=3.392, length=3.708, ppl=13.58, wps=212098, ups=3.41, wpb=62254.2, bsz=1975.5, num_updates=47000, lr=0.000461266, gnorm=0.973, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:13:00 | INFO | train_inner | epoch 024:   1492 / 1983 loss=3.727, nll_loss=1.563, word_ins=3.354, length=3.729, ppl=13.25, wps=212306, ups=3.43, wpb=61827.3, bsz=1990.7, num_updates=47100, lr=0.000460776, gnorm=0.93, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:13:30 | INFO | train_inner | epoch 024:   1592 / 1983 loss=3.768, nll_loss=1.601, word_ins=3.388, length=3.801, ppl=13.63, wps=210797, ups=3.44, wpb=61272.2, bsz=1910.2, num_updates=47200, lr=0.000460287, gnorm=0.962, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:13:59 | INFO | train_inner | epoch 024:   1692 / 1983 loss=3.771, nll_loss=1.609, word_ins=3.397, length=3.743, ppl=13.65, wps=209948, ups=3.43, wpb=61212, bsz=1901.4, num_updates=47300, lr=0.0004598, gnorm=0.983, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:14:28 | INFO | train_inner | epoch 024:   1792 / 1983 loss=3.715, nll_loss=1.553, word_ins=3.345, length=3.693, ppl=13.13, wps=211567, ups=3.41, wpb=62012.7, bsz=1988.7, num_updates=47400, lr=0.000459315, gnorm=0.935, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:14:57 | INFO | train_inner | epoch 024:   1892 / 1983 loss=3.712, nll_loss=1.549, word_ins=3.342, length=3.699, ppl=13.1, wps=211710, ups=3.42, wpb=61830.4, bsz=2012.1, num_updates=47500, lr=0.000458831, gnorm=0.937, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 22:15:40 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.613 | nll_loss 1.383 | word_ins 3.263 | length 3.504 | ppl 12.24 | wps 77972 | wpb 41551 | bsz 1500 | num_updates 47591 | best_loss 3.613
2023-03-01 22:15:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 22:15:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint24.pt (epoch 24 @ 47591 updates, score 3.613) (writing took 13.838929311954416 seconds)
2023-03-01 22:15:54 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-03-01 22:15:54 | INFO | train | epoch 024 | loss 3.741 | nll_loss 1.58 | word_ins 3.371 | length 3.704 | ppl 13.37 | wps 196514 | ups 3.19 | wpb 61628.5 | bsz 1997.6 | num_updates 47591 | lr 0.000458393 | gnorm 0.957 | loss_scale 32768 | train_wall 578 | wall 0
2023-03-01 22:15:54 | INFO | fairseq.trainer | begin training epoch 25
2023-03-01 22:16:08 | INFO | train_inner | epoch 025:      9 / 1983 loss=3.749, nll_loss=1.586, word_ins=3.376, length=3.73, ppl=13.44, wps=86486.6, ups=1.41, wpb=61527.7, bsz=1991.4, num_updates=47600, lr=0.000458349, gnorm=0.965, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:16:38 | INFO | train_inner | epoch 025:    109 / 1983 loss=3.691, nll_loss=1.538, word_ins=3.332, length=3.591, ppl=12.92, wps=211381, ups=3.41, wpb=62030.3, bsz=2005.7, num_updates=47700, lr=0.000457869, gnorm=0.956, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:17:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-01 22:17:07 | INFO | train_inner | epoch 025:    210 / 1983 loss=3.723, nll_loss=1.557, word_ins=3.349, length=3.741, ppl=13.21, wps=207869, ups=3.4, wpb=61176.2, bsz=2003.2, num_updates=47800, lr=0.000457389, gnorm=0.968, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:17:36 | INFO | train_inner | epoch 025:    310 / 1983 loss=3.732, nll_loss=1.575, word_ins=3.365, length=3.676, ppl=13.29, wps=212494, ups=3.43, wpb=61893.2, bsz=1925.1, num_updates=47900, lr=0.000456912, gnorm=0.948, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:18:05 | INFO | train_inner | epoch 025:    410 / 1983 loss=3.735, nll_loss=1.57, word_ins=3.361, length=3.741, ppl=13.32, wps=210823, ups=3.42, wpb=61669.3, bsz=1905.9, num_updates=48000, lr=0.000456435, gnorm=0.978, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:18:35 | INFO | train_inner | epoch 025:    510 / 1983 loss=3.707, nll_loss=1.547, word_ins=3.34, length=3.667, ppl=13.06, wps=209691, ups=3.42, wpb=61282.9, bsz=2028.9, num_updates=48100, lr=0.000455961, gnorm=0.936, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:19:04 | INFO | train_inner | epoch 025:    610 / 1983 loss=3.715, nll_loss=1.553, word_ins=3.345, length=3.706, ppl=13.14, wps=212038, ups=3.42, wpb=62051, bsz=1979.7, num_updates=48200, lr=0.000455488, gnorm=0.941, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:19:33 | INFO | train_inner | epoch 025:    710 / 1983 loss=3.674, nll_loss=1.521, word_ins=3.316, length=3.583, ppl=12.77, wps=211145, ups=3.42, wpb=61660.7, bsz=2013.4, num_updates=48300, lr=0.000455016, gnorm=0.935, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:20:03 | INFO | train_inner | epoch 025:    810 / 1983 loss=3.701, nll_loss=1.543, word_ins=3.336, length=3.646, ppl=13, wps=210468, ups=3.41, wpb=61799, bsz=2042.1, num_updates=48400, lr=0.000454545, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:20:32 | INFO | train_inner | epoch 025:    910 / 1983 loss=3.725, nll_loss=1.564, word_ins=3.355, length=3.695, ppl=13.22, wps=209785, ups=3.41, wpb=61602.2, bsz=2008.4, num_updates=48500, lr=0.000454077, gnorm=0.942, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:21:01 | INFO | train_inner | epoch 025:   1010 / 1983 loss=3.716, nll_loss=1.555, word_ins=3.347, length=3.69, ppl=13.14, wps=211168, ups=3.42, wpb=61718, bsz=1962.6, num_updates=48600, lr=0.000453609, gnorm=0.934, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:21:30 | INFO | train_inner | epoch 025:   1110 / 1983 loss=3.651, nll_loss=1.496, word_ins=3.293, length=3.581, ppl=12.56, wps=212009, ups=3.41, wpb=62162.2, bsz=2096, num_updates=48700, lr=0.000453143, gnorm=0.922, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:22:00 | INFO | train_inner | epoch 025:   1210 / 1983 loss=3.72, nll_loss=1.565, word_ins=3.356, length=3.644, ppl=13.18, wps=211142, ups=3.41, wpb=61870.4, bsz=2011.4, num_updates=48800, lr=0.000452679, gnorm=0.934, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:22:29 | INFO | train_inner | epoch 025:   1310 / 1983 loss=3.701, nll_loss=1.538, word_ins=3.331, length=3.698, ppl=13, wps=210375, ups=3.42, wpb=61478.4, bsz=2039.8, num_updates=48900, lr=0.000452216, gnorm=0.927, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:22:58 | INFO | train_inner | epoch 025:   1410 / 1983 loss=3.747, nll_loss=1.582, word_ins=3.371, length=3.756, ppl=13.42, wps=209982, ups=3.43, wpb=61303.1, bsz=1884.3, num_updates=49000, lr=0.000451754, gnorm=0.948, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:23:27 | INFO | train_inner | epoch 025:   1510 / 1983 loss=3.691, nll_loss=1.532, word_ins=3.325, length=3.658, ppl=12.91, wps=211577, ups=3.42, wpb=61917.2, bsz=2045.2, num_updates=49100, lr=0.000451294, gnorm=0.934, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:23:57 | INFO | train_inner | epoch 025:   1610 / 1983 loss=3.672, nll_loss=1.516, word_ins=3.311, length=3.612, ppl=12.75, wps=210643, ups=3.42, wpb=61588, bsz=2071, num_updates=49200, lr=0.000450835, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:24:26 | INFO | train_inner | epoch 025:   1710 / 1983 loss=3.733, nll_loss=1.567, word_ins=3.358, length=3.759, ppl=13.3, wps=209390, ups=3.44, wpb=60921.6, bsz=1979.1, num_updates=49300, lr=0.000450377, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:24:55 | INFO | train_inner | epoch 025:   1810 / 1983 loss=3.757, nll_loss=1.592, word_ins=3.379, length=3.784, ppl=13.52, wps=209930, ups=3.41, wpb=61507.6, bsz=1929.1, num_updates=49400, lr=0.000449921, gnorm=0.983, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:25:25 | INFO | train_inner | epoch 025:   1910 / 1983 loss=3.666, nll_loss=1.514, word_ins=3.309, length=3.57, ppl=12.69, wps=210083, ups=3.4, wpb=61878.5, bsz=2107.2, num_updates=49500, lr=0.000449467, gnorm=1.024, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 22:26:00 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.58 | nll_loss 1.362 | word_ins 3.238 | length 3.416 | ppl 11.96 | wps 86550.4 | wpb 41551 | bsz 1500 | num_updates 49573 | best_loss 3.58
2023-03-01 22:26:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 22:26:15 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint25.pt (epoch 25 @ 49573 updates, score 3.58) (writing took 14.489145721076056 seconds)
2023-03-01 22:26:15 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-03-01 22:26:15 | INFO | train | epoch 025 | loss 3.709 | nll_loss 1.55 | word_ins 3.342 | length 3.673 | ppl 13.08 | wps 196636 | ups 3.19 | wpb 61630 | bsz 1998 | num_updates 49573 | lr 0.000449136 | gnorm 0.945 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 22:26:15 | INFO | fairseq.trainer | begin training epoch 26
2023-03-01 22:26:34 | INFO | train_inner | epoch 026:     27 / 1983 loss=3.717, nll_loss=1.559, word_ins=3.35, length=3.666, ppl=13.15, wps=88229.2, ups=1.45, wpb=60944.3, bsz=1913.4, num_updates=49600, lr=0.000449013, gnorm=0.939, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:27:03 | INFO | train_inner | epoch 026:    127 / 1983 loss=3.655, nll_loss=1.497, word_ins=3.294, length=3.61, ppl=12.6, wps=210235, ups=3.4, wpb=61887.4, bsz=2026.9, num_updates=49700, lr=0.000448561, gnorm=0.931, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:27:32 | INFO | train_inner | epoch 026:    227 / 1983 loss=3.67, nll_loss=1.511, word_ins=3.307, length=3.631, ppl=12.73, wps=209562, ups=3.41, wpb=61498.5, bsz=2099.3, num_updates=49800, lr=0.000448111, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:28:02 | INFO | train_inner | epoch 026:    327 / 1983 loss=3.684, nll_loss=1.523, word_ins=3.318, length=3.661, ppl=12.85, wps=210516, ups=3.41, wpb=61704, bsz=2001.4, num_updates=49900, lr=0.000447661, gnorm=0.92, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:28:31 | INFO | train_inner | epoch 026:    427 / 1983 loss=3.697, nll_loss=1.539, word_ins=3.332, length=3.651, ppl=12.97, wps=209774, ups=3.41, wpb=61434.2, bsz=1983.3, num_updates=50000, lr=0.000447214, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:29:00 | INFO | train_inner | epoch 026:    527 / 1983 loss=3.701, nll_loss=1.539, word_ins=3.331, length=3.702, ppl=13.01, wps=211601, ups=3.43, wpb=61756.8, bsz=1929, num_updates=50100, lr=0.000446767, gnorm=0.951, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:29:30 | INFO | train_inner | epoch 026:    627 / 1983 loss=3.705, nll_loss=1.545, word_ins=3.337, length=3.681, ppl=13.04, wps=212144, ups=3.4, wpb=62346.5, bsz=1953.8, num_updates=50200, lr=0.000446322, gnorm=0.952, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:29:59 | INFO | train_inner | epoch 026:    727 / 1983 loss=3.656, nll_loss=1.494, word_ins=3.29, length=3.659, ppl=12.61, wps=211457, ups=3.41, wpb=61925.4, bsz=2069.3, num_updates=50300, lr=0.000445878, gnorm=0.916, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:30:28 | INFO | train_inner | epoch 026:    827 / 1983 loss=3.683, nll_loss=1.521, word_ins=3.316, length=3.668, ppl=12.84, wps=212851, ups=3.43, wpb=62121.3, bsz=1958.6, num_updates=50400, lr=0.000445435, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:30:57 | INFO | train_inner | epoch 026:    927 / 1983 loss=3.721, nll_loss=1.559, word_ins=3.349, length=3.716, ppl=13.19, wps=209293, ups=3.42, wpb=61279.1, bsz=1955.4, num_updates=50500, lr=0.000444994, gnorm=0.947, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:31:27 | INFO | train_inner | epoch 026:   1027 / 1983 loss=3.658, nll_loss=1.503, word_ins=3.299, length=3.594, ppl=12.62, wps=210649, ups=3.42, wpb=61572.3, bsz=2043.9, num_updates=50600, lr=0.000444554, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:31:56 | INFO | train_inner | epoch 026:   1127 / 1983 loss=3.724, nll_loss=1.563, word_ins=3.353, length=3.71, ppl=13.21, wps=210727, ups=3.44, wpb=61261.7, bsz=1881.3, num_updates=50700, lr=0.000444116, gnorm=0.953, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:32:25 | INFO | train_inner | epoch 026:   1227 / 1983 loss=3.658, nll_loss=1.499, word_ins=3.295, length=3.63, ppl=12.62, wps=207582, ups=3.39, wpb=61160.8, bsz=2105.4, num_updates=50800, lr=0.000443678, gnorm=0.911, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:32:54 | INFO | train_inner | epoch 026:   1327 / 1983 loss=3.711, nll_loss=1.545, word_ins=3.337, length=3.744, ppl=13.1, wps=209583, ups=3.42, wpb=61225.3, bsz=1953, num_updates=50900, lr=0.000443242, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:33:24 | INFO | train_inner | epoch 026:   1427 / 1983 loss=3.672, nll_loss=1.51, word_ins=3.305, length=3.667, ppl=12.74, wps=209910, ups=3.4, wpb=61771, bsz=2015.8, num_updates=51000, lr=0.000442807, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:33:53 | INFO | train_inner | epoch 026:   1527 / 1983 loss=3.702, nll_loss=1.549, word_ins=3.339, length=3.627, ppl=13.02, wps=210746, ups=3.41, wpb=61722.1, bsz=2001.4, num_updates=51100, lr=0.000442374, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:34:22 | INFO | train_inner | epoch 026:   1627 / 1983 loss=3.701, nll_loss=1.539, word_ins=3.331, length=3.703, ppl=13.01, wps=211105, ups=3.42, wpb=61751.6, bsz=1943.5, num_updates=51200, lr=0.000441942, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:34:52 | INFO | train_inner | epoch 026:   1727 / 1983 loss=3.688, nll_loss=1.524, word_ins=3.318, length=3.7, ppl=12.88, wps=211764, ups=3.43, wpb=61819.1, bsz=1968.9, num_updates=51300, lr=0.000441511, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:35:21 | INFO | train_inner | epoch 026:   1827 / 1983 loss=3.651, nll_loss=1.491, word_ins=3.287, length=3.635, ppl=12.56, wps=210785, ups=3.43, wpb=61489, bsz=2043.3, num_updates=51400, lr=0.000441081, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:35:50 | INFO | train_inner | epoch 026:   1927 / 1983 loss=3.643, nll_loss=1.48, word_ins=3.277, length=3.657, ppl=12.49, wps=211782, ups=3.43, wpb=61759.8, bsz=2052.5, num_updates=51500, lr=0.000440653, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 22:36:21 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.563 | nll_loss 1.348 | word_ins 3.222 | length 3.409 | ppl 11.82 | wps 109496 | wpb 41551 | bsz 1500 | num_updates 51556 | best_loss 3.563
2023-03-01 22:36:21 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 22:36:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint26.pt (epoch 26 @ 51556 updates, score 3.563) (writing took 10.24944795796182 seconds)
2023-03-01 22:36:31 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-03-01 22:36:31 | INFO | train | epoch 026 | loss 3.683 | nll_loss 1.522 | word_ins 3.316 | length 3.664 | ppl 12.84 | wps 198230 | ups 3.22 | wpb 61628.5 | bsz 1997.6 | num_updates 51556 | lr 0.000440413 | gnorm 0.924 | loss_scale 16384 | train_wall 578 | wall 0
2023-03-01 22:36:31 | INFO | fairseq.trainer | begin training epoch 27
2023-03-01 22:36:54 | INFO | train_inner | epoch 027:     44 / 1983 loss=3.66, nll_loss=1.501, word_ins=3.297, length=3.632, ppl=12.64, wps=95274.4, ups=1.56, wpb=61198.3, bsz=1981.4, num_updates=51600, lr=0.000440225, gnorm=0.936, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:37:24 | INFO | train_inner | epoch 027:    144 / 1983 loss=3.647, nll_loss=1.489, word_ins=3.287, length=3.606, ppl=12.53, wps=210145, ups=3.4, wpb=61838.5, bsz=2033.3, num_updates=51700, lr=0.000439799, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:37:53 | INFO | train_inner | epoch 027:    244 / 1983 loss=3.638, nll_loss=1.477, word_ins=3.275, length=3.63, ppl=12.45, wps=211956, ups=3.42, wpb=62027.8, bsz=2083, num_updates=51800, lr=0.000439375, gnorm=0.9, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:38:22 | INFO | train_inner | epoch 027:    344 / 1983 loss=3.663, nll_loss=1.498, word_ins=3.294, length=3.682, ppl=12.66, wps=210644, ups=3.41, wpb=61730.5, bsz=2012.1, num_updates=51900, lr=0.000438951, gnorm=0.92, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:38:51 | INFO | train_inner | epoch 027:    444 / 1983 loss=3.635, nll_loss=1.472, word_ins=3.271, length=3.64, ppl=12.42, wps=211011, ups=3.42, wpb=61630.6, bsz=1989.8, num_updates=52000, lr=0.000438529, gnorm=0.903, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:39:20 | INFO | train_inner | epoch 027:    544 / 1983 loss=3.658, nll_loss=1.5, word_ins=3.296, length=3.624, ppl=12.62, wps=212793, ups=3.43, wpb=61966.3, bsz=1937.3, num_updates=52100, lr=0.000438108, gnorm=0.907, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:39:50 | INFO | train_inner | epoch 027:    644 / 1983 loss=3.641, nll_loss=1.485, word_ins=3.282, length=3.593, ppl=12.48, wps=209344, ups=3.42, wpb=61205.6, bsz=2014.1, num_updates=52200, lr=0.000437688, gnorm=0.9, loss_scale=32768, train_wall=29, wall=0
2023-03-01 22:39:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-01 22:40:20 | INFO | train_inner | epoch 027:    745 / 1983 loss=3.685, nll_loss=1.525, word_ins=3.318, length=3.669, ppl=12.86, wps=208032, ups=3.36, wpb=61906.7, bsz=1981, num_updates=52300, lr=0.000437269, gnorm=0.914, loss_scale=16384, train_wall=30, wall=0
2023-03-01 22:40:49 | INFO | train_inner | epoch 027:    845 / 1983 loss=3.645, nll_loss=1.492, word_ins=3.288, length=3.568, ppl=12.51, wps=210048, ups=3.42, wpb=61392.3, bsz=2032, num_updates=52400, lr=0.000436852, gnorm=0.927, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:41:18 | INFO | train_inner | epoch 027:    945 / 1983 loss=3.612, nll_loss=1.456, word_ins=3.255, length=3.572, ppl=12.23, wps=209838, ups=3.4, wpb=61711.1, bsz=2125.6, num_updates=52500, lr=0.000436436, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:41:47 | INFO | train_inner | epoch 027:   1045 / 1983 loss=3.683, nll_loss=1.518, word_ins=3.312, length=3.71, ppl=12.84, wps=209379, ups=3.43, wpb=61090.4, bsz=1922.9, num_updates=52600, lr=0.000436021, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:42:17 | INFO | train_inner | epoch 027:   1145 / 1983 loss=3.679, nll_loss=1.518, word_ins=3.312, length=3.676, ppl=12.81, wps=209632, ups=3.41, wpb=61561, bsz=1981.5, num_updates=52700, lr=0.000435607, gnorm=0.927, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:42:46 | INFO | train_inner | epoch 027:   1245 / 1983 loss=3.669, nll_loss=1.512, word_ins=3.306, length=3.635, ppl=12.72, wps=211330, ups=3.42, wpb=61763, bsz=1968.3, num_updates=52800, lr=0.000435194, gnorm=0.924, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:43:15 | INFO | train_inner | epoch 027:   1345 / 1983 loss=3.634, nll_loss=1.476, word_ins=3.273, length=3.613, ppl=12.41, wps=212346, ups=3.43, wpb=61842.8, bsz=2002, num_updates=52900, lr=0.000434783, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:43:44 | INFO | train_inner | epoch 027:   1445 / 1983 loss=3.673, nll_loss=1.504, word_ins=3.299, length=3.742, ppl=12.75, wps=210388, ups=3.43, wpb=61325.9, bsz=1987.2, num_updates=53000, lr=0.000434372, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:44:13 | INFO | train_inner | epoch 027:   1545 / 1983 loss=3.641, nll_loss=1.476, word_ins=3.273, length=3.675, ppl=12.47, wps=211337, ups=3.44, wpb=61520, bsz=2028.1, num_updates=53100, lr=0.000433963, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:44:43 | INFO | train_inner | epoch 027:   1645 / 1983 loss=3.668, nll_loss=1.508, word_ins=3.302, length=3.659, ppl=12.71, wps=211079, ups=3.42, wpb=61648.9, bsz=1974.1, num_updates=53200, lr=0.000433555, gnorm=0.925, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:45:12 | INFO | train_inner | epoch 027:   1745 / 1983 loss=3.635, nll_loss=1.475, word_ins=3.273, length=3.621, ppl=12.42, wps=211174, ups=3.41, wpb=61856.8, bsz=1987.5, num_updates=53300, lr=0.000433148, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:45:41 | INFO | train_inner | epoch 027:   1845 / 1983 loss=3.708, nll_loss=1.542, word_ins=3.332, length=3.759, ppl=13.07, wps=211886, ups=3.43, wpb=61799.9, bsz=1882.7, num_updates=53400, lr=0.000432742, gnorm=0.93, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:46:10 | INFO | train_inner | epoch 027:   1945 / 1983 loss=3.668, nll_loss=1.508, word_ins=3.301, length=3.668, ppl=12.71, wps=211358, ups=3.43, wpb=61588.6, bsz=1959.6, num_updates=53500, lr=0.000432338, gnorm=0.913, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 22:46:36 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.556 | nll_loss 1.334 | word_ins 3.205 | length 3.51 | ppl 11.76 | wps 99985.4 | wpb 41551 | bsz 1500 | num_updates 53538 | best_loss 3.556
2023-03-01 22:46:36 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 22:46:49 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint27.pt (epoch 27 @ 53538 updates, score 3.556) (writing took 12.203321879031137 seconds)
2023-03-01 22:46:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-03-01 22:46:49 | INFO | train | epoch 027 | loss 3.656 | nll_loss 1.496 | word_ins 3.291 | length 3.649 | ppl 12.61 | wps 197844 | ups 3.21 | wpb 61632.9 | bsz 1998 | num_updates 53538 | lr 0.000432184 | gnorm 0.913 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 22:46:49 | INFO | fairseq.trainer | begin training epoch 28
2023-03-01 22:47:20 | INFO | train_inner | epoch 028:     62 / 1983 loss=3.595, nll_loss=1.441, word_ins=3.241, length=3.539, ppl=12.08, wps=88171.3, ups=1.43, wpb=61661.3, bsz=2033, num_updates=53600, lr=0.000431934, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:47:50 | INFO | train_inner | epoch 028:    162 / 1983 loss=3.66, nll_loss=1.497, word_ins=3.293, length=3.672, ppl=12.64, wps=208813, ups=3.4, wpb=61432.2, bsz=1947.4, num_updates=53700, lr=0.000431532, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:48:19 | INFO | train_inner | epoch 028:    262 / 1983 loss=3.658, nll_loss=1.491, word_ins=3.287, length=3.705, ppl=12.62, wps=210857, ups=3.42, wpb=61584, bsz=1944.1, num_updates=53800, lr=0.000431131, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:48:48 | INFO | train_inner | epoch 028:    362 / 1983 loss=3.621, nll_loss=1.465, word_ins=3.263, length=3.576, ppl=12.3, wps=211705, ups=3.41, wpb=62063.2, bsz=2072.2, num_updates=53900, lr=0.00043073, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:49:17 | INFO | train_inner | epoch 028:    462 / 1983 loss=3.648, nll_loss=1.49, word_ins=3.286, length=3.623, ppl=12.54, wps=211760, ups=3.42, wpb=61923.9, bsz=2004.2, num_updates=54000, lr=0.000430331, gnorm=0.948, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:49:47 | INFO | train_inner | epoch 028:    562 / 1983 loss=3.665, nll_loss=1.5, word_ins=3.295, length=3.702, ppl=12.68, wps=210262, ups=3.41, wpb=61636.5, bsz=1951.8, num_updates=54100, lr=0.000429934, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:50:16 | INFO | train_inner | epoch 028:    662 / 1983 loss=3.63, nll_loss=1.464, word_ins=3.263, length=3.671, ppl=12.38, wps=212218, ups=3.42, wpb=61962.8, bsz=1983.9, num_updates=54200, lr=0.000429537, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:50:45 | INFO | train_inner | epoch 028:    762 / 1983 loss=3.629, nll_loss=1.474, word_ins=3.271, length=3.582, ppl=12.37, wps=209558, ups=3.41, wpb=61409.1, bsz=2052.7, num_updates=54300, lr=0.000429141, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:51:14 | INFO | train_inner | epoch 028:    862 / 1983 loss=3.624, nll_loss=1.468, word_ins=3.265, length=3.585, ppl=12.33, wps=211863, ups=3.43, wpb=61763.1, bsz=2061.8, num_updates=54400, lr=0.000428746, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:51:43 | INFO | train_inner | epoch 028:    962 / 1983 loss=3.643, nll_loss=1.476, word_ins=3.273, length=3.702, ppl=12.49, wps=208932, ups=3.45, wpb=60626.5, bsz=1982.6, num_updates=54500, lr=0.000428353, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:52:12 | INFO | train_inner | epoch 028:   1062 / 1983 loss=3.617, nll_loss=1.46, word_ins=3.258, length=3.584, ppl=12.27, wps=212028, ups=3.43, wpb=61897.8, bsz=2023.1, num_updates=54600, lr=0.00042796, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:52:42 | INFO | train_inner | epoch 028:   1162 / 1983 loss=3.635, nll_loss=1.474, word_ins=3.271, length=3.639, ppl=12.42, wps=211718, ups=3.42, wpb=61889.1, bsz=1996.4, num_updates=54700, lr=0.000427569, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:53:11 | INFO | train_inner | epoch 028:   1262 / 1983 loss=3.612, nll_loss=1.454, word_ins=3.253, length=3.594, ppl=12.23, wps=212438, ups=3.42, wpb=62116.4, bsz=1975.4, num_updates=54800, lr=0.000427179, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:53:40 | INFO | train_inner | epoch 028:   1362 / 1983 loss=3.644, nll_loss=1.477, word_ins=3.273, length=3.705, ppl=12.5, wps=209825, ups=3.42, wpb=61432.2, bsz=1995.9, num_updates=54900, lr=0.00042679, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:54:09 | INFO | train_inner | epoch 028:   1462 / 1983 loss=3.637, nll_loss=1.47, word_ins=3.267, length=3.701, ppl=12.44, wps=211020, ups=3.43, wpb=61440.2, bsz=1979.2, num_updates=55000, lr=0.000426401, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:54:39 | INFO | train_inner | epoch 028:   1562 / 1983 loss=3.595, nll_loss=1.437, word_ins=3.237, length=3.581, ppl=12.08, wps=210869, ups=3.42, wpb=61694.8, bsz=2019, num_updates=55100, lr=0.000426014, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:55:08 | INFO | train_inner | epoch 028:   1662 / 1983 loss=3.632, nll_loss=1.472, word_ins=3.269, length=3.628, ppl=12.39, wps=212310, ups=3.42, wpb=62118, bsz=1991.6, num_updates=55200, lr=0.000425628, gnorm=0.943, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:55:37 | INFO | train_inner | epoch 028:   1762 / 1983 loss=3.637, nll_loss=1.474, word_ins=3.27, length=3.668, ppl=12.44, wps=210022, ups=3.43, wpb=61220.1, bsz=1971.1, num_updates=55300, lr=0.000425243, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:56:06 | INFO | train_inner | epoch 028:   1862 / 1983 loss=3.641, nll_loss=1.482, word_ins=3.278, length=3.627, ppl=12.47, wps=210153, ups=3.41, wpb=61552, bsz=2005.4, num_updates=55400, lr=0.000424859, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:56:36 | INFO | train_inner | epoch 028:   1962 / 1983 loss=3.652, nll_loss=1.49, word_ins=3.285, length=3.665, ppl=12.57, wps=208859, ups=3.42, wpb=61124.7, bsz=1982.5, num_updates=55500, lr=0.000424476, gnorm=0.908, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 22:56:59 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.517 | nll_loss 1.3 | word_ins 3.177 | length 3.402 | ppl 11.45 | wps 135257 | wpb 41551 | bsz 1500 | num_updates 55521 | best_loss 3.517
2023-03-01 22:56:59 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 22:57:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint28.pt (epoch 28 @ 55521 updates, score 3.517) (writing took 12.098682514042594 seconds)
2023-03-01 22:57:11 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-03-01 22:57:11 | INFO | train | epoch 028 | loss 3.633 | nll_loss 1.472 | word_ins 3.269 | length 3.636 | ppl 12.41 | wps 196497 | ups 3.19 | wpb 61628.5 | bsz 1997.6 | num_updates 55521 | lr 0.000424396 | gnorm 0.904 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 22:57:11 | INFO | fairseq.trainer | begin training epoch 29
2023-03-01 22:57:44 | INFO | train_inner | epoch 029:     79 / 1983 loss=3.597, nll_loss=1.438, word_ins=3.239, length=3.578, ppl=12.1, wps=88644.1, ups=1.46, wpb=60853.3, bsz=2024.9, num_updates=55600, lr=0.000424094, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:58:14 | INFO | train_inner | epoch 029:    179 / 1983 loss=3.598, nll_loss=1.439, word_ins=3.239, length=3.586, ppl=12.11, wps=209993, ups=3.41, wpb=61613.9, bsz=2014.7, num_updates=55700, lr=0.000423714, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:58:43 | INFO | train_inner | epoch 029:    279 / 1983 loss=3.611, nll_loss=1.45, word_ins=3.249, length=3.621, ppl=12.22, wps=209263, ups=3.41, wpb=61300.7, bsz=2007, num_updates=55800, lr=0.000423334, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:59:12 | INFO | train_inner | epoch 029:    379 / 1983 loss=3.612, nll_loss=1.451, word_ins=3.25, length=3.619, ppl=12.23, wps=210964, ups=3.41, wpb=61941.3, bsz=2002.9, num_updates=55900, lr=0.000422955, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-01 22:59:41 | INFO | train_inner | epoch 029:    479 / 1983 loss=3.607, nll_loss=1.445, word_ins=3.245, length=3.623, ppl=12.18, wps=212598, ups=3.42, wpb=62096.2, bsz=1967.3, num_updates=56000, lr=0.000422577, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:00:11 | INFO | train_inner | epoch 029:    579 / 1983 loss=3.668, nll_loss=1.501, word_ins=3.295, length=3.728, ppl=12.71, wps=210104, ups=3.44, wpb=61108.5, bsz=1917.9, num_updates=56100, lr=0.0004222, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:00:40 | INFO | train_inner | epoch 029:    679 / 1983 loss=3.618, nll_loss=1.455, word_ins=3.253, length=3.647, ppl=12.28, wps=210855, ups=3.43, wpb=61559.1, bsz=1948.2, num_updates=56200, lr=0.000421825, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:01:09 | INFO | train_inner | epoch 029:    779 / 1983 loss=3.628, nll_loss=1.467, word_ins=3.265, length=3.633, ppl=12.36, wps=210993, ups=3.42, wpb=61772, bsz=1977.6, num_updates=56300, lr=0.00042145, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:01:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-01 23:01:39 | INFO | train_inner | epoch 029:    880 / 1983 loss=3.582, nll_loss=1.424, word_ins=3.225, length=3.573, ppl=11.98, wps=208942, ups=3.38, wpb=61789, bsz=2046.6, num_updates=56400, lr=0.000421076, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:02:08 | INFO | train_inner | epoch 029:    980 / 1983 loss=3.632, nll_loss=1.472, word_ins=3.269, length=3.633, ppl=12.4, wps=210718, ups=3.43, wpb=61504.5, bsz=1992.4, num_updates=56500, lr=0.000420703, gnorm=0.959, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:02:37 | INFO | train_inner | epoch 029:   1080 / 1983 loss=3.603, nll_loss=1.448, word_ins=3.246, length=3.565, ppl=12.15, wps=211355, ups=3.42, wpb=61756.9, bsz=2055.2, num_updates=56600, lr=0.000420331, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:03:06 | INFO | train_inner | epoch 029:   1180 / 1983 loss=3.612, nll_loss=1.455, word_ins=3.253, length=3.588, ppl=12.23, wps=212936, ups=3.44, wpb=61817.6, bsz=1912.2, num_updates=56700, lr=0.000419961, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:03:35 | INFO | train_inner | epoch 029:   1280 / 1983 loss=3.596, nll_loss=1.436, word_ins=3.236, length=3.599, ppl=12.09, wps=212386, ups=3.44, wpb=61704.2, bsz=1971, num_updates=56800, lr=0.000419591, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:04:04 | INFO | train_inner | epoch 029:   1380 / 1983 loss=3.63, nll_loss=1.467, word_ins=3.264, length=3.661, ppl=12.38, wps=212228, ups=3.43, wpb=61827.3, bsz=1976.2, num_updates=56900, lr=0.000419222, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:04:34 | INFO | train_inner | epoch 029:   1480 / 1983 loss=3.605, nll_loss=1.448, word_ins=3.246, length=3.589, ppl=12.17, wps=210310, ups=3.41, wpb=61635.9, bsz=2045.7, num_updates=57000, lr=0.000418854, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:05:03 | INFO | train_inner | epoch 029:   1580 / 1983 loss=3.659, nll_loss=1.49, word_ins=3.285, length=3.739, ppl=12.63, wps=208910, ups=3.41, wpb=61194.8, bsz=1966.8, num_updates=57100, lr=0.000418487, gnorm=0.922, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:05:32 | INFO | train_inner | epoch 029:   1680 / 1983 loss=3.607, nll_loss=1.448, word_ins=3.246, length=3.611, ppl=12.19, wps=211214, ups=3.43, wpb=61639.3, bsz=1998.4, num_updates=57200, lr=0.000418121, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:06:01 | INFO | train_inner | epoch 029:   1780 / 1983 loss=3.589, nll_loss=1.428, word_ins=3.228, length=3.604, ppl=12.03, wps=212974, ups=3.43, wpb=62055.4, bsz=2036, num_updates=57300, lr=0.000417756, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:06:30 | INFO | train_inner | epoch 029:   1880 / 1983 loss=3.577, nll_loss=1.427, word_ins=3.227, length=3.496, ppl=11.93, wps=211479, ups=3.43, wpb=61727.3, bsz=2106, num_updates=57400, lr=0.000417392, gnorm=0.923, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:07:00 | INFO | train_inner | epoch 029:   1980 / 1983 loss=3.602, nll_loss=1.441, word_ins=3.24, length=3.613, ppl=12.14, wps=211816, ups=3.43, wpb=61740, bsz=2043.8, num_updates=57500, lr=0.000417029, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 23:07:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.499 | nll_loss 1.279 | word_ins 3.149 | length 3.501 | ppl 11.3 | wps 82616.7 | wpb 41551 | bsz 1500 | num_updates 57503 | best_loss 3.499
2023-03-01 23:07:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 23:07:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint29.pt (epoch 29 @ 57503 updates, score 3.499) (writing took 10.498467992059886 seconds)
2023-03-01 23:07:25 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-03-01 23:07:25 | INFO | train | epoch 029 | loss 3.613 | nll_loss 1.452 | word_ins 3.251 | length 3.618 | ppl 12.23 | wps 198762 | ups 3.23 | wpb 61627.1 | bsz 1997.7 | num_updates 57503 | lr 0.000417018 | gnorm 0.899 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 23:07:25 | INFO | fairseq.trainer | begin training epoch 30
2023-03-01 23:08:07 | INFO | train_inner | epoch 030:     97 / 1983 loss=3.568, nll_loss=1.406, word_ins=3.209, length=3.592, ppl=11.86, wps=90865, ups=1.49, wpb=60994.5, bsz=2054.5, num_updates=57600, lr=0.000416667, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:08:36 | INFO | train_inner | epoch 030:    197 / 1983 loss=3.609, nll_loss=1.443, word_ins=3.242, length=3.669, ppl=12.2, wps=211465, ups=3.43, wpb=61708.9, bsz=1926.7, num_updates=57700, lr=0.000416305, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:09:05 | INFO | train_inner | epoch 030:    297 / 1983 loss=3.549, nll_loss=1.395, word_ins=3.199, length=3.5, ppl=11.7, wps=210162, ups=3.39, wpb=62061.4, bsz=2064, num_updates=57800, lr=0.000415945, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:09:35 | INFO | train_inner | epoch 030:    397 / 1983 loss=3.589, nll_loss=1.431, word_ins=3.231, length=3.578, ppl=12.03, wps=205689, ups=3.36, wpb=61144.5, bsz=2055.4, num_updates=57900, lr=0.000415586, gnorm=0.884, loss_scale=16384, train_wall=30, wall=0
2023-03-01 23:10:04 | INFO | train_inner | epoch 030:    497 / 1983 loss=3.591, nll_loss=1.432, word_ins=3.232, length=3.585, ppl=12.05, wps=210155, ups=3.42, wpb=61521.1, bsz=1982.4, num_updates=58000, lr=0.000415227, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:10:34 | INFO | train_inner | epoch 030:    597 / 1983 loss=3.601, nll_loss=1.437, word_ins=3.237, length=3.644, ppl=12.14, wps=210821, ups=3.41, wpb=61867.6, bsz=1949.9, num_updates=58100, lr=0.00041487, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:11:03 | INFO | train_inner | epoch 030:    697 / 1983 loss=3.613, nll_loss=1.448, word_ins=3.247, length=3.662, ppl=12.23, wps=210009, ups=3.4, wpb=61737.4, bsz=2020.9, num_updates=58200, lr=0.000414513, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:11:33 | INFO | train_inner | epoch 030:    797 / 1983 loss=3.607, nll_loss=1.452, word_ins=3.25, length=3.578, ppl=12.19, wps=210320, ups=3.4, wpb=61897.4, bsz=2002.2, num_updates=58300, lr=0.000414158, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:12:02 | INFO | train_inner | epoch 030:    897 / 1983 loss=3.617, nll_loss=1.457, word_ins=3.255, length=3.627, ppl=12.27, wps=212928, ups=3.43, wpb=62046.3, bsz=1892, num_updates=58400, lr=0.000413803, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:12:31 | INFO | train_inner | epoch 030:    997 / 1983 loss=3.591, nll_loss=1.431, word_ins=3.231, length=3.595, ppl=12.05, wps=211263, ups=3.42, wpb=61852.2, bsz=2025.8, num_updates=58500, lr=0.000413449, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:13:00 | INFO | train_inner | epoch 030:   1097 / 1983 loss=3.58, nll_loss=1.419, word_ins=3.22, length=3.599, ppl=11.96, wps=212274, ups=3.43, wpb=61880.5, bsz=1963.7, num_updates=58600, lr=0.000413096, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:13:29 | INFO | train_inner | epoch 030:   1197 / 1983 loss=3.612, nll_loss=1.449, word_ins=3.247, length=3.646, ppl=12.22, wps=208347, ups=3.41, wpb=61014, bsz=2014.4, num_updates=58700, lr=0.000412744, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:13:59 | INFO | train_inner | epoch 030:   1297 / 1983 loss=3.564, nll_loss=1.407, word_ins=3.209, length=3.551, ppl=11.83, wps=210058, ups=3.43, wpb=61302.5, bsz=2069.5, num_updates=58800, lr=0.000412393, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:14:28 | INFO | train_inner | epoch 030:   1397 / 1983 loss=3.591, nll_loss=1.43, word_ins=3.229, length=3.611, ppl=12.05, wps=208461, ups=3.4, wpb=61252.1, bsz=2019, num_updates=58900, lr=0.000412043, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:14:57 | INFO | train_inner | epoch 030:   1497 / 1983 loss=3.624, nll_loss=1.466, word_ins=3.262, length=3.626, ppl=12.33, wps=210771, ups=3.42, wpb=61664.3, bsz=1933.3, num_updates=59000, lr=0.000411693, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:15:27 | INFO | train_inner | epoch 030:   1597 / 1983 loss=3.595, nll_loss=1.433, word_ins=3.232, length=3.626, ppl=12.08, wps=208198, ups=3.41, wpb=61016.2, bsz=2053.4, num_updates=59100, lr=0.000411345, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:15:56 | INFO | train_inner | epoch 030:   1697 / 1983 loss=3.581, nll_loss=1.426, word_ins=3.226, length=3.546, ppl=11.96, wps=212183, ups=3.42, wpb=61997.2, bsz=2019, num_updates=59200, lr=0.000410997, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:16:25 | INFO | train_inner | epoch 030:   1797 / 1983 loss=3.598, nll_loss=1.434, word_ins=3.233, length=3.647, ppl=12.11, wps=211229, ups=3.42, wpb=61778.4, bsz=1969.4, num_updates=59300, lr=0.000410651, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:16:54 | INFO | train_inner | epoch 030:   1897 / 1983 loss=3.601, nll_loss=1.437, word_ins=3.235, length=3.66, ppl=12.14, wps=211121, ups=3.43, wpb=61518.6, bsz=1944.2, num_updates=59400, lr=0.000410305, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 23:17:34 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.495 | nll_loss 1.276 | word_ins 3.159 | length 3.36 | ppl 11.28 | wps 88482 | wpb 41551 | bsz 1500 | num_updates 59486 | best_loss 3.495
2023-03-01 23:17:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 23:17:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint30.pt (epoch 30 @ 59486 updates, score 3.495) (writing took 10.500192950014025 seconds)
2023-03-01 23:17:44 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-03-01 23:17:44 | INFO | train | epoch 030 | loss 3.593 | nll_loss 1.433 | word_ins 3.233 | length 3.603 | ppl 12.07 | wps 197414 | ups 3.2 | wpb 61628.5 | bsz 1997.6 | num_updates 59486 | lr 0.000410008 | gnorm 0.888 | loss_scale 16384 | train_wall 578 | wall 0
2023-03-01 23:17:44 | INFO | fairseq.trainer | begin training epoch 31
2023-03-01 23:17:59 | INFO | train_inner | epoch 031:     14 / 1983 loss=3.559, nll_loss=1.408, word_ins=3.209, length=3.496, ppl=11.79, wps=94868.1, ups=1.53, wpb=61927.1, bsz=1991.7, num_updates=59500, lr=0.00040996, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:18:29 | INFO | train_inner | epoch 031:    114 / 1983 loss=3.58, nll_loss=1.419, word_ins=3.22, length=3.597, ppl=11.96, wps=211555, ups=3.41, wpb=62100.7, bsz=1973.6, num_updates=59600, lr=0.000409616, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:18:58 | INFO | train_inner | epoch 031:    214 / 1983 loss=3.553, nll_loss=1.39, word_ins=3.194, length=3.593, ppl=11.74, wps=211138, ups=3.42, wpb=61734.3, bsz=2004.9, num_updates=59700, lr=0.000409273, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:19:27 | INFO | train_inner | epoch 031:    314 / 1983 loss=3.594, nll_loss=1.432, word_ins=3.231, length=3.628, ppl=12.08, wps=210836, ups=3.42, wpb=61633.2, bsz=1922.7, num_updates=59800, lr=0.00040893, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:19:57 | INFO | train_inner | epoch 031:    414 / 1983 loss=3.556, nll_loss=1.398, word_ins=3.201, length=3.549, ppl=11.76, wps=210922, ups=3.41, wpb=61870.4, bsz=2033, num_updates=59900, lr=0.000408589, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:20:26 | INFO | train_inner | epoch 031:    514 / 1983 loss=3.606, nll_loss=1.437, word_ins=3.237, length=3.69, ppl=12.17, wps=207230, ups=3.42, wpb=60595.7, bsz=1920.5, num_updates=60000, lr=0.000408248, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:20:55 | INFO | train_inner | epoch 031:    614 / 1983 loss=3.604, nll_loss=1.439, word_ins=3.238, length=3.659, ppl=12.16, wps=210760, ups=3.41, wpb=61786.2, bsz=1927.5, num_updates=60100, lr=0.000407909, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:21:25 | INFO | train_inner | epoch 031:    714 / 1983 loss=3.581, nll_loss=1.421, word_ins=3.221, length=3.594, ppl=11.96, wps=210745, ups=3.41, wpb=61780, bsz=1999.3, num_updates=60200, lr=0.00040757, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:21:54 | INFO | train_inner | epoch 031:    814 / 1983 loss=3.567, nll_loss=1.409, word_ins=3.211, length=3.564, ppl=11.85, wps=210533, ups=3.42, wpb=61626.7, bsz=2042.4, num_updates=60300, lr=0.000407231, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:22:23 | INFO | train_inner | epoch 031:    914 / 1983 loss=3.578, nll_loss=1.418, word_ins=3.218, length=3.597, ppl=11.94, wps=211947, ups=3.42, wpb=61916.4, bsz=1969.2, num_updates=60400, lr=0.000406894, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:22:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-01 23:22:53 | INFO | train_inner | epoch 031:   1015 / 1983 loss=3.543, nll_loss=1.387, word_ins=3.19, length=3.53, ppl=11.66, wps=207578, ups=3.37, wpb=61513.6, bsz=2092.2, num_updates=60500, lr=0.000406558, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:23:22 | INFO | train_inner | epoch 031:   1115 / 1983 loss=3.544, nll_loss=1.385, word_ins=3.188, length=3.557, ppl=11.66, wps=210579, ups=3.43, wpb=61375.7, bsz=2059.2, num_updates=60600, lr=0.000406222, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:23:51 | INFO | train_inner | epoch 031:   1215 / 1983 loss=3.592, nll_loss=1.436, word_ins=3.235, length=3.572, ppl=12.06, wps=210101, ups=3.4, wpb=61735.5, bsz=1998.8, num_updates=60700, lr=0.000405887, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:24:20 | INFO | train_inner | epoch 031:   1315 / 1983 loss=3.559, nll_loss=1.4, word_ins=3.202, length=3.569, ppl=11.79, wps=210332, ups=3.41, wpb=61658.1, bsz=1992.7, num_updates=60800, lr=0.000405554, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:24:50 | INFO | train_inner | epoch 031:   1415 / 1983 loss=3.557, nll_loss=1.398, word_ins=3.2, length=3.575, ppl=11.77, wps=210384, ups=3.41, wpb=61663.5, bsz=2027, num_updates=60900, lr=0.00040522, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:25:19 | INFO | train_inner | epoch 031:   1515 / 1983 loss=3.571, nll_loss=1.412, word_ins=3.213, length=3.578, ppl=11.88, wps=211053, ups=3.41, wpb=61936.3, bsz=1973, num_updates=61000, lr=0.000404888, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:25:48 | INFO | train_inner | epoch 031:   1615 / 1983 loss=3.559, nll_loss=1.401, word_ins=3.202, length=3.561, ppl=11.78, wps=212681, ups=3.43, wpb=62020.4, bsz=2010.9, num_updates=61100, lr=0.000404557, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:26:18 | INFO | train_inner | epoch 031:   1715 / 1983 loss=3.601, nll_loss=1.436, word_ins=3.234, length=3.671, ppl=12.14, wps=210626, ups=3.42, wpb=61582.3, bsz=1985.5, num_updates=61200, lr=0.000404226, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:26:47 | INFO | train_inner | epoch 031:   1815 / 1983 loss=3.598, nll_loss=1.435, word_ins=3.233, length=3.65, ppl=12.11, wps=210555, ups=3.43, wpb=61312.2, bsz=1931.8, num_updates=61300, lr=0.000403896, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:27:16 | INFO | train_inner | epoch 031:   1915 / 1983 loss=3.548, nll_loss=1.392, word_ins=3.194, length=3.536, ppl=11.7, wps=210141, ups=3.41, wpb=61664.2, bsz=2079.8, num_updates=61400, lr=0.000403567, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 23:27:51 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.479 | nll_loss 1.264 | word_ins 3.143 | length 3.365 | ppl 11.15 | wps 100681 | wpb 41551 | bsz 1500 | num_updates 61468 | best_loss 3.479
2023-03-01 23:27:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 23:28:03 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint31.pt (epoch 31 @ 61468 updates, score 3.479) (writing took 11.881070469040424 seconds)
2023-03-01 23:28:03 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-03-01 23:28:03 | INFO | train | epoch 031 | loss 3.573 | nll_loss 1.413 | word_ins 3.214 | length 3.594 | ppl 11.9 | wps 197416 | ups 3.2 | wpb 61627.4 | bsz 1997.9 | num_updates 61468 | lr 0.000403344 | gnorm 0.881 | loss_scale 16384 | train_wall 578 | wall 0
2023-03-01 23:28:03 | INFO | fairseq.trainer | begin training epoch 32
2023-03-01 23:28:27 | INFO | train_inner | epoch 032:     32 / 1983 loss=3.584, nll_loss=1.42, word_ins=3.22, length=3.643, ppl=11.99, wps=86633.4, ups=1.42, wpb=61091.9, bsz=2016.9, num_updates=61500, lr=0.000403239, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:28:56 | INFO | train_inner | epoch 032:    132 / 1983 loss=3.551, nll_loss=1.395, word_ins=3.197, length=3.533, ppl=11.72, wps=212041, ups=3.42, wpb=62060.3, bsz=1949.1, num_updates=61600, lr=0.000402911, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:29:25 | INFO | train_inner | epoch 032:    232 / 1983 loss=3.553, nll_loss=1.397, word_ins=3.2, length=3.53, ppl=11.74, wps=210774, ups=3.4, wpb=61935.2, bsz=2006.8, num_updates=61700, lr=0.000402585, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:29:54 | INFO | train_inner | epoch 032:    332 / 1983 loss=3.554, nll_loss=1.392, word_ins=3.195, length=3.588, ppl=11.74, wps=212466, ups=3.45, wpb=61641.6, bsz=1942.1, num_updates=61800, lr=0.000402259, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:30:23 | INFO | train_inner | epoch 032:    432 / 1983 loss=3.548, nll_loss=1.385, word_ins=3.188, length=3.591, ppl=11.69, wps=209932, ups=3.43, wpb=61228.7, bsz=2033.1, num_updates=61900, lr=0.000401934, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:30:53 | INFO | train_inner | epoch 032:    532 / 1983 loss=3.572, nll_loss=1.416, word_ins=3.216, length=3.56, ppl=11.89, wps=211074, ups=3.42, wpb=61700.4, bsz=1980.1, num_updates=62000, lr=0.00040161, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:31:22 | INFO | train_inner | epoch 032:    632 / 1983 loss=3.579, nll_loss=1.419, word_ins=3.219, length=3.607, ppl=11.95, wps=209601, ups=3.41, wpb=61463.9, bsz=1943.8, num_updates=62100, lr=0.000401286, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:31:51 | INFO | train_inner | epoch 032:    732 / 1983 loss=3.578, nll_loss=1.411, word_ins=3.212, length=3.66, ppl=11.94, wps=210131, ups=3.43, wpb=61350.1, bsz=1914.4, num_updates=62200, lr=0.000400963, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:32:20 | INFO | train_inner | epoch 032:    832 / 1983 loss=3.541, nll_loss=1.384, word_ins=3.187, length=3.54, ppl=11.64, wps=209526, ups=3.42, wpb=61279.6, bsz=2044.2, num_updates=62300, lr=0.000400642, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:32:50 | INFO | train_inner | epoch 032:    932 / 1983 loss=3.559, nll_loss=1.406, word_ins=3.207, length=3.521, ppl=11.79, wps=213272, ups=3.42, wpb=62271, bsz=1958.1, num_updates=62400, lr=0.00040032, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:33:19 | INFO | train_inner | epoch 032:   1032 / 1983 loss=3.53, nll_loss=1.374, word_ins=3.178, length=3.521, ppl=11.55, wps=212600, ups=3.43, wpb=62048.2, bsz=2038.4, num_updates=62500, lr=0.0004, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:33:48 | INFO | train_inner | epoch 032:   1132 / 1983 loss=3.57, nll_loss=1.408, word_ins=3.209, length=3.61, ppl=11.88, wps=211378, ups=3.44, wpb=61495.5, bsz=2019.2, num_updates=62600, lr=0.00039968, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:34:17 | INFO | train_inner | epoch 032:   1232 / 1983 loss=3.544, nll_loss=1.387, word_ins=3.189, length=3.55, ppl=11.67, wps=211051, ups=3.41, wpb=61884.1, bsz=2032.2, num_updates=62700, lr=0.000399362, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:34:46 | INFO | train_inner | epoch 032:   1332 / 1983 loss=3.584, nll_loss=1.426, word_ins=3.225, length=3.592, ppl=11.99, wps=212098, ups=3.43, wpb=61800.5, bsz=1953.4, num_updates=62800, lr=0.000399043, gnorm=0.892, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:35:16 | INFO | train_inner | epoch 032:   1432 / 1983 loss=3.564, nll_loss=1.405, word_ins=3.206, length=3.578, ppl=11.83, wps=210143, ups=3.42, wpb=61388, bsz=2002.6, num_updates=62900, lr=0.000398726, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:35:45 | INFO | train_inner | epoch 032:   1532 / 1983 loss=3.544, nll_loss=1.386, word_ins=3.188, length=3.552, ppl=11.66, wps=212240, ups=3.44, wpb=61765.6, bsz=2041.8, num_updates=63000, lr=0.00039841, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:36:14 | INFO | train_inner | epoch 032:   1632 / 1983 loss=3.555, nll_loss=1.4, word_ins=3.201, length=3.545, ppl=11.76, wps=210823, ups=3.42, wpb=61651.6, bsz=1955, num_updates=63100, lr=0.000398094, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:36:43 | INFO | train_inner | epoch 032:   1732 / 1983 loss=3.574, nll_loss=1.411, word_ins=3.211, length=3.633, ppl=11.91, wps=210132, ups=3.42, wpb=61500.8, bsz=1968.8, num_updates=63200, lr=0.000397779, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:37:12 | INFO | train_inner | epoch 032:   1832 / 1983 loss=3.543, nll_loss=1.384, word_ins=3.187, length=3.556, ppl=11.65, wps=210298, ups=3.42, wpb=61472.8, bsz=2066.7, num_updates=63300, lr=0.000397464, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:37:42 | INFO | train_inner | epoch 032:   1932 / 1983 loss=3.542, nll_loss=1.384, word_ins=3.188, length=3.542, ppl=11.65, wps=210712, ups=3.42, wpb=61600.5, bsz=2047.8, num_updates=63400, lr=0.000397151, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 23:38:10 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.46 | nll_loss 1.247 | word_ins 3.123 | length 3.364 | ppl 11 | wps 186514 | wpb 41551 | bsz 1500 | num_updates 63451 | best_loss 3.46
2023-03-01 23:38:10 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 23:38:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint32.pt (epoch 32 @ 63451 updates, score 3.46) (writing took 11.994681191979907 seconds)
2023-03-01 23:38:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-03-01 23:38:23 | INFO | train | epoch 032 | loss 3.557 | nll_loss 1.398 | word_ins 3.2 | length 3.57 | ppl 11.77 | wps 197271 | ups 3.2 | wpb 61628.5 | bsz 1997.6 | num_updates 63451 | lr 0.000396991 | gnorm 0.878 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 23:38:23 | INFO | fairseq.trainer | begin training epoch 33
2023-03-01 23:38:48 | INFO | train_inner | epoch 033:     49 / 1983 loss=3.525, nll_loss=1.365, word_ins=3.169, length=3.554, ppl=11.51, wps=92715.7, ups=1.52, wpb=61170.4, bsz=2115.2, num_updates=63500, lr=0.000396838, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:39:17 | INFO | train_inner | epoch 033:    149 / 1983 loss=3.568, nll_loss=1.407, word_ins=3.209, length=3.59, ppl=11.86, wps=211066, ups=3.41, wpb=61966.4, bsz=1907.5, num_updates=63600, lr=0.000396526, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:39:46 | INFO | train_inner | epoch 033:    249 / 1983 loss=3.542, nll_loss=1.38, word_ins=3.184, length=3.578, ppl=11.65, wps=211330, ups=3.44, wpb=61452.2, bsz=1961.2, num_updates=63700, lr=0.000396214, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:40:16 | INFO | train_inner | epoch 033:    349 / 1983 loss=3.556, nll_loss=1.396, word_ins=3.198, length=3.581, ppl=11.76, wps=206689, ups=3.4, wpb=60860, bsz=2016.9, num_updates=63800, lr=0.000395904, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:40:45 | INFO | train_inner | epoch 033:    449 / 1983 loss=3.535, nll_loss=1.374, word_ins=3.178, length=3.574, ppl=11.59, wps=211759, ups=3.43, wpb=61792.5, bsz=2019, num_updates=63900, lr=0.000395594, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:41:14 | INFO | train_inner | epoch 033:    549 / 1983 loss=3.566, nll_loss=1.403, word_ins=3.204, length=3.617, ppl=11.84, wps=210627, ups=3.42, wpb=61659, bsz=1955.8, num_updates=64000, lr=0.000395285, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:41:43 | INFO | train_inner | epoch 033:    649 / 1983 loss=3.555, nll_loss=1.399, word_ins=3.2, length=3.541, ppl=11.75, wps=212860, ups=3.44, wpb=61919.9, bsz=1946.8, num_updates=64100, lr=0.000394976, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:42:12 | INFO | train_inner | epoch 033:    749 / 1983 loss=3.543, nll_loss=1.379, word_ins=3.182, length=3.606, ppl=11.65, wps=210665, ups=3.43, wpb=61329.7, bsz=1995.2, num_updates=64200, lr=0.000394669, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:42:41 | INFO | train_inner | epoch 033:    849 / 1983 loss=3.535, nll_loss=1.377, word_ins=3.18, length=3.555, ppl=11.59, wps=210812, ups=3.43, wpb=61423, bsz=2059.5, num_updates=64300, lr=0.000394362, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:43:10 | INFO | train_inner | epoch 033:    949 / 1983 loss=3.543, nll_loss=1.382, word_ins=3.185, length=3.584, ppl=11.66, wps=210922, ups=3.43, wpb=61518.1, bsz=1967.4, num_updates=64400, lr=0.000394055, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:43:40 | INFO | train_inner | epoch 033:   1049 / 1983 loss=3.541, nll_loss=1.386, word_ins=3.188, length=3.525, ppl=11.64, wps=212617, ups=3.42, wpb=62246.2, bsz=2010.6, num_updates=64500, lr=0.00039375, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:43:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-01 23:44:09 | INFO | train_inner | epoch 033:   1150 / 1983 loss=3.542, nll_loss=1.387, word_ins=3.189, length=3.526, ppl=11.65, wps=208890, ups=3.38, wpb=61755.2, bsz=1994.2, num_updates=64600, lr=0.000393445, gnorm=0.9, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:44:39 | INFO | train_inner | epoch 033:   1250 / 1983 loss=3.519, nll_loss=1.36, word_ins=3.164, length=3.553, ppl=11.46, wps=209239, ups=3.4, wpb=61557.4, bsz=2106.2, num_updates=64700, lr=0.000393141, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:45:08 | INFO | train_inner | epoch 033:   1350 / 1983 loss=3.572, nll_loss=1.405, word_ins=3.206, length=3.666, ppl=11.9, wps=211002, ups=3.44, wpb=61288.9, bsz=1885.5, num_updates=64800, lr=0.000392837, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:45:37 | INFO | train_inner | epoch 033:   1450 / 1983 loss=3.537, nll_loss=1.376, word_ins=3.179, length=3.58, ppl=11.61, wps=213511, ups=3.43, wpb=62324.8, bsz=2006.2, num_updates=64900, lr=0.000392534, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:46:06 | INFO | train_inner | epoch 033:   1550 / 1983 loss=3.519, nll_loss=1.365, word_ins=3.169, length=3.507, ppl=11.47, wps=209913, ups=3.43, wpb=61178, bsz=2040.4, num_updates=65000, lr=0.000392232, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:46:36 | INFO | train_inner | epoch 033:   1650 / 1983 loss=3.517, nll_loss=1.361, word_ins=3.165, length=3.518, ppl=11.45, wps=210964, ups=3.4, wpb=62053, bsz=2100.9, num_updates=65100, lr=0.000391931, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:47:05 | INFO | train_inner | epoch 033:   1750 / 1983 loss=3.548, nll_loss=1.389, word_ins=3.19, length=3.575, ppl=11.69, wps=210554, ups=3.42, wpb=61652, bsz=1974.1, num_updates=65200, lr=0.00039163, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:47:34 | INFO | train_inner | epoch 033:   1850 / 1983 loss=3.566, nll_loss=1.401, word_ins=3.202, length=3.643, ppl=11.85, wps=210811, ups=3.42, wpb=61594.3, bsz=1934.2, num_updates=65300, lr=0.00039133, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:48:03 | INFO | train_inner | epoch 033:   1950 / 1983 loss=3.532, nll_loss=1.374, word_ins=3.178, length=3.538, ppl=11.57, wps=211004, ups=3.43, wpb=61446.3, bsz=1999.8, num_updates=65400, lr=0.000391031, gnorm=0.927, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 23:48:27 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.442 | nll_loss 1.226 | word_ins 3.106 | length 3.355 | ppl 10.86 | wps 85913.1 | wpb 41551 | bsz 1500 | num_updates 65433 | best_loss 3.442
2023-03-01 23:48:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 23:48:40 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint33.pt (epoch 33 @ 65433 updates, score 3.442) (writing took 13.667829384910874 seconds)
2023-03-01 23:48:40 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-03-01 23:48:40 | INFO | train | epoch 033 | loss 3.543 | nll_loss 1.383 | word_ins 3.186 | length 3.571 | ppl 11.66 | wps 197669 | ups 3.21 | wpb 61627 | bsz 1997.7 | num_updates 65433 | lr 0.000390932 | gnorm 0.876 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 23:48:40 | INFO | fairseq.trainer | begin training epoch 34
2023-03-01 23:49:12 | INFO | train_inner | epoch 034:     67 / 1983 loss=3.523, nll_loss=1.365, word_ins=3.17, length=3.533, ppl=11.5, wps=90034.6, ups=1.46, wpb=61517.5, bsz=2030, num_updates=65500, lr=0.000390732, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:49:41 | INFO | train_inner | epoch 034:    167 / 1983 loss=3.553, nll_loss=1.393, word_ins=3.194, length=3.59, ppl=11.74, wps=207554, ups=3.41, wpb=60810.2, bsz=1948, num_updates=65600, lr=0.000390434, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:50:10 | INFO | train_inner | epoch 034:    267 / 1983 loss=3.516, nll_loss=1.355, word_ins=3.161, length=3.558, ppl=11.44, wps=209548, ups=3.42, wpb=61307.4, bsz=1975.4, num_updates=65700, lr=0.000390137, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:50:39 | INFO | train_inner | epoch 034:    367 / 1983 loss=3.506, nll_loss=1.349, word_ins=3.155, length=3.512, ppl=11.36, wps=210010, ups=3.41, wpb=61632.5, bsz=2114, num_updates=65800, lr=0.000389841, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:51:09 | INFO | train_inner | epoch 034:    467 / 1983 loss=3.519, nll_loss=1.36, word_ins=3.165, length=3.547, ppl=11.47, wps=212318, ups=3.43, wpb=61887, bsz=2000.2, num_updates=65900, lr=0.000389545, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:51:38 | INFO | train_inner | epoch 034:    567 / 1983 loss=3.525, nll_loss=1.368, word_ins=3.171, length=3.54, ppl=11.51, wps=209883, ups=3.41, wpb=61556.8, bsz=2014.6, num_updates=66000, lr=0.000389249, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:52:07 | INFO | train_inner | epoch 034:    667 / 1983 loss=3.508, nll_loss=1.349, word_ins=3.154, length=3.534, ppl=11.37, wps=210721, ups=3.4, wpb=61954.9, bsz=2063.4, num_updates=66100, lr=0.000388955, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:52:37 | INFO | train_inner | epoch 034:    767 / 1983 loss=3.512, nll_loss=1.353, word_ins=3.159, length=3.537, ppl=11.41, wps=211007, ups=3.4, wpb=62009.5, bsz=2031.8, num_updates=66200, lr=0.000388661, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:53:06 | INFO | train_inner | epoch 034:    867 / 1983 loss=3.541, nll_loss=1.379, word_ins=3.182, length=3.59, ppl=11.64, wps=211056, ups=3.43, wpb=61615.5, bsz=1967.9, num_updates=66300, lr=0.000388368, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:53:35 | INFO | train_inner | epoch 034:    967 / 1983 loss=3.532, nll_loss=1.373, word_ins=3.176, length=3.555, ppl=11.57, wps=212995, ups=3.44, wpb=61853.1, bsz=1940.2, num_updates=66400, lr=0.000388075, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:54:04 | INFO | train_inner | epoch 034:   1067 / 1983 loss=3.516, nll_loss=1.355, word_ins=3.161, length=3.555, ppl=11.44, wps=210877, ups=3.43, wpb=61427.3, bsz=2037.4, num_updates=66500, lr=0.000387783, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:54:33 | INFO | train_inner | epoch 034:   1167 / 1983 loss=3.546, nll_loss=1.385, word_ins=3.187, length=3.591, ppl=11.68, wps=210303, ups=3.42, wpb=61496.5, bsz=1937, num_updates=66600, lr=0.000387492, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:55:02 | INFO | train_inner | epoch 034:   1267 / 1983 loss=3.536, nll_loss=1.376, word_ins=3.178, length=3.582, ppl=11.6, wps=211239, ups=3.43, wpb=61525.1, bsz=1962.9, num_updates=66700, lr=0.000387202, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:55:32 | INFO | train_inner | epoch 034:   1367 / 1983 loss=3.554, nll_loss=1.401, word_ins=3.201, length=3.527, ppl=11.74, wps=211439, ups=3.43, wpb=61690.6, bsz=1913.6, num_updates=66800, lr=0.000386912, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:56:01 | INFO | train_inner | epoch 034:   1467 / 1983 loss=3.51, nll_loss=1.348, word_ins=3.153, length=3.569, ppl=11.39, wps=212504, ups=3.43, wpb=61980.5, bsz=1999.7, num_updates=66900, lr=0.000386622, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:56:30 | INFO | train_inner | epoch 034:   1567 / 1983 loss=3.526, nll_loss=1.366, word_ins=3.169, length=3.568, ppl=11.52, wps=209454, ups=3.43, wpb=61091.8, bsz=2019, num_updates=67000, lr=0.000386334, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:56:59 | INFO | train_inner | epoch 034:   1667 / 1983 loss=3.527, nll_loss=1.364, word_ins=3.167, length=3.593, ppl=11.52, wps=212131, ups=3.44, wpb=61754.6, bsz=2013.1, num_updates=67100, lr=0.000386046, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:57:28 | INFO | train_inner | epoch 034:   1767 / 1983 loss=3.511, nll_loss=1.353, word_ins=3.157, length=3.536, ppl=11.4, wps=212114, ups=3.43, wpb=61836, bsz=2020.4, num_updates=67200, lr=0.000385758, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:57:58 | INFO | train_inner | epoch 034:   1867 / 1983 loss=3.532, nll_loss=1.371, word_ins=3.174, length=3.581, ppl=11.57, wps=211761, ups=3.41, wpb=62063.3, bsz=2026.2, num_updates=67300, lr=0.000385472, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:58:27 | INFO | train_inner | epoch 034:   1967 / 1983 loss=3.518, nll_loss=1.358, word_ins=3.162, length=3.554, ppl=11.45, wps=211131, ups=3.43, wpb=61539.8, bsz=1966, num_updates=67400, lr=0.000385186, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-01 23:58:44 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.445 | nll_loss 1.234 | word_ins 3.113 | length 3.328 | ppl 10.89 | wps 127781 | wpb 41551 | bsz 1500 | num_updates 67416 | best_loss 3.442
2023-03-01 23:58:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-01 23:58:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint34.pt (epoch 34 @ 67416 updates, score 3.445) (writing took 9.008120426908135 seconds)
2023-03-01 23:58:53 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-03-01 23:58:53 | INFO | train | epoch 034 | loss 3.526 | nll_loss 1.366 | word_ins 3.17 | length 3.558 | ppl 11.52 | wps 199537 | ups 3.24 | wpb 61628.5 | bsz 1997.6 | num_updates 67416 | lr 0.00038514 | gnorm 0.872 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-01 23:58:53 | INFO | fairseq.trainer | begin training epoch 35
2023-03-01 23:59:29 | INFO | train_inner | epoch 035:     84 / 1983 loss=3.534, nll_loss=1.372, word_ins=3.175, length=3.584, ppl=11.58, wps=98422.4, ups=1.61, wpb=61079.5, bsz=1954.4, num_updates=67500, lr=0.0003849, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-01 23:59:58 | INFO | train_inner | epoch 035:    184 / 1983 loss=3.554, nll_loss=1.397, word_ins=3.198, length=3.566, ppl=11.75, wps=209581, ups=3.41, wpb=61414.1, bsz=1953.2, num_updates=67600, lr=0.000384615, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:00:27 | INFO | train_inner | epoch 035:    284 / 1983 loss=3.492, nll_loss=1.338, word_ins=3.145, length=3.467, ppl=11.25, wps=212196, ups=3.42, wpb=62113.2, bsz=2014.6, num_updates=67700, lr=0.000384331, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:00:57 | INFO | train_inner | epoch 035:    384 / 1983 loss=3.495, nll_loss=1.334, word_ins=3.141, length=3.541, ppl=11.28, wps=212731, ups=3.42, wpb=62129.1, bsz=1980.2, num_updates=67800, lr=0.000384048, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:01:26 | INFO | train_inner | epoch 035:    484 / 1983 loss=3.522, nll_loss=1.359, word_ins=3.164, length=3.583, ppl=11.49, wps=210964, ups=3.42, wpb=61694.5, bsz=1998.8, num_updates=67900, lr=0.000383765, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:01:55 | INFO | train_inner | epoch 035:    584 / 1983 loss=3.543, nll_loss=1.384, word_ins=3.186, length=3.569, ppl=11.66, wps=212304, ups=3.43, wpb=61921.8, bsz=1934.8, num_updates=68000, lr=0.000383482, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:02:24 | INFO | train_inner | epoch 035:    684 / 1983 loss=3.487, nll_loss=1.328, word_ins=3.135, length=3.516, ppl=11.21, wps=210301, ups=3.42, wpb=61491.7, bsz=2061.5, num_updates=68100, lr=0.000383201, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:02:53 | INFO | train_inner | epoch 035:    784 / 1983 loss=3.512, nll_loss=1.351, word_ins=3.156, length=3.558, ppl=11.41, wps=210603, ups=3.43, wpb=61483.3, bsz=1989.3, num_updates=68200, lr=0.00038292, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:03:23 | INFO | train_inner | epoch 035:    884 / 1983 loss=3.519, nll_loss=1.359, word_ins=3.163, length=3.562, ppl=11.47, wps=211565, ups=3.43, wpb=61683.2, bsz=1966.2, num_updates=68300, lr=0.000382639, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:03:52 | INFO | train_inner | epoch 035:    984 / 1983 loss=3.505, nll_loss=1.348, word_ins=3.153, length=3.525, ppl=11.36, wps=209729, ups=3.41, wpb=61511.8, bsz=2055.4, num_updates=68400, lr=0.00038236, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:04:21 | INFO | train_inner | epoch 035:   1084 / 1983 loss=3.486, nll_loss=1.329, word_ins=3.135, length=3.512, ppl=11.21, wps=212688, ups=3.43, wpb=61922.3, bsz=1991.4, num_updates=68500, lr=0.00038208, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:04:50 | INFO | train_inner | epoch 035:   1184 / 1983 loss=3.511, nll_loss=1.352, word_ins=3.157, length=3.539, ppl=11.4, wps=209974, ups=3.41, wpb=61497.2, bsz=2018.7, num_updates=68600, lr=0.000381802, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:05:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 00:05:20 | INFO | train_inner | epoch 035:   1285 / 1983 loss=3.477, nll_loss=1.32, word_ins=3.127, length=3.501, ppl=11.14, wps=209958, ups=3.39, wpb=62016.1, bsz=2102.9, num_updates=68700, lr=0.000381524, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:05:49 | INFO | train_inner | epoch 035:   1385 / 1983 loss=3.497, nll_loss=1.34, word_ins=3.145, length=3.515, ppl=11.29, wps=212862, ups=3.43, wpb=62084.9, bsz=2019, num_updates=68800, lr=0.000381246, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:06:18 | INFO | train_inner | epoch 035:   1485 / 1983 loss=3.547, nll_loss=1.388, word_ins=3.189, length=3.581, ppl=11.69, wps=209794, ups=3.43, wpb=61246.9, bsz=1926.2, num_updates=68900, lr=0.00038097, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:06:47 | INFO | train_inner | epoch 035:   1585 / 1983 loss=3.505, nll_loss=1.342, word_ins=3.147, length=3.586, ppl=11.36, wps=210889, ups=3.42, wpb=61672.4, bsz=1979.1, num_updates=69000, lr=0.000380693, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:07:17 | INFO | train_inner | epoch 035:   1685 / 1983 loss=3.506, nll_loss=1.352, word_ins=3.156, length=3.5, ppl=11.36, wps=210389, ups=3.41, wpb=61784.3, bsz=1967.4, num_updates=69100, lr=0.000380418, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:07:46 | INFO | train_inner | epoch 035:   1785 / 1983 loss=3.523, nll_loss=1.36, word_ins=3.164, length=3.596, ppl=11.5, wps=210776, ups=3.42, wpb=61565.3, bsz=1954.2, num_updates=69200, lr=0.000380143, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:08:15 | INFO | train_inner | epoch 035:   1885 / 1983 loss=3.499, nll_loss=1.339, word_ins=3.144, length=3.547, ppl=11.31, wps=209799, ups=3.42, wpb=61316.1, bsz=2054.9, num_updates=69300, lr=0.000379869, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 00:08:59 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.428 | nll_loss 1.211 | word_ins 3.09 | length 3.379 | ppl 10.76 | wps 97551.4 | wpb 41551 | bsz 1500 | num_updates 69398 | best_loss 3.428
2023-03-02 00:08:59 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 00:09:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint35.pt (epoch 35 @ 69398 updates, score 3.428) (writing took 12.480949676013552 seconds)
2023-03-02 00:09:11 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-03-02 00:09:12 | INFO | train | epoch 035 | loss 3.512 | nll_loss 1.353 | word_ins 3.158 | length 3.547 | ppl 11.41 | wps 197461 | ups 3.2 | wpb 61627.1 | bsz 1997.8 | num_updates 69398 | lr 0.0003796 | gnorm 0.876 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 00:09:12 | INFO | fairseq.trainer | begin training epoch 36
2023-03-02 00:09:25 | INFO | train_inner | epoch 036:      2 / 1983 loss=3.537, nll_loss=1.376, word_ins=3.177, length=3.601, ppl=11.61, wps=87431.6, ups=1.44, wpb=60607, bsz=1999.8, num_updates=69400, lr=0.000379595, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:09:54 | INFO | train_inner | epoch 036:    102 / 1983 loss=3.464, nll_loss=1.31, word_ins=3.119, length=3.451, ppl=11.04, wps=209458, ups=3.4, wpb=61530.2, bsz=2097.8, num_updates=69500, lr=0.000379322, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:10:23 | INFO | train_inner | epoch 036:    202 / 1983 loss=3.484, nll_loss=1.325, word_ins=3.133, length=3.511, ppl=11.19, wps=210311, ups=3.42, wpb=61507.3, bsz=2023, num_updates=69600, lr=0.000379049, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:10:53 | INFO | train_inner | epoch 036:    302 / 1983 loss=3.511, nll_loss=1.354, word_ins=3.159, length=3.517, ppl=11.4, wps=209539, ups=3.4, wpb=61669.2, bsz=1950.4, num_updates=69700, lr=0.000378777, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:11:22 | INFO | train_inner | epoch 036:    402 / 1983 loss=3.515, nll_loss=1.356, word_ins=3.16, length=3.544, ppl=11.43, wps=209162, ups=3.41, wpb=61403.8, bsz=1941.6, num_updates=69800, lr=0.000378506, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:11:51 | INFO | train_inner | epoch 036:    502 / 1983 loss=3.5, nll_loss=1.339, word_ins=3.145, length=3.557, ppl=11.32, wps=211306, ups=3.41, wpb=61883.7, bsz=2027.3, num_updates=69900, lr=0.000378235, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:12:20 | INFO | train_inner | epoch 036:    602 / 1983 loss=3.487, nll_loss=1.33, word_ins=3.137, length=3.502, ppl=11.21, wps=211614, ups=3.43, wpb=61711.7, bsz=2030.5, num_updates=70000, lr=0.000377964, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:12:50 | INFO | train_inner | epoch 036:    702 / 1983 loss=3.493, nll_loss=1.336, word_ins=3.142, length=3.503, ppl=11.26, wps=212539, ups=3.43, wpb=61936.4, bsz=2020.7, num_updates=70100, lr=0.000377695, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:13:19 | INFO | train_inner | epoch 036:    802 / 1983 loss=3.495, nll_loss=1.338, word_ins=3.143, length=3.515, ppl=11.27, wps=212062, ups=3.42, wpb=61994, bsz=2045, num_updates=70200, lr=0.000377426, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:13:48 | INFO | train_inner | epoch 036:    902 / 1983 loss=3.499, nll_loss=1.337, word_ins=3.142, length=3.571, ppl=11.31, wps=212356, ups=3.45, wpb=61558, bsz=1931.3, num_updates=70300, lr=0.000377157, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:14:17 | INFO | train_inner | epoch 036:   1002 / 1983 loss=3.489, nll_loss=1.335, word_ins=3.141, length=3.484, ppl=11.23, wps=210251, ups=3.39, wpb=62022.2, bsz=2097.9, num_updates=70400, lr=0.000376889, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:14:46 | INFO | train_inner | epoch 036:   1102 / 1983 loss=3.479, nll_loss=1.322, word_ins=3.129, length=3.498, ppl=11.15, wps=214024, ups=3.45, wpb=62075.4, bsz=2008.3, num_updates=70500, lr=0.000376622, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:15:16 | INFO | train_inner | epoch 036:   1202 / 1983 loss=3.521, nll_loss=1.361, word_ins=3.164, length=3.573, ppl=11.48, wps=210578, ups=3.42, wpb=61497.3, bsz=1986.2, num_updates=70600, lr=0.000376355, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:15:45 | INFO | train_inner | epoch 036:   1302 / 1983 loss=3.556, nll_loss=1.388, word_ins=3.189, length=3.673, ppl=11.76, wps=208989, ups=3.43, wpb=60977.3, bsz=1914.2, num_updates=70700, lr=0.000376089, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:16:14 | INFO | train_inner | epoch 036:   1402 / 1983 loss=3.505, nll_loss=1.347, word_ins=3.152, length=3.53, ppl=11.35, wps=208855, ups=3.42, wpb=61149.8, bsz=2014, num_updates=70800, lr=0.000375823, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:16:43 | INFO | train_inner | epoch 036:   1502 / 1983 loss=3.479, nll_loss=1.318, word_ins=3.125, length=3.539, ppl=11.15, wps=212521, ups=3.42, wpb=62055.9, bsz=2095, num_updates=70900, lr=0.000375558, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:17:12 | INFO | train_inner | epoch 036:   1602 / 1983 loss=3.528, nll_loss=1.37, word_ins=3.172, length=3.558, ppl=11.54, wps=211952, ups=3.43, wpb=61782.5, bsz=1902.2, num_updates=71000, lr=0.000375293, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:17:42 | INFO | train_inner | epoch 036:   1702 / 1983 loss=3.518, nll_loss=1.357, word_ins=3.16, length=3.573, ppl=11.45, wps=210040, ups=3.43, wpb=61170.5, bsz=1969.6, num_updates=71100, lr=0.000375029, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:18:10 | INFO | train_inner | epoch 036:   1802 / 1983 loss=3.525, nll_loss=1.359, word_ins=3.163, length=3.627, ppl=11.52, wps=212924, ups=3.45, wpb=61645.5, bsz=1894.9, num_updates=71200, lr=0.000374766, gnorm=0.916, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:18:40 | INFO | train_inner | epoch 036:   1902 / 1983 loss=3.481, nll_loss=1.323, word_ins=3.13, length=3.513, ppl=11.17, wps=211870, ups=3.43, wpb=61727.3, bsz=2013.8, num_updates=71300, lr=0.000374503, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 00:19:19 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.403 | nll_loss 1.197 | word_ins 3.07 | length 3.336 | ppl 10.58 | wps 84153.6 | wpb 41551 | bsz 1500 | num_updates 71381 | best_loss 3.403
2023-03-02 00:19:19 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 00:19:33 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint36.pt (epoch 36 @ 71381 updates, score 3.403) (writing took 14.161633791052736 seconds)
2023-03-02 00:19:33 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-03-02 00:19:33 | INFO | train | epoch 036 | loss 3.502 | nll_loss 1.343 | word_ins 3.148 | length 3.54 | ppl 11.33 | wps 196515 | ups 3.19 | wpb 61628.5 | bsz 1997.6 | num_updates 71381 | lr 0.00037429 | gnorm 0.885 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 00:19:33 | INFO | fairseq.trainer | begin training epoch 37
2023-03-02 00:19:51 | INFO | train_inner | epoch 037:     19 / 1983 loss=3.511, nll_loss=1.347, word_ins=3.152, length=3.595, ppl=11.4, wps=85298.7, ups=1.39, wpb=61205.8, bsz=1959, num_updates=71400, lr=0.000374241, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:20:21 | INFO | train_inner | epoch 037:    119 / 1983 loss=3.47, nll_loss=1.311, word_ins=3.12, length=3.498, ppl=11.08, wps=210144, ups=3.42, wpb=61453, bsz=2013.6, num_updates=71500, lr=0.000373979, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:20:50 | INFO | train_inner | epoch 037:    219 / 1983 loss=3.472, nll_loss=1.317, word_ins=3.125, length=3.471, ppl=11.1, wps=211930, ups=3.42, wpb=61913.4, bsz=1985.8, num_updates=71600, lr=0.000373718, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:21:19 | INFO | train_inner | epoch 037:    319 / 1983 loss=3.522, nll_loss=1.361, word_ins=3.164, length=3.577, ppl=11.49, wps=211533, ups=3.43, wpb=61728.5, bsz=1919.4, num_updates=71700, lr=0.000373457, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:21:48 | INFO | train_inner | epoch 037:    419 / 1983 loss=3.497, nll_loss=1.337, word_ins=3.143, length=3.537, ppl=11.29, wps=209444, ups=3.42, wpb=61329, bsz=1967.9, num_updates=71800, lr=0.000373197, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:22:17 | INFO | train_inner | epoch 037:    519 / 1983 loss=3.485, nll_loss=1.329, word_ins=3.135, length=3.496, ppl=11.2, wps=212013, ups=3.43, wpb=61853.2, bsz=1981.2, num_updates=71900, lr=0.000372937, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:22:47 | INFO | train_inner | epoch 037:    619 / 1983 loss=3.465, nll_loss=1.308, word_ins=3.117, length=3.482, ppl=11.04, wps=212418, ups=3.41, wpb=62249.5, bsz=2028.3, num_updates=72000, lr=0.000372678, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:23:16 | INFO | train_inner | epoch 037:    719 / 1983 loss=3.464, nll_loss=1.311, word_ins=3.119, length=3.445, ppl=11.03, wps=209562, ups=3.4, wpb=61625, bsz=2116.7, num_updates=72100, lr=0.000372419, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:23:45 | INFO | train_inner | epoch 037:    819 / 1983 loss=3.534, nll_loss=1.373, word_ins=3.174, length=3.601, ppl=11.59, wps=210178, ups=3.45, wpb=61004, bsz=1887, num_updates=72200, lr=0.000372161, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:24:14 | INFO | train_inner | epoch 037:    919 / 1983 loss=3.49, nll_loss=1.334, word_ins=3.139, length=3.509, ppl=11.24, wps=211040, ups=3.42, wpb=61734.4, bsz=1985.2, num_updates=72300, lr=0.000371904, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:24:44 | INFO | train_inner | epoch 037:   1019 / 1983 loss=3.458, nll_loss=1.299, word_ins=3.108, length=3.507, ppl=10.99, wps=212253, ups=3.42, wpb=61974.4, bsz=1989.4, num_updates=72400, lr=0.000371647, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:25:13 | INFO | train_inner | epoch 037:   1119 / 1983 loss=3.48, nll_loss=1.32, word_ins=3.127, length=3.523, ppl=11.16, wps=210979, ups=3.41, wpb=61941.8, bsz=2039, num_updates=72500, lr=0.000371391, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:25:42 | INFO | train_inner | epoch 037:   1219 / 1983 loss=3.484, nll_loss=1.327, word_ins=3.133, length=3.511, ppl=11.19, wps=209901, ups=3.41, wpb=61490.7, bsz=2014.1, num_updates=72600, lr=0.000371135, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:26:12 | INFO | train_inner | epoch 037:   1319 / 1983 loss=3.453, nll_loss=1.297, word_ins=3.106, length=3.464, ppl=10.95, wps=211822, ups=3.41, wpb=62184.5, bsz=2119.8, num_updates=72700, lr=0.000370879, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:26:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 00:26:41 | INFO | train_inner | epoch 037:   1420 / 1983 loss=3.468, nll_loss=1.311, word_ins=3.119, length=3.488, ppl=11.06, wps=208626, ups=3.38, wpb=61690.5, bsz=2081, num_updates=72800, lr=0.000370625, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:27:10 | INFO | train_inner | epoch 037:   1520 / 1983 loss=3.503, nll_loss=1.34, word_ins=3.145, length=3.579, ppl=11.34, wps=211017, ups=3.43, wpb=61525.5, bsz=1965.9, num_updates=72900, lr=0.00037037, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:27:40 | INFO | train_inner | epoch 037:   1620 / 1983 loss=3.495, nll_loss=1.336, word_ins=3.141, length=3.541, ppl=11.28, wps=210411, ups=3.43, wpb=61316.5, bsz=1936.5, num_updates=73000, lr=0.000370117, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:28:09 | INFO | train_inner | epoch 037:   1720 / 1983 loss=3.494, nll_loss=1.34, word_ins=3.145, length=3.495, ppl=11.27, wps=211814, ups=3.43, wpb=61688.7, bsz=1953.2, num_updates=73100, lr=0.000369863, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:28:38 | INFO | train_inner | epoch 037:   1820 / 1983 loss=3.507, nll_loss=1.343, word_ins=3.147, length=3.603, ppl=11.37, wps=210516, ups=3.43, wpb=61361.5, bsz=1940.9, num_updates=73200, lr=0.000369611, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:29:07 | INFO | train_inner | epoch 037:   1920 / 1983 loss=3.472, nll_loss=1.315, word_ins=3.122, length=3.506, ppl=11.1, wps=209730, ups=3.42, wpb=61360.8, bsz=2027.8, num_updates=73300, lr=0.000369358, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 00:29:41 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.429 | nll_loss 1.199 | word_ins 3.078 | length 3.505 | ppl 10.77 | wps 101293 | wpb 41551 | bsz 1500 | num_updates 73363 | best_loss 3.403
2023-03-02 00:29:41 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 00:29:49 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint37.pt (epoch 37 @ 73363 updates, score 3.429) (writing took 7.9227322589140385 seconds)
2023-03-02 00:29:49 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-03-02 00:29:49 | INFO | train | epoch 037 | loss 3.486 | nll_loss 1.327 | word_ins 3.133 | length 3.522 | ppl 11.2 | wps 198557 | ups 3.22 | wpb 61628.9 | bsz 1997.5 | num_updates 73363 | lr 0.0003692 | gnorm 0.888 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 00:29:49 | INFO | fairseq.trainer | begin training epoch 38
2023-03-02 00:30:11 | INFO | train_inner | epoch 038:     37 / 1983 loss=3.486, nll_loss=1.326, word_ins=3.131, length=3.546, ppl=11.2, wps=96295.6, ups=1.58, wpb=61084.9, bsz=2041.6, num_updates=73400, lr=0.000369107, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:30:40 | INFO | train_inner | epoch 038:    137 / 1983 loss=3.496, nll_loss=1.327, word_ins=3.134, length=3.622, ppl=11.28, wps=210434, ups=3.44, wpb=61205.4, bsz=1908.8, num_updates=73500, lr=0.000368856, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:31:09 | INFO | train_inner | epoch 038:    237 / 1983 loss=3.476, nll_loss=1.318, word_ins=3.126, length=3.506, ppl=11.13, wps=211218, ups=3.42, wpb=61766.9, bsz=1960.4, num_updates=73600, lr=0.000368605, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:31:38 | INFO | train_inner | epoch 038:    337 / 1983 loss=3.451, nll_loss=1.292, word_ins=3.101, length=3.499, ppl=10.93, wps=211432, ups=3.44, wpb=61436.7, bsz=2064.6, num_updates=73700, lr=0.000368355, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:32:07 | INFO | train_inner | epoch 038:    437 / 1983 loss=3.49, nll_loss=1.332, word_ins=3.138, length=3.516, ppl=11.23, wps=211986, ups=3.42, wpb=61907.3, bsz=1922, num_updates=73800, lr=0.000368105, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:32:37 | INFO | train_inner | epoch 038:    537 / 1983 loss=3.477, nll_loss=1.317, word_ins=3.124, length=3.53, ppl=11.14, wps=209228, ups=3.4, wpb=61530.4, bsz=2055.6, num_updates=73900, lr=0.000367856, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:33:06 | INFO | train_inner | epoch 038:    637 / 1983 loss=3.507, nll_loss=1.35, word_ins=3.154, length=3.529, ppl=11.37, wps=210378, ups=3.42, wpb=61583.2, bsz=1972.2, num_updates=74000, lr=0.000367607, gnorm=0.922, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:33:35 | INFO | train_inner | epoch 038:    737 / 1983 loss=3.494, nll_loss=1.333, word_ins=3.138, length=3.559, ppl=11.27, wps=211927, ups=3.43, wpb=61774.8, bsz=1954.7, num_updates=74100, lr=0.000367359, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:34:04 | INFO | train_inner | epoch 038:    837 / 1983 loss=3.474, nll_loss=1.319, word_ins=3.125, length=3.492, ppl=11.11, wps=211421, ups=3.43, wpb=61650.2, bsz=2006.2, num_updates=74200, lr=0.000367112, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:34:34 | INFO | train_inner | epoch 038:    937 / 1983 loss=3.447, nll_loss=1.293, word_ins=3.102, length=3.448, ppl=10.9, wps=209020, ups=3.4, wpb=61461.5, bsz=2145.2, num_updates=74300, lr=0.000366864, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:35:03 | INFO | train_inner | epoch 038:   1037 / 1983 loss=3.459, nll_loss=1.3, word_ins=3.109, length=3.505, ppl=11, wps=211152, ups=3.42, wpb=61681.6, bsz=2028.5, num_updates=74400, lr=0.000366618, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:35:32 | INFO | train_inner | epoch 038:   1137 / 1983 loss=3.462, nll_loss=1.307, word_ins=3.115, length=3.469, ppl=11.02, wps=212384, ups=3.43, wpb=61865, bsz=1997.9, num_updates=74500, lr=0.000366372, gnorm=0.892, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:36:01 | INFO | train_inner | epoch 038:   1237 / 1983 loss=3.517, nll_loss=1.35, word_ins=3.153, length=3.636, ppl=11.45, wps=209892, ups=3.42, wpb=61370.2, bsz=1858.2, num_updates=74600, lr=0.000366126, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:36:30 | INFO | train_inner | epoch 038:   1337 / 1983 loss=3.468, nll_loss=1.312, word_ins=3.119, length=3.488, ppl=11.06, wps=212089, ups=3.43, wpb=61838.3, bsz=2025, num_updates=74700, lr=0.000365881, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:37:00 | INFO | train_inner | epoch 038:   1437 / 1983 loss=3.477, nll_loss=1.319, word_ins=3.125, length=3.517, ppl=11.13, wps=209995, ups=3.41, wpb=61577.9, bsz=1992.1, num_updates=74800, lr=0.000365636, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:37:29 | INFO | train_inner | epoch 038:   1537 / 1983 loss=3.493, nll_loss=1.332, word_ins=3.137, length=3.556, ppl=11.26, wps=210128, ups=3.41, wpb=61598.3, bsz=1975.4, num_updates=74900, lr=0.000365392, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:37:58 | INFO | train_inner | epoch 038:   1637 / 1983 loss=3.446, nll_loss=1.294, word_ins=3.103, length=3.43, ppl=10.9, wps=212423, ups=3.43, wpb=61977.1, bsz=2059.1, num_updates=75000, lr=0.000365148, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:38:27 | INFO | train_inner | epoch 038:   1737 / 1983 loss=3.473, nll_loss=1.316, word_ins=3.122, length=3.508, ppl=11.11, wps=210310, ups=3.43, wpb=61285, bsz=2024.2, num_updates=75100, lr=0.000364905, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:38:56 | INFO | train_inner | epoch 038:   1837 / 1983 loss=3.481, nll_loss=1.321, word_ins=3.127, length=3.544, ppl=11.17, wps=212628, ups=3.44, wpb=61751.5, bsz=1952.4, num_updates=75200, lr=0.000364662, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:39:26 | INFO | train_inner | epoch 038:   1937 / 1983 loss=3.467, nll_loss=1.312, word_ins=3.119, length=3.481, ppl=11.06, wps=211733, ups=3.42, wpb=61876.1, bsz=2022, num_updates=75300, lr=0.00036442, gnorm=0.908, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 00:39:53 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.406 | nll_loss 1.197 | word_ins 3.078 | length 3.275 | ppl 10.6 | wps 139780 | wpb 41551 | bsz 1500 | num_updates 75346 | best_loss 3.403
2023-03-02 00:39:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 00:40:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint38.pt (epoch 38 @ 75346 updates, score 3.406) (writing took 8.494650321896188 seconds)
2023-03-02 00:40:01 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-03-02 00:40:01 | INFO | train | epoch 038 | loss 3.476 | nll_loss 1.318 | word_ins 3.124 | length 3.515 | ppl 11.13 | wps 199392 | ups 3.24 | wpb 61628.5 | bsz 1997.6 | num_updates 75346 | lr 0.000364309 | gnorm 0.894 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 00:40:01 | INFO | fairseq.trainer | begin training epoch 39
2023-03-02 00:40:27 | INFO | train_inner | epoch 039:     54 / 1983 loss=3.443, nll_loss=1.288, word_ins=3.097, length=3.456, ppl=10.87, wps=99615, ups=1.62, wpb=61424.6, bsz=2068.3, num_updates=75400, lr=0.000364179, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:40:56 | INFO | train_inner | epoch 039:    154 / 1983 loss=3.503, nll_loss=1.338, word_ins=3.143, length=3.591, ppl=11.33, wps=211788, ups=3.43, wpb=61724.9, bsz=1879.8, num_updates=75500, lr=0.000363937, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:41:25 | INFO | train_inner | epoch 039:    254 / 1983 loss=3.492, nll_loss=1.326, word_ins=3.132, length=3.6, ppl=11.25, wps=211134, ups=3.44, wpb=61344, bsz=1923.2, num_updates=75600, lr=0.000363696, gnorm=0.914, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:41:55 | INFO | train_inner | epoch 039:    354 / 1983 loss=3.453, nll_loss=1.296, word_ins=3.105, length=3.48, ppl=10.95, wps=209726, ups=3.41, wpb=61589, bsz=2063, num_updates=75700, lr=0.000363456, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:42:24 | INFO | train_inner | epoch 039:    454 / 1983 loss=3.456, nll_loss=1.299, word_ins=3.108, length=3.48, ppl=10.97, wps=211402, ups=3.44, wpb=61386.8, bsz=1973.8, num_updates=75800, lr=0.000363216, gnorm=0.904, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:42:53 | INFO | train_inner | epoch 039:    554 / 1983 loss=3.445, nll_loss=1.287, word_ins=3.097, length=3.484, ppl=10.89, wps=212685, ups=3.43, wpb=61986.4, bsz=2013.8, num_updates=75900, lr=0.000362977, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:43:22 | INFO | train_inner | epoch 039:    654 / 1983 loss=3.469, nll_loss=1.309, word_ins=3.116, length=3.529, ppl=11.07, wps=212010, ups=3.43, wpb=61810.9, bsz=1903, num_updates=76000, lr=0.000362738, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:43:51 | INFO | train_inner | epoch 039:    754 / 1983 loss=3.475, nll_loss=1.311, word_ins=3.118, length=3.574, ppl=11.12, wps=211784, ups=3.44, wpb=61570.6, bsz=1943.3, num_updates=76100, lr=0.0003625, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:44:20 | INFO | train_inner | epoch 039:    854 / 1983 loss=3.486, nll_loss=1.324, word_ins=3.13, length=3.556, ppl=11.2, wps=210766, ups=3.43, wpb=61489.1, bsz=1967.3, num_updates=76200, lr=0.000362262, gnorm=0.923, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:44:50 | INFO | train_inner | epoch 039:    954 / 1983 loss=3.477, nll_loss=1.318, word_ins=3.124, length=3.526, ppl=11.13, wps=209950, ups=3.42, wpb=61441.4, bsz=2016.7, num_updates=76300, lr=0.000362024, gnorm=0.908, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:45:19 | INFO | train_inner | epoch 039:   1054 / 1983 loss=3.471, nll_loss=1.31, word_ins=3.118, length=3.54, ppl=11.09, wps=211485, ups=3.42, wpb=61749.1, bsz=1978.9, num_updates=76400, lr=0.000361787, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:45:48 | INFO | train_inner | epoch 039:   1154 / 1983 loss=3.461, nll_loss=1.307, word_ins=3.114, length=3.467, ppl=11.01, wps=211732, ups=3.42, wpb=61839.4, bsz=2049.9, num_updates=76500, lr=0.000361551, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:46:17 | INFO | train_inner | epoch 039:   1254 / 1983 loss=3.422, nll_loss=1.267, word_ins=3.078, length=3.437, ppl=10.72, wps=213203, ups=3.42, wpb=62251.5, bsz=2106.6, num_updates=76600, lr=0.000361315, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:46:47 | INFO | train_inner | epoch 039:   1354 / 1983 loss=3.486, nll_loss=1.327, word_ins=3.132, length=3.536, ppl=11.2, wps=208794, ups=3.41, wpb=61306.7, bsz=2035, num_updates=76700, lr=0.000361079, gnorm=0.913, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:47:16 | INFO | train_inner | epoch 039:   1454 / 1983 loss=3.47, nll_loss=1.313, word_ins=3.119, length=3.513, ppl=11.08, wps=211217, ups=3.43, wpb=61519.1, bsz=1984.2, num_updates=76800, lr=0.000360844, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:47:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 00:47:45 | INFO | train_inner | epoch 039:   1555 / 1983 loss=3.435, nll_loss=1.285, word_ins=3.094, length=3.413, ppl=10.82, wps=208856, ups=3.38, wpb=61827.5, bsz=2095.3, num_updates=76900, lr=0.000360609, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:48:14 | INFO | train_inner | epoch 039:   1655 / 1983 loss=3.479, nll_loss=1.32, word_ins=3.126, length=3.537, ppl=11.15, wps=211750, ups=3.44, wpb=61549.5, bsz=1942.3, num_updates=77000, lr=0.000360375, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:48:44 | INFO | train_inner | epoch 039:   1755 / 1983 loss=3.464, nll_loss=1.314, word_ins=3.12, length=3.439, ppl=11.03, wps=210950, ups=3.41, wpb=61807.2, bsz=2025.6, num_updates=77100, lr=0.000360141, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:49:13 | INFO | train_inner | epoch 039:   1855 / 1983 loss=3.436, nll_loss=1.285, word_ins=3.094, length=3.42, ppl=10.82, wps=211215, ups=3.41, wpb=61934.8, bsz=2074.3, num_updates=77200, lr=0.000359908, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:49:42 | INFO | train_inner | epoch 039:   1955 / 1983 loss=3.498, nll_loss=1.335, word_ins=3.139, length=3.589, ppl=11.3, wps=210494, ups=3.43, wpb=61391.8, bsz=1959.8, num_updates=77300, lr=0.000359675, gnorm=0.914, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:49:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 00:50:04 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.396 | nll_loss 1.178 | word_ins 3.061 | length 3.351 | ppl 10.53 | wps 95216.9 | wpb 41551 | bsz 1500 | num_updates 77328 | best_loss 3.396
2023-03-02 00:50:04 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 00:50:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint39.pt (epoch 39 @ 77328 updates, score 3.396) (writing took 11.524200424086303 seconds)
2023-03-02 00:50:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-03-02 00:50:16 | INFO | train | epoch 039 | loss 3.467 | nll_loss 1.308 | word_ins 3.116 | length 3.51 | ppl 11.05 | wps 198796 | ups 3.23 | wpb 61627.3 | bsz 1997.8 | num_updates 77328 | lr 0.00035961 | gnorm 0.907 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 00:50:16 | INFO | fairseq.trainer | begin training epoch 40
2023-03-02 00:50:48 | INFO | train_inner | epoch 040:     72 / 1983 loss=3.482, nll_loss=1.324, word_ins=3.13, length=3.518, ppl=11.17, wps=93525.5, ups=1.52, wpb=61520.8, bsz=1874.2, num_updates=77400, lr=0.000359443, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:51:17 | INFO | train_inner | epoch 040:    172 / 1983 loss=3.454, nll_loss=1.292, word_ins=3.1, length=3.532, ppl=10.95, wps=207230, ups=3.41, wpb=60688.1, bsz=2021.3, num_updates=77500, lr=0.000359211, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:51:46 | INFO | train_inner | epoch 040:    272 / 1983 loss=3.465, nll_loss=1.302, word_ins=3.11, length=3.549, ppl=11.04, wps=210718, ups=3.43, wpb=61433.9, bsz=2003.4, num_updates=77600, lr=0.000358979, gnorm=0.916, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:52:16 | INFO | train_inner | epoch 040:    372 / 1983 loss=3.441, nll_loss=1.286, word_ins=3.095, length=3.454, ppl=10.86, wps=210602, ups=3.4, wpb=61961.1, bsz=2042.7, num_updates=77700, lr=0.000358748, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:52:45 | INFO | train_inner | epoch 040:    472 / 1983 loss=3.466, nll_loss=1.309, word_ins=3.116, length=3.494, ppl=11.05, wps=211111, ups=3.42, wpb=61809.3, bsz=1982.7, num_updates=77800, lr=0.000358517, gnorm=0.929, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:53:14 | INFO | train_inner | epoch 040:    572 / 1983 loss=3.473, nll_loss=1.307, word_ins=3.115, length=3.587, ppl=11.11, wps=210759, ups=3.43, wpb=61496.2, bsz=1982.8, num_updates=77900, lr=0.000358287, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:53:44 | INFO | train_inner | epoch 040:    672 / 1983 loss=3.413, nll_loss=1.261, word_ins=3.072, length=3.405, ppl=10.65, wps=213473, ups=3.43, wpb=62165.6, bsz=2053.5, num_updates=78000, lr=0.000358057, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:54:13 | INFO | train_inner | epoch 040:    772 / 1983 loss=3.462, nll_loss=1.302, word_ins=3.109, length=3.529, ppl=11.02, wps=210866, ups=3.43, wpb=61478.7, bsz=2009, num_updates=78100, lr=0.000357828, gnorm=0.913, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:54:42 | INFO | train_inner | epoch 040:    872 / 1983 loss=3.456, nll_loss=1.297, word_ins=3.104, length=3.513, ppl=10.97, wps=213028, ups=3.42, wpb=62295.6, bsz=2002.2, num_updates=78200, lr=0.000357599, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:55:11 | INFO | train_inner | epoch 040:    972 / 1983 loss=3.425, nll_loss=1.265, word_ins=3.076, length=3.494, ppl=10.74, wps=212450, ups=3.44, wpb=61697.1, bsz=2004.2, num_updates=78300, lr=0.000357371, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:55:40 | INFO | train_inner | epoch 040:   1072 / 1983 loss=3.468, nll_loss=1.314, word_ins=3.12, length=3.477, ppl=11.06, wps=211563, ups=3.43, wpb=61687.6, bsz=1977.5, num_updates=78400, lr=0.000357143, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:56:09 | INFO | train_inner | epoch 040:   1172 / 1983 loss=3.45, nll_loss=1.295, word_ins=3.103, length=3.468, ppl=10.93, wps=211116, ups=3.43, wpb=61511.5, bsz=1975.4, num_updates=78500, lr=0.000356915, gnorm=0.925, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:56:38 | INFO | train_inner | epoch 040:   1272 / 1983 loss=3.449, nll_loss=1.294, word_ins=3.102, length=3.473, ppl=10.92, wps=210451, ups=3.43, wpb=61345.6, bsz=1969.1, num_updates=78600, lr=0.000356688, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:57:08 | INFO | train_inner | epoch 040:   1372 / 1983 loss=3.442, nll_loss=1.283, word_ins=3.092, length=3.495, ppl=10.87, wps=210886, ups=3.42, wpb=61615.5, bsz=2019, num_updates=78700, lr=0.000356462, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:57:37 | INFO | train_inner | epoch 040:   1472 / 1983 loss=3.471, nll_loss=1.308, word_ins=3.115, length=3.561, ppl=11.09, wps=211418, ups=3.44, wpb=61451.3, bsz=1963.3, num_updates=78800, lr=0.000356235, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:58:06 | INFO | train_inner | epoch 040:   1572 / 1983 loss=3.484, nll_loss=1.318, word_ins=3.124, length=3.6, ppl=11.19, wps=210769, ups=3.44, wpb=61309.4, bsz=1952.6, num_updates=78900, lr=0.000356009, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:58:35 | INFO | train_inner | epoch 040:   1672 / 1983 loss=3.464, nll_loss=1.304, word_ins=3.111, length=3.528, ppl=11.03, wps=212230, ups=3.43, wpb=61821, bsz=2040.6, num_updates=79000, lr=0.000355784, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:59:04 | INFO | train_inner | epoch 040:   1772 / 1983 loss=3.451, nll_loss=1.292, word_ins=3.101, length=3.508, ppl=10.94, wps=212340, ups=3.43, wpb=61935.8, bsz=2002, num_updates=79100, lr=0.000355559, gnorm=0.931, loss_scale=16384, train_wall=29, wall=0
2023-03-02 00:59:33 | INFO | train_inner | epoch 040:   1872 / 1983 loss=3.449, nll_loss=1.297, word_ins=3.104, length=3.448, ppl=10.92, wps=210138, ups=3.41, wpb=61579.1, bsz=2007.4, num_updates=79200, lr=0.000355335, gnorm=0.938, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:00:03 | INFO | train_inner | epoch 040:   1972 / 1983 loss=3.444, nll_loss=1.288, word_ins=3.096, length=3.475, ppl=10.88, wps=210572, ups=3.41, wpb=61728.6, bsz=2068.4, num_updates=79300, lr=0.00035511, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 01:00:20 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.399 | nll_loss 1.187 | word_ins 3.066 | length 3.328 | ppl 10.55 | wps 114429 | wpb 41551 | bsz 1500 | num_updates 79311 | best_loss 3.396
2023-03-02 01:00:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 01:00:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint40.pt (epoch 40 @ 79311 updates, score 3.399) (writing took 6.546492503024638 seconds)
2023-03-02 01:00:26 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-03-02 01:00:26 | INFO | train | epoch 040 | loss 3.455 | nll_loss 1.297 | word_ins 3.105 | length 3.506 | ppl 10.97 | wps 200154 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 79311 | lr 0.000355086 | gnorm 0.914 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 01:00:26 | INFO | fairseq.trainer | begin training epoch 41
2023-03-02 01:01:05 | INFO | train_inner | epoch 041:     89 / 1983 loss=3.418, nll_loss=1.268, word_ins=3.079, length=3.39, ppl=10.69, wps=98877, ups=1.61, wpb=61380.9, bsz=2032.6, num_updates=79400, lr=0.000354887, gnorm=0.917, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:01:34 | INFO | train_inner | epoch 041:    189 / 1983 loss=3.466, nll_loss=1.3, word_ins=3.108, length=3.58, ppl=11.05, wps=209310, ups=3.43, wpb=61104.6, bsz=1986.6, num_updates=79500, lr=0.000354663, gnorm=0.955, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:02:03 | INFO | train_inner | epoch 041:    289 / 1983 loss=3.439, nll_loss=1.278, word_ins=3.088, length=3.513, ppl=10.85, wps=211062, ups=3.42, wpb=61682.9, bsz=2030.2, num_updates=79600, lr=0.000354441, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:02:32 | INFO | train_inner | epoch 041:    389 / 1983 loss=3.423, nll_loss=1.27, word_ins=3.08, length=3.431, ppl=10.73, wps=213821, ups=3.45, wpb=61957.4, bsz=2028.9, num_updates=79700, lr=0.000354218, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:03:01 | INFO | train_inner | epoch 041:    489 / 1983 loss=3.427, nll_loss=1.274, word_ins=3.084, length=3.43, ppl=10.76, wps=212121, ups=3.42, wpb=62037.1, bsz=2052.4, num_updates=79800, lr=0.000353996, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:03:31 | INFO | train_inner | epoch 041:    589 / 1983 loss=3.425, nll_loss=1.269, word_ins=3.08, length=3.451, ppl=10.74, wps=210764, ups=3.43, wpb=61473.7, bsz=2067.3, num_updates=79900, lr=0.000353775, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:04:00 | INFO | train_inner | epoch 041:    689 / 1983 loss=3.451, nll_loss=1.296, word_ins=3.104, length=3.475, ppl=10.94, wps=211697, ups=3.42, wpb=61825.4, bsz=1951.7, num_updates=80000, lr=0.000353553, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:04:29 | INFO | train_inner | epoch 041:    789 / 1983 loss=3.485, nll_loss=1.32, word_ins=3.126, length=3.592, ppl=11.2, wps=210502, ups=3.43, wpb=61366.3, bsz=1929, num_updates=80100, lr=0.000353333, gnorm=0.949, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:04:58 | INFO | train_inner | epoch 041:    889 / 1983 loss=3.397, nll_loss=1.245, word_ins=3.057, length=3.404, ppl=10.54, wps=212664, ups=3.42, wpb=62222.1, bsz=2109.4, num_updates=80200, lr=0.000353112, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:05:27 | INFO | train_inner | epoch 041:    989 / 1983 loss=3.455, nll_loss=1.293, word_ins=3.101, length=3.536, ppl=10.97, wps=210133, ups=3.43, wpb=61297.3, bsz=1963.3, num_updates=80300, lr=0.000352892, gnorm=0.93, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:05:56 | INFO | train_inner | epoch 041:   1089 / 1983 loss=3.437, nll_loss=1.28, word_ins=3.089, length=3.483, ppl=10.83, wps=211907, ups=3.44, wpb=61568.2, bsz=1948.4, num_updates=80400, lr=0.000352673, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:06:26 | INFO | train_inner | epoch 041:   1189 / 1983 loss=3.471, nll_loss=1.306, word_ins=3.113, length=3.579, ppl=11.09, wps=212437, ups=3.43, wpb=61886.2, bsz=1904.6, num_updates=80500, lr=0.000352454, gnorm=0.959, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:06:55 | INFO | train_inner | epoch 041:   1289 / 1983 loss=3.451, nll_loss=1.289, word_ins=3.097, length=3.532, ppl=10.93, wps=211824, ups=3.43, wpb=61824.6, bsz=1950.1, num_updates=80600, lr=0.000352235, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:07:24 | INFO | train_inner | epoch 041:   1389 / 1983 loss=3.454, nll_loss=1.295, word_ins=3.103, length=3.517, ppl=10.96, wps=210243, ups=3.43, wpb=61271.8, bsz=1950.1, num_updates=80700, lr=0.000352017, gnorm=0.962, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:07:53 | INFO | train_inner | epoch 041:   1489 / 1983 loss=3.437, nll_loss=1.29, word_ins=3.098, length=3.394, ppl=10.83, wps=208276, ups=3.39, wpb=61448.5, bsz=2135.1, num_updates=80800, lr=0.000351799, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:08:23 | INFO | train_inner | epoch 041:   1589 / 1983 loss=3.439, nll_loss=1.279, word_ins=3.088, length=3.501, ppl=10.84, wps=209147, ups=3.39, wpb=61753.8, bsz=2071, num_updates=80900, lr=0.000351581, gnorm=0.913, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:08:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 01:08:52 | INFO | train_inner | epoch 041:   1690 / 1983 loss=3.451, nll_loss=1.293, word_ins=3.101, length=3.495, ppl=10.94, wps=209425, ups=3.4, wpb=61605.8, bsz=1955.9, num_updates=81000, lr=0.000351364, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:09:21 | INFO | train_inner | epoch 041:   1790 / 1983 loss=3.432, nll_loss=1.277, word_ins=3.086, length=3.459, ppl=10.79, wps=214157, ups=3.44, wpb=62189.2, bsz=1969.7, num_updates=81100, lr=0.000351147, gnorm=0.923, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:09:51 | INFO | train_inner | epoch 041:   1890 / 1983 loss=3.479, nll_loss=1.315, word_ins=3.121, length=3.584, ppl=11.15, wps=210884, ups=3.42, wpb=61617, bsz=1976.2, num_updates=81200, lr=0.000350931, gnorm=0.944, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 01:10:31 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.405 | nll_loss 1.175 | word_ins 3.054 | length 3.517 | ppl 10.59 | wps 92931.2 | wpb 41551 | bsz 1500 | num_updates 81293 | best_loss 3.396
2023-03-02 01:10:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 01:10:39 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint41.pt (epoch 41 @ 81293 updates, score 3.405) (writing took 8.020901564974338 seconds)
2023-03-02 01:10:39 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-03-02 01:10:39 | INFO | train | epoch 041 | loss 3.445 | nll_loss 1.287 | word_ins 3.095 | length 3.495 | ppl 10.89 | wps 199343 | ups 3.23 | wpb 61628.7 | bsz 1997.7 | num_updates 81293 | lr 0.00035073 | gnorm 0.929 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 01:10:39 | INFO | fairseq.trainer | begin training epoch 42
2023-03-02 01:10:52 | INFO | train_inner | epoch 042:      7 / 1983 loss=3.467, nll_loss=1.303, word_ins=3.109, length=3.58, ppl=11.06, wps=98189.9, ups=1.62, wpb=60580.8, bsz=1891.8, num_updates=81300, lr=0.000350715, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:11:22 | INFO | train_inner | epoch 042:    107 / 1983 loss=3.432, nll_loss=1.274, word_ins=3.085, length=3.47, ppl=10.79, wps=211279, ups=3.42, wpb=61737.4, bsz=1995.1, num_updates=81400, lr=0.0003505, gnorm=0.927, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:11:51 | INFO | train_inner | epoch 042:    207 / 1983 loss=3.392, nll_loss=1.239, word_ins=3.052, length=3.396, ppl=10.5, wps=211800, ups=3.43, wpb=61720.7, bsz=2089.1, num_updates=81500, lr=0.000350285, gnorm=0.929, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:12:20 | INFO | train_inner | epoch 042:    307 / 1983 loss=3.419, nll_loss=1.261, word_ins=3.072, length=3.466, ppl=10.69, wps=210366, ups=3.42, wpb=61486.7, bsz=2047.3, num_updates=81600, lr=0.00035007, gnorm=0.935, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:12:49 | INFO | train_inner | epoch 042:    407 / 1983 loss=3.448, nll_loss=1.29, word_ins=3.098, length=3.496, ppl=10.91, wps=210791, ups=3.42, wpb=61585.7, bsz=1956.3, num_updates=81700, lr=0.000349856, gnorm=0.945, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:13:18 | INFO | train_inner | epoch 042:    507 / 1983 loss=3.467, nll_loss=1.309, word_ins=3.115, length=3.518, ppl=11.06, wps=211688, ups=3.42, wpb=61839.7, bsz=1896.3, num_updates=81800, lr=0.000349642, gnorm=0.971, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:13:48 | INFO | train_inner | epoch 042:    607 / 1983 loss=3.446, nll_loss=1.28, word_ins=3.089, length=3.57, ppl=10.9, wps=211390, ups=3.43, wpb=61702, bsz=1982.2, num_updates=81900, lr=0.000349428, gnorm=0.962, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:14:17 | INFO | train_inner | epoch 042:    707 / 1983 loss=3.44, nll_loss=1.279, word_ins=3.089, length=3.513, ppl=10.85, wps=209438, ups=3.41, wpb=61361.1, bsz=1976.5, num_updates=82000, lr=0.000349215, gnorm=0.939, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:14:46 | INFO | train_inner | epoch 042:    807 / 1983 loss=3.418, nll_loss=1.263, word_ins=3.073, length=3.447, ppl=10.69, wps=211248, ups=3.42, wpb=61769.9, bsz=2011, num_updates=82100, lr=0.000349002, gnorm=0.931, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:15:15 | INFO | train_inner | epoch 042:    907 / 1983 loss=3.408, nll_loss=1.251, word_ins=3.062, length=3.461, ppl=10.62, wps=211925, ups=3.42, wpb=62000.3, bsz=2091.4, num_updates=82200, lr=0.00034879, gnorm=0.92, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:15:45 | INFO | train_inner | epoch 042:   1007 / 1983 loss=3.443, nll_loss=1.279, word_ins=3.088, length=3.544, ppl=10.87, wps=212794, ups=3.42, wpb=62133.5, bsz=1978.5, num_updates=82300, lr=0.000348578, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:16:14 | INFO | train_inner | epoch 042:   1107 / 1983 loss=3.441, nll_loss=1.28, word_ins=3.089, length=3.524, ppl=10.86, wps=210011, ups=3.41, wpb=61528.2, bsz=2016.7, num_updates=82400, lr=0.000348367, gnorm=0.94, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:16:43 | INFO | train_inner | epoch 042:   1207 / 1983 loss=3.431, nll_loss=1.27, word_ins=3.08, length=3.509, ppl=10.78, wps=209973, ups=3.43, wpb=61168.6, bsz=1957.4, num_updates=82500, lr=0.000348155, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:17:12 | INFO | train_inner | epoch 042:   1307 / 1983 loss=3.431, nll_loss=1.268, word_ins=3.078, length=3.523, ppl=10.78, wps=211703, ups=3.44, wpb=61566.9, bsz=1961, num_updates=82600, lr=0.000347945, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:17:41 | INFO | train_inner | epoch 042:   1407 / 1983 loss=3.405, nll_loss=1.256, word_ins=3.067, length=3.381, ppl=10.59, wps=212018, ups=3.41, wpb=62202.9, bsz=2161.2, num_updates=82700, lr=0.000347734, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:18:11 | INFO | train_inner | epoch 042:   1507 / 1983 loss=3.468, nll_loss=1.311, word_ins=3.117, length=3.51, ppl=11.06, wps=211176, ups=3.42, wpb=61769.2, bsz=1929, num_updates=82800, lr=0.000347524, gnorm=0.953, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:18:40 | INFO | train_inner | epoch 042:   1607 / 1983 loss=3.443, nll_loss=1.286, word_ins=3.094, length=3.488, ppl=10.88, wps=210377, ups=3.42, wpb=61597.3, bsz=2004.8, num_updates=82900, lr=0.000347314, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:19:09 | INFO | train_inner | epoch 042:   1707 / 1983 loss=3.434, nll_loss=1.275, word_ins=3.084, length=3.503, ppl=10.81, wps=211299, ups=3.43, wpb=61661.8, bsz=1950.5, num_updates=83000, lr=0.000347105, gnorm=0.956, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:19:38 | INFO | train_inner | epoch 042:   1807 / 1983 loss=3.455, nll_loss=1.293, word_ins=3.101, length=3.537, ppl=10.96, wps=210022, ups=3.43, wpb=61252.2, bsz=1972.3, num_updates=83100, lr=0.000346896, gnorm=0.938, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:20:08 | INFO | train_inner | epoch 042:   1907 / 1983 loss=3.454, nll_loss=1.3, word_ins=3.106, length=3.472, ppl=10.96, wps=209754, ups=3.4, wpb=61620, bsz=2004.4, num_updates=83200, lr=0.000346688, gnorm=0.949, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 01:20:46 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.37 | nll_loss 1.156 | word_ins 3.036 | length 3.333 | ppl 10.34 | wps 95180.8 | wpb 41551 | bsz 1500 | num_updates 83276 | best_loss 3.37
2023-03-02 01:20:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 01:21:00 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint42.pt (epoch 42 @ 83276 updates, score 3.37) (writing took 14.126992129022256 seconds)
2023-03-02 01:21:00 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-03-02 01:21:00 | INFO | train | epoch 042 | loss 3.436 | nll_loss 1.278 | word_ins 3.087 | length 3.491 | ppl 10.82 | wps 196945 | ups 3.2 | wpb 61628.5 | bsz 1997.6 | num_updates 83276 | lr 0.000346529 | gnorm 0.943 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 01:21:00 | INFO | fairseq.trainer | begin training epoch 43
2023-03-02 01:21:21 | INFO | train_inner | epoch 043:     24 / 1983 loss=3.442, nll_loss=1.285, word_ins=3.094, length=3.479, ppl=10.86, wps=82820.2, ups=1.36, wpb=60938.7, bsz=1984.1, num_updates=83300, lr=0.000346479, gnorm=0.97, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:21:50 | INFO | train_inner | epoch 043:    124 / 1983 loss=3.42, nll_loss=1.261, word_ins=3.072, length=3.484, ppl=10.71, wps=211487, ups=3.44, wpb=61562.3, bsz=1935.8, num_updates=83400, lr=0.000346272, gnorm=0.944, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:22:20 | INFO | train_inner | epoch 043:    224 / 1983 loss=3.429, nll_loss=1.276, word_ins=3.086, length=3.437, ppl=10.77, wps=210744, ups=3.42, wpb=61532.9, bsz=1962.3, num_updates=83500, lr=0.000346064, gnorm=0.945, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:22:49 | INFO | train_inner | epoch 043:    324 / 1983 loss=3.402, nll_loss=1.245, word_ins=3.057, length=3.445, ppl=10.57, wps=212285, ups=3.43, wpb=61910.9, bsz=2016.9, num_updates=83600, lr=0.000345857, gnorm=0.952, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:23:18 | INFO | train_inner | epoch 043:    424 / 1983 loss=3.441, nll_loss=1.277, word_ins=3.086, length=3.544, ppl=10.86, wps=211468, ups=3.44, wpb=61417.8, bsz=1943, num_updates=83700, lr=0.000345651, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:23:47 | INFO | train_inner | epoch 043:    524 / 1983 loss=3.41, nll_loss=1.257, word_ins=3.068, length=3.428, ppl=10.63, wps=212028, ups=3.42, wpb=61972, bsz=1994.6, num_updates=83800, lr=0.000345444, gnorm=0.937, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:24:16 | INFO | train_inner | epoch 043:    624 / 1983 loss=3.42, nll_loss=1.263, word_ins=3.073, length=3.468, ppl=10.7, wps=210472, ups=3.42, wpb=61472, bsz=2009.3, num_updates=83900, lr=0.000345238, gnorm=0.934, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:24:46 | INFO | train_inner | epoch 043:    724 / 1983 loss=3.438, nll_loss=1.28, word_ins=3.089, length=3.497, ppl=10.84, wps=210541, ups=3.42, wpb=61563.7, bsz=1966.6, num_updates=84000, lr=0.000345033, gnorm=0.941, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:25:15 | INFO | train_inner | epoch 043:    824 / 1983 loss=3.408, nll_loss=1.254, word_ins=3.066, length=3.424, ppl=10.62, wps=210797, ups=3.41, wpb=61764.2, bsz=1994.9, num_updates=84100, lr=0.000344828, gnorm=0.962, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:25:44 | INFO | train_inner | epoch 043:    924 / 1983 loss=3.438, nll_loss=1.281, word_ins=3.089, length=3.492, ppl=10.84, wps=209527, ups=3.41, wpb=61361.6, bsz=2014.9, num_updates=84200, lr=0.000344623, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:26:13 | INFO | train_inner | epoch 043:   1024 / 1983 loss=3.475, nll_loss=1.311, word_ins=3.116, length=3.583, ppl=11.12, wps=211801, ups=3.43, wpb=61814.8, bsz=1916.2, num_updates=84300, lr=0.000344418, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:26:43 | INFO | train_inner | epoch 043:   1124 / 1983 loss=3.422, nll_loss=1.269, word_ins=3.078, length=3.435, ppl=10.72, wps=210955, ups=3.41, wpb=61782.5, bsz=2042.7, num_updates=84400, lr=0.000344214, gnorm=0.935, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:27:12 | INFO | train_inner | epoch 043:   1224 / 1983 loss=3.439, nll_loss=1.282, word_ins=3.09, length=3.481, ppl=10.84, wps=212023, ups=3.43, wpb=61832.6, bsz=1984.6, num_updates=84500, lr=0.00034401, gnorm=0.967, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:27:41 | INFO | train_inner | epoch 043:   1324 / 1983 loss=3.433, nll_loss=1.269, word_ins=3.079, length=3.54, ppl=10.8, wps=211238, ups=3.43, wpb=61567.4, bsz=1978.5, num_updates=84600, lr=0.000343807, gnorm=0.949, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:28:10 | INFO | train_inner | epoch 043:   1424 / 1983 loss=3.42, nll_loss=1.268, word_ins=3.077, length=3.428, ppl=10.7, wps=211301, ups=3.42, wpb=61866.9, bsz=2001.9, num_updates=84700, lr=0.000343604, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:28:39 | INFO | train_inner | epoch 043:   1524 / 1983 loss=3.438, nll_loss=1.274, word_ins=3.084, length=3.545, ppl=10.84, wps=210083, ups=3.42, wpb=61345, bsz=1983.4, num_updates=84800, lr=0.000343401, gnorm=0.962, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:29:09 | INFO | train_inner | epoch 043:   1624 / 1983 loss=3.424, nll_loss=1.274, word_ins=3.083, length=3.408, ppl=10.73, wps=211015, ups=3.4, wpb=62012.6, bsz=2074, num_updates=84900, lr=0.000343199, gnorm=0.954, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:29:38 | INFO | train_inner | epoch 043:   1724 / 1983 loss=3.446, nll_loss=1.286, word_ins=3.093, length=3.53, ppl=10.9, wps=210805, ups=3.43, wpb=61531.7, bsz=2005.8, num_updates=85000, lr=0.000342997, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:29:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 01:30:08 | INFO | train_inner | epoch 043:   1825 / 1983 loss=3.408, nll_loss=1.252, word_ins=3.063, length=3.45, ppl=10.61, wps=208144, ups=3.37, wpb=61736.7, bsz=2102.6, num_updates=85100, lr=0.000342796, gnorm=0.946, loss_scale=16384, train_wall=30, wall=0
2023-03-02 01:30:37 | INFO | train_inner | epoch 043:   1925 / 1983 loss=3.427, nll_loss=1.264, word_ins=3.074, length=3.528, ppl=10.75, wps=211308, ups=3.45, wpb=61276.2, bsz=1987, num_updates=85200, lr=0.000342594, gnorm=0.954, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:30:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 01:31:09 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.358 | nll_loss 1.151 | word_ins 3.029 | length 3.283 | ppl 10.25 | wps 48675.3 | wpb 41551 | bsz 1500 | num_updates 85258 | best_loss 3.358
2023-03-02 01:31:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 01:31:26 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint43.pt (epoch 43 @ 85258 updates, score 3.358) (writing took 16.883002158021554 seconds)
2023-03-02 01:31:26 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-03-02 01:31:26 | INFO | train | epoch 043 | loss 3.427 | nll_loss 1.27 | word_ins 3.079 | length 3.48 | ppl 10.76 | wps 194972 | ups 3.16 | wpb 61628.3 | bsz 1997.4 | num_updates 85258 | lr 0.000342478 | gnorm 0.953 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 01:31:26 | INFO | fairseq.trainer | begin training epoch 44
2023-03-02 01:31:54 | INFO | train_inner | epoch 044:     42 / 1983 loss=3.404, nll_loss=1.252, word_ins=3.063, length=3.414, ppl=10.59, wps=79102, ups=1.3, wpb=60986.4, bsz=2080.6, num_updates=85300, lr=0.000342393, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:32:23 | INFO | train_inner | epoch 044:    142 / 1983 loss=3.423, nll_loss=1.27, word_ins=3.08, length=3.431, ppl=10.73, wps=210738, ups=3.42, wpb=61698.1, bsz=1988.3, num_updates=85400, lr=0.000342193, gnorm=0.964, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:32:52 | INFO | train_inner | epoch 044:    242 / 1983 loss=3.416, nll_loss=1.259, word_ins=3.07, length=3.461, ppl=10.68, wps=209398, ups=3.41, wpb=61393.2, bsz=2043.9, num_updates=85500, lr=0.000341993, gnorm=0.945, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:33:22 | INFO | train_inner | epoch 044:    342 / 1983 loss=3.432, nll_loss=1.27, word_ins=3.08, length=3.517, ppl=10.79, wps=210732, ups=3.42, wpb=61608.3, bsz=1979.5, num_updates=85600, lr=0.000341793, gnorm=0.984, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:33:51 | INFO | train_inner | epoch 044:    442 / 1983 loss=3.399, nll_loss=1.243, word_ins=3.055, length=3.44, ppl=10.55, wps=212098, ups=3.43, wpb=61760.3, bsz=2007, num_updates=85700, lr=0.000341593, gnorm=0.952, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:34:20 | INFO | train_inner | epoch 044:    542 / 1983 loss=3.389, nll_loss=1.232, word_ins=3.045, length=3.439, ppl=10.48, wps=211273, ups=3.43, wpb=61641.5, bsz=2043.4, num_updates=85800, lr=0.000341394, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:34:49 | INFO | train_inner | epoch 044:    642 / 1983 loss=3.435, nll_loss=1.276, word_ins=3.085, length=3.502, ppl=10.82, wps=211312, ups=3.42, wpb=61703.2, bsz=1986.5, num_updates=85900, lr=0.000341196, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:35:18 | INFO | train_inner | epoch 044:    742 / 1983 loss=3.424, nll_loss=1.265, word_ins=3.075, length=3.485, ppl=10.73, wps=210451, ups=3.41, wpb=61702.4, bsz=2009.9, num_updates=86000, lr=0.000340997, gnorm=0.976, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:35:48 | INFO | train_inner | epoch 044:    842 / 1983 loss=3.42, nll_loss=1.263, word_ins=3.073, length=3.47, ppl=10.7, wps=211170, ups=3.42, wpb=61673.8, bsz=2001.2, num_updates=86100, lr=0.000340799, gnorm=0.951, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:36:17 | INFO | train_inner | epoch 044:    942 / 1983 loss=3.432, nll_loss=1.276, word_ins=3.084, length=3.474, ppl=10.79, wps=213121, ups=3.45, wpb=61809.3, bsz=1939.8, num_updates=86200, lr=0.000340601, gnorm=0.974, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:36:46 | INFO | train_inner | epoch 044:   1042 / 1983 loss=3.418, nll_loss=1.262, word_ins=3.072, length=3.463, ppl=10.69, wps=210836, ups=3.41, wpb=61801, bsz=1993.1, num_updates=86300, lr=0.000340404, gnorm=0.953, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:37:15 | INFO | train_inner | epoch 044:   1142 / 1983 loss=3.421, nll_loss=1.259, word_ins=3.069, length=3.514, ppl=10.71, wps=211039, ups=3.43, wpb=61452.2, bsz=1971.8, num_updates=86400, lr=0.000340207, gnorm=0.971, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:37:44 | INFO | train_inner | epoch 044:   1242 / 1983 loss=3.422, nll_loss=1.266, word_ins=3.076, length=3.463, ppl=10.72, wps=209926, ups=3.41, wpb=61547, bsz=1973.4, num_updates=86500, lr=0.00034001, gnorm=0.964, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:38:14 | INFO | train_inner | epoch 044:   1342 / 1983 loss=3.394, nll_loss=1.241, word_ins=3.053, length=3.411, ppl=10.51, wps=211238, ups=3.42, wpb=61760.5, bsz=2072, num_updates=86600, lr=0.000339814, gnorm=0.949, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:38:43 | INFO | train_inner | epoch 044:   1442 / 1983 loss=3.418, nll_loss=1.263, word_ins=3.073, length=3.457, ppl=10.69, wps=211821, ups=3.42, wpb=61910.1, bsz=2013.8, num_updates=86700, lr=0.000339618, gnorm=0.966, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:39:12 | INFO | train_inner | epoch 044:   1542 / 1983 loss=3.436, nll_loss=1.275, word_ins=3.084, length=3.52, ppl=10.82, wps=210924, ups=3.43, wpb=61466.5, bsz=1931.5, num_updates=86800, lr=0.000339422, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:39:41 | INFO | train_inner | epoch 044:   1642 / 1983 loss=3.391, nll_loss=1.24, word_ins=3.051, length=3.397, ppl=10.49, wps=211536, ups=3.42, wpb=61937.3, bsz=2085.8, num_updates=86900, lr=0.000339227, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:40:11 | INFO | train_inner | epoch 044:   1742 / 1983 loss=3.442, nll_loss=1.285, word_ins=3.092, length=3.501, ppl=10.87, wps=210637, ups=3.42, wpb=61561.1, bsz=1969.8, num_updates=87000, lr=0.000339032, gnorm=0.971, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:40:40 | INFO | train_inner | epoch 044:   1842 / 1983 loss=3.419, nll_loss=1.259, word_ins=3.069, length=3.499, ppl=10.7, wps=211786, ups=3.43, wpb=61682.6, bsz=1952.6, num_updates=87100, lr=0.000338837, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:41:09 | INFO | train_inner | epoch 044:   1942 / 1983 loss=3.426, nll_loss=1.265, word_ins=3.075, length=3.511, ppl=10.75, wps=211963, ups=3.45, wpb=61436.5, bsz=1965.4, num_updates=87200, lr=0.000338643, gnorm=0.964, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 01:41:33 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.354 | nll_loss 1.145 | word_ins 3.024 | length 3.306 | ppl 10.23 | wps 110072 | wpb 41551 | bsz 1500 | num_updates 87241 | best_loss 3.354
2023-03-02 01:41:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 01:41:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint44.pt (epoch 44 @ 87241 updates, score 3.354) (writing took 13.754605306079611 seconds)
2023-03-02 01:41:47 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-03-02 01:41:47 | INFO | train | epoch 044 | loss 3.419 | nll_loss 1.261 | word_ins 3.072 | length 3.47 | ppl 10.69 | wps 196929 | ups 3.2 | wpb 61628.5 | bsz 1997.6 | num_updates 87241 | lr 0.000338563 | gnorm 0.965 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 01:41:47 | INFO | fairseq.trainer | begin training epoch 45
2023-03-02 01:42:19 | INFO | train_inner | epoch 045:     59 / 1983 loss=3.422, nll_loss=1.262, word_ins=3.072, length=3.507, ppl=10.72, wps=86630.2, ups=1.42, wpb=61172.2, bsz=1943.5, num_updates=87300, lr=0.000338449, gnorm=0.983, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:42:48 | INFO | train_inner | epoch 045:    159 / 1983 loss=3.429, nll_loss=1.27, word_ins=3.08, length=3.49, ppl=10.77, wps=212242, ups=3.44, wpb=61752.2, bsz=1924.3, num_updates=87400, lr=0.000338255, gnorm=0.984, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:43:18 | INFO | train_inner | epoch 045:    259 / 1983 loss=3.429, nll_loss=1.263, word_ins=3.073, length=3.559, ppl=10.77, wps=209574, ups=3.42, wpb=61212.9, bsz=1942.7, num_updates=87500, lr=0.000338062, gnorm=0.97, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:43:47 | INFO | train_inner | epoch 045:    359 / 1983 loss=3.414, nll_loss=1.257, word_ins=3.067, length=3.465, ppl=10.66, wps=213659, ups=3.45, wpb=62011.1, bsz=1883.6, num_updates=87600, lr=0.000337869, gnorm=0.987, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:44:16 | INFO | train_inner | epoch 045:    459 / 1983 loss=3.392, nll_loss=1.24, word_ins=3.052, length=3.394, ppl=10.5, wps=211267, ups=3.41, wpb=61969.4, bsz=2076.3, num_updates=87700, lr=0.000337676, gnorm=0.943, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:44:45 | INFO | train_inner | epoch 045:    559 / 1983 loss=3.411, nll_loss=1.252, word_ins=3.063, length=3.487, ppl=10.64, wps=209600, ups=3.41, wpb=61421.8, bsz=2001.9, num_updates=87800, lr=0.000337484, gnorm=0.959, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:45:14 | INFO | train_inner | epoch 045:    659 / 1983 loss=3.401, nll_loss=1.239, word_ins=3.051, length=3.497, ppl=10.56, wps=210087, ups=3.43, wpb=61248.6, bsz=2087.4, num_updates=87900, lr=0.000337292, gnorm=0.984, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:45:44 | INFO | train_inner | epoch 045:    759 / 1983 loss=3.415, nll_loss=1.26, word_ins=3.07, length=3.449, ppl=10.66, wps=210957, ups=3.42, wpb=61703.2, bsz=2025.6, num_updates=88000, lr=0.0003371, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:46:13 | INFO | train_inner | epoch 045:    859 / 1983 loss=3.413, nll_loss=1.258, word_ins=3.068, length=3.449, ppl=10.65, wps=212666, ups=3.43, wpb=62014.7, bsz=1983.4, num_updates=88100, lr=0.000336909, gnorm=0.986, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:46:42 | INFO | train_inner | epoch 045:    959 / 1983 loss=3.397, nll_loss=1.241, word_ins=3.053, length=3.437, ppl=10.53, wps=211083, ups=3.42, wpb=61674.9, bsz=2007, num_updates=88200, lr=0.000336718, gnorm=0.983, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:47:11 | INFO | train_inner | epoch 045:   1059 / 1983 loss=3.402, nll_loss=1.248, word_ins=3.059, length=3.436, ppl=10.57, wps=210290, ups=3.42, wpb=61482.5, bsz=2041.8, num_updates=88300, lr=0.000336527, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:47:41 | INFO | train_inner | epoch 045:   1159 / 1983 loss=3.412, nll_loss=1.255, word_ins=3.066, length=3.456, ppl=10.64, wps=209635, ups=3.41, wpb=61533.4, bsz=2071.5, num_updates=88400, lr=0.000336336, gnorm=0.959, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:48:10 | INFO | train_inner | epoch 045:   1259 / 1983 loss=3.434, nll_loss=1.273, word_ins=3.082, length=3.516, ppl=10.81, wps=210708, ups=3.43, wpb=61440.7, bsz=1918.1, num_updates=88500, lr=0.000336146, gnorm=0.986, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:48:39 | INFO | train_inner | epoch 045:   1359 / 1983 loss=3.419, nll_loss=1.261, word_ins=3.071, length=3.482, ppl=10.7, wps=211056, ups=3.43, wpb=61619.1, bsz=1991, num_updates=88600, lr=0.000335957, gnorm=0.979, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:49:08 | INFO | train_inner | epoch 045:   1459 / 1983 loss=3.408, nll_loss=1.253, word_ins=3.063, length=3.444, ppl=10.61, wps=211107, ups=3.4, wpb=62027, bsz=2093, num_updates=88700, lr=0.000335767, gnorm=0.98, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:49:38 | INFO | train_inner | epoch 045:   1559 / 1983 loss=3.418, nll_loss=1.261, word_ins=3.071, length=3.472, ppl=10.69, wps=210798, ups=3.42, wpb=61553.4, bsz=1981, num_updates=88800, lr=0.000335578, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:50:07 | INFO | train_inner | epoch 045:   1659 / 1983 loss=3.395, nll_loss=1.234, word_ins=3.047, length=3.487, ppl=10.52, wps=209031, ups=3.43, wpb=60962.5, bsz=2055.5, num_updates=88900, lr=0.000335389, gnorm=0.979, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:50:36 | INFO | train_inner | epoch 045:   1759 / 1983 loss=3.397, nll_loss=1.245, word_ins=3.056, length=3.41, ppl=10.53, wps=212852, ups=3.42, wpb=62153.5, bsz=2007.1, num_updates=89000, lr=0.000335201, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:51:05 | INFO | train_inner | epoch 045:   1859 / 1983 loss=3.417, nll_loss=1.257, word_ins=3.067, length=3.494, ppl=10.68, wps=212076, ups=3.43, wpb=61798.9, bsz=1952.2, num_updates=89100, lr=0.000335013, gnorm=0.999, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:51:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 01:51:34 | INFO | train_inner | epoch 045:   1960 / 1983 loss=3.425, nll_loss=1.262, word_ins=3.071, length=3.542, ppl=10.74, wps=211513, ups=3.42, wpb=61884.3, bsz=1909.9, num_updates=89200, lr=0.000334825, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:51:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 01:51:56 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.362 | nll_loss 1.151 | word_ins 3.029 | length 3.336 | ppl 10.28 | wps 84397.1 | wpb 41551 | bsz 1500 | num_updates 89223 | best_loss 3.354
2023-03-02 01:51:56 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 01:52:05 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint45.pt (epoch 45 @ 89223 updates, score 3.362) (writing took 8.238825624925084 seconds)
2023-03-02 01:52:05 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-03-02 01:52:05 | INFO | train | epoch 045 | loss 3.411 | nll_loss 1.254 | word_ins 3.064 | length 3.471 | ppl 10.64 | wps 197719 | ups 3.21 | wpb 61628.1 | bsz 1998 | num_updates 89223 | lr 0.000334782 | gnorm 0.977 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 01:52:05 | INFO | fairseq.trainer | begin training epoch 46
2023-03-02 01:52:38 | INFO | train_inner | epoch 046:     77 / 1983 loss=3.353, nll_loss=1.202, word_ins=3.018, length=3.352, ppl=10.22, wps=96714.2, ups=1.57, wpb=61433.2, bsz=2111, num_updates=89300, lr=0.000334637, gnorm=0.978, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:53:07 | INFO | train_inner | epoch 046:    177 / 1983 loss=3.364, nll_loss=1.218, word_ins=3.031, length=3.328, ppl=10.3, wps=212579, ups=3.42, wpb=62103.7, bsz=2103.8, num_updates=89400, lr=0.00033445, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:53:36 | INFO | train_inner | epoch 046:    277 / 1983 loss=3.425, nll_loss=1.262, word_ins=3.072, length=3.531, ppl=10.74, wps=211918, ups=3.42, wpb=61909.1, bsz=1874.7, num_updates=89500, lr=0.000334263, gnorm=1.003, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:54:06 | INFO | train_inner | epoch 046:    377 / 1983 loss=3.418, nll_loss=1.259, word_ins=3.069, length=3.484, ppl=10.69, wps=208793, ups=3.43, wpb=60956.4, bsz=1965.6, num_updates=89600, lr=0.000334077, gnorm=0.986, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:54:35 | INFO | train_inner | epoch 046:    477 / 1983 loss=3.396, nll_loss=1.238, word_ins=3.05, length=3.457, ppl=10.52, wps=210713, ups=3.43, wpb=61440.7, bsz=2037.4, num_updates=89700, lr=0.00033389, gnorm=0.998, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:55:04 | INFO | train_inner | epoch 046:    577 / 1983 loss=3.404, nll_loss=1.243, word_ins=3.054, length=3.499, ppl=10.59, wps=208347, ups=3.41, wpb=61106.9, bsz=2063, num_updates=89800, lr=0.000333704, gnorm=0.976, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:55:33 | INFO | train_inner | epoch 046:    677 / 1983 loss=3.384, nll_loss=1.227, word_ins=3.04, length=3.437, ppl=10.44, wps=209580, ups=3.41, wpb=61485.5, bsz=2058.5, num_updates=89900, lr=0.000333519, gnorm=0.973, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:56:03 | INFO | train_inner | epoch 046:    777 / 1983 loss=3.425, nll_loss=1.263, word_ins=3.072, length=3.522, ppl=10.74, wps=209670, ups=3.43, wpb=61128, bsz=1973, num_updates=90000, lr=0.000333333, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:56:32 | INFO | train_inner | epoch 046:    877 / 1983 loss=3.41, nll_loss=1.253, word_ins=3.064, length=3.467, ppl=10.63, wps=212758, ups=3.44, wpb=61929.4, bsz=1979.4, num_updates=90100, lr=0.000333148, gnorm=0.984, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:57:01 | INFO | train_inner | epoch 046:    977 / 1983 loss=3.401, nll_loss=1.246, word_ins=3.057, length=3.44, ppl=10.56, wps=212364, ups=3.43, wpb=61924.9, bsz=2018.4, num_updates=90200, lr=0.000332964, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:57:30 | INFO | train_inner | epoch 046:   1077 / 1983 loss=3.423, nll_loss=1.266, word_ins=3.075, length=3.488, ppl=10.73, wps=211242, ups=3.43, wpb=61645.5, bsz=1972.6, num_updates=90300, lr=0.000332779, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:57:59 | INFO | train_inner | epoch 046:   1177 / 1983 loss=3.383, nll_loss=1.231, word_ins=3.043, length=3.405, ppl=10.43, wps=212425, ups=3.42, wpb=62114.4, bsz=2039.3, num_updates=90400, lr=0.000332595, gnorm=0.995, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:58:28 | INFO | train_inner | epoch 046:   1277 / 1983 loss=3.393, nll_loss=1.234, word_ins=3.046, length=3.47, ppl=10.51, wps=210645, ups=3.43, wpb=61350.4, bsz=1988.4, num_updates=90500, lr=0.000332411, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:58:58 | INFO | train_inner | epoch 046:   1377 / 1983 loss=3.38, nll_loss=1.224, word_ins=3.037, length=3.431, ppl=10.41, wps=213312, ups=3.43, wpb=62273.6, bsz=2059.4, num_updates=90600, lr=0.000332228, gnorm=0.97, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:59:27 | INFO | train_inner | epoch 046:   1477 / 1983 loss=3.417, nll_loss=1.258, word_ins=3.068, length=3.493, ppl=10.68, wps=210953, ups=3.43, wpb=61463.4, bsz=1933.2, num_updates=90700, lr=0.000332045, gnorm=0.987, loss_scale=16384, train_wall=29, wall=0
2023-03-02 01:59:56 | INFO | train_inner | epoch 046:   1577 / 1983 loss=3.417, nll_loss=1.254, word_ins=3.064, length=3.536, ppl=10.68, wps=212319, ups=3.44, wpb=61651.3, bsz=1921.8, num_updates=90800, lr=0.000331862, gnorm=0.983, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:00:25 | INFO | train_inner | epoch 046:   1677 / 1983 loss=3.397, nll_loss=1.245, word_ins=3.056, length=3.409, ppl=10.54, wps=210192, ups=3.4, wpb=61787.7, bsz=2034.1, num_updates=90900, lr=0.000331679, gnorm=1.002, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:00:54 | INFO | train_inner | epoch 046:   1777 / 1983 loss=3.411, nll_loss=1.254, word_ins=3.064, length=3.468, ppl=10.64, wps=211539, ups=3.43, wpb=61636, bsz=1974.2, num_updates=91000, lr=0.000331497, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:01:24 | INFO | train_inner | epoch 046:   1877 / 1983 loss=3.427, nll_loss=1.268, word_ins=3.077, length=3.5, ppl=10.75, wps=209997, ups=3.42, wpb=61395.9, bsz=1993.9, num_updates=91100, lr=0.000331315, gnorm=0.998, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:01:53 | INFO | train_inner | epoch 046:   1977 / 1983 loss=3.445, nll_loss=1.284, word_ins=3.091, length=3.536, ppl=10.89, wps=211287, ups=3.42, wpb=61807.5, bsz=1908.6, num_updates=91200, lr=0.000331133, gnorm=1.017, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 02:02:08 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.359 | nll_loss 1.141 | word_ins 3.023 | length 3.361 | ppl 10.26 | wps 83350.3 | wpb 41551 | bsz 1500 | num_updates 91206 | best_loss 3.354
2023-03-02 02:02:08 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 02:02:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint46.pt (epoch 46 @ 91206 updates, score 3.359) (writing took 9.643446796922944 seconds)
2023-03-02 02:02:17 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-03-02 02:02:17 | INFO | train | epoch 046 | loss 3.404 | nll_loss 1.247 | word_ins 3.058 | length 3.465 | ppl 10.59 | wps 199454 | ups 3.24 | wpb 61628.5 | bsz 1997.6 | num_updates 91206 | lr 0.000331122 | gnorm 0.988 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 02:02:17 | INFO | fairseq.trainer | begin training epoch 47
2023-03-02 02:02:55 | INFO | train_inner | epoch 047:     94 / 1983 loss=3.398, nll_loss=1.237, word_ins=3.049, length=3.488, ppl=10.54, wps=97936.4, ups=1.61, wpb=60908.3, bsz=1961.3, num_updates=91300, lr=0.000330952, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:03:24 | INFO | train_inner | epoch 047:    194 / 1983 loss=3.405, nll_loss=1.241, word_ins=3.054, length=3.51, ppl=10.59, wps=210323, ups=3.42, wpb=61564.6, bsz=1910.4, num_updates=91400, lr=0.000330771, gnorm=1.027, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:03:53 | INFO | train_inner | epoch 047:    294 / 1983 loss=3.365, nll_loss=1.21, word_ins=3.025, length=3.406, ppl=10.31, wps=211945, ups=3.42, wpb=61998.6, bsz=2040.5, num_updates=91500, lr=0.00033059, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:04:23 | INFO | train_inner | epoch 047:    394 / 1983 loss=3.414, nll_loss=1.254, word_ins=3.065, length=3.492, ppl=10.66, wps=210513, ups=3.42, wpb=61515, bsz=1963.8, num_updates=91600, lr=0.000330409, gnorm=0.991, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:04:52 | INFO | train_inner | epoch 047:    494 / 1983 loss=3.397, nll_loss=1.237, word_ins=3.049, length=3.481, ppl=10.54, wps=211500, ups=3.42, wpb=61788.8, bsz=1953.2, num_updates=91700, lr=0.000330229, gnorm=1.001, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:05:21 | INFO | train_inner | epoch 047:    594 / 1983 loss=3.4, nll_loss=1.243, word_ins=3.054, length=3.463, ppl=10.56, wps=210897, ups=3.41, wpb=61816.6, bsz=1997.8, num_updates=91800, lr=0.000330049, gnorm=0.985, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:05:50 | INFO | train_inner | epoch 047:    694 / 1983 loss=3.389, nll_loss=1.237, word_ins=3.048, length=3.411, ppl=10.48, wps=211339, ups=3.42, wpb=61767.8, bsz=1994.6, num_updates=91900, lr=0.00032987, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:06:20 | INFO | train_inner | epoch 047:    794 / 1983 loss=3.415, nll_loss=1.258, word_ins=3.068, length=3.472, ppl=10.67, wps=208516, ups=3.42, wpb=61019.9, bsz=2029.6, num_updates=92000, lr=0.00032969, gnorm=0.999, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:06:49 | INFO | train_inner | epoch 047:    894 / 1983 loss=3.396, nll_loss=1.237, word_ins=3.049, length=3.471, ppl=10.53, wps=212412, ups=3.44, wpb=61731.3, bsz=1945.6, num_updates=92100, lr=0.000329511, gnorm=1.008, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:07:18 | INFO | train_inner | epoch 047:    994 / 1983 loss=3.402, nll_loss=1.25, word_ins=3.06, length=3.422, ppl=10.57, wps=210618, ups=3.42, wpb=61658.5, bsz=2005.4, num_updates=92200, lr=0.000329332, gnorm=0.985, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:07:47 | INFO | train_inner | epoch 047:   1094 / 1983 loss=3.415, nll_loss=1.254, word_ins=3.064, length=3.508, ppl=10.66, wps=209934, ups=3.43, wpb=61186.2, bsz=1981.5, num_updates=92300, lr=0.000329154, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:08:16 | INFO | train_inner | epoch 047:   1194 / 1983 loss=3.384, nll_loss=1.23, word_ins=3.042, length=3.425, ppl=10.44, wps=210589, ups=3.44, wpb=61233, bsz=1992.3, num_updates=92400, lr=0.000328976, gnorm=0.957, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:08:45 | INFO | train_inner | epoch 047:   1294 / 1983 loss=3.394, nll_loss=1.234, word_ins=3.045, length=3.491, ppl=10.52, wps=210431, ups=3.43, wpb=61360.8, bsz=1988.9, num_updates=92500, lr=0.000328798, gnorm=0.966, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:09:15 | INFO | train_inner | epoch 047:   1394 / 1983 loss=3.386, nll_loss=1.232, word_ins=3.044, length=3.413, ppl=10.45, wps=210566, ups=3.41, wpb=61729.7, bsz=2045.8, num_updates=92600, lr=0.00032862, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:09:44 | INFO | train_inner | epoch 047:   1494 / 1983 loss=3.411, nll_loss=1.254, word_ins=3.065, length=3.462, ppl=10.64, wps=209616, ups=3.4, wpb=61593, bsz=2003.4, num_updates=92700, lr=0.000328443, gnorm=1.021, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:10:14 | INFO | train_inner | epoch 047:   1594 / 1983 loss=3.393, nll_loss=1.236, word_ins=3.048, length=3.45, ppl=10.5, wps=212770, ups=3.41, wpb=62422.2, bsz=2054.5, num_updates=92800, lr=0.000328266, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:10:43 | INFO | train_inner | epoch 047:   1694 / 1983 loss=3.397, nll_loss=1.241, word_ins=3.052, length=3.449, ppl=10.53, wps=210323, ups=3.4, wpb=61833.9, bsz=2025.1, num_updates=92900, lr=0.000328089, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:11:12 | INFO | train_inner | epoch 047:   1794 / 1983 loss=3.374, nll_loss=1.22, word_ins=3.033, length=3.413, ppl=10.37, wps=212878, ups=3.43, wpb=62001.8, bsz=2023.7, num_updates=93000, lr=0.000327913, gnorm=0.987, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:11:41 | INFO | train_inner | epoch 047:   1894 / 1983 loss=3.39, nll_loss=1.236, word_ins=3.047, length=3.427, ppl=10.48, wps=211653, ups=3.4, wpb=62230.4, bsz=2027.4, num_updates=93100, lr=0.000327737, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:12:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 02:12:23 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.353 | nll_loss 1.134 | word_ins 3.013 | length 3.4 | ppl 10.22 | wps 141177 | wpb 41551 | bsz 1500 | num_updates 93189 | best_loss 3.353
2023-03-02 02:12:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 02:12:36 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint47.pt (epoch 47 @ 93189 updates, score 3.353) (writing took 13.351852427003905 seconds)
2023-03-02 02:12:36 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-03-02 02:12:36 | INFO | train | epoch 047 | loss 3.396 | nll_loss 1.239 | word_ins 3.05 | length 3.456 | ppl 10.52 | wps 197524 | ups 3.21 | wpb 61628.5 | bsz 1997.6 | num_updates 93189 | lr 0.00032758 | gnorm 0.998 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 02:12:36 | INFO | fairseq.trainer | begin training epoch 48
2023-03-02 02:12:50 | INFO | train_inner | epoch 048:     11 / 1983 loss=3.376, nll_loss=1.22, word_ins=3.033, length=3.433, ppl=10.39, wps=88501.7, ups=1.45, wpb=60840.3, bsz=2023, num_updates=93200, lr=0.000327561, gnorm=1.023, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:13:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 02:13:20 | INFO | train_inner | epoch 048:    112 / 1983 loss=3.394, nll_loss=1.236, word_ins=3.048, length=3.46, ppl=10.51, wps=208653, ups=3.39, wpb=61608.2, bsz=2016.2, num_updates=93300, lr=0.000327385, gnorm=1.002, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:13:49 | INFO | train_inner | epoch 048:    212 / 1983 loss=3.374, nll_loss=1.218, word_ins=3.031, length=3.435, ppl=10.37, wps=211121, ups=3.43, wpb=61610.8, bsz=2042.6, num_updates=93400, lr=0.00032721, gnorm=0.971, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:14:18 | INFO | train_inner | epoch 048:    312 / 1983 loss=3.406, nll_loss=1.249, word_ins=3.06, length=3.463, ppl=10.6, wps=211685, ups=3.41, wpb=62022.8, bsz=1906.2, num_updates=93500, lr=0.000327035, gnorm=1.039, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:14:47 | INFO | train_inner | epoch 048:    412 / 1983 loss=3.402, nll_loss=1.246, word_ins=3.056, length=3.455, ppl=10.57, wps=211212, ups=3.42, wpb=61731.7, bsz=1947.6, num_updates=93600, lr=0.00032686, gnorm=1.011, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:15:17 | INFO | train_inner | epoch 048:    512 / 1983 loss=3.387, nll_loss=1.228, word_ins=3.041, length=3.468, ppl=10.46, wps=209718, ups=3.42, wpb=61298.7, bsz=1959.7, num_updates=93700, lr=0.000326686, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:15:46 | INFO | train_inner | epoch 048:    612 / 1983 loss=3.356, nll_loss=1.202, word_ins=3.017, length=3.4, ppl=10.24, wps=210899, ups=3.41, wpb=61832.4, bsz=2137.9, num_updates=93800, lr=0.000326512, gnorm=0.943, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:16:15 | INFO | train_inner | epoch 048:    712 / 1983 loss=3.411, nll_loss=1.246, word_ins=3.057, length=3.538, ppl=10.63, wps=209860, ups=3.42, wpb=61354.3, bsz=1914.3, num_updates=93900, lr=0.000326338, gnorm=1.017, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:16:44 | INFO | train_inner | epoch 048:    812 / 1983 loss=3.405, nll_loss=1.247, word_ins=3.058, length=3.473, ppl=10.59, wps=211506, ups=3.43, wpb=61620, bsz=1960.5, num_updates=94000, lr=0.000326164, gnorm=1.033, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:17:14 | INFO | train_inner | epoch 048:    912 / 1983 loss=3.386, nll_loss=1.231, word_ins=3.043, length=3.427, ppl=10.45, wps=210301, ups=3.41, wpb=61687.5, bsz=1996.2, num_updates=94100, lr=0.000325991, gnorm=0.999, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:17:43 | INFO | train_inner | epoch 048:   1012 / 1983 loss=3.392, nll_loss=1.237, word_ins=3.048, length=3.442, ppl=10.5, wps=210996, ups=3.41, wpb=61843.9, bsz=2005.6, num_updates=94200, lr=0.000325818, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:18:12 | INFO | train_inner | epoch 048:   1112 / 1983 loss=3.41, nll_loss=1.248, word_ins=3.059, length=3.507, ppl=10.63, wps=211293, ups=3.44, wpb=61497.9, bsz=1886.6, num_updates=94300, lr=0.000325645, gnorm=1.042, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:18:41 | INFO | train_inner | epoch 048:   1212 / 1983 loss=3.34, nll_loss=1.19, word_ins=3.005, length=3.346, ppl=10.13, wps=210657, ups=3.41, wpb=61692.9, bsz=2081.5, num_updates=94400, lr=0.000325472, gnorm=0.966, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:19:11 | INFO | train_inner | epoch 048:   1312 / 1983 loss=3.369, nll_loss=1.215, word_ins=3.028, length=3.405, ppl=10.33, wps=209466, ups=3.41, wpb=61438.2, bsz=2065, num_updates=94500, lr=0.0003253, gnorm=1.008, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:19:40 | INFO | train_inner | epoch 048:   1412 / 1983 loss=3.402, nll_loss=1.241, word_ins=3.052, length=3.507, ppl=10.57, wps=209598, ups=3.41, wpb=61378.9, bsz=2017.5, num_updates=94600, lr=0.000325128, gnorm=1.011, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:20:09 | INFO | train_inner | epoch 048:   1512 / 1983 loss=3.405, nll_loss=1.247, word_ins=3.057, length=3.486, ppl=10.6, wps=211320, ups=3.41, wpb=61919.1, bsz=2002.9, num_updates=94700, lr=0.000324956, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:20:38 | INFO | train_inner | epoch 048:   1612 / 1983 loss=3.417, nll_loss=1.255, word_ins=3.065, length=3.519, ppl=10.68, wps=211260, ups=3.44, wpb=61483.9, bsz=1907, num_updates=94800, lr=0.000324785, gnorm=1.032, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:21:08 | INFO | train_inner | epoch 048:   1712 / 1983 loss=3.388, nll_loss=1.232, word_ins=3.044, length=3.437, ppl=10.47, wps=211046, ups=3.41, wpb=61853.1, bsz=2012, num_updates=94900, lr=0.000324614, gnorm=1.013, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:21:37 | INFO | train_inner | epoch 048:   1812 / 1983 loss=3.367, nll_loss=1.212, word_ins=3.026, length=3.409, ppl=10.32, wps=210504, ups=3.42, wpb=61546.2, bsz=2065.3, num_updates=95000, lr=0.000324443, gnorm=1.007, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:22:06 | INFO | train_inner | epoch 048:   1912 / 1983 loss=3.388, nll_loss=1.238, word_ins=3.049, length=3.388, ppl=10.47, wps=212591, ups=3.43, wpb=61913.2, bsz=2019.3, num_updates=95100, lr=0.000324272, gnorm=1.004, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 02:22:40 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 3.329 | nll_loss 1.115 | word_ins 3.002 | length 3.275 | ppl 10.05 | wps 128917 | wpb 41551 | bsz 1500 | num_updates 95171 | best_loss 3.329
2023-03-02 02:22:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 02:22:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint48.pt (epoch 48 @ 95171 updates, score 3.329) (writing took 11.609478311962448 seconds)
2023-03-02 02:22:52 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-03-02 02:22:52 | INFO | train | epoch 048 | loss 3.389 | nll_loss 1.232 | word_ins 3.044 | length 3.45 | ppl 10.48 | wps 198328 | ups 3.22 | wpb 61627.4 | bsz 1997.4 | num_updates 95171 | lr 0.000324151 | gnorm 1.008 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 02:22:52 | INFO | fairseq.trainer | begin training epoch 49
2023-03-02 02:23:15 | INFO | train_inner | epoch 049:     29 / 1983 loss=3.387, nll_loss=1.226, word_ins=3.038, length=3.492, ppl=10.46, wps=89202.7, ups=1.45, wpb=61350.4, bsz=1985.6, num_updates=95200, lr=0.000324102, gnorm=1.047, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:23:44 | INFO | train_inner | epoch 049:    129 / 1983 loss=3.385, nll_loss=1.225, word_ins=3.038, length=3.465, ppl=10.44, wps=211363, ups=3.42, wpb=61808.6, bsz=1980.5, num_updates=95300, lr=0.000323932, gnorm=1.084, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:24:13 | INFO | train_inner | epoch 049:    229 / 1983 loss=3.411, nll_loss=1.247, word_ins=3.057, length=3.534, ppl=10.63, wps=210322, ups=3.42, wpb=61567, bsz=1888.4, num_updates=95400, lr=0.000323762, gnorm=1.021, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:24:43 | INFO | train_inner | epoch 049:    329 / 1983 loss=3.366, nll_loss=1.214, word_ins=3.028, length=3.385, ppl=10.31, wps=212231, ups=3.42, wpb=62096.6, bsz=1948.6, num_updates=95500, lr=0.000323592, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:25:12 | INFO | train_inner | epoch 049:    429 / 1983 loss=3.352, nll_loss=1.196, word_ins=3.011, length=3.406, ppl=10.21, wps=210879, ups=3.41, wpb=61777.8, bsz=2070.3, num_updates=95600, lr=0.000323423, gnorm=0.999, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:25:41 | INFO | train_inner | epoch 049:    529 / 1983 loss=3.396, nll_loss=1.233, word_ins=3.045, length=3.511, ppl=10.53, wps=207789, ups=3.41, wpb=60851.5, bsz=2024.9, num_updates=95700, lr=0.000323254, gnorm=1.002, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:26:10 | INFO | train_inner | epoch 049:    629 / 1983 loss=3.401, nll_loss=1.239, word_ins=3.051, length=3.503, ppl=10.56, wps=211172, ups=3.43, wpb=61532, bsz=1923.8, num_updates=95800, lr=0.000323085, gnorm=1.031, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:26:40 | INFO | train_inner | epoch 049:    729 / 1983 loss=3.389, nll_loss=1.229, word_ins=3.041, length=3.481, ppl=10.48, wps=212473, ups=3.43, wpb=61875.8, bsz=1912.5, num_updates=95900, lr=0.000322917, gnorm=1.031, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:27:09 | INFO | train_inner | epoch 049:    829 / 1983 loss=3.409, nll_loss=1.248, word_ins=3.059, length=3.5, ppl=10.62, wps=210915, ups=3.42, wpb=61685.9, bsz=1966.5, num_updates=96000, lr=0.000322749, gnorm=1.026, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:27:38 | INFO | train_inner | epoch 049:    929 / 1983 loss=3.377, nll_loss=1.221, word_ins=3.034, length=3.433, ppl=10.39, wps=209631, ups=3.42, wpb=61370.4, bsz=2049.8, num_updates=96100, lr=0.000322581, gnorm=1.008, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:28:07 | INFO | train_inner | epoch 049:   1029 / 1983 loss=3.388, nll_loss=1.231, word_ins=3.043, length=3.453, ppl=10.47, wps=209124, ups=3.41, wpb=61285.1, bsz=2012.2, num_updates=96200, lr=0.000322413, gnorm=0.998, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:28:37 | INFO | train_inner | epoch 049:   1129 / 1983 loss=3.388, nll_loss=1.23, word_ins=3.042, length=3.462, ppl=10.47, wps=209451, ups=3.41, wpb=61475.4, bsz=2054.7, num_updates=96300, lr=0.000322245, gnorm=1.025, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:29:06 | INFO | train_inner | epoch 049:   1229 / 1983 loss=3.337, nll_loss=1.186, word_ins=3.002, length=3.352, ppl=10.1, wps=210482, ups=3.42, wpb=61576.6, bsz=2102.2, num_updates=96400, lr=0.000322078, gnorm=1.013, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:29:35 | INFO | train_inner | epoch 049:   1329 / 1983 loss=3.362, nll_loss=1.21, word_ins=3.023, length=3.387, ppl=10.28, wps=210921, ups=3.41, wpb=61852.2, bsz=2064.3, num_updates=96500, lr=0.000321911, gnorm=0.99, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:30:05 | INFO | train_inner | epoch 049:   1429 / 1983 loss=3.392, nll_loss=1.235, word_ins=3.046, length=3.454, ppl=10.49, wps=210879, ups=3.41, wpb=61828, bsz=2008.5, num_updates=96600, lr=0.000321745, gnorm=1.026, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:30:34 | INFO | train_inner | epoch 049:   1529 / 1983 loss=3.391, nll_loss=1.23, word_ins=3.041, length=3.497, ppl=10.49, wps=211041, ups=3.42, wpb=61634.9, bsz=1984.7, num_updates=96700, lr=0.000321578, gnorm=1.029, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:31:03 | INFO | train_inner | epoch 049:   1629 / 1983 loss=3.381, nll_loss=1.227, word_ins=3.039, length=3.427, ppl=10.42, wps=210852, ups=3.43, wpb=61515.4, bsz=1995.1, num_updates=96800, lr=0.000321412, gnorm=1.022, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:31:32 | INFO | train_inner | epoch 049:   1729 / 1983 loss=3.383, nll_loss=1.225, word_ins=3.037, length=3.464, ppl=10.43, wps=211429, ups=3.43, wpb=61728, bsz=2027.5, num_updates=96900, lr=0.000321246, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:32:01 | INFO | train_inner | epoch 049:   1829 / 1983 loss=3.385, nll_loss=1.224, word_ins=3.036, length=3.492, ppl=10.45, wps=212974, ups=3.43, wpb=62046, bsz=1966.3, num_updates=97000, lr=0.000321081, gnorm=1.042, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:32:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-03-02 02:32:31 | INFO | train_inner | epoch 049:   1930 / 1983 loss=3.395, nll_loss=1.238, word_ins=3.048, length=3.469, ppl=10.52, wps=209735, ups=3.39, wpb=61935.2, bsz=1913.3, num_updates=97100, lr=0.000320915, gnorm=1.041, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 02:33:00 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 3.315 | nll_loss 1.105 | word_ins 2.992 | length 3.235 | ppl 9.96 | wps 77504.5 | wpb 41551 | bsz 1500 | num_updates 97153 | best_loss 3.315
2023-03-02 02:33:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 02:33:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint49.pt (epoch 49 @ 97153 updates, score 3.315) (writing took 15.837004952016287 seconds)
2023-03-02 02:33:16 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-03-02 02:33:16 | INFO | train | epoch 049 | loss 3.384 | nll_loss 1.226 | word_ins 3.038 | length 3.457 | ppl 10.44 | wps 195731 | ups 3.18 | wpb 61629.7 | bsz 1997.3 | num_updates 97153 | lr 0.000320828 | gnorm 1.022 | loss_scale 8192 | train_wall 577 | wall 0
2023-03-02 02:33:16 | INFO | fairseq.trainer | begin training epoch 50
2023-03-02 02:33:43 | INFO | train_inner | epoch 050:     47 / 1983 loss=3.369, nll_loss=1.214, word_ins=3.027, length=3.423, ppl=10.33, wps=83997.9, ups=1.38, wpb=60799.8, bsz=2055.6, num_updates=97200, lr=0.00032075, gnorm=1.002, loss_scale=8192, train_wall=30, wall=0
2023-03-02 02:34:13 | INFO | train_inner | epoch 050:    147 / 1983 loss=3.395, nll_loss=1.24, word_ins=3.051, length=3.434, ppl=10.52, wps=209435, ups=3.41, wpb=61415.6, bsz=1954.7, num_updates=97300, lr=0.000320585, gnorm=1.03, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:34:42 | INFO | train_inner | epoch 050:    247 / 1983 loss=3.337, nll_loss=1.184, word_ins=3, length=3.371, ppl=10.1, wps=212469, ups=3.42, wpb=62041.3, bsz=2015.7, num_updates=97400, lr=0.000320421, gnorm=1.011, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:35:11 | INFO | train_inner | epoch 050:    347 / 1983 loss=3.392, nll_loss=1.237, word_ins=3.048, length=3.443, ppl=10.5, wps=209414, ups=3.41, wpb=61357.2, bsz=1988, num_updates=97500, lr=0.000320256, gnorm=1.015, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:35:40 | INFO | train_inner | epoch 050:    447 / 1983 loss=3.39, nll_loss=1.227, word_ins=3.039, length=3.504, ppl=10.48, wps=209033, ups=3.42, wpb=61155.8, bsz=1985.3, num_updates=97600, lr=0.000320092, gnorm=1.019, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:36:10 | INFO | train_inner | epoch 050:    547 / 1983 loss=3.37, nll_loss=1.217, word_ins=3.031, length=3.389, ppl=10.34, wps=208596, ups=3.38, wpb=61669.2, bsz=2054.3, num_updates=97700, lr=0.000319928, gnorm=0.995, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:36:39 | INFO | train_inner | epoch 050:    647 / 1983 loss=3.349, nll_loss=1.198, word_ins=3.013, length=3.363, ppl=10.19, wps=212170, ups=3.41, wpb=62206.6, bsz=2038.9, num_updates=97800, lr=0.000319765, gnorm=1.031, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:37:08 | INFO | train_inner | epoch 050:    747 / 1983 loss=3.396, nll_loss=1.235, word_ins=3.046, length=3.497, ppl=10.53, wps=213145, ups=3.44, wpb=61889.5, bsz=1918.1, num_updates=97900, lr=0.000319601, gnorm=1.044, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:37:38 | INFO | train_inner | epoch 050:    847 / 1983 loss=3.403, nll_loss=1.243, word_ins=3.054, length=3.499, ppl=10.58, wps=208194, ups=3.42, wpb=60853.2, bsz=1947.3, num_updates=98000, lr=0.000319438, gnorm=1.036, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:38:07 | INFO | train_inner | epoch 050:    947 / 1983 loss=3.383, nll_loss=1.229, word_ins=3.041, length=3.425, ppl=10.43, wps=211142, ups=3.42, wpb=61822.5, bsz=2003.3, num_updates=98100, lr=0.000319275, gnorm=1.031, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:38:36 | INFO | train_inner | epoch 050:   1047 / 1983 loss=3.363, nll_loss=1.204, word_ins=3.018, length=3.449, ppl=10.29, wps=211501, ups=3.43, wpb=61689, bsz=2017, num_updates=98200, lr=0.000319113, gnorm=1.033, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:39:05 | INFO | train_inner | epoch 050:   1147 / 1983 loss=3.382, nll_loss=1.223, word_ins=3.035, length=3.472, ppl=10.43, wps=208229, ups=3.41, wpb=61149.7, bsz=2025.6, num_updates=98300, lr=0.00031895, gnorm=1.008, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:39:35 | INFO | train_inner | epoch 050:   1247 / 1983 loss=3.389, nll_loss=1.228, word_ins=3.04, length=3.486, ppl=10.47, wps=211982, ups=3.42, wpb=61959.6, bsz=1951.3, num_updates=98400, lr=0.000318788, gnorm=1.049, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:40:04 | INFO | train_inner | epoch 050:   1347 / 1983 loss=3.382, nll_loss=1.226, word_ins=3.038, length=3.441, ppl=10.42, wps=212031, ups=3.43, wpb=61855.5, bsz=1961.8, num_updates=98500, lr=0.000318626, gnorm=1.028, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:40:33 | INFO | train_inner | epoch 050:   1447 / 1983 loss=3.374, nll_loss=1.213, word_ins=3.026, length=3.481, ppl=10.37, wps=211754, ups=3.44, wpb=61587.4, bsz=1975.2, num_updates=98600, lr=0.000318465, gnorm=1.031, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:41:02 | INFO | train_inner | epoch 050:   1547 / 1983 loss=3.371, nll_loss=1.214, word_ins=3.027, length=3.439, ppl=10.35, wps=213766, ups=3.44, wpb=62099.7, bsz=2017.8, num_updates=98700, lr=0.000318304, gnorm=1.027, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:41:31 | INFO | train_inner | epoch 050:   1647 / 1983 loss=3.389, nll_loss=1.228, word_ins=3.039, length=3.493, ppl=10.47, wps=210314, ups=3.43, wpb=61251.8, bsz=1993, num_updates=98800, lr=0.000318142, gnorm=1.042, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:42:00 | INFO | train_inner | epoch 050:   1747 / 1983 loss=3.381, nll_loss=1.225, word_ins=3.037, length=3.444, ppl=10.42, wps=212387, ups=3.43, wpb=61989.7, bsz=1997.8, num_updates=98900, lr=0.000317982, gnorm=1.027, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:42:29 | INFO | train_inner | epoch 050:   1847 / 1983 loss=3.347, nll_loss=1.19, word_ins=3.005, length=3.418, ppl=10.17, wps=213536, ups=3.43, wpb=62312.7, bsz=2038.3, num_updates=99000, lr=0.000317821, gnorm=1.027, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:42:59 | INFO | train_inner | epoch 050:   1947 / 1983 loss=3.364, nll_loss=1.209, word_ins=3.022, length=3.42, ppl=10.3, wps=210715, ups=3.42, wpb=61570.3, bsz=2062.4, num_updates=99100, lr=0.00031766, gnorm=1, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 02:43:24 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 3.312 | nll_loss 1.104 | word_ins 2.982 | length 3.3 | ppl 9.93 | wps 54263.6 | wpb 41551 | bsz 1500 | num_updates 99136 | best_loss 3.312
2023-03-02 02:43:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 02:43:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint50.pt (epoch 50 @ 99136 updates, score 3.312) (writing took 14.415727035026066 seconds)
2023-03-02 02:43:39 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-03-02 02:43:39 | INFO | train | epoch 050 | loss 3.377 | nll_loss 1.22 | word_ins 3.032 | length 3.445 | ppl 10.39 | wps 196284 | ups 3.18 | wpb 61628.5 | bsz 1997.6 | num_updates 99136 | lr 0.000317603 | gnorm 1.027 | loss_scale 8192 | train_wall 577 | wall 0
2023-03-02 02:43:39 | INFO | fairseq.trainer | begin training epoch 51
2023-03-02 02:44:09 | INFO | train_inner | epoch 051:     64 / 1983 loss=3.415, nll_loss=1.254, word_ins=3.064, length=3.505, ppl=10.66, wps=87385.3, ups=1.43, wpb=61202.5, bsz=1891.2, num_updates=99200, lr=0.0003175, gnorm=1.083, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:44:38 | INFO | train_inner | epoch 051:    164 / 1983 loss=3.376, nll_loss=1.217, word_ins=3.03, length=3.456, ppl=10.38, wps=209898, ups=3.41, wpb=61555.7, bsz=1901.8, num_updates=99300, lr=0.00031734, gnorm=1.038, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:45:07 | INFO | train_inner | epoch 051:    264 / 1983 loss=3.364, nll_loss=1.209, word_ins=3.023, length=3.414, ppl=10.3, wps=209079, ups=3.39, wpb=61613.1, bsz=2059.6, num_updates=99400, lr=0.000317181, gnorm=1.039, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:45:37 | INFO | train_inner | epoch 051:    364 / 1983 loss=3.365, nll_loss=1.209, word_ins=3.022, length=3.428, ppl=10.3, wps=209607, ups=3.41, wpb=61507.3, bsz=2062, num_updates=99500, lr=0.000317021, gnorm=1.034, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:46:06 | INFO | train_inner | epoch 051:    464 / 1983 loss=3.351, nll_loss=1.193, word_ins=3.008, length=3.426, ppl=10.2, wps=211259, ups=3.43, wpb=61594.7, bsz=2036.7, num_updates=99600, lr=0.000316862, gnorm=1.025, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:46:35 | INFO | train_inner | epoch 051:    564 / 1983 loss=3.325, nll_loss=1.171, word_ins=2.988, length=3.37, ppl=10.02, wps=211034, ups=3.42, wpb=61731.9, bsz=2071.5, num_updates=99700, lr=0.000316703, gnorm=1.005, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:47:05 | INFO | train_inner | epoch 051:    664 / 1983 loss=3.369, nll_loss=1.214, word_ins=3.026, length=3.429, ppl=10.33, wps=209345, ups=3.41, wpb=61301.6, bsz=2014.2, num_updates=99800, lr=0.000316544, gnorm=1.039, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:47:34 | INFO | train_inner | epoch 051:    764 / 1983 loss=3.374, nll_loss=1.213, word_ins=3.026, length=3.48, ppl=10.37, wps=209521, ups=3.41, wpb=61434.3, bsz=1990.7, num_updates=99900, lr=0.000316386, gnorm=1.024, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:48:03 | INFO | train_inner | epoch 051:    864 / 1983 loss=3.369, nll_loss=1.209, word_ins=3.022, length=3.462, ppl=10.33, wps=209533, ups=3.41, wpb=61375.2, bsz=1992.3, num_updates=100000, lr=0.000316228, gnorm=1.042, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:48:32 | INFO | train_inner | epoch 051:    964 / 1983 loss=3.355, nll_loss=1.207, word_ins=3.02, length=3.35, ppl=10.23, wps=211852, ups=3.42, wpb=62016.8, bsz=2083.7, num_updates=100100, lr=0.00031607, gnorm=1.035, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:49:02 | INFO | train_inner | epoch 051:   1064 / 1983 loss=3.373, nll_loss=1.213, word_ins=3.026, length=3.473, ppl=10.36, wps=209575, ups=3.42, wpb=61246.5, bsz=2052.6, num_updates=100200, lr=0.000315912, gnorm=1.011, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:49:31 | INFO | train_inner | epoch 051:   1164 / 1983 loss=3.39, nll_loss=1.232, word_ins=3.043, length=3.475, ppl=10.49, wps=214100, ups=3.44, wpb=62306.5, bsz=1883.1, num_updates=100300, lr=0.000315754, gnorm=1.056, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:50:00 | INFO | train_inner | epoch 051:   1264 / 1983 loss=3.343, nll_loss=1.188, word_ins=3.003, length=3.405, ppl=10.15, wps=210228, ups=3.4, wpb=61763.2, bsz=2124.2, num_updates=100400, lr=0.000315597, gnorm=1.029, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:50:29 | INFO | train_inner | epoch 051:   1364 / 1983 loss=3.367, nll_loss=1.209, word_ins=3.022, length=3.453, ppl=10.32, wps=211717, ups=3.44, wpb=61612, bsz=2019.7, num_updates=100500, lr=0.00031544, gnorm=1.003, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:50:58 | INFO | train_inner | epoch 051:   1464 / 1983 loss=3.353, nll_loss=1.192, word_ins=3.007, length=3.46, ppl=10.21, wps=211481, ups=3.43, wpb=61642.5, bsz=2028.6, num_updates=100600, lr=0.000315283, gnorm=1.003, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:51:28 | INFO | train_inner | epoch 051:   1564 / 1983 loss=3.365, nll_loss=1.206, word_ins=3.02, length=3.446, ppl=10.3, wps=210436, ups=3.42, wpb=61582.3, bsz=2011.6, num_updates=100700, lr=0.000315127, gnorm=1.029, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:51:57 | INFO | train_inner | epoch 051:   1664 / 1983 loss=3.418, nll_loss=1.259, word_ins=3.068, length=3.502, ppl=10.69, wps=209418, ups=3.42, wpb=61277.8, bsz=1899.6, num_updates=100800, lr=0.00031497, gnorm=1.027, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:52:26 | INFO | train_inner | epoch 051:   1764 / 1983 loss=3.38, nll_loss=1.221, word_ins=3.032, length=3.476, ppl=10.41, wps=212960, ups=3.44, wpb=61978, bsz=1924.2, num_updates=100900, lr=0.000314814, gnorm=1.058, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:52:55 | INFO | train_inner | epoch 051:   1864 / 1983 loss=3.366, nll_loss=1.207, word_ins=3.02, length=3.461, ppl=10.31, wps=211568, ups=3.44, wpb=61584.2, bsz=1927, num_updates=101000, lr=0.000314658, gnorm=1.04, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:53:24 | INFO | train_inner | epoch 051:   1964 / 1983 loss=3.386, nll_loss=1.232, word_ins=3.043, length=3.433, ppl=10.46, wps=211859, ups=3.44, wpb=61675.8, bsz=1966.8, num_updates=101100, lr=0.000314503, gnorm=1.042, loss_scale=8192, train_wall=29, wall=0
2023-03-02 02:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 02:53:44 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 3.331 | nll_loss 1.114 | word_ins 2.994 | length 3.377 | ppl 10.07 | wps 126923 | wpb 41551 | bsz 1500 | num_updates 101119 | best_loss 3.312
2023-03-02 02:53:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 02:53:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint51.pt (epoch 51 @ 101119 updates, score 3.331) (writing took 8.237589141004719 seconds)
2023-03-02 02:53:52 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-03-02 02:53:52 | INFO | train | epoch 051 | loss 3.369 | nll_loss 1.212 | word_ins 3.025 | length 3.444 | ppl 10.33 | wps 199215 | ups 3.23 | wpb 61628.5 | bsz 1997.6 | num_updates 101119 | lr 0.000314473 | gnorm 1.032 | loss_scale 8192 | train_wall 577 | wall 0
2023-03-02 02:53:52 | INFO | fairseq.trainer | begin training epoch 52
2023-03-02 02:54:28 | INFO | train_inner | epoch 052:     81 / 1983 loss=3.382, nll_loss=1.222, word_ins=3.034, length=3.476, ppl=10.43, wps=97094.1, ups=1.58, wpb=61484.5, bsz=1891.5, num_updates=101200, lr=0.000314347, gnorm=1.062, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:54:57 | INFO | train_inner | epoch 052:    181 / 1983 loss=3.315, nll_loss=1.168, word_ins=2.986, length=3.296, ppl=9.95, wps=210939, ups=3.4, wpb=62117.2, bsz=2016.2, num_updates=101300, lr=0.000314192, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:55:26 | INFO | train_inner | epoch 052:    281 / 1983 loss=3.338, nll_loss=1.182, word_ins=2.998, length=3.392, ppl=10.11, wps=210217, ups=3.41, wpb=61691.1, bsz=2126.2, num_updates=101400, lr=0.000314037, gnorm=1.032, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:55:56 | INFO | train_inner | epoch 052:    381 / 1983 loss=3.361, nll_loss=1.207, word_ins=3.02, length=3.404, ppl=10.27, wps=212216, ups=3.43, wpb=61856.7, bsz=1951.4, num_updates=101500, lr=0.000313882, gnorm=1.034, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:56:25 | INFO | train_inner | epoch 052:    481 / 1983 loss=3.344, nll_loss=1.185, word_ins=3.001, length=3.435, ppl=10.15, wps=210806, ups=3.42, wpb=61648.3, bsz=2023.3, num_updates=101600, lr=0.000313728, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:56:54 | INFO | train_inner | epoch 052:    581 / 1983 loss=3.367, nll_loss=1.211, word_ins=3.024, length=3.431, ppl=10.32, wps=211563, ups=3.43, wpb=61610.1, bsz=1973.4, num_updates=101700, lr=0.000313574, gnorm=1.057, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:57:23 | INFO | train_inner | epoch 052:    681 / 1983 loss=3.358, nll_loss=1.204, word_ins=3.017, length=3.413, ppl=10.25, wps=210443, ups=3.42, wpb=61454.3, bsz=2024.6, num_updates=101800, lr=0.00031342, gnorm=1.038, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:57:52 | INFO | train_inner | epoch 052:    781 / 1983 loss=3.354, nll_loss=1.193, word_ins=3.008, length=3.459, ppl=10.22, wps=210687, ups=3.42, wpb=61544.6, bsz=2012.8, num_updates=101900, lr=0.000313266, gnorm=1.036, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:58:22 | INFO | train_inner | epoch 052:    881 / 1983 loss=3.395, nll_loss=1.235, word_ins=3.046, length=3.492, ppl=10.52, wps=209878, ups=3.42, wpb=61322.1, bsz=1970.5, num_updates=102000, lr=0.000313112, gnorm=1.038, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:58:51 | INFO | train_inner | epoch 052:    981 / 1983 loss=3.35, nll_loss=1.194, word_ins=3.009, length=3.415, ppl=10.2, wps=210466, ups=3.42, wpb=61461.9, bsz=2038.7, num_updates=102100, lr=0.000312959, gnorm=1.003, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:59:20 | INFO | train_inner | epoch 052:   1081 / 1983 loss=3.388, nll_loss=1.228, word_ins=3.039, length=3.481, ppl=10.47, wps=208715, ups=3.41, wpb=61147.8, bsz=1994.1, num_updates=102200, lr=0.000312806, gnorm=1.037, loss_scale=16384, train_wall=29, wall=0
2023-03-02 02:59:49 | INFO | train_inner | epoch 052:   1181 / 1983 loss=3.353, nll_loss=1.196, word_ins=3.011, length=3.417, ppl=10.21, wps=212814, ups=3.44, wpb=61940.8, bsz=1976.9, num_updates=102300, lr=0.000312653, gnorm=1.051, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:00:18 | INFO | train_inner | epoch 052:   1281 / 1983 loss=3.361, nll_loss=1.207, word_ins=3.02, length=3.413, ppl=10.28, wps=210807, ups=3.42, wpb=61627.7, bsz=2035.4, num_updates=102400, lr=0.0003125, gnorm=1.041, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:00:48 | INFO | train_inner | epoch 052:   1381 / 1983 loss=3.421, nll_loss=1.258, word_ins=3.066, length=3.548, ppl=10.71, wps=208998, ups=3.43, wpb=61008.7, bsz=1880.9, num_updates=102500, lr=0.000312348, gnorm=1.011, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:01:17 | INFO | train_inner | epoch 052:   1481 / 1983 loss=3.345, nll_loss=1.187, word_ins=3.002, length=3.432, ppl=10.16, wps=210982, ups=3.43, wpb=61515.8, bsz=2056, num_updates=102600, lr=0.000312195, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:01:46 | INFO | train_inner | epoch 052:   1581 / 1983 loss=3.35, nll_loss=1.198, word_ins=3.013, length=3.373, ppl=10.2, wps=212756, ups=3.42, wpb=62177.2, bsz=2044.3, num_updates=102700, lr=0.000312043, gnorm=1.031, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:02:15 | INFO | train_inner | epoch 052:   1681 / 1983 loss=3.36, nll_loss=1.2, word_ins=3.014, length=3.454, ppl=10.27, wps=212939, ups=3.45, wpb=61755, bsz=1947.9, num_updates=102800, lr=0.000311891, gnorm=1.067, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:02:44 | INFO | train_inner | epoch 052:   1781 / 1983 loss=3.367, nll_loss=1.208, word_ins=3.021, length=3.462, ppl=10.32, wps=213746, ups=3.45, wpb=62026.3, bsz=1974.2, num_updates=102900, lr=0.00031174, gnorm=1.053, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:03:13 | INFO | train_inner | epoch 052:   1881 / 1983 loss=3.38, nll_loss=1.218, word_ins=3.03, length=3.5, ppl=10.41, wps=210794, ups=3.43, wpb=61444.8, bsz=1965.6, num_updates=103000, lr=0.000311588, gnorm=1.042, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:03:42 | INFO | train_inner | epoch 052:   1981 / 1983 loss=3.346, nll_loss=1.193, word_ins=3.007, length=3.385, ppl=10.17, wps=211390, ups=3.41, wpb=61939.3, bsz=2063, num_updates=103100, lr=0.000311437, gnorm=1.046, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 03:04:15 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.328 | nll_loss 1.118 | word_ins 2.997 | length 3.314 | ppl 10.04 | wps 61431.4 | wpb 41551 | bsz 1500 | num_updates 103102 | best_loss 3.312
2023-03-02 03:04:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 03:04:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint52.pt (epoch 52 @ 103102 updates, score 3.328) (writing took 7.285441852058284 seconds)
2023-03-02 03:04:22 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-03-02 03:04:22 | INFO | train | epoch 052 | loss 3.362 | nll_loss 1.205 | word_ins 3.019 | length 3.435 | ppl 10.28 | wps 193869 | ups 3.15 | wpb 61628.5 | bsz 1997.6 | num_updates 103102 | lr 0.000311434 | gnorm 1.036 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 03:04:22 | INFO | fairseq.trainer | begin training epoch 53
2023-03-02 03:05:14 | INFO | train_inner | epoch 053:     98 / 1983 loss=3.357, nll_loss=1.197, word_ins=3.012, length=3.449, ppl=10.25, wps=67051.4, ups=1.1, wpb=61071.3, bsz=1979.1, num_updates=103200, lr=0.000311286, gnorm=1.033, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:05:43 | INFO | train_inner | epoch 053:    198 / 1983 loss=3.344, nll_loss=1.189, word_ins=3.004, length=3.403, ppl=10.16, wps=211764, ups=3.43, wpb=61724.6, bsz=2017.1, num_updates=103300, lr=0.000311136, gnorm=1.051, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:06:12 | INFO | train_inner | epoch 053:    298 / 1983 loss=3.35, nll_loss=1.19, word_ins=3.006, length=3.44, ppl=10.19, wps=209945, ups=3.42, wpb=61321.4, bsz=1977.4, num_updates=103400, lr=0.000310985, gnorm=1.035, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:06:41 | INFO | train_inner | epoch 053:    398 / 1983 loss=3.367, nll_loss=1.212, word_ins=3.025, length=3.426, ppl=10.32, wps=211684, ups=3.43, wpb=61804.7, bsz=1912.9, num_updates=103500, lr=0.000310835, gnorm=1.048, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:07:10 | INFO | train_inner | epoch 053:    498 / 1983 loss=3.333, nll_loss=1.181, word_ins=2.997, length=3.368, ppl=10.08, wps=211293, ups=3.43, wpb=61608.9, bsz=2089.5, num_updates=103600, lr=0.000310685, gnorm=1.038, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:07:40 | INFO | train_inner | epoch 053:    598 / 1983 loss=3.361, nll_loss=1.206, word_ins=3.02, length=3.418, ppl=10.28, wps=210856, ups=3.42, wpb=61741.7, bsz=2023, num_updates=103700, lr=0.000310535, gnorm=1.051, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:08:09 | INFO | train_inner | epoch 053:    698 / 1983 loss=3.345, nll_loss=1.192, word_ins=3.007, length=3.382, ppl=10.16, wps=212415, ups=3.42, wpb=62056, bsz=2045, num_updates=103800, lr=0.000310385, gnorm=1.043, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:08:38 | INFO | train_inner | epoch 053:    798 / 1983 loss=3.354, nll_loss=1.196, word_ins=3.01, length=3.439, ppl=10.23, wps=211424, ups=3.43, wpb=61684.5, bsz=2006, num_updates=103900, lr=0.000310236, gnorm=1.05, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:09:07 | INFO | train_inner | epoch 053:    898 / 1983 loss=3.368, nll_loss=1.208, word_ins=3.021, length=3.47, ppl=10.33, wps=211353, ups=3.42, wpb=61869.8, bsz=1968.3, num_updates=104000, lr=0.000310087, gnorm=1.063, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:09:37 | INFO | train_inner | epoch 053:    998 / 1983 loss=3.416, nll_loss=1.249, word_ins=3.058, length=3.573, ppl=10.67, wps=209086, ups=3.42, wpb=61200.5, bsz=1853.7, num_updates=104100, lr=0.000309938, gnorm=1.044, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:10:06 | INFO | train_inner | epoch 053:   1098 / 1983 loss=3.368, nll_loss=1.211, word_ins=3.024, length=3.438, ppl=10.32, wps=212637, ups=3.43, wpb=61903.5, bsz=1956.5, num_updates=104200, lr=0.000309789, gnorm=1.035, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:10:35 | INFO | train_inner | epoch 053:   1198 / 1983 loss=3.343, nll_loss=1.185, word_ins=3, length=3.427, ppl=10.15, wps=210639, ups=3.42, wpb=61510.3, bsz=2079.4, num_updates=104300, lr=0.000309641, gnorm=1.034, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:11:04 | INFO | train_inner | epoch 053:   1298 / 1983 loss=3.362, nll_loss=1.204, word_ins=3.017, length=3.452, ppl=10.28, wps=210758, ups=3.44, wpb=61349.1, bsz=1975, num_updates=104400, lr=0.000309492, gnorm=1.024, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:11:33 | INFO | train_inner | epoch 053:   1398 / 1983 loss=3.348, nll_loss=1.191, word_ins=3.005, length=3.427, ppl=10.18, wps=212122, ups=3.44, wpb=61739.3, bsz=1987.8, num_updates=104500, lr=0.000309344, gnorm=1.054, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:12:02 | INFO | train_inner | epoch 053:   1498 / 1983 loss=3.361, nll_loss=1.203, word_ins=3.017, length=3.445, ppl=10.27, wps=211863, ups=3.42, wpb=61911.2, bsz=2006.5, num_updates=104600, lr=0.000309196, gnorm=1.031, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:12:31 | INFO | train_inner | epoch 053:   1598 / 1983 loss=3.36, nll_loss=1.205, word_ins=3.018, length=3.416, ppl=10.27, wps=211444, ups=3.45, wpb=61349.4, bsz=1965.4, num_updates=104700, lr=0.000309049, gnorm=1.046, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:13:00 | INFO | train_inner | epoch 053:   1698 / 1983 loss=3.349, nll_loss=1.194, word_ins=3.009, length=3.398, ppl=10.19, wps=212636, ups=3.43, wpb=61991, bsz=2042.2, num_updates=104800, lr=0.000308901, gnorm=1.039, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:13:30 | INFO | train_inner | epoch 053:   1798 / 1983 loss=3.359, nll_loss=1.2, word_ins=3.013, length=3.455, ppl=10.26, wps=211464, ups=3.43, wpb=61649.4, bsz=1978.2, num_updates=104900, lr=0.000308754, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:13:59 | INFO | train_inner | epoch 053:   1898 / 1983 loss=3.35, nll_loss=1.193, word_ins=3.007, length=3.43, ppl=10.19, wps=209094, ups=3.42, wpb=61200.4, bsz=2051.8, num_updates=105000, lr=0.000308607, gnorm=1.016, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 03:14:37 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 3.33 | nll_loss 1.123 | word_ins 3.001 | length 3.3 | ppl 10.06 | wps 86351.2 | wpb 41551 | bsz 1500 | num_updates 105085 | best_loss 3.312
2023-03-02 03:14:37 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 03:14:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint53.pt (epoch 53 @ 105085 updates, score 3.33) (writing took 6.029656958999112 seconds)
2023-03-02 03:14:43 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-03-02 03:14:43 | INFO | train | epoch 053 | loss 3.358 | nll_loss 1.201 | word_ins 3.014 | length 3.434 | ppl 10.25 | wps 197069 | ups 3.2 | wpb 61628.5 | bsz 1997.6 | num_updates 105085 | lr 0.000308482 | gnorm 1.039 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 03:14:43 | INFO | fairseq.trainer | begin training epoch 54
2023-03-02 03:14:57 | INFO | train_inner | epoch 054:     15 / 1983 loss=3.355, nll_loss=1.2, word_ins=3.014, length=3.411, ppl=10.23, wps=106482, ups=1.73, wpb=61573.8, bsz=2031.5, num_updates=105100, lr=0.00030846, gnorm=1.028, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:15:26 | INFO | train_inner | epoch 054:    115 / 1983 loss=3.352, nll_loss=1.196, word_ins=3.011, length=3.41, ppl=10.21, wps=211406, ups=3.42, wpb=61727.6, bsz=1959.4, num_updates=105200, lr=0.000308313, gnorm=1.049, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:15:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 03:15:55 | INFO | train_inner | epoch 054:    216 / 1983 loss=3.339, nll_loss=1.184, word_ins=3, length=3.398, ppl=10.12, wps=209445, ups=3.39, wpb=61851.9, bsz=2043, num_updates=105300, lr=0.000308167, gnorm=1.07, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:16:25 | INFO | train_inner | epoch 054:    316 / 1983 loss=3.344, nll_loss=1.186, word_ins=3.001, length=3.435, ppl=10.16, wps=209618, ups=3.4, wpb=61590.5, bsz=2049, num_updates=105400, lr=0.000308021, gnorm=1.032, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:16:54 | INFO | train_inner | epoch 054:    416 / 1983 loss=3.358, nll_loss=1.205, word_ins=3.018, length=3.398, ppl=10.25, wps=211182, ups=3.42, wpb=61741, bsz=1973.8, num_updates=105500, lr=0.000307875, gnorm=1.056, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:17:23 | INFO | train_inner | epoch 054:    516 / 1983 loss=3.324, nll_loss=1.172, word_ins=2.988, length=3.365, ppl=10.02, wps=210677, ups=3.41, wpb=61696, bsz=2075.5, num_updates=105600, lr=0.000307729, gnorm=1.028, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:17:53 | INFO | train_inner | epoch 054:    616 / 1983 loss=3.342, nll_loss=1.189, word_ins=3.003, length=3.381, ppl=10.14, wps=210743, ups=3.42, wpb=61554.8, bsz=2033, num_updates=105700, lr=0.000307583, gnorm=1.011, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:18:22 | INFO | train_inner | epoch 054:    716 / 1983 loss=3.352, nll_loss=1.198, word_ins=3.011, length=3.409, ppl=10.21, wps=209633, ups=3.42, wpb=61367.9, bsz=2060.9, num_updates=105800, lr=0.000307438, gnorm=1.004, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:18:51 | INFO | train_inner | epoch 054:    816 / 1983 loss=3.375, nll_loss=1.215, word_ins=3.028, length=3.468, ppl=10.37, wps=208624, ups=3.4, wpb=61303.8, bsz=1952.7, num_updates=105900, lr=0.000307293, gnorm=1.055, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:19:20 | INFO | train_inner | epoch 054:    916 / 1983 loss=3.355, nll_loss=1.199, word_ins=3.012, length=3.426, ppl=10.23, wps=212283, ups=3.44, wpb=61654.6, bsz=1948, num_updates=106000, lr=0.000307148, gnorm=1.049, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:19:49 | INFO | train_inner | epoch 054:   1016 / 1983 loss=3.357, nll_loss=1.2, word_ins=3.013, length=3.445, ppl=10.25, wps=211234, ups=3.44, wpb=61475.6, bsz=1973.4, num_updates=106100, lr=0.000307003, gnorm=1.045, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:20:19 | INFO | train_inner | epoch 054:   1116 / 1983 loss=3.329, nll_loss=1.173, word_ins=2.99, length=3.391, ppl=10.05, wps=210632, ups=3.42, wpb=61502.5, bsz=2069.4, num_updates=106200, lr=0.000306858, gnorm=1.023, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:20:48 | INFO | train_inner | epoch 054:   1216 / 1983 loss=3.371, nll_loss=1.209, word_ins=3.022, length=3.488, ppl=10.35, wps=212511, ups=3.45, wpb=61681.9, bsz=1905.4, num_updates=106300, lr=0.000306714, gnorm=1.043, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:21:17 | INFO | train_inner | epoch 054:   1316 / 1983 loss=3.361, nll_loss=1.199, word_ins=3.012, length=3.487, ppl=10.27, wps=211685, ups=3.44, wpb=61585.2, bsz=1948.3, num_updates=106400, lr=0.00030657, gnorm=1.061, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:21:46 | INFO | train_inner | epoch 054:   1416 / 1983 loss=3.353, nll_loss=1.2, word_ins=3.014, length=3.394, ppl=10.22, wps=211435, ups=3.43, wpb=61726.1, bsz=2008.7, num_updates=106500, lr=0.000306426, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:22:15 | INFO | train_inner | epoch 054:   1516 / 1983 loss=3.318, nll_loss=1.167, word_ins=2.983, length=3.346, ppl=9.97, wps=213020, ups=3.44, wpb=61902.3, bsz=2015.4, num_updates=106600, lr=0.000306282, gnorm=1.024, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:22:44 | INFO | train_inner | epoch 054:   1616 / 1983 loss=3.371, nll_loss=1.209, word_ins=3.022, length=3.493, ppl=10.35, wps=211467, ups=3.43, wpb=61576.9, bsz=1994.3, num_updates=106700, lr=0.000306138, gnorm=1.032, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:23:13 | INFO | train_inner | epoch 054:   1716 / 1983 loss=3.33, nll_loss=1.176, word_ins=2.992, length=3.383, ppl=10.06, wps=210120, ups=3.42, wpb=61433.9, bsz=2089, num_updates=106800, lr=0.000305995, gnorm=0.999, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:23:43 | INFO | train_inner | epoch 054:   1816 / 1983 loss=3.336, nll_loss=1.179, word_ins=2.994, length=3.42, ppl=10.1, wps=211288, ups=3.42, wpb=61785.2, bsz=2018.6, num_updates=106900, lr=0.000305852, gnorm=1.051, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:24:12 | INFO | train_inner | epoch 054:   1916 / 1983 loss=3.387, nll_loss=1.229, word_ins=3.04, length=3.47, ppl=10.46, wps=212837, ups=3.44, wpb=61931.2, bsz=1835, num_updates=107000, lr=0.000305709, gnorm=1.07, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 03:24:46 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.318 | nll_loss 1.106 | word_ins 2.992 | length 3.258 | ppl 9.97 | wps 96107.9 | wpb 41551 | bsz 1500 | num_updates 107067 | best_loss 3.312
2023-03-02 03:24:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 03:24:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint54.pt (epoch 54 @ 107067 updates, score 3.318) (writing took 5.795350381056778 seconds)
2023-03-02 03:24:52 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-03-02 03:24:52 | INFO | train | epoch 054 | loss 3.35 | nll_loss 1.194 | word_ins 3.008 | length 3.421 | ppl 10.2 | wps 200529 | ups 3.25 | wpb 61628.1 | bsz 1997.4 | num_updates 107067 | lr 0.000305613 | gnorm 1.038 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 03:24:52 | INFO | fairseq.trainer | begin training epoch 55
2023-03-02 03:25:12 | INFO | train_inner | epoch 055:     33 / 1983 loss=3.35, nll_loss=1.196, word_ins=3.01, length=3.4, ppl=10.2, wps=102886, ups=1.67, wpb=61692.8, bsz=1965, num_updates=107100, lr=0.000305566, gnorm=1.078, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:25:41 | INFO | train_inner | epoch 055:    133 / 1983 loss=3.344, nll_loss=1.189, word_ins=3.004, length=3.399, ppl=10.16, wps=212779, ups=3.43, wpb=61985.5, bsz=1946.5, num_updates=107200, lr=0.000305424, gnorm=1.033, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:26:10 | INFO | train_inner | epoch 055:    233 / 1983 loss=3.333, nll_loss=1.181, word_ins=2.997, length=3.357, ppl=10.07, wps=210272, ups=3.42, wpb=61556.3, bsz=2002.4, num_updates=107300, lr=0.000305281, gnorm=1.027, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:26:39 | INFO | train_inner | epoch 055:    333 / 1983 loss=3.336, nll_loss=1.184, word_ins=2.999, length=3.365, ppl=10.1, wps=210611, ups=3.41, wpb=61788.8, bsz=2027.3, num_updates=107400, lr=0.000305139, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:27:09 | INFO | train_inner | epoch 055:    433 / 1983 loss=3.349, nll_loss=1.192, word_ins=3.007, length=3.415, ppl=10.19, wps=210726, ups=3.43, wpb=61367.1, bsz=1954.8, num_updates=107500, lr=0.000304997, gnorm=1.046, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:27:38 | INFO | train_inner | epoch 055:    533 / 1983 loss=3.361, nll_loss=1.198, word_ins=3.012, length=3.488, ppl=10.28, wps=212196, ups=3.44, wpb=61625.2, bsz=1903.1, num_updates=107600, lr=0.000304855, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:28:07 | INFO | train_inner | epoch 055:    633 / 1983 loss=3.344, nll_loss=1.189, word_ins=3.003, length=3.406, ppl=10.15, wps=212761, ups=3.44, wpb=61830.5, bsz=1982.5, num_updates=107700, lr=0.000304714, gnorm=1.054, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:28:36 | INFO | train_inner | epoch 055:    733 / 1983 loss=3.317, nll_loss=1.166, word_ins=2.984, length=3.337, ppl=9.97, wps=210558, ups=3.41, wpb=61799, bsz=2109.9, num_updates=107800, lr=0.000304572, gnorm=1.002, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:29:05 | INFO | train_inner | epoch 055:    833 / 1983 loss=3.33, nll_loss=1.177, word_ins=2.993, length=3.372, ppl=10.06, wps=211469, ups=3.42, wpb=61836.6, bsz=2043.1, num_updates=107900, lr=0.000304431, gnorm=1.029, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:29:35 | INFO | train_inner | epoch 055:    933 / 1983 loss=3.335, nll_loss=1.182, word_ins=2.997, length=3.386, ppl=10.09, wps=210327, ups=3.41, wpb=61592.1, bsz=2069.5, num_updates=108000, lr=0.00030429, gnorm=1.026, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:30:04 | INFO | train_inner | epoch 055:   1033 / 1983 loss=3.351, nll_loss=1.197, word_ins=3.01, length=3.41, ppl=10.21, wps=210165, ups=3.43, wpb=61361.4, bsz=1978.7, num_updates=108100, lr=0.00030415, gnorm=1.028, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:30:33 | INFO | train_inner | epoch 055:   1133 / 1983 loss=3.363, nll_loss=1.21, word_ins=3.023, length=3.406, ppl=10.29, wps=209877, ups=3.4, wpb=61767.6, bsz=2013.3, num_updates=108200, lr=0.000304009, gnorm=1.034, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:31:02 | INFO | train_inner | epoch 055:   1233 / 1983 loss=3.354, nll_loss=1.197, word_ins=3.011, length=3.428, ppl=10.22, wps=213029, ups=3.46, wpb=61635, bsz=1958.9, num_updates=108300, lr=0.000303869, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:31:31 | INFO | train_inner | epoch 055:   1333 / 1983 loss=3.342, nll_loss=1.184, word_ins=2.999, length=3.429, ppl=10.14, wps=212664, ups=3.43, wpb=61933.1, bsz=2003.3, num_updates=108400, lr=0.000303728, gnorm=1.072, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:32:01 | INFO | train_inner | epoch 055:   1433 / 1983 loss=3.327, nll_loss=1.174, word_ins=2.99, length=3.378, ppl=10.04, wps=211644, ups=3.42, wpb=61847.6, bsz=2088.7, num_updates=108500, lr=0.000303588, gnorm=1.042, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:32:30 | INFO | train_inner | epoch 055:   1533 / 1983 loss=3.339, nll_loss=1.179, word_ins=2.994, length=3.448, ppl=10.12, wps=208954, ups=3.44, wpb=60824, bsz=1976.5, num_updates=108600, lr=0.000303449, gnorm=1.034, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:32:59 | INFO | train_inner | epoch 055:   1633 / 1983 loss=3.382, nll_loss=1.216, word_ins=3.028, length=3.541, ppl=10.43, wps=212120, ups=3.44, wpb=61624.1, bsz=1903.1, num_updates=108700, lr=0.000303309, gnorm=1.048, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:33:28 | INFO | train_inner | epoch 055:   1733 / 1983 loss=3.329, nll_loss=1.177, word_ins=2.992, length=3.373, ppl=10.05, wps=211802, ups=3.43, wpb=61693, bsz=2058.6, num_updates=108800, lr=0.00030317, gnorm=0.995, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:33:57 | INFO | train_inner | epoch 055:   1833 / 1983 loss=3.361, nll_loss=1.199, word_ins=3.012, length=3.48, ppl=10.27, wps=210636, ups=3.43, wpb=61382.7, bsz=1985.2, num_updates=108900, lr=0.00030303, gnorm=1.054, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:34:26 | INFO | train_inner | epoch 055:   1933 / 1983 loss=3.354, nll_loss=1.193, word_ins=3.007, length=3.476, ppl=10.23, wps=209893, ups=3.41, wpb=61474.7, bsz=2054.6, num_updates=109000, lr=0.000302891, gnorm=1.027, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 03:34:55 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 3.313 | nll_loss 1.097 | word_ins 2.978 | length 3.354 | ppl 9.94 | wps 89504.9 | wpb 41551 | bsz 1500 | num_updates 109050 | best_loss 3.312
2023-03-02 03:34:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 03:35:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint55.pt (epoch 55 @ 109050 updates, score 3.313) (writing took 6.819188255001791 seconds)
2023-03-02 03:35:01 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-03-02 03:35:01 | INFO | train | epoch 055 | loss 3.346 | nll_loss 1.19 | word_ins 3.004 | length 3.416 | ppl 10.17 | wps 200410 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 109050 | lr 0.000302822 | gnorm 1.033 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 03:35:01 | INFO | fairseq.trainer | begin training epoch 56
2023-03-02 03:35:27 | INFO | train_inner | epoch 056:     50 / 1983 loss=3.363, nll_loss=1.205, word_ins=3.019, length=3.445, ppl=10.29, wps=101221, ups=1.65, wpb=61160.5, bsz=1899.5, num_updates=109100, lr=0.000302752, gnorm=1.05, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:35:56 | INFO | train_inner | epoch 056:    150 / 1983 loss=3.33, nll_loss=1.173, word_ins=2.989, length=3.416, ppl=10.06, wps=211574, ups=3.44, wpb=61502.8, bsz=1970.6, num_updates=109200, lr=0.000302614, gnorm=1.024, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:36:25 | INFO | train_inner | epoch 056:    250 / 1983 loss=3.323, nll_loss=1.169, word_ins=2.985, length=3.379, ppl=10.01, wps=211026, ups=3.42, wpb=61730.7, bsz=2043.4, num_updates=109300, lr=0.000302475, gnorm=1.004, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:36:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 03:36:54 | INFO | train_inner | epoch 056:    351 / 1983 loss=3.329, nll_loss=1.173, word_ins=2.989, length=3.395, ppl=10.05, wps=209971, ups=3.39, wpb=61852.7, bsz=2021, num_updates=109400, lr=0.000302337, gnorm=1.017, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:37:24 | INFO | train_inner | epoch 056:    451 / 1983 loss=3.36, nll_loss=1.196, word_ins=3.01, length=3.497, ppl=10.27, wps=211153, ups=3.43, wpb=61495.7, bsz=1918.1, num_updates=109500, lr=0.000302199, gnorm=1.039, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:37:53 | INFO | train_inner | epoch 056:    551 / 1983 loss=3.327, nll_loss=1.177, word_ins=2.992, length=3.348, ppl=10.04, wps=211296, ups=3.42, wpb=61704.2, bsz=2094.8, num_updates=109600, lr=0.000302061, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:38:22 | INFO | train_inner | epoch 056:    651 / 1983 loss=3.342, nll_loss=1.185, word_ins=3, length=3.422, ppl=10.14, wps=209888, ups=3.42, wpb=61432.3, bsz=1979.5, num_updates=109700, lr=0.000301923, gnorm=1.041, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:38:51 | INFO | train_inner | epoch 056:    751 / 1983 loss=3.356, nll_loss=1.194, word_ins=3.007, length=3.483, ppl=10.24, wps=211846, ups=3.44, wpb=61661.6, bsz=1971.4, num_updates=109800, lr=0.000301786, gnorm=1.062, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:39:20 | INFO | train_inner | epoch 056:    851 / 1983 loss=3.317, nll_loss=1.163, word_ins=2.979, length=3.375, ppl=9.97, wps=212031, ups=3.42, wpb=62027.2, bsz=2059.2, num_updates=109900, lr=0.000301648, gnorm=1.028, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:39:50 | INFO | train_inner | epoch 056:    951 / 1983 loss=3.337, nll_loss=1.181, word_ins=2.996, length=3.406, ppl=10.11, wps=212190, ups=3.43, wpb=61847.9, bsz=2001.4, num_updates=110000, lr=0.000301511, gnorm=1.048, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:40:19 | INFO | train_inner | epoch 056:   1051 / 1983 loss=3.36, nll_loss=1.204, word_ins=3.017, length=3.431, ppl=10.27, wps=211499, ups=3.43, wpb=61668.7, bsz=1973.2, num_updates=110100, lr=0.000301374, gnorm=1.037, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:40:48 | INFO | train_inner | epoch 056:   1151 / 1983 loss=3.334, nll_loss=1.181, word_ins=2.996, length=3.385, ppl=10.09, wps=211840, ups=3.42, wpb=61909, bsz=2099.5, num_updates=110200, lr=0.000301238, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:41:17 | INFO | train_inner | epoch 056:   1251 / 1983 loss=3.344, nll_loss=1.187, word_ins=3.001, length=3.425, ppl=10.15, wps=210822, ups=3.43, wpb=61456, bsz=1967, num_updates=110300, lr=0.000301101, gnorm=1.059, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:41:46 | INFO | train_inner | epoch 056:   1351 / 1983 loss=3.326, nll_loss=1.175, word_ins=2.991, length=3.351, ppl=10.03, wps=210866, ups=3.42, wpb=61586.3, bsz=2021.3, num_updates=110400, lr=0.000300965, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:42:16 | INFO | train_inner | epoch 056:   1451 / 1983 loss=3.35, nll_loss=1.192, word_ins=3.006, length=3.441, ppl=10.2, wps=212161, ups=3.43, wpb=61904.8, bsz=1949, num_updates=110500, lr=0.000300828, gnorm=1.022, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:42:45 | INFO | train_inner | epoch 056:   1551 / 1983 loss=3.356, nll_loss=1.201, word_ins=3.014, length=3.422, ppl=10.24, wps=210305, ups=3.41, wpb=61591.5, bsz=1995.4, num_updates=110600, lr=0.000300692, gnorm=1.016, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:43:14 | INFO | train_inner | epoch 056:   1651 / 1983 loss=3.332, nll_loss=1.175, word_ins=2.99, length=3.416, ppl=10.07, wps=210769, ups=3.44, wpb=61289.7, bsz=1976.1, num_updates=110700, lr=0.000300557, gnorm=1.055, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:43:43 | INFO | train_inner | epoch 056:   1751 / 1983 loss=3.346, nll_loss=1.192, word_ins=3.006, length=3.403, ppl=10.17, wps=210819, ups=3.41, wpb=61780.4, bsz=2023, num_updates=110800, lr=0.000300421, gnorm=1.034, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:44:12 | INFO | train_inner | epoch 056:   1851 / 1983 loss=3.342, nll_loss=1.185, word_ins=3, length=3.423, ppl=10.14, wps=210793, ups=3.43, wpb=61461.7, bsz=1988.4, num_updates=110900, lr=0.000300285, gnorm=1.026, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:44:42 | INFO | train_inner | epoch 056:   1951 / 1983 loss=3.354, nll_loss=1.194, word_ins=3.008, length=3.461, ppl=10.22, wps=210752, ups=3.42, wpb=61537, bsz=1958.6, num_updates=111000, lr=0.00030015, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:44:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 03:45:05 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 3.287 | nll_loss 1.083 | word_ins 2.961 | length 3.259 | ppl 9.76 | wps 123347 | wpb 41551 | bsz 1500 | num_updates 111032 | best_loss 3.287
2023-03-02 03:45:05 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 03:45:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint56.pt (epoch 56 @ 111032 updates, score 3.287) (writing took 8.225207192939706 seconds)
2023-03-02 03:45:13 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2023-03-02 03:45:13 | INFO | train | epoch 056 | loss 3.341 | nll_loss 1.185 | word_ins 2.999 | length 3.415 | ppl 10.13 | wps 199739 | ups 3.24 | wpb 61628 | bsz 1997.7 | num_updates 111032 | lr 0.000300107 | gnorm 1.029 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 03:45:13 | INFO | fairseq.trainer | begin training epoch 57
2023-03-02 03:45:43 | INFO | train_inner | epoch 057:     68 / 1983 loss=3.304, nll_loss=1.148, word_ins=2.966, length=3.374, ppl=9.88, wps=99618.8, ups=1.62, wpb=61460.7, bsz=2034.7, num_updates=111100, lr=0.000300015, gnorm=1.028, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:46:13 | INFO | train_inner | epoch 057:    168 / 1983 loss=3.321, nll_loss=1.168, word_ins=2.984, length=3.363, ppl=9.99, wps=211995, ups=3.41, wpb=62164.6, bsz=1980.9, num_updates=111200, lr=0.00029988, gnorm=1.059, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:46:42 | INFO | train_inner | epoch 057:    268 / 1983 loss=3.316, nll_loss=1.166, word_ins=2.982, length=3.335, ppl=9.96, wps=208686, ups=3.39, wpb=61506.3, bsz=2097.8, num_updates=111300, lr=0.000299745, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:47:11 | INFO | train_inner | epoch 057:    368 / 1983 loss=3.318, nll_loss=1.163, word_ins=2.98, length=3.38, ppl=9.98, wps=209889, ups=3.42, wpb=61452.1, bsz=2086.6, num_updates=111400, lr=0.000299611, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:47:40 | INFO | train_inner | epoch 057:    468 / 1983 loss=3.333, nll_loss=1.177, word_ins=2.993, length=3.407, ppl=10.08, wps=212006, ups=3.44, wpb=61644, bsz=1980.9, num_updates=111500, lr=0.000299476, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:48:09 | INFO | train_inner | epoch 057:    568 / 1983 loss=3.355, nll_loss=1.191, word_ins=3.005, length=3.501, ppl=10.24, wps=212147, ups=3.44, wpb=61670.7, bsz=1910.6, num_updates=111600, lr=0.000299342, gnorm=1.042, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:48:39 | INFO | train_inner | epoch 057:    668 / 1983 loss=3.32, nll_loss=1.167, word_ins=2.983, length=3.37, ppl=9.99, wps=211458, ups=3.43, wpb=61694.8, bsz=2014.3, num_updates=111700, lr=0.000299208, gnorm=1.036, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:49:08 | INFO | train_inner | epoch 057:    768 / 1983 loss=3.302, nll_loss=1.154, word_ins=2.971, length=3.301, ppl=9.86, wps=212815, ups=3.43, wpb=62018.4, bsz=2046.6, num_updates=111800, lr=0.000299074, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:49:37 | INFO | train_inner | epoch 057:    868 / 1983 loss=3.297, nll_loss=1.15, word_ins=2.967, length=3.3, ppl=9.83, wps=211104, ups=3.43, wpb=61587.5, bsz=2109.6, num_updates=111900, lr=0.000298941, gnorm=0.995, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:50:06 | INFO | train_inner | epoch 057:    968 / 1983 loss=3.353, nll_loss=1.191, word_ins=3.005, length=3.477, ppl=10.22, wps=212265, ups=3.42, wpb=62057.1, bsz=1951.6, num_updates=112000, lr=0.000298807, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:50:35 | INFO | train_inner | epoch 057:   1068 / 1983 loss=3.329, nll_loss=1.174, word_ins=2.989, length=3.401, ppl=10.05, wps=211228, ups=3.42, wpb=61692.3, bsz=2024.5, num_updates=112100, lr=0.000298674, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:51:05 | INFO | train_inner | epoch 057:   1168 / 1983 loss=3.359, nll_loss=1.201, word_ins=3.014, length=3.448, ppl=10.26, wps=210389, ups=3.43, wpb=61305.1, bsz=1977.1, num_updates=112200, lr=0.000298541, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:51:34 | INFO | train_inner | epoch 057:   1268 / 1983 loss=3.365, nll_loss=1.203, word_ins=3.016, length=3.49, ppl=10.31, wps=210082, ups=3.41, wpb=61583.3, bsz=1946.3, num_updates=112300, lr=0.000298408, gnorm=1.023, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:52:03 | INFO | train_inner | epoch 057:   1368 / 1983 loss=3.375, nll_loss=1.218, word_ins=3.03, length=3.451, ppl=10.37, wps=210605, ups=3.43, wpb=61392, bsz=1913.2, num_updates=112400, lr=0.000298275, gnorm=1.065, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:52:32 | INFO | train_inner | epoch 057:   1468 / 1983 loss=3.324, nll_loss=1.171, word_ins=2.987, length=3.377, ppl=10.02, wps=212255, ups=3.43, wpb=61883.5, bsz=2034.2, num_updates=112500, lr=0.000298142, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:53:01 | INFO | train_inner | epoch 057:   1568 / 1983 loss=3.349, nll_loss=1.191, word_ins=3.005, length=3.438, ppl=10.19, wps=210189, ups=3.42, wpb=61492.6, bsz=2018.6, num_updates=112600, lr=0.00029801, gnorm=1.018, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:53:31 | INFO | train_inner | epoch 057:   1668 / 1983 loss=3.378, nll_loss=1.213, word_ins=3.025, length=3.53, ppl=10.39, wps=210374, ups=3.43, wpb=61322, bsz=1845.4, num_updates=112700, lr=0.000297878, gnorm=1.047, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:54:00 | INFO | train_inner | epoch 057:   1768 / 1983 loss=3.345, nll_loss=1.181, word_ins=2.996, length=3.493, ppl=10.16, wps=209995, ups=3.43, wpb=61219.8, bsz=2004.4, num_updates=112800, lr=0.000297746, gnorm=1.013, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:54:29 | INFO | train_inner | epoch 057:   1868 / 1983 loss=3.34, nll_loss=1.183, word_ins=2.997, length=3.431, ppl=10.13, wps=212054, ups=3.43, wpb=61801.7, bsz=2014.7, num_updates=112900, lr=0.000297614, gnorm=1.044, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:54:58 | INFO | train_inner | epoch 057:   1968 / 1983 loss=3.344, nll_loss=1.188, word_ins=3.001, length=3.433, ppl=10.16, wps=212600, ups=3.45, wpb=61708.3, bsz=1968.2, num_updates=113000, lr=0.000297482, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 03:55:16 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 3.314 | nll_loss 1.106 | word_ins 2.984 | length 3.307 | ppl 9.95 | wps 98621.2 | wpb 41551 | bsz 1500 | num_updates 113015 | best_loss 3.287
2023-03-02 03:55:16 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 03:55:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint57.pt (epoch 57 @ 113015 updates, score 3.314) (writing took 5.653600931051187 seconds)
2023-03-02 03:55:22 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2023-03-02 03:55:22 | INFO | train | epoch 057 | loss 3.336 | nll_loss 1.18 | word_ins 2.995 | length 3.415 | ppl 10.1 | wps 200698 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 113015 | lr 0.000297462 | gnorm 1.026 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 03:55:22 | INFO | fairseq.trainer | begin training epoch 58
2023-03-02 03:55:57 | INFO | train_inner | epoch 058:     85 / 1983 loss=3.339, nll_loss=1.18, word_ins=2.996, length=3.432, ppl=10.12, wps=103740, ups=1.7, wpb=61153.1, bsz=1941.4, num_updates=113100, lr=0.000297351, gnorm=1.044, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:56:26 | INFO | train_inner | epoch 058:    185 / 1983 loss=3.334, nll_loss=1.18, word_ins=2.995, length=3.391, ppl=10.08, wps=211163, ups=3.43, wpb=61541.7, bsz=1959.4, num_updates=113200, lr=0.000297219, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:56:55 | INFO | train_inner | epoch 058:    285 / 1983 loss=3.323, nll_loss=1.168, word_ins=2.984, length=3.391, ppl=10.01, wps=208697, ups=3.4, wpb=61380, bsz=2014, num_updates=113300, lr=0.000297088, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:57:25 | INFO | train_inner | epoch 058:    385 / 1983 loss=3.319, nll_loss=1.164, word_ins=2.981, length=3.384, ppl=9.98, wps=210602, ups=3.41, wpb=61808.8, bsz=2004.4, num_updates=113400, lr=0.000296957, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:57:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 03:57:54 | INFO | train_inner | epoch 058:    486 / 1983 loss=3.346, nll_loss=1.186, word_ins=3.001, length=3.457, ppl=10.17, wps=205980, ups=3.38, wpb=60971.3, bsz=1941.2, num_updates=113500, lr=0.000296826, gnorm=1.028, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:58:24 | INFO | train_inner | epoch 058:    586 / 1983 loss=3.344, nll_loss=1.186, word_ins=3, length=3.431, ppl=10.15, wps=211019, ups=3.41, wpb=61819.8, bsz=1963.4, num_updates=113600, lr=0.000296695, gnorm=1.035, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:58:53 | INFO | train_inner | epoch 058:    686 / 1983 loss=3.344, nll_loss=1.189, word_ins=3.003, length=3.416, ppl=10.16, wps=209606, ups=3.42, wpb=61210.7, bsz=1975.4, num_updates=113700, lr=0.000296565, gnorm=1.025, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:59:22 | INFO | train_inner | epoch 058:    786 / 1983 loss=3.299, nll_loss=1.147, word_ins=2.965, length=3.345, ppl=9.85, wps=211204, ups=3.42, wpb=61781.4, bsz=2061.4, num_updates=113800, lr=0.000296435, gnorm=1.027, loss_scale=16384, train_wall=29, wall=0
2023-03-02 03:59:52 | INFO | train_inner | epoch 058:    886 / 1983 loss=3.323, nll_loss=1.168, word_ins=2.983, length=3.398, ppl=10.01, wps=210470, ups=3.41, wpb=61694, bsz=2070.2, num_updates=113900, lr=0.000296304, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:00:21 | INFO | train_inner | epoch 058:    986 / 1983 loss=3.316, nll_loss=1.162, word_ins=2.978, length=3.383, ppl=9.96, wps=213175, ups=3.44, wpb=61971.3, bsz=2011.6, num_updates=114000, lr=0.000296174, gnorm=1.018, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:00:50 | INFO | train_inner | epoch 058:   1086 / 1983 loss=3.32, nll_loss=1.167, word_ins=2.983, length=3.373, ppl=9.99, wps=210030, ups=3.42, wpb=61423.4, bsz=2020.4, num_updates=114100, lr=0.000296045, gnorm=1.016, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:01:19 | INFO | train_inner | epoch 058:   1186 / 1983 loss=3.329, nll_loss=1.176, word_ins=2.991, length=3.384, ppl=10.05, wps=211375, ups=3.42, wpb=61886.3, bsz=2028.5, num_updates=114200, lr=0.000295915, gnorm=1.001, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:01:48 | INFO | train_inner | epoch 058:   1286 / 1983 loss=3.312, nll_loss=1.159, word_ins=2.976, length=3.365, ppl=9.93, wps=210807, ups=3.4, wpb=61934.2, bsz=2084.7, num_updates=114300, lr=0.000295786, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:02:18 | INFO | train_inner | epoch 058:   1386 / 1983 loss=3.317, nll_loss=1.157, word_ins=2.973, length=3.441, ppl=9.97, wps=209922, ups=3.42, wpb=61430.5, bsz=2040.6, num_updates=114400, lr=0.000295656, gnorm=1.022, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:02:47 | INFO | train_inner | epoch 058:   1486 / 1983 loss=3.348, nll_loss=1.19, word_ins=3.003, length=3.443, ppl=10.18, wps=211891, ups=3.42, wpb=61995.7, bsz=1882.4, num_updates=114500, lr=0.000295527, gnorm=1.03, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:03:16 | INFO | train_inner | epoch 058:   1586 / 1983 loss=3.336, nll_loss=1.181, word_ins=2.996, length=3.404, ppl=10.1, wps=211950, ups=3.42, wpb=61892.8, bsz=1930.4, num_updates=114600, lr=0.000295398, gnorm=1.033, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:03:46 | INFO | train_inner | epoch 058:   1686 / 1983 loss=3.319, nll_loss=1.167, word_ins=2.982, length=3.37, ppl=9.98, wps=211129, ups=3.41, wpb=61844.7, bsz=2041.8, num_updates=114700, lr=0.000295269, gnorm=1.018, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:04:15 | INFO | train_inner | epoch 058:   1786 / 1983 loss=3.333, nll_loss=1.176, word_ins=2.991, length=3.422, ppl=10.08, wps=209669, ups=3.42, wpb=61223.5, bsz=2051.3, num_updates=114800, lr=0.000295141, gnorm=1.008, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:04:44 | INFO | train_inner | epoch 058:   1886 / 1983 loss=3.35, nll_loss=1.19, word_ins=3.004, length=3.463, ppl=10.19, wps=212036, ups=3.43, wpb=61867.2, bsz=1927.6, num_updates=114900, lr=0.000295012, gnorm=1.031, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 04:05:26 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 3.309 | nll_loss 1.095 | word_ins 2.974 | length 3.357 | ppl 9.91 | wps 84072.9 | wpb 41551 | bsz 1500 | num_updates 114997 | best_loss 3.287
2023-03-02 04:05:26 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 04:05:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint58.pt (epoch 58 @ 114997 updates, score 3.309) (writing took 5.795378252048977 seconds)
2023-03-02 04:05:31 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2023-03-02 04:05:31 | INFO | train | epoch 058 | loss 3.33 | nll_loss 1.174 | word_ins 2.99 | length 3.407 | ppl 10.06 | wps 200429 | ups 3.25 | wpb 61627.7 | bsz 1997.9 | num_updates 114997 | lr 0.000294888 | gnorm 1.022 | loss_scale 16384 | train_wall 578 | wall 0
2023-03-02 04:05:31 | INFO | fairseq.trainer | begin training epoch 59
2023-03-02 04:05:43 | INFO | train_inner | epoch 059:      3 / 1983 loss=3.358, nll_loss=1.199, word_ins=3.012, length=3.466, ppl=10.26, wps=103986, ups=1.7, wpb=61244.1, bsz=1954.2, num_updates=115000, lr=0.000294884, gnorm=1.062, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:06:12 | INFO | train_inner | epoch 059:    103 / 1983 loss=3.358, nll_loss=1.196, word_ins=3.01, length=3.477, ppl=10.25, wps=209623, ups=3.4, wpb=61685.7, bsz=1866.6, num_updates=115100, lr=0.000294756, gnorm=1.029, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:06:42 | INFO | train_inner | epoch 059:    203 / 1983 loss=3.309, nll_loss=1.152, word_ins=2.969, length=3.4, ppl=9.91, wps=211368, ups=3.42, wpb=61854.9, bsz=2022, num_updates=115200, lr=0.000294628, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:07:11 | INFO | train_inner | epoch 059:    303 / 1983 loss=3.333, nll_loss=1.175, word_ins=2.99, length=3.429, ppl=10.08, wps=209942, ups=3.42, wpb=61474.5, bsz=1976.4, num_updates=115300, lr=0.0002945, gnorm=1.035, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:07:40 | INFO | train_inner | epoch 059:    403 / 1983 loss=3.31, nll_loss=1.156, word_ins=2.973, length=3.369, ppl=9.92, wps=208512, ups=3.38, wpb=61763.2, bsz=2028.4, num_updates=115400, lr=0.000294372, gnorm=0.994, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:08:10 | INFO | train_inner | epoch 059:    503 / 1983 loss=3.346, nll_loss=1.19, word_ins=3.004, length=3.427, ppl=10.17, wps=211629, ups=3.42, wpb=61848.1, bsz=1945.7, num_updates=115500, lr=0.000294245, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:08:39 | INFO | train_inner | epoch 059:    603 / 1983 loss=3.309, nll_loss=1.159, word_ins=2.976, length=3.339, ppl=9.91, wps=211522, ups=3.42, wpb=61931.1, bsz=2072.2, num_updates=115600, lr=0.000294118, gnorm=0.977, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:09:08 | INFO | train_inner | epoch 059:    703 / 1983 loss=3.333, nll_loss=1.177, word_ins=2.992, length=3.408, ppl=10.08, wps=210195, ups=3.41, wpb=61629.7, bsz=1990.1, num_updates=115700, lr=0.000293991, gnorm=1.029, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:09:38 | INFO | train_inner | epoch 059:    803 / 1983 loss=3.316, nll_loss=1.166, word_ins=2.982, length=3.335, ppl=9.96, wps=212251, ups=3.42, wpb=62148.9, bsz=1998.1, num_updates=115800, lr=0.000293864, gnorm=1.076, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:10:07 | INFO | train_inner | epoch 059:    903 / 1983 loss=3.309, nll_loss=1.156, word_ins=2.973, length=3.367, ppl=9.91, wps=210154, ups=3.42, wpb=61453.6, bsz=2067.4, num_updates=115900, lr=0.000293737, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:10:36 | INFO | train_inner | epoch 059:   1003 / 1983 loss=3.316, nll_loss=1.163, word_ins=2.979, length=3.371, ppl=9.96, wps=209938, ups=3.42, wpb=61390.2, bsz=2036.5, num_updates=116000, lr=0.00029361, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:11:05 | INFO | train_inner | epoch 059:   1103 / 1983 loss=3.314, nll_loss=1.161, word_ins=2.977, length=3.368, ppl=9.95, wps=211960, ups=3.43, wpb=61865.2, bsz=1960.8, num_updates=116100, lr=0.000293484, gnorm=0.994, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:11:34 | INFO | train_inner | epoch 059:   1203 / 1983 loss=3.365, nll_loss=1.213, word_ins=3.024, length=3.411, ppl=10.31, wps=211468, ups=3.43, wpb=61722, bsz=1955.8, num_updates=116200, lr=0.000293357, gnorm=1.068, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:12:04 | INFO | train_inner | epoch 059:   1303 / 1983 loss=3.334, nll_loss=1.178, word_ins=2.993, length=3.418, ppl=10.09, wps=209773, ups=3.41, wpb=61524.8, bsz=1995.1, num_updates=116300, lr=0.000293231, gnorm=1.037, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:12:33 | INFO | train_inner | epoch 059:   1403 / 1983 loss=3.32, nll_loss=1.16, word_ins=2.976, length=3.441, ppl=9.99, wps=211443, ups=3.46, wpb=61189.1, bsz=2016.8, num_updates=116400, lr=0.000293105, gnorm=1.002, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:13:02 | INFO | train_inner | epoch 059:   1503 / 1983 loss=3.33, nll_loss=1.176, word_ins=2.991, length=3.393, ppl=10.05, wps=210231, ups=3.43, wpb=61283.4, bsz=2023.4, num_updates=116500, lr=0.000292979, gnorm=0.997, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:13:31 | INFO | train_inner | epoch 059:   1603 / 1983 loss=3.327, nll_loss=1.171, word_ins=2.986, length=3.406, ppl=10.03, wps=211354, ups=3.43, wpb=61704.4, bsz=2015.8, num_updates=116600, lr=0.000292854, gnorm=1.002, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:14:00 | INFO | train_inner | epoch 059:   1703 / 1983 loss=3.317, nll_loss=1.166, word_ins=2.982, length=3.353, ppl=9.97, wps=210919, ups=3.42, wpb=61586, bsz=2046.4, num_updates=116700, lr=0.000292728, gnorm=1.013, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:14:29 | INFO | train_inner | epoch 059:   1803 / 1983 loss=3.328, nll_loss=1.175, word_ins=2.99, length=3.379, ppl=10.04, wps=212365, ups=3.44, wpb=61690.1, bsz=1979, num_updates=116800, lr=0.000292603, gnorm=1.046, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:14:58 | INFO | train_inner | epoch 059:   1903 / 1983 loss=3.323, nll_loss=1.165, word_ins=2.98, length=3.423, ppl=10.01, wps=211968, ups=3.43, wpb=61756.5, bsz=1985.3, num_updates=116900, lr=0.000292478, gnorm=1.019, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 04:15:35 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 3.282 | nll_loss 1.069 | word_ins 2.953 | length 3.292 | ppl 9.73 | wps 84997.8 | wpb 41551 | bsz 1500 | num_updates 116980 | best_loss 3.282
2023-03-02 04:15:35 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 04:15:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint59.pt (epoch 59 @ 116980 updates, score 3.282) (writing took 8.94988442293834 seconds)
2023-03-02 04:15:44 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2023-03-02 04:15:44 | INFO | train | epoch 059 | loss 3.327 | nll_loss 1.172 | word_ins 2.987 | length 3.399 | ppl 10.03 | wps 199347 | ups 3.23 | wpb 61628.5 | bsz 1997.6 | num_updates 116980 | lr 0.000292378 | gnorm 1.016 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 04:15:44 | INFO | fairseq.trainer | begin training epoch 60
2023-03-02 04:16:00 | INFO | train_inner | epoch 060:     20 / 1983 loss=3.332, nll_loss=1.171, word_ins=2.986, length=3.462, ppl=10.07, wps=99576.1, ups=1.63, wpb=61152.4, bsz=1991.9, num_updates=117000, lr=0.000292353, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:16:29 | INFO | train_inner | epoch 060:    120 / 1983 loss=3.272, nll_loss=1.125, word_ins=2.944, length=3.277, ppl=9.66, wps=211290, ups=3.41, wpb=61980.1, bsz=2127.7, num_updates=117100, lr=0.000292228, gnorm=0.99, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:16:58 | INFO | train_inner | epoch 060:    220 / 1983 loss=3.315, nll_loss=1.163, word_ins=2.98, length=3.353, ppl=9.95, wps=209880, ups=3.42, wpb=61375.1, bsz=2025.5, num_updates=117200, lr=0.000292103, gnorm=1.018, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:17:28 | INFO | train_inner | epoch 060:    320 / 1983 loss=3.311, nll_loss=1.158, word_ins=2.974, length=3.37, ppl=9.92, wps=210949, ups=3.43, wpb=61452.6, bsz=1953.1, num_updates=117300, lr=0.000291979, gnorm=0.996, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:17:57 | INFO | train_inner | epoch 060:    420 / 1983 loss=3.314, nll_loss=1.158, word_ins=2.974, length=3.397, ppl=9.94, wps=210213, ups=3.41, wpb=61688.2, bsz=1980.6, num_updates=117400, lr=0.000291854, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:18:26 | INFO | train_inner | epoch 060:    520 / 1983 loss=3.293, nll_loss=1.137, word_ins=2.955, length=3.381, ppl=9.8, wps=211570, ups=3.43, wpb=61663.9, bsz=2050.5, num_updates=117500, lr=0.00029173, gnorm=1.02, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:18:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 04:18:56 | INFO | train_inner | epoch 060:    621 / 1983 loss=3.35, nll_loss=1.197, word_ins=3.01, length=3.402, ppl=10.2, wps=208721, ups=3.39, wpb=61505.2, bsz=1854.9, num_updates=117600, lr=0.000291606, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:19:25 | INFO | train_inner | epoch 060:    721 / 1983 loss=3.33, nll_loss=1.178, word_ins=2.993, length=3.368, ppl=10.05, wps=207814, ups=3.39, wpb=61299.7, bsz=2069.3, num_updates=117700, lr=0.000291482, gnorm=1.022, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:19:54 | INFO | train_inner | epoch 060:    821 / 1983 loss=3.355, nll_loss=1.193, word_ins=3.006, length=3.496, ppl=10.23, wps=211153, ups=3.44, wpb=61412.3, bsz=1898.5, num_updates=117800, lr=0.000291358, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:20:23 | INFO | train_inner | epoch 060:    921 / 1983 loss=3.304, nll_loss=1.15, word_ins=2.968, length=3.357, ppl=9.87, wps=212692, ups=3.44, wpb=61915, bsz=2024.5, num_updates=117900, lr=0.000291235, gnorm=1.021, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:20:52 | INFO | train_inner | epoch 060:   1021 / 1983 loss=3.318, nll_loss=1.161, word_ins=2.977, length=3.409, ppl=9.97, wps=212379, ups=3.44, wpb=61681.1, bsz=2023.2, num_updates=118000, lr=0.000291111, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:21:21 | INFO | train_inner | epoch 060:   1121 / 1983 loss=3.315, nll_loss=1.158, word_ins=2.975, length=3.401, ppl=9.95, wps=210861, ups=3.43, wpb=61563.3, bsz=2059.5, num_updates=118100, lr=0.000290988, gnorm=0.986, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:21:51 | INFO | train_inner | epoch 060:   1221 / 1983 loss=3.323, nll_loss=1.169, word_ins=2.985, length=3.38, ppl=10, wps=211330, ups=3.42, wpb=61764.1, bsz=2033.8, num_updates=118200, lr=0.000290865, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:22:20 | INFO | train_inner | epoch 060:   1321 / 1983 loss=3.314, nll_loss=1.159, word_ins=2.975, length=3.387, ppl=9.95, wps=211293, ups=3.44, wpb=61391.4, bsz=1985.5, num_updates=118300, lr=0.000290742, gnorm=0.995, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:22:49 | INFO | train_inner | epoch 060:   1421 / 1983 loss=3.325, nll_loss=1.172, word_ins=2.987, length=3.378, ppl=10.02, wps=211397, ups=3.41, wpb=62014.4, bsz=2057.1, num_updates=118400, lr=0.000290619, gnorm=1.025, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:23:18 | INFO | train_inner | epoch 060:   1521 / 1983 loss=3.312, nll_loss=1.157, word_ins=2.974, length=3.379, ppl=9.93, wps=211860, ups=3.42, wpb=61891.8, bsz=1979.4, num_updates=118500, lr=0.000290496, gnorm=1.016, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:23:47 | INFO | train_inner | epoch 060:   1621 / 1983 loss=3.346, nll_loss=1.188, word_ins=3.001, length=3.447, ppl=10.17, wps=212689, ups=3.44, wpb=61914, bsz=1968.2, num_updates=118600, lr=0.000290374, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:24:17 | INFO | train_inner | epoch 060:   1721 / 1983 loss=3.349, nll_loss=1.189, word_ins=3.003, length=3.469, ppl=10.19, wps=210832, ups=3.44, wpb=61300.7, bsz=1943.5, num_updates=118700, lr=0.000290252, gnorm=0.977, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:24:46 | INFO | train_inner | epoch 060:   1821 / 1983 loss=3.325, nll_loss=1.164, word_ins=2.98, length=3.447, ppl=10.02, wps=210939, ups=3.43, wpb=61495.7, bsz=1990.4, num_updates=118800, lr=0.000290129, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:25:15 | INFO | train_inner | epoch 060:   1921 / 1983 loss=3.343, nll_loss=1.184, word_ins=2.998, length=3.447, ppl=10.14, wps=210957, ups=3.42, wpb=61745.8, bsz=1942.6, num_updates=118900, lr=0.000290007, gnorm=1.017, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 04:25:48 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 3.303 | nll_loss 1.097 | word_ins 2.976 | length 3.266 | ppl 9.87 | wps 82478.4 | wpb 41551 | bsz 1500 | num_updates 118962 | best_loss 3.282
2023-03-02 04:25:48 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 04:25:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint60.pt (epoch 60 @ 118962 updates, score 3.303) (writing took 5.92615888803266 seconds)
2023-03-02 04:25:54 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2023-03-02 04:25:54 | INFO | train | epoch 060 | loss 3.322 | nll_loss 1.166 | word_ins 2.982 | length 3.398 | ppl 10 | wps 200506 | ups 3.25 | wpb 61630.5 | bsz 1997.6 | num_updates 118962 | lr 0.000289932 | gnorm 1.007 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 04:25:54 | INFO | fairseq.trainer | begin training epoch 61
2023-03-02 04:26:15 | INFO | train_inner | epoch 061:     38 / 1983 loss=3.308, nll_loss=1.156, word_ins=2.972, length=3.361, ppl=9.91, wps=103137, ups=1.67, wpb=61608.9, bsz=1959.5, num_updates=119000, lr=0.000289886, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:26:44 | INFO | train_inner | epoch 061:    138 / 1983 loss=3.278, nll_loss=1.126, word_ins=2.946, length=3.325, ppl=9.7, wps=211544, ups=3.4, wpb=62137.4, bsz=2093.9, num_updates=119100, lr=0.000289764, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:27:13 | INFO | train_inner | epoch 061:    238 / 1983 loss=3.322, nll_loss=1.163, word_ins=2.979, length=3.425, ppl=10, wps=211132, ups=3.43, wpb=61473.1, bsz=1967.3, num_updates=119200, lr=0.000289642, gnorm=0.999, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:27:42 | INFO | train_inner | epoch 061:    338 / 1983 loss=3.317, nll_loss=1.16, word_ins=2.977, length=3.405, ppl=9.97, wps=211863, ups=3.43, wpb=61715.2, bsz=1935.6, num_updates=119300, lr=0.000289521, gnorm=1.038, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:28:11 | INFO | train_inner | epoch 061:    438 / 1983 loss=3.35, nll_loss=1.188, word_ins=3.002, length=3.48, ppl=10.2, wps=208212, ups=3.44, wpb=60567.7, bsz=1976.2, num_updates=119400, lr=0.0002894, gnorm=1.044, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:28:41 | INFO | train_inner | epoch 061:    538 / 1983 loss=3.335, nll_loss=1.173, word_ins=2.989, length=3.464, ppl=10.09, wps=212485, ups=3.43, wpb=61907.2, bsz=1897, num_updates=119500, lr=0.000289278, gnorm=1.023, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:29:10 | INFO | train_inner | epoch 061:    638 / 1983 loss=3.314, nll_loss=1.155, word_ins=2.972, length=3.421, ppl=9.94, wps=211147, ups=3.44, wpb=61463.4, bsz=1944.5, num_updates=119600, lr=0.000289157, gnorm=1.025, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:29:39 | INFO | train_inner | epoch 061:    738 / 1983 loss=3.288, nll_loss=1.133, word_ins=2.952, length=3.361, ppl=9.77, wps=211597, ups=3.43, wpb=61634.7, bsz=2084.3, num_updates=119700, lr=0.000289037, gnorm=0.998, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:30:08 | INFO | train_inner | epoch 061:    838 / 1983 loss=3.297, nll_loss=1.144, word_ins=2.962, length=3.36, ppl=9.83, wps=212553, ups=3.44, wpb=61848.8, bsz=2031.8, num_updates=119800, lr=0.000288916, gnorm=1, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:30:37 | INFO | train_inner | epoch 061:    938 / 1983 loss=3.345, nll_loss=1.187, word_ins=3.001, length=3.441, ppl=10.16, wps=210458, ups=3.42, wpb=61498.9, bsz=1993.9, num_updates=119900, lr=0.000288795, gnorm=1.014, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:31:06 | INFO | train_inner | epoch 061:   1038 / 1983 loss=3.309, nll_loss=1.15, word_ins=2.967, length=3.41, ppl=9.91, wps=210180, ups=3.43, wpb=61307.3, bsz=2007, num_updates=120000, lr=0.000288675, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:31:35 | INFO | train_inner | epoch 061:   1138 / 1983 loss=3.324, nll_loss=1.165, word_ins=2.981, length=3.437, ppl=10.02, wps=212869, ups=3.45, wpb=61762.1, bsz=1945.8, num_updates=120100, lr=0.000288555, gnorm=0.991, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:32:05 | INFO | train_inner | epoch 061:   1238 / 1983 loss=3.313, nll_loss=1.155, word_ins=2.972, length=3.411, ppl=9.94, wps=210981, ups=3.42, wpb=61777.2, bsz=2025.2, num_updates=120200, lr=0.000288435, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:32:34 | INFO | train_inner | epoch 061:   1338 / 1983 loss=3.316, nll_loss=1.16, word_ins=2.976, length=3.397, ppl=9.96, wps=213519, ups=3.43, wpb=62184.3, bsz=1916.2, num_updates=120300, lr=0.000288315, gnorm=1.021, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:33:03 | INFO | train_inner | epoch 061:   1438 / 1983 loss=3.302, nll_loss=1.15, word_ins=2.967, length=3.35, ppl=9.86, wps=210501, ups=3.41, wpb=61672.2, bsz=2047.8, num_updates=120400, lr=0.000288195, gnorm=1.017, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:33:32 | INFO | train_inner | epoch 061:   1538 / 1983 loss=3.294, nll_loss=1.144, word_ins=2.961, length=3.329, ppl=9.81, wps=212394, ups=3.44, wpb=61804.2, bsz=2118.3, num_updates=120500, lr=0.000288076, gnorm=0.996, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:34:01 | INFO | train_inner | epoch 061:   1638 / 1983 loss=3.324, nll_loss=1.173, word_ins=2.987, length=3.365, ppl=10.01, wps=210204, ups=3.43, wpb=61354.2, bsz=2044.5, num_updates=120600, lr=0.000287956, gnorm=1.026, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:34:31 | INFO | train_inner | epoch 061:   1738 / 1983 loss=3.328, nll_loss=1.174, word_ins=2.989, length=3.388, ppl=10.04, wps=211023, ups=3.42, wpb=61725.4, bsz=2024.1, num_updates=120700, lr=0.000287837, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:35:00 | INFO | train_inner | epoch 061:   1838 / 1983 loss=3.323, nll_loss=1.163, word_ins=2.979, length=3.445, ppl=10.01, wps=208897, ups=3.4, wpb=61482.6, bsz=2026.5, num_updates=120800, lr=0.000287718, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:35:29 | INFO | train_inner | epoch 061:   1938 / 1983 loss=3.34, nll_loss=1.178, word_ins=2.992, length=3.479, ppl=10.13, wps=214430, ups=3.46, wpb=61889, bsz=1882.3, num_updates=120900, lr=0.000287599, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 04:35:55 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 3.284 | nll_loss 1.07 | word_ins 2.953 | length 3.3 | ppl 9.74 | wps 81887.7 | wpb 41551 | bsz 1500 | num_updates 120945 | best_loss 3.282
2023-03-02 04:35:55 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 04:36:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint61.pt (epoch 61 @ 120945 updates, score 3.284) (writing took 5.626287056016736 seconds)
2023-03-02 04:36:01 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2023-03-02 04:36:01 | INFO | train | epoch 061 | loss 3.316 | nll_loss 1.16 | word_ins 2.976 | length 3.402 | ppl 9.96 | wps 201183 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 120945 | lr 0.000287545 | gnorm 1.005 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 04:36:01 | INFO | fairseq.trainer | begin training epoch 62
2023-03-02 04:36:27 | INFO | train_inner | epoch 062:     55 / 1983 loss=3.326, nll_loss=1.172, word_ins=2.987, length=3.391, ppl=10.03, wps=105064, ups=1.72, wpb=61000.1, bsz=1999.3, num_updates=121000, lr=0.00028748, gnorm=1.003, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:36:56 | INFO | train_inner | epoch 062:    155 / 1983 loss=3.3, nll_loss=1.151, word_ins=2.969, length=3.311, ppl=9.85, wps=211375, ups=3.42, wpb=61796.2, bsz=1997.4, num_updates=121100, lr=0.000287361, gnorm=1.003, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:37:25 | INFO | train_inner | epoch 062:    255 / 1983 loss=3.295, nll_loss=1.142, word_ins=2.96, length=3.345, ppl=9.81, wps=211309, ups=3.42, wpb=61822.6, bsz=2035.8, num_updates=121200, lr=0.000287242, gnorm=1.022, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:37:55 | INFO | train_inner | epoch 062:    355 / 1983 loss=3.286, nll_loss=1.129, word_ins=2.948, length=3.38, ppl=9.76, wps=212689, ups=3.43, wpb=61923.6, bsz=2011.7, num_updates=121300, lr=0.000287124, gnorm=0.996, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:38:24 | INFO | train_inner | epoch 062:    455 / 1983 loss=3.305, nll_loss=1.154, word_ins=2.971, length=3.343, ppl=9.88, wps=211358, ups=3.43, wpb=61651.6, bsz=1986.8, num_updates=121400, lr=0.000287006, gnorm=1.035, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:38:53 | INFO | train_inner | epoch 062:    555 / 1983 loss=3.3, nll_loss=1.142, word_ins=2.96, length=3.403, ppl=9.85, wps=209579, ups=3.43, wpb=61091.4, bsz=2086.4, num_updates=121500, lr=0.000286888, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:39:22 | INFO | train_inner | epoch 062:    655 / 1983 loss=3.334, nll_loss=1.174, word_ins=2.989, length=3.448, ppl=10.08, wps=211641, ups=3.44, wpb=61542.6, bsz=1900.6, num_updates=121600, lr=0.00028677, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:39:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 04:39:51 | INFO | train_inner | epoch 062:    756 / 1983 loss=3.325, nll_loss=1.166, word_ins=2.981, length=3.436, ppl=10.02, wps=209618, ups=3.42, wpb=61305.5, bsz=1935.8, num_updates=121700, lr=0.000286652, gnorm=0.973, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:40:20 | INFO | train_inner | epoch 062:    856 / 1983 loss=3.297, nll_loss=1.143, word_ins=2.961, length=3.359, ppl=9.83, wps=211462, ups=3.42, wpb=61888, bsz=2053.8, num_updates=121800, lr=0.000286534, gnorm=0.99, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:40:50 | INFO | train_inner | epoch 062:    956 / 1983 loss=3.301, nll_loss=1.144, word_ins=2.962, length=3.39, ppl=9.85, wps=212061, ups=3.43, wpb=61890.6, bsz=2027, num_updates=121900, lr=0.000286417, gnorm=0.966, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:41:19 | INFO | train_inner | epoch 062:   1056 / 1983 loss=3.299, nll_loss=1.149, word_ins=2.966, length=3.333, ppl=9.84, wps=212502, ups=3.43, wpb=61916.3, bsz=2031, num_updates=122000, lr=0.000286299, gnorm=0.976, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:41:48 | INFO | train_inner | epoch 062:   1156 / 1983 loss=3.302, nll_loss=1.148, word_ins=2.965, length=3.366, ppl=9.86, wps=212908, ups=3.44, wpb=61841.3, bsz=2052.4, num_updates=122100, lr=0.000286182, gnorm=0.979, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:42:17 | INFO | train_inner | epoch 062:   1256 / 1983 loss=3.331, nll_loss=1.172, word_ins=2.986, length=3.444, ppl=10.06, wps=210486, ups=3.43, wpb=61377.5, bsz=1997.2, num_updates=122200, lr=0.000286065, gnorm=0.994, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:42:46 | INFO | train_inner | epoch 062:   1356 / 1983 loss=3.312, nll_loss=1.159, word_ins=2.975, length=3.367, ppl=9.93, wps=212258, ups=3.41, wpb=62202.4, bsz=2040, num_updates=122300, lr=0.000285948, gnorm=0.987, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:43:15 | INFO | train_inner | epoch 062:   1456 / 1983 loss=3.325, nll_loss=1.168, word_ins=2.983, length=3.419, ppl=10.02, wps=211919, ups=3.44, wpb=61647.9, bsz=1949.1, num_updates=122400, lr=0.000285831, gnorm=1.01, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:43:45 | INFO | train_inner | epoch 062:   1556 / 1983 loss=3.315, nll_loss=1.158, word_ins=2.974, length=3.406, ppl=9.95, wps=210009, ups=3.42, wpb=61353, bsz=2023, num_updates=122500, lr=0.000285714, gnorm=0.981, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:44:14 | INFO | train_inner | epoch 062:   1656 / 1983 loss=3.342, nll_loss=1.181, word_ins=2.995, length=3.471, ppl=10.14, wps=212641, ups=3.44, wpb=61837, bsz=1945.5, num_updates=122600, lr=0.000285598, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:44:43 | INFO | train_inner | epoch 062:   1756 / 1983 loss=3.323, nll_loss=1.165, word_ins=2.981, length=3.42, ppl=10, wps=211562, ups=3.43, wpb=61655.8, bsz=1961.8, num_updates=122700, lr=0.000285481, gnorm=1.005, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:45:12 | INFO | train_inner | epoch 062:   1856 / 1983 loss=3.334, nll_loss=1.18, word_ins=2.994, length=3.407, ppl=10.09, wps=209503, ups=3.42, wpb=61243.1, bsz=1964.6, num_updates=122800, lr=0.000285365, gnorm=1.001, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:45:41 | INFO | train_inner | epoch 062:   1956 / 1983 loss=3.316, nll_loss=1.16, word_ins=2.976, length=3.403, ppl=9.96, wps=211519, ups=3.42, wpb=61760.9, bsz=1978.4, num_updates=122900, lr=0.000285249, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 04:46:01 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 3.271 | nll_loss 1.066 | word_ins 2.947 | length 3.252 | ppl 9.65 | wps 106163 | wpb 41551 | bsz 1500 | num_updates 122927 | best_loss 3.271
2023-03-02 04:46:01 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 04:46:10 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint62.pt (epoch 62 @ 122927 updates, score 3.271) (writing took 8.547773784957826 seconds)
2023-03-02 04:46:10 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2023-03-02 04:46:10 | INFO | train | epoch 062 | loss 3.313 | nll_loss 1.158 | word_ins 2.974 | length 3.393 | ppl 9.94 | wps 200638 | ups 3.26 | wpb 61627.7 | bsz 1997.9 | num_updates 122927 | lr 0.000285218 | gnorm 0.994 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 04:46:10 | INFO | fairseq.trainer | begin training epoch 63
2023-03-02 04:46:41 | INFO | train_inner | epoch 063:     73 / 1983 loss=3.291, nll_loss=1.135, word_ins=2.954, length=3.371, ppl=9.79, wps=102527, ups=1.68, wpb=61044.4, bsz=1995, num_updates=123000, lr=0.000285133, gnorm=1.012, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:47:10 | INFO | train_inner | epoch 063:    173 / 1983 loss=3.299, nll_loss=1.144, word_ins=2.962, length=3.371, ppl=9.84, wps=209581, ups=3.42, wpb=61331.5, bsz=2026.3, num_updates=123100, lr=0.000285017, gnorm=0.97, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:47:39 | INFO | train_inner | epoch 063:    273 / 1983 loss=3.309, nll_loss=1.152, word_ins=2.968, length=3.41, ppl=9.91, wps=210496, ups=3.42, wpb=61573.5, bsz=2050.1, num_updates=123200, lr=0.000284901, gnorm=1.009, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:48:09 | INFO | train_inner | epoch 063:    373 / 1983 loss=3.285, nll_loss=1.135, word_ins=2.954, length=3.315, ppl=9.75, wps=212537, ups=3.42, wpb=62135.6, bsz=2013.5, num_updates=123300, lr=0.000284786, gnorm=1.015, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:48:38 | INFO | train_inner | epoch 063:    473 / 1983 loss=3.308, nll_loss=1.152, word_ins=2.969, length=3.388, ppl=9.9, wps=208884, ups=3.4, wpb=61525.7, bsz=2121.5, num_updates=123400, lr=0.00028467, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:49:07 | INFO | train_inner | epoch 063:    573 / 1983 loss=3.281, nll_loss=1.131, word_ins=2.949, length=3.318, ppl=9.72, wps=210906, ups=3.42, wpb=61749.7, bsz=2068.2, num_updates=123500, lr=0.000284555, gnorm=0.948, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:49:37 | INFO | train_inner | epoch 063:    673 / 1983 loss=3.288, nll_loss=1.132, word_ins=2.951, length=3.37, ppl=9.77, wps=210125, ups=3.41, wpb=61625.7, bsz=1992.3, num_updates=123600, lr=0.00028444, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:50:06 | INFO | train_inner | epoch 063:    773 / 1983 loss=3.314, nll_loss=1.159, word_ins=2.974, length=3.398, ppl=9.95, wps=212999, ups=3.45, wpb=61759.4, bsz=1922.8, num_updates=123700, lr=0.000284325, gnorm=0.979, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:50:35 | INFO | train_inner | epoch 063:    873 / 1983 loss=3.327, nll_loss=1.171, word_ins=2.986, length=3.414, ppl=10.03, wps=210455, ups=3.42, wpb=61463.5, bsz=1986.5, num_updates=123800, lr=0.00028421, gnorm=0.977, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:51:04 | INFO | train_inner | epoch 063:    973 / 1983 loss=3.296, nll_loss=1.143, word_ins=2.96, length=3.361, ppl=9.82, wps=213132, ups=3.42, wpb=62373, bsz=1978.7, num_updates=123900, lr=0.000284095, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:51:33 | INFO | train_inner | epoch 063:   1073 / 1983 loss=3.279, nll_loss=1.127, word_ins=2.946, length=3.335, ppl=9.71, wps=212404, ups=3.44, wpb=61803.5, bsz=2069.9, num_updates=124000, lr=0.000283981, gnorm=0.996, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:52:02 | INFO | train_inner | epoch 063:   1173 / 1983 loss=3.29, nll_loss=1.133, word_ins=2.951, length=3.395, ppl=9.78, wps=210762, ups=3.43, wpb=61363.6, bsz=2053.2, num_updates=124100, lr=0.000283866, gnorm=0.972, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:52:32 | INFO | train_inner | epoch 063:   1273 / 1983 loss=3.344, nll_loss=1.184, word_ins=2.998, length=3.465, ppl=10.15, wps=211478, ups=3.43, wpb=61647.6, bsz=1939.4, num_updates=124200, lr=0.000283752, gnorm=0.996, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:53:01 | INFO | train_inner | epoch 063:   1373 / 1983 loss=3.353, nll_loss=1.185, word_ins=2.999, length=3.541, ppl=10.22, wps=210717, ups=3.43, wpb=61433.7, bsz=1861.1, num_updates=124300, lr=0.000283638, gnorm=1.014, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:53:30 | INFO | train_inner | epoch 063:   1473 / 1983 loss=3.316, nll_loss=1.161, word_ins=2.977, length=3.389, ppl=9.96, wps=211110, ups=3.43, wpb=61628.1, bsz=1979.5, num_updates=124400, lr=0.000283524, gnorm=0.959, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:53:59 | INFO | train_inner | epoch 063:   1573 / 1983 loss=3.315, nll_loss=1.163, word_ins=2.978, length=3.373, ppl=9.95, wps=212009, ups=3.43, wpb=61821.8, bsz=1967.8, num_updates=124500, lr=0.00028341, gnorm=0.985, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:54:28 | INFO | train_inner | epoch 063:   1673 / 1983 loss=3.309, nll_loss=1.152, word_ins=2.968, length=3.402, ppl=9.91, wps=210934, ups=3.42, wpb=61594.6, bsz=1966.2, num_updates=124600, lr=0.000283296, gnorm=0.962, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:54:58 | INFO | train_inner | epoch 063:   1773 / 1983 loss=3.318, nll_loss=1.162, word_ins=2.978, length=3.398, ppl=9.97, wps=209381, ups=3.4, wpb=61616.2, bsz=1965.4, num_updates=124700, lr=0.000283183, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:55:27 | INFO | train_inner | epoch 063:   1873 / 1983 loss=3.311, nll_loss=1.156, word_ins=2.972, length=3.387, ppl=9.92, wps=210662, ups=3.42, wpb=61586, bsz=1971.8, num_updates=124800, lr=0.000283069, gnorm=0.976, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:55:56 | INFO | train_inner | epoch 063:   1973 / 1983 loss=3.318, nll_loss=1.161, word_ins=2.977, length=3.416, ppl=9.98, wps=208854, ups=3.4, wpb=61368.9, bsz=1976.3, num_updates=124900, lr=0.000282956, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:55:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 04:56:13 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 3.295 | nll_loss 1.086 | word_ins 2.966 | length 3.301 | ppl 9.82 | wps 84193.9 | wpb 41551 | bsz 1500 | num_updates 124910 | best_loss 3.271
2023-03-02 04:56:13 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 04:56:18 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint63.pt (epoch 63 @ 124910 updates, score 3.295) (writing took 5.752955144038424 seconds)
2023-03-02 04:56:18 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2023-03-02 04:56:18 | INFO | train | epoch 063 | loss 3.307 | nll_loss 1.152 | word_ins 2.968 | length 3.39 | ppl 9.9 | wps 200798 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 124910 | lr 0.000282945 | gnorm 0.986 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 04:56:18 | INFO | fairseq.trainer | begin training epoch 64
2023-03-02 04:56:55 | INFO | train_inner | epoch 064:     90 / 1983 loss=3.299, nll_loss=1.15, word_ins=2.967, length=3.323, ppl=9.84, wps=104698, ups=1.71, wpb=61228.8, bsz=2049.6, num_updates=125000, lr=0.000282843, gnorm=0.99, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:57:24 | INFO | train_inner | epoch 064:    190 / 1983 loss=3.308, nll_loss=1.15, word_ins=2.967, length=3.411, ppl=9.9, wps=210555, ups=3.43, wpb=61330.2, bsz=1927, num_updates=125100, lr=0.00028273, gnorm=0.976, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:57:53 | INFO | train_inner | epoch 064:    290 / 1983 loss=3.308, nll_loss=1.151, word_ins=2.968, length=3.403, ppl=9.91, wps=210679, ups=3.41, wpb=61821, bsz=1998.1, num_updates=125200, lr=0.000282617, gnorm=0.986, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:58:23 | INFO | train_inner | epoch 064:    390 / 1983 loss=3.29, nll_loss=1.139, word_ins=2.957, length=3.331, ppl=9.78, wps=210927, ups=3.39, wpb=62297.5, bsz=2036.7, num_updates=125300, lr=0.000282504, gnorm=0.982, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:58:52 | INFO | train_inner | epoch 064:    490 / 1983 loss=3.303, nll_loss=1.147, word_ins=2.964, length=3.395, ppl=9.87, wps=211929, ups=3.43, wpb=61831, bsz=1988.8, num_updates=125400, lr=0.000282391, gnorm=0.969, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:59:21 | INFO | train_inner | epoch 064:    590 / 1983 loss=3.291, nll_loss=1.138, word_ins=2.956, length=3.356, ppl=9.79, wps=210821, ups=3.42, wpb=61710.9, bsz=2036.6, num_updates=125500, lr=0.000282279, gnorm=0.967, loss_scale=16384, train_wall=29, wall=0
2023-03-02 04:59:51 | INFO | train_inner | epoch 064:    690 / 1983 loss=3.296, nll_loss=1.139, word_ins=2.957, length=3.396, ppl=9.82, wps=209907, ups=3.41, wpb=61549.9, bsz=2078.6, num_updates=125600, lr=0.000282166, gnorm=0.959, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:00:20 | INFO | train_inner | epoch 064:    790 / 1983 loss=3.297, nll_loss=1.147, word_ins=2.964, length=3.328, ppl=9.83, wps=211603, ups=3.42, wpb=61822.4, bsz=2007.4, num_updates=125700, lr=0.000282054, gnorm=0.971, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:00:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 05:00:49 | INFO | train_inner | epoch 064:    891 / 1983 loss=3.298, nll_loss=1.146, word_ins=2.963, length=3.353, ppl=9.84, wps=208519, ups=3.38, wpb=61622.6, bsz=2002.3, num_updates=125800, lr=0.000281942, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:01:19 | INFO | train_inner | epoch 064:    991 / 1983 loss=3.283, nll_loss=1.126, word_ins=2.945, length=3.38, ppl=9.73, wps=209820, ups=3.41, wpb=61488.8, bsz=2052.2, num_updates=125900, lr=0.00028183, gnorm=0.948, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:01:48 | INFO | train_inner | epoch 064:   1091 / 1983 loss=3.306, nll_loss=1.147, word_ins=2.964, length=3.419, ppl=9.89, wps=211045, ups=3.45, wpb=61229.5, bsz=1991, num_updates=126000, lr=0.000281718, gnorm=0.97, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:02:17 | INFO | train_inner | epoch 064:   1191 / 1983 loss=3.329, nll_loss=1.171, word_ins=2.985, length=3.436, ppl=10.05, wps=211559, ups=3.42, wpb=61849.4, bsz=1891.5, num_updates=126100, lr=0.000281606, gnorm=0.995, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:02:46 | INFO | train_inner | epoch 064:   1291 / 1983 loss=3.304, nll_loss=1.146, word_ins=2.963, length=3.412, ppl=9.88, wps=212479, ups=3.43, wpb=61926.3, bsz=1972.7, num_updates=126200, lr=0.000281495, gnorm=0.981, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:03:15 | INFO | train_inner | epoch 064:   1391 / 1983 loss=3.32, nll_loss=1.161, word_ins=2.977, length=3.438, ppl=9.99, wps=211180, ups=3.43, wpb=61618.3, bsz=1987.8, num_updates=126300, lr=0.000281383, gnorm=1.006, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:03:44 | INFO | train_inner | epoch 064:   1491 / 1983 loss=3.316, nll_loss=1.158, word_ins=2.974, length=3.42, ppl=9.96, wps=209911, ups=3.43, wpb=61150.1, bsz=2007.3, num_updates=126400, lr=0.000281272, gnorm=0.978, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:04:14 | INFO | train_inner | epoch 064:   1591 / 1983 loss=3.291, nll_loss=1.139, word_ins=2.956, length=3.348, ppl=9.79, wps=210138, ups=3.41, wpb=61541.3, bsz=2024.9, num_updates=126500, lr=0.000281161, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:04:43 | INFO | train_inner | epoch 064:   1691 / 1983 loss=3.304, nll_loss=1.148, word_ins=2.964, length=3.403, ppl=9.88, wps=212795, ups=3.44, wpb=61915, bsz=2001.4, num_updates=126600, lr=0.00028105, gnorm=0.961, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:05:12 | INFO | train_inner | epoch 064:   1791 / 1983 loss=3.311, nll_loss=1.154, word_ins=2.97, length=3.407, ppl=9.92, wps=212847, ups=3.44, wpb=61814.2, bsz=1979, num_updates=126700, lr=0.000280939, gnorm=0.997, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:05:41 | INFO | train_inner | epoch 064:   1891 / 1983 loss=3.314, nll_loss=1.163, word_ins=2.978, length=3.363, ppl=9.94, wps=211923, ups=3.44, wpb=61569.8, bsz=2005.5, num_updates=126800, lr=0.000280828, gnorm=0.977, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 05:06:20 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 3.277 | nll_loss 1.066 | word_ins 2.951 | length 3.256 | ppl 9.69 | wps 116406 | wpb 41551 | bsz 1500 | num_updates 126892 | best_loss 3.271
2023-03-02 05:06:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 05:06:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint64.pt (epoch 64 @ 126892 updates, score 3.277) (writing took 5.503164732013829 seconds)
2023-03-02 05:06:25 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2023-03-02 05:06:25 | INFO | train | epoch 064 | loss 3.305 | nll_loss 1.15 | word_ins 2.967 | length 3.389 | ppl 9.89 | wps 201264 | ups 3.27 | wpb 61626.8 | bsz 1997.3 | num_updates 126892 | lr 0.000280726 | gnorm 0.976 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 05:06:25 | INFO | fairseq.trainer | begin training epoch 65
2023-03-02 05:06:37 | INFO | train_inner | epoch 065:      8 / 1983 loss=3.324, nll_loss=1.168, word_ins=2.983, length=3.409, ppl=10.01, wps=107951, ups=1.77, wpb=60888, bsz=1954.6, num_updates=126900, lr=0.000280717, gnorm=1.007, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:07:06 | INFO | train_inner | epoch 065:    108 / 1983 loss=3.319, nll_loss=1.156, word_ins=2.972, length=3.466, ppl=9.98, wps=209126, ups=3.43, wpb=60950.3, bsz=1903.3, num_updates=127000, lr=0.000280607, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:07:36 | INFO | train_inner | epoch 065:    208 / 1983 loss=3.294, nll_loss=1.141, word_ins=2.959, length=3.355, ppl=9.81, wps=212789, ups=3.43, wpb=61988.4, bsz=1962.6, num_updates=127100, lr=0.000280496, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:08:05 | INFO | train_inner | epoch 065:    308 / 1983 loss=3.282, nll_loss=1.127, word_ins=2.945, length=3.366, ppl=9.73, wps=208849, ups=3.41, wpb=61221.1, bsz=2059, num_updates=127200, lr=0.000280386, gnorm=0.957, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:08:34 | INFO | train_inner | epoch 065:    408 / 1983 loss=3.296, nll_loss=1.143, word_ins=2.961, length=3.356, ppl=9.82, wps=212230, ups=3.43, wpb=61784.9, bsz=1965.5, num_updates=127300, lr=0.000280276, gnorm=0.989, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:09:03 | INFO | train_inner | epoch 065:    508 / 1983 loss=3.296, nll_loss=1.144, word_ins=2.961, length=3.347, ppl=9.82, wps=211307, ups=3.42, wpb=61775.6, bsz=2055.8, num_updates=127400, lr=0.000280166, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:09:32 | INFO | train_inner | epoch 065:    608 / 1983 loss=3.294, nll_loss=1.139, word_ins=2.956, length=3.372, ppl=9.81, wps=211948, ups=3.44, wpb=61553.5, bsz=1968, num_updates=127500, lr=0.000280056, gnorm=0.961, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:10:01 | INFO | train_inner | epoch 065:    708 / 1983 loss=3.302, nll_loss=1.147, word_ins=2.964, length=3.376, ppl=9.86, wps=210354, ups=3.43, wpb=61347.4, bsz=2008.9, num_updates=127600, lr=0.000279946, gnorm=0.985, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:10:31 | INFO | train_inner | epoch 065:    808 / 1983 loss=3.281, nll_loss=1.129, word_ins=2.948, length=3.333, ppl=9.72, wps=212957, ups=3.42, wpb=62206.2, bsz=2030.4, num_updates=127700, lr=0.000279837, gnorm=0.966, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:11:00 | INFO | train_inner | epoch 065:    908 / 1983 loss=3.305, nll_loss=1.151, word_ins=2.967, length=3.378, ppl=9.88, wps=214088, ups=3.44, wpb=62222.7, bsz=1893, num_updates=127800, lr=0.000279727, gnorm=0.953, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:11:29 | INFO | train_inner | epoch 065:   1008 / 1983 loss=3.288, nll_loss=1.132, word_ins=2.95, length=3.389, ppl=9.77, wps=210474, ups=3.42, wpb=61571.7, bsz=2044.2, num_updates=127900, lr=0.000279618, gnorm=0.942, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:11:58 | INFO | train_inner | epoch 065:   1108 / 1983 loss=3.339, nll_loss=1.177, word_ins=2.991, length=3.478, ppl=10.12, wps=213095, ups=3.45, wpb=61787.9, bsz=1847.2, num_updates=128000, lr=0.000279508, gnorm=0.993, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:12:27 | INFO | train_inner | epoch 065:   1208 / 1983 loss=3.307, nll_loss=1.15, word_ins=2.966, length=3.412, ppl=9.9, wps=210638, ups=3.42, wpb=61535, bsz=1964.6, num_updates=128100, lr=0.000279399, gnorm=0.995, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:12:57 | INFO | train_inner | epoch 065:   1308 / 1983 loss=3.281, nll_loss=1.127, word_ins=2.945, length=3.352, ppl=9.72, wps=209545, ups=3.4, wpb=61663.1, bsz=2113.4, num_updates=128200, lr=0.00027929, gnorm=0.968, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:13:26 | INFO | train_inner | epoch 065:   1408 / 1983 loss=3.321, nll_loss=1.163, word_ins=2.978, length=3.424, ppl=9.99, wps=210603, ups=3.44, wpb=61235.2, bsz=1963.4, num_updates=128300, lr=0.000279182, gnorm=0.945, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:13:55 | INFO | train_inner | epoch 065:   1508 / 1983 loss=3.317, nll_loss=1.156, word_ins=2.972, length=3.452, ppl=9.96, wps=212026, ups=3.44, wpb=61604.6, bsz=1936.6, num_updates=128400, lr=0.000279073, gnorm=0.953, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:14:24 | INFO | train_inner | epoch 065:   1608 / 1983 loss=3.283, nll_loss=1.131, word_ins=2.949, length=3.34, ppl=9.74, wps=210028, ups=3.42, wpb=61450.8, bsz=2081.9, num_updates=128500, lr=0.000278964, gnorm=0.951, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:14:53 | INFO | train_inner | epoch 065:   1708 / 1983 loss=3.314, nll_loss=1.155, word_ins=2.971, length=3.43, ppl=9.95, wps=211633, ups=3.44, wpb=61511, bsz=2023.7, num_updates=128600, lr=0.000278856, gnorm=0.977, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:15:22 | INFO | train_inner | epoch 065:   1808 / 1983 loss=3.276, nll_loss=1.128, word_ins=2.945, length=3.308, ppl=9.69, wps=211944, ups=3.43, wpb=61827.2, bsz=2100.6, num_updates=128700, lr=0.000278747, gnorm=0.967, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:15:51 | INFO | train_inner | epoch 065:   1908 / 1983 loss=3.302, nll_loss=1.144, word_ins=2.96, length=3.415, ppl=9.86, wps=211957, ups=3.43, wpb=61751.6, bsz=2031.1, num_updates=128800, lr=0.000278639, gnorm=0.939, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 05:16:26 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 3.291 | nll_loss 1.08 | word_ins 2.961 | length 3.296 | ppl 9.79 | wps 121775 | wpb 41551 | bsz 1500 | num_updates 128875 | best_loss 3.271
2023-03-02 05:16:26 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 05:16:31 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint65.pt (epoch 65 @ 128875 updates, score 3.291) (writing took 5.617826557019725 seconds)
2023-03-02 05:16:31 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2023-03-02 05:16:31 | INFO | train | epoch 065 | loss 3.299 | nll_loss 1.144 | word_ins 2.961 | length 3.385 | ppl 9.85 | wps 201692 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 128875 | lr 0.000278558 | gnorm 0.966 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 05:16:31 | INFO | fairseq.trainer | begin training epoch 66
2023-03-02 05:16:49 | INFO | train_inner | epoch 066:     25 / 1983 loss=3.286, nll_loss=1.133, word_ins=2.951, length=3.346, ppl=9.75, wps=107851, ups=1.75, wpb=61572, bsz=2015.6, num_updates=128900, lr=0.000278531, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:17:18 | INFO | train_inner | epoch 066:    125 / 1983 loss=3.276, nll_loss=1.124, word_ins=2.944, length=3.321, ppl=9.68, wps=211878, ups=3.41, wpb=62074.7, bsz=2031.3, num_updates=129000, lr=0.000278423, gnorm=0.946, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:17:47 | INFO | train_inner | epoch 066:    225 / 1983 loss=3.273, nll_loss=1.125, word_ins=2.944, length=3.292, ppl=9.67, wps=212891, ups=3.44, wpb=61972.3, bsz=2055.2, num_updates=129100, lr=0.000278315, gnorm=0.99, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:18:16 | INFO | train_inner | epoch 066:    325 / 1983 loss=3.304, nll_loss=1.144, word_ins=2.961, length=3.428, ppl=9.88, wps=210313, ups=3.42, wpb=61409.8, bsz=1935, num_updates=129200, lr=0.000278207, gnorm=0.939, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:18:46 | INFO | train_inner | epoch 066:    425 / 1983 loss=3.29, nll_loss=1.139, word_ins=2.957, length=3.332, ppl=9.78, wps=209593, ups=3.4, wpb=61677.6, bsz=2018.7, num_updates=129300, lr=0.0002781, gnorm=0.955, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:19:15 | INFO | train_inner | epoch 066:    525 / 1983 loss=3.263, nll_loss=1.106, word_ins=2.927, length=3.359, ppl=9.6, wps=210065, ups=3.43, wpb=61287.2, bsz=2096.6, num_updates=129400, lr=0.000277992, gnorm=0.924, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:19:44 | INFO | train_inner | epoch 066:    625 / 1983 loss=3.274, nll_loss=1.124, word_ins=2.942, length=3.324, ppl=9.68, wps=211539, ups=3.43, wpb=61626.5, bsz=2018.9, num_updates=129500, lr=0.000277885, gnorm=0.97, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:20:13 | INFO | train_inner | epoch 066:    725 / 1983 loss=3.324, nll_loss=1.166, word_ins=2.981, length=3.431, ppl=10.01, wps=212130, ups=3.43, wpb=61852.5, bsz=1935.6, num_updates=129600, lr=0.000277778, gnorm=0.947, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:20:42 | INFO | train_inner | epoch 066:    825 / 1983 loss=3.328, nll_loss=1.171, word_ins=2.985, length=3.428, ppl=10.04, wps=212632, ups=3.45, wpb=61713.7, bsz=1909, num_updates=129700, lr=0.000277671, gnorm=0.975, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:21:11 | INFO | train_inner | epoch 066:    925 / 1983 loss=3.285, nll_loss=1.131, word_ins=2.949, length=3.36, ppl=9.75, wps=209574, ups=3.43, wpb=61106, bsz=2078.6, num_updates=129800, lr=0.000277564, gnorm=0.925, loss_scale=32768, train_wall=29, wall=0
2023-03-02 05:21:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 05:21:41 | INFO | train_inner | epoch 066:   1026 / 1983 loss=3.283, nll_loss=1.132, word_ins=2.949, length=3.338, ppl=9.73, wps=209145, ups=3.4, wpb=61426.7, bsz=2011.2, num_updates=129900, lr=0.000277457, gnorm=0.936, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:22:10 | INFO | train_inner | epoch 066:   1126 / 1983 loss=3.283, nll_loss=1.133, word_ins=2.951, length=3.328, ppl=9.74, wps=211951, ups=3.43, wpb=61765.8, bsz=2028.4, num_updates=130000, lr=0.00027735, gnorm=0.949, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:22:39 | INFO | train_inner | epoch 066:   1226 / 1983 loss=3.3, nll_loss=1.142, word_ins=2.96, length=3.401, ppl=9.85, wps=212010, ups=3.43, wpb=61849.5, bsz=2009, num_updates=130100, lr=0.000277243, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:23:08 | INFO | train_inner | epoch 066:   1326 / 1983 loss=3.319, nll_loss=1.166, word_ins=2.98, length=3.387, ppl=9.98, wps=210968, ups=3.42, wpb=61774.6, bsz=1948, num_updates=130200, lr=0.000277137, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:23:37 | INFO | train_inner | epoch 066:   1426 / 1983 loss=3.318, nll_loss=1.159, word_ins=2.974, length=3.438, ppl=9.97, wps=212417, ups=3.45, wpb=61589.9, bsz=1893.6, num_updates=130300, lr=0.000277031, gnorm=0.965, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:24:06 | INFO | train_inner | epoch 066:   1526 / 1983 loss=3.289, nll_loss=1.136, word_ins=2.954, length=3.354, ppl=9.77, wps=210824, ups=3.42, wpb=61703.2, bsz=1992.1, num_updates=130400, lr=0.000276924, gnorm=0.943, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:24:36 | INFO | train_inner | epoch 066:   1626 / 1983 loss=3.298, nll_loss=1.14, word_ins=2.957, length=3.405, ppl=9.83, wps=211940, ups=3.44, wpb=61645.7, bsz=2052.3, num_updates=130500, lr=0.000276818, gnorm=0.95, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:25:05 | INFO | train_inner | epoch 066:   1726 / 1983 loss=3.314, nll_loss=1.157, word_ins=2.973, length=3.413, ppl=9.94, wps=210777, ups=3.41, wpb=61770.6, bsz=1953, num_updates=130600, lr=0.000276712, gnorm=0.943, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:25:34 | INFO | train_inner | epoch 066:   1826 / 1983 loss=3.317, nll_loss=1.157, word_ins=2.972, length=3.444, ppl=9.96, wps=211887, ups=3.45, wpb=61454.5, bsz=1947.8, num_updates=130700, lr=0.000276606, gnorm=0.944, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:26:03 | INFO | train_inner | epoch 066:   1926 / 1983 loss=3.292, nll_loss=1.134, word_ins=2.952, length=3.403, ppl=9.8, wps=212468, ups=3.45, wpb=61594.5, bsz=1959.5, num_updates=130800, lr=0.000276501, gnorm=0.942, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:26:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 05:26:32 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 3.276 | nll_loss 1.064 | word_ins 2.948 | length 3.286 | ppl 9.69 | wps 84514.3 | wpb 41551 | bsz 1500 | num_updates 130857 | best_loss 3.271
2023-03-02 05:26:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 05:26:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint66.pt (epoch 66 @ 130857 updates, score 3.276) (writing took 5.763715412933379 seconds)
2023-03-02 05:26:38 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2023-03-02 05:26:38 | INFO | train | epoch 066 | loss 3.295 | nll_loss 1.14 | word_ins 2.958 | length 3.376 | ppl 9.82 | wps 201456 | ups 3.27 | wpb 61627.9 | bsz 1997.5 | num_updates 130857 | lr 0.00027644 | gnorm 0.951 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 05:26:38 | INFO | fairseq.trainer | begin training epoch 67
2023-03-02 05:27:00 | INFO | train_inner | epoch 067:     43 / 1983 loss=3.279, nll_loss=1.126, word_ins=2.944, length=3.353, ppl=9.71, wps=107619, ups=1.76, wpb=61255.6, bsz=1984.6, num_updates=130900, lr=0.000276395, gnorm=0.963, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:27:29 | INFO | train_inner | epoch 067:    143 / 1983 loss=3.279, nll_loss=1.125, word_ins=2.944, length=3.352, ppl=9.71, wps=209962, ups=3.43, wpb=61236.4, bsz=2028.4, num_updates=131000, lr=0.000276289, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:27:58 | INFO | train_inner | epoch 067:    243 / 1983 loss=3.284, nll_loss=1.136, word_ins=2.953, length=3.309, ppl=9.74, wps=210840, ups=3.42, wpb=61566, bsz=2023.4, num_updates=131100, lr=0.000276184, gnorm=0.936, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:28:27 | INFO | train_inner | epoch 067:    343 / 1983 loss=3.302, nll_loss=1.14, word_ins=2.957, length=3.448, ppl=9.86, wps=211523, ups=3.44, wpb=61406.6, bsz=1933.8, num_updates=131200, lr=0.000276079, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:28:57 | INFO | train_inner | epoch 067:    443 / 1983 loss=3.265, nll_loss=1.117, word_ins=2.937, length=3.285, ppl=9.61, wps=211669, ups=3.42, wpb=61978.3, bsz=2031, num_updates=131300, lr=0.000275974, gnorm=0.941, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:29:26 | INFO | train_inner | epoch 067:    543 / 1983 loss=3.294, nll_loss=1.139, word_ins=2.957, length=3.366, ppl=9.81, wps=213023, ups=3.43, wpb=62022.6, bsz=1992.6, num_updates=131400, lr=0.000275869, gnorm=0.954, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:29:55 | INFO | train_inner | epoch 067:    643 / 1983 loss=3.312, nll_loss=1.149, word_ins=2.965, length=3.466, ppl=9.93, wps=211233, ups=3.44, wpb=61327.2, bsz=1926.3, num_updates=131500, lr=0.000275764, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:30:24 | INFO | train_inner | epoch 067:    743 / 1983 loss=3.313, nll_loss=1.158, word_ins=2.973, length=3.401, ppl=9.94, wps=212012, ups=3.42, wpb=61934.3, bsz=1965.5, num_updates=131600, lr=0.000275659, gnorm=0.942, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:30:53 | INFO | train_inner | epoch 067:    843 / 1983 loss=3.28, nll_loss=1.129, word_ins=2.947, length=3.333, ppl=9.71, wps=211666, ups=3.43, wpb=61699.6, bsz=2052.1, num_updates=131700, lr=0.000275554, gnorm=0.93, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:31:22 | INFO | train_inner | epoch 067:    943 / 1983 loss=3.26, nll_loss=1.112, word_ins=2.931, length=3.286, ppl=9.58, wps=212669, ups=3.42, wpb=62097.8, bsz=2055.8, num_updates=131800, lr=0.00027545, gnorm=0.939, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:31:52 | INFO | train_inner | epoch 067:   1043 / 1983 loss=3.273, nll_loss=1.121, word_ins=2.94, length=3.331, ppl=9.67, wps=209767, ups=3.4, wpb=61672.8, bsz=2077.2, num_updates=131900, lr=0.000275345, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:32:21 | INFO | train_inner | epoch 067:   1143 / 1983 loss=3.284, nll_loss=1.131, word_ins=2.949, length=3.349, ppl=9.74, wps=210985, ups=3.43, wpb=61526, bsz=2004.7, num_updates=132000, lr=0.000275241, gnorm=0.939, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:32:50 | INFO | train_inner | epoch 067:   1243 / 1983 loss=3.273, nll_loss=1.118, word_ins=2.937, length=3.359, ppl=9.66, wps=212663, ups=3.43, wpb=62000.5, bsz=2026.6, num_updates=132100, lr=0.000275137, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:33:19 | INFO | train_inner | epoch 067:   1343 / 1983 loss=3.308, nll_loss=1.152, word_ins=2.968, length=3.397, ppl=9.9, wps=212355, ups=3.42, wpb=62104.5, bsz=1976.8, num_updates=132200, lr=0.000275033, gnorm=0.942, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:33:49 | INFO | train_inner | epoch 067:   1443 / 1983 loss=3.285, nll_loss=1.129, word_ins=2.947, length=3.377, ppl=9.75, wps=209146, ups=3.41, wpb=61382.8, bsz=2094.1, num_updates=132300, lr=0.000274929, gnorm=0.929, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:34:18 | INFO | train_inner | epoch 067:   1543 / 1983 loss=3.326, nll_loss=1.167, word_ins=2.982, length=3.44, ppl=10.03, wps=211666, ups=3.45, wpb=61432.6, bsz=1898, num_updates=132400, lr=0.000274825, gnorm=0.969, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:34:47 | INFO | train_inner | epoch 067:   1643 / 1983 loss=3.283, nll_loss=1.13, word_ins=2.947, length=3.361, ppl=9.74, wps=210930, ups=3.43, wpb=61483.1, bsz=2024.4, num_updates=132500, lr=0.000274721, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:35:16 | INFO | train_inner | epoch 067:   1743 / 1983 loss=3.307, nll_loss=1.149, word_ins=2.965, length=3.416, ppl=9.89, wps=210048, ups=3.44, wpb=61069, bsz=1937.9, num_updates=132600, lr=0.000274618, gnorm=0.948, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:35:45 | INFO | train_inner | epoch 067:   1843 / 1983 loss=3.323, nll_loss=1.166, word_ins=2.98, length=3.426, ppl=10.01, wps=210578, ups=3.43, wpb=61338.2, bsz=1947.4, num_updates=132700, lr=0.000274514, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:36:14 | INFO | train_inner | epoch 067:   1943 / 1983 loss=3.306, nll_loss=1.152, word_ins=2.968, length=3.385, ppl=9.89, wps=209885, ups=3.41, wpb=61561.1, bsz=1986.7, num_updates=132800, lr=0.000274411, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 05:36:39 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 3.279 | nll_loss 1.065 | word_ins 2.952 | length 3.261 | ppl 9.71 | wps 96250.6 | wpb 41551 | bsz 1500 | num_updates 132840 | best_loss 3.271
2023-03-02 05:36:39 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 05:36:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint67.pt (epoch 67 @ 132840 updates, score 3.279) (writing took 5.627212341991253 seconds)
2023-03-02 05:36:45 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2023-03-02 05:36:45 | INFO | train | epoch 067 | loss 3.291 | nll_loss 1.137 | word_ins 2.954 | length 3.369 | ppl 9.79 | wps 201288 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 132840 | lr 0.000274369 | gnorm 0.936 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 05:36:45 | INFO | fairseq.trainer | begin training epoch 68
2023-03-02 05:37:12 | INFO | train_inner | epoch 068:     60 / 1983 loss=3.276, nll_loss=1.126, word_ins=2.945, length=3.316, ppl=9.69, wps=106575, ups=1.73, wpb=61685.2, bsz=1974.7, num_updates=132900, lr=0.000274307, gnorm=0.93, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:37:41 | INFO | train_inner | epoch 068:    160 / 1983 loss=3.286, nll_loss=1.125, word_ins=2.944, length=3.423, ppl=9.76, wps=209707, ups=3.43, wpb=61106, bsz=1922.6, num_updates=133000, lr=0.000274204, gnorm=0.947, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:38:11 | INFO | train_inner | epoch 068:    260 / 1983 loss=3.247, nll_loss=1.099, word_ins=2.92, length=3.268, ppl=9.49, wps=212889, ups=3.42, wpb=62185.5, bsz=2091.9, num_updates=133100, lr=0.000274101, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:38:40 | INFO | train_inner | epoch 068:    360 / 1983 loss=3.298, nll_loss=1.144, word_ins=2.961, length=3.37, ppl=9.83, wps=210796, ups=3.41, wpb=61887, bsz=1945.1, num_updates=133200, lr=0.000273998, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:39:09 | INFO | train_inner | epoch 068:    460 / 1983 loss=3.278, nll_loss=1.128, word_ins=2.946, length=3.319, ppl=9.7, wps=210493, ups=3.41, wpb=61718.4, bsz=2041.8, num_updates=133300, lr=0.000273896, gnorm=0.967, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:39:38 | INFO | train_inner | epoch 068:    560 / 1983 loss=3.276, nll_loss=1.124, word_ins=2.943, length=3.329, ppl=9.68, wps=213189, ups=3.43, wpb=62081.5, bsz=2003, num_updates=133400, lr=0.000273793, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:40:07 | INFO | train_inner | epoch 068:    660 / 1983 loss=3.294, nll_loss=1.145, word_ins=2.961, length=3.331, ppl=9.81, wps=211028, ups=3.44, wpb=61434.1, bsz=1994.8, num_updates=133500, lr=0.00027369, gnorm=0.936, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:40:37 | INFO | train_inner | epoch 068:    760 / 1983 loss=3.272, nll_loss=1.118, word_ins=2.937, length=3.352, ppl=9.66, wps=212548, ups=3.43, wpb=61944.2, bsz=1983.6, num_updates=133600, lr=0.000273588, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:41:06 | INFO | train_inner | epoch 068:    860 / 1983 loss=3.276, nll_loss=1.129, word_ins=2.947, length=3.292, ppl=9.69, wps=210676, ups=3.42, wpb=61662.6, bsz=2143.1, num_updates=133700, lr=0.000273485, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:41:35 | INFO | train_inner | epoch 068:    960 / 1983 loss=3.26, nll_loss=1.109, word_ins=2.929, length=3.31, ppl=9.58, wps=210418, ups=3.42, wpb=61519, bsz=2125, num_updates=133800, lr=0.000273383, gnorm=0.923, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:42:04 | INFO | train_inner | epoch 068:   1060 / 1983 loss=3.316, nll_loss=1.154, word_ins=2.97, length=3.461, ppl=9.96, wps=210838, ups=3.43, wpb=61553.8, bsz=1998.8, num_updates=133900, lr=0.000273281, gnorm=0.921, loss_scale=32768, train_wall=29, wall=0
2023-03-02 05:42:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 05:42:34 | INFO | train_inner | epoch 068:   1161 / 1983 loss=3.318, nll_loss=1.158, word_ins=2.974, length=3.448, ppl=9.98, wps=208631, ups=3.41, wpb=61256.7, bsz=1890.6, num_updates=134000, lr=0.000273179, gnorm=0.945, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:43:03 | INFO | train_inner | epoch 068:   1261 / 1983 loss=3.276, nll_loss=1.121, word_ins=2.939, length=3.37, ppl=9.69, wps=212618, ups=3.43, wpb=62003.8, bsz=2022.2, num_updates=134100, lr=0.000273077, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:43:32 | INFO | train_inner | epoch 068:   1361 / 1983 loss=3.285, nll_loss=1.128, word_ins=2.946, length=3.395, ppl=9.75, wps=211544, ups=3.44, wpb=61538, bsz=1971, num_updates=134200, lr=0.000272976, gnorm=0.914, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:44:01 | INFO | train_inner | epoch 068:   1461 / 1983 loss=3.308, nll_loss=1.152, word_ins=2.968, length=3.398, ppl=9.9, wps=210947, ups=3.43, wpb=61546.3, bsz=1938.2, num_updates=134300, lr=0.000272874, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:44:30 | INFO | train_inner | epoch 068:   1561 / 1983 loss=3.282, nll_loss=1.129, word_ins=2.947, length=3.357, ppl=9.73, wps=210892, ups=3.42, wpb=61609.9, bsz=2042.6, num_updates=134400, lr=0.000272772, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:44:59 | INFO | train_inner | epoch 068:   1661 / 1983 loss=3.301, nll_loss=1.148, word_ins=2.964, length=3.371, ppl=9.86, wps=212576, ups=3.44, wpb=61880.8, bsz=1964, num_updates=134500, lr=0.000272671, gnorm=0.929, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:45:29 | INFO | train_inner | epoch 068:   1761 / 1983 loss=3.282, nll_loss=1.132, word_ins=2.949, length=3.328, ppl=9.73, wps=209573, ups=3.42, wpb=61224.7, bsz=2057.7, num_updates=134600, lr=0.00027257, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:45:58 | INFO | train_inner | epoch 068:   1861 / 1983 loss=3.287, nll_loss=1.129, word_ins=2.947, length=3.402, ppl=9.76, wps=211828, ups=3.44, wpb=61534.5, bsz=2020.9, num_updates=134700, lr=0.000272468, gnorm=0.917, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:46:27 | INFO | train_inner | epoch 068:   1961 / 1983 loss=3.299, nll_loss=1.143, word_ins=2.959, length=3.398, ppl=9.84, wps=211809, ups=3.44, wpb=61644.5, bsz=1906.6, num_updates=134800, lr=0.000272367, gnorm=0.922, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 05:46:46 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 3.259 | nll_loss 1.047 | word_ins 2.929 | length 3.293 | ppl 9.57 | wps 107932 | wpb 41551 | bsz 1500 | num_updates 134822 | best_loss 3.259
2023-03-02 05:46:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 05:46:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint68.pt (epoch 68 @ 134822 updates, score 3.259) (writing took 8.314002186991274 seconds)
2023-03-02 05:46:54 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2023-03-02 05:46:54 | INFO | train | epoch 068 | loss 3.288 | nll_loss 1.133 | word_ins 2.951 | length 3.368 | ppl 9.76 | wps 200502 | ups 3.25 | wpb 61627.4 | bsz 1997.7 | num_updates 134822 | lr 0.000272345 | gnorm 0.925 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 05:46:54 | INFO | fairseq.trainer | begin training epoch 69
2023-03-02 05:47:26 | INFO | train_inner | epoch 069:     78 / 1983 loss=3.311, nll_loss=1.15, word_ins=2.967, length=3.442, ppl=9.92, wps=102152, ups=1.68, wpb=60775.9, bsz=1926.4, num_updates=134900, lr=0.000272266, gnorm=0.974, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:47:56 | INFO | train_inner | epoch 069:    178 / 1983 loss=3.26, nll_loss=1.111, word_ins=2.931, length=3.289, ppl=9.58, wps=212328, ups=3.41, wpb=62252.7, bsz=2009.8, num_updates=135000, lr=0.000272166, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:48:25 | INFO | train_inner | epoch 069:    278 / 1983 loss=3.275, nll_loss=1.12, word_ins=2.939, length=3.36, ppl=9.68, wps=213104, ups=3.44, wpb=62023.5, bsz=1935.4, num_updates=135100, lr=0.000272065, gnorm=0.933, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:48:54 | INFO | train_inner | epoch 069:    378 / 1983 loss=3.245, nll_loss=1.096, word_ins=2.917, length=3.273, ppl=9.48, wps=213180, ups=3.44, wpb=61933.2, bsz=2088.4, num_updates=135200, lr=0.000271964, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:49:23 | INFO | train_inner | epoch 069:    478 / 1983 loss=3.259, nll_loss=1.11, word_ins=2.93, length=3.297, ppl=9.58, wps=213837, ups=3.44, wpb=62196.5, bsz=2004.7, num_updates=135300, lr=0.000271864, gnorm=0.926, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:49:52 | INFO | train_inner | epoch 069:    578 / 1983 loss=3.302, nll_loss=1.141, word_ins=2.958, length=3.437, ppl=9.86, wps=212316, ups=3.44, wpb=61653.4, bsz=1874.6, num_updates=135400, lr=0.000271763, gnorm=0.914, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:50:21 | INFO | train_inner | epoch 069:    678 / 1983 loss=3.294, nll_loss=1.137, word_ins=2.954, length=3.398, ppl=9.81, wps=208545, ups=3.41, wpb=61132.6, bsz=2039, num_updates=135500, lr=0.000271663, gnorm=0.9, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:50:50 | INFO | train_inner | epoch 069:    778 / 1983 loss=3.316, nll_loss=1.156, word_ins=2.971, length=3.443, ppl=9.96, wps=210383, ups=3.44, wpb=61152.8, bsz=1932.1, num_updates=135600, lr=0.000271563, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:51:19 | INFO | train_inner | epoch 069:    878 / 1983 loss=3.278, nll_loss=1.124, word_ins=2.942, length=3.358, ppl=9.7, wps=211729, ups=3.43, wpb=61686.3, bsz=1996, num_updates=135700, lr=0.000271463, gnorm=0.916, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:51:49 | INFO | train_inner | epoch 069:    978 / 1983 loss=3.271, nll_loss=1.118, word_ins=2.937, length=3.346, ppl=9.65, wps=211483, ups=3.42, wpb=61780.3, bsz=1989, num_updates=135800, lr=0.000271363, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:52:18 | INFO | train_inner | epoch 069:   1078 / 1983 loss=3.27, nll_loss=1.114, word_ins=2.933, length=3.37, ppl=9.65, wps=211003, ups=3.42, wpb=61723.5, bsz=2090.8, num_updates=135900, lr=0.000271263, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:52:47 | INFO | train_inner | epoch 069:   1178 / 1983 loss=3.28, nll_loss=1.123, word_ins=2.942, length=3.383, ppl=9.71, wps=210497, ups=3.44, wpb=61235.9, bsz=2069.9, num_updates=136000, lr=0.000271163, gnorm=0.904, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:53:16 | INFO | train_inner | epoch 069:   1278 / 1983 loss=3.307, nll_loss=1.149, word_ins=2.965, length=3.42, ppl=9.9, wps=208292, ups=3.41, wpb=61007.6, bsz=2025.7, num_updates=136100, lr=0.000271063, gnorm=0.921, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:53:46 | INFO | train_inner | epoch 069:   1378 / 1983 loss=3.285, nll_loss=1.133, word_ins=2.95, length=3.348, ppl=9.75, wps=212753, ups=3.42, wpb=62188.8, bsz=1991.9, num_updates=136200, lr=0.000270964, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:54:15 | INFO | train_inner | epoch 069:   1478 / 1983 loss=3.293, nll_loss=1.138, word_ins=2.955, length=3.379, ppl=9.8, wps=212478, ups=3.45, wpb=61618.1, bsz=1963.5, num_updates=136300, lr=0.000270864, gnorm=0.923, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:54:44 | INFO | train_inner | epoch 069:   1578 / 1983 loss=3.29, nll_loss=1.135, word_ins=2.952, length=3.375, ppl=9.78, wps=210840, ups=3.42, wpb=61701.9, bsz=2104.6, num_updates=136400, lr=0.000270765, gnorm=0.913, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:55:13 | INFO | train_inner | epoch 069:   1678 / 1983 loss=3.266, nll_loss=1.115, word_ins=2.935, length=3.315, ppl=9.62, wps=212217, ups=3.44, wpb=61730.2, bsz=1988.8, num_updates=136500, lr=0.000270666, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:55:42 | INFO | train_inner | epoch 069:   1778 / 1983 loss=3.298, nll_loss=1.15, word_ins=2.966, length=3.327, ppl=9.84, wps=212125, ups=3.44, wpb=61725.8, bsz=1946.8, num_updates=136600, lr=0.000270567, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:56:11 | INFO | train_inner | epoch 069:   1878 / 1983 loss=3.282, nll_loss=1.128, word_ins=2.946, length=3.364, ppl=9.73, wps=211643, ups=3.43, wpb=61751.9, bsz=2002.6, num_updates=136700, lr=0.000270468, gnorm=0.904, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:56:40 | INFO | train_inner | epoch 069:   1978 / 1983 loss=3.311, nll_loss=1.15, word_ins=2.966, length=3.448, ppl=9.92, wps=211168, ups=3.44, wpb=61422.2, bsz=1925.5, num_updates=136800, lr=0.000270369, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 05:56:54 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 3.286 | nll_loss 1.066 | word_ins 2.955 | length 3.301 | ppl 9.75 | wps 101686 | wpb 41551 | bsz 1500 | num_updates 136805 | best_loss 3.259
2023-03-02 05:56:54 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 05:57:00 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint69.pt (epoch 69 @ 136805 updates, score 3.286) (writing took 5.4362902760040015 seconds)
2023-03-02 05:57:00 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2023-03-02 05:57:00 | INFO | train | epoch 069 | loss 3.284 | nll_loss 1.129 | word_ins 2.947 | length 3.366 | ppl 9.74 | wps 201686 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 136805 | lr 0.000270364 | gnorm 0.911 | loss_scale 16384 | train_wall 575 | wall 0
2023-03-02 05:57:00 | INFO | fairseq.trainer | begin training epoch 70
2023-03-02 05:57:37 | INFO | train_inner | epoch 070:     95 / 1983 loss=3.295, nll_loss=1.139, word_ins=2.956, length=3.386, ppl=9.81, wps=107355, ups=1.75, wpb=61278.1, bsz=1842.1, num_updates=136900, lr=0.00027027, gnorm=0.917, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:58:07 | INFO | train_inner | epoch 070:    195 / 1983 loss=3.276, nll_loss=1.124, word_ins=2.943, length=3.333, ppl=9.69, wps=209526, ups=3.41, wpb=61368.9, bsz=2008.2, num_updates=137000, lr=0.000270172, gnorm=0.929, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:58:36 | INFO | train_inner | epoch 070:    295 / 1983 loss=3.265, nll_loss=1.116, word_ins=2.935, length=3.304, ppl=9.61, wps=211849, ups=3.42, wpb=61937.3, bsz=2024.3, num_updates=137100, lr=0.000270073, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:59:05 | INFO | train_inner | epoch 070:    395 / 1983 loss=3.284, nll_loss=1.126, word_ins=2.945, length=3.399, ppl=9.74, wps=210737, ups=3.44, wpb=61295.5, bsz=1974.1, num_updates=137200, lr=0.000269975, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-02 05:59:34 | INFO | train_inner | epoch 070:    495 / 1983 loss=3.301, nll_loss=1.144, word_ins=2.961, length=3.396, ppl=9.85, wps=210092, ups=3.43, wpb=61308.5, bsz=1939.8, num_updates=137300, lr=0.000269876, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:00:03 | INFO | train_inner | epoch 070:    595 / 1983 loss=3.284, nll_loss=1.127, word_ins=2.946, length=3.379, ppl=9.74, wps=211793, ups=3.42, wpb=61971.5, bsz=1997.5, num_updates=137400, lr=0.000269778, gnorm=0.919, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:00:33 | INFO | train_inner | epoch 070:    695 / 1983 loss=3.273, nll_loss=1.121, word_ins=2.94, length=3.331, ppl=9.66, wps=212249, ups=3.42, wpb=61988, bsz=1948.1, num_updates=137500, lr=0.00026968, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:01:02 | INFO | train_inner | epoch 070:    795 / 1983 loss=3.276, nll_loss=1.123, word_ins=2.941, length=3.357, ppl=9.69, wps=210508, ups=3.43, wpb=61346.5, bsz=2000.8, num_updates=137600, lr=0.000269582, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:01:31 | INFO | train_inner | epoch 070:    895 / 1983 loss=3.292, nll_loss=1.133, word_ins=2.951, length=3.415, ppl=9.8, wps=210619, ups=3.43, wpb=61349.4, bsz=2001, num_updates=137700, lr=0.000269484, gnorm=0.906, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:02:00 | INFO | train_inner | epoch 070:    995 / 1983 loss=3.289, nll_loss=1.134, word_ins=2.951, length=3.373, ppl=9.77, wps=210715, ups=3.43, wpb=61368.3, bsz=2007.2, num_updates=137800, lr=0.000269386, gnorm=0.907, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:02:29 | INFO | train_inner | epoch 070:   1095 / 1983 loss=3.289, nll_loss=1.13, word_ins=2.948, length=3.415, ppl=9.78, wps=212008, ups=3.44, wpb=61648.6, bsz=1990.9, num_updates=137900, lr=0.000269289, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:02:58 | INFO | train_inner | epoch 070:   1195 / 1983 loss=3.266, nll_loss=1.108, word_ins=2.928, length=3.378, ppl=9.62, wps=210968, ups=3.43, wpb=61429.3, bsz=2033.4, num_updates=138000, lr=0.000269191, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:03:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 06:03:28 | INFO | train_inner | epoch 070:   1296 / 1983 loss=3.287, nll_loss=1.137, word_ins=2.954, length=3.326, ppl=9.76, wps=210376, ups=3.39, wpb=62073.1, bsz=2044.6, num_updates=138100, lr=0.000269093, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:03:57 | INFO | train_inner | epoch 070:   1396 / 1983 loss=3.278, nll_loss=1.128, word_ins=2.946, length=3.323, ppl=9.7, wps=210900, ups=3.41, wpb=61783, bsz=2066.7, num_updates=138200, lr=0.000268996, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:04:26 | INFO | train_inner | epoch 070:   1496 / 1983 loss=3.257, nll_loss=1.106, word_ins=2.926, length=3.316, ppl=9.56, wps=212932, ups=3.42, wpb=62176.1, bsz=2050.6, num_updates=138300, lr=0.000268899, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:04:55 | INFO | train_inner | epoch 070:   1596 / 1983 loss=3.279, nll_loss=1.125, word_ins=2.943, length=3.361, ppl=9.71, wps=210513, ups=3.43, wpb=61348.9, bsz=2055.6, num_updates=138400, lr=0.000268802, gnorm=0.892, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:05:25 | INFO | train_inner | epoch 070:   1696 / 1983 loss=3.303, nll_loss=1.146, word_ins=2.962, length=3.41, ppl=9.87, wps=211483, ups=3.42, wpb=61839.6, bsz=1959.9, num_updates=138500, lr=0.000268705, gnorm=0.923, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:05:54 | INFO | train_inner | epoch 070:   1796 / 1983 loss=3.278, nll_loss=1.124, word_ins=2.942, length=3.356, ppl=9.7, wps=210901, ups=3.43, wpb=61416.8, bsz=2039.9, num_updates=138600, lr=0.000268608, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:06:23 | INFO | train_inner | epoch 070:   1896 / 1983 loss=3.286, nll_loss=1.131, word_ins=2.948, length=3.382, ppl=9.76, wps=213053, ups=3.45, wpb=61715.1, bsz=1956, num_updates=138700, lr=0.000268511, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 06:07:00 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 3.261 | nll_loss 1.054 | word_ins 2.94 | length 3.215 | ppl 9.59 | wps 92470 | wpb 41551 | bsz 1500 | num_updates 138787 | best_loss 3.259
2023-03-02 06:07:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 06:07:05 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint70.pt (epoch 70 @ 138787 updates, score 3.261) (writing took 5.370844746008515 seconds)
2023-03-02 06:07:05 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2023-03-02 06:07:05 | INFO | train | epoch 070 | loss 3.282 | nll_loss 1.128 | word_ins 2.945 | length 3.365 | ppl 9.73 | wps 201751 | ups 3.27 | wpb 61626.9 | bsz 1997.2 | num_updates 138787 | lr 0.000268427 | gnorm 0.903 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 06:07:05 | INFO | fairseq.trainer | begin training epoch 71
2023-03-02 06:07:19 | INFO | train_inner | epoch 071:     13 / 1983 loss=3.28, nll_loss=1.128, word_ins=2.945, length=3.346, ppl=9.71, wps=109389, ups=1.78, wpb=61505.1, bsz=2022.6, num_updates=138800, lr=0.000268414, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:07:48 | INFO | train_inner | epoch 071:    113 / 1983 loss=3.289, nll_loss=1.126, word_ins=2.944, length=3.449, ppl=9.78, wps=211049, ups=3.44, wpb=61373.7, bsz=1909.9, num_updates=138900, lr=0.000268317, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:08:17 | INFO | train_inner | epoch 071:    213 / 1983 loss=3.263, nll_loss=1.11, word_ins=2.93, length=3.328, ppl=9.6, wps=210369, ups=3.43, wpb=61420.7, bsz=2081.2, num_updates=139000, lr=0.000268221, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:08:46 | INFO | train_inner | epoch 071:    313 / 1983 loss=3.264, nll_loss=1.109, word_ins=2.928, length=3.357, ppl=9.61, wps=212163, ups=3.45, wpb=61431, bsz=1947.9, num_updates=139100, lr=0.000268124, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:09:16 | INFO | train_inner | epoch 071:    413 / 1983 loss=3.246, nll_loss=1.1, word_ins=2.921, length=3.252, ppl=9.49, wps=211346, ups=3.42, wpb=61840.1, bsz=2044, num_updates=139200, lr=0.000268028, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:09:45 | INFO | train_inner | epoch 071:    513 / 1983 loss=3.271, nll_loss=1.116, word_ins=2.934, length=3.37, ppl=9.66, wps=214023, ups=3.45, wpb=62067.8, bsz=1977.4, num_updates=139300, lr=0.000267932, gnorm=0.914, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:10:14 | INFO | train_inner | epoch 071:    613 / 1983 loss=3.283, nll_loss=1.134, word_ins=2.951, length=3.323, ppl=9.74, wps=211855, ups=3.41, wpb=62071.7, bsz=2008.3, num_updates=139400, lr=0.000267836, gnorm=0.935, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:10:43 | INFO | train_inner | epoch 071:    713 / 1983 loss=3.277, nll_loss=1.128, word_ins=2.946, length=3.309, ppl=9.69, wps=210582, ups=3.42, wpb=61564.5, bsz=2024.2, num_updates=139500, lr=0.00026774, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:11:12 | INFO | train_inner | epoch 071:    813 / 1983 loss=3.259, nll_loss=1.109, word_ins=2.928, length=3.307, ppl=9.57, wps=210190, ups=3.42, wpb=61478.4, bsz=2079.3, num_updates=139600, lr=0.000267644, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:11:41 | INFO | train_inner | epoch 071:    913 / 1983 loss=3.261, nll_loss=1.109, word_ins=2.928, length=3.326, ppl=9.59, wps=212191, ups=3.44, wpb=61743.5, bsz=2051.5, num_updates=139700, lr=0.000267548, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:12:10 | INFO | train_inner | epoch 071:   1013 / 1983 loss=3.265, nll_loss=1.109, word_ins=2.929, length=3.36, ppl=9.61, wps=212909, ups=3.44, wpb=61864.2, bsz=2018.6, num_updates=139800, lr=0.000267452, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:12:40 | INFO | train_inner | epoch 071:   1113 / 1983 loss=3.267, nll_loss=1.117, word_ins=2.935, length=3.315, ppl=9.63, wps=213303, ups=3.43, wpb=62162.2, bsz=2029, num_updates=139900, lr=0.000267357, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:13:09 | INFO | train_inner | epoch 071:   1213 / 1983 loss=3.304, nll_loss=1.148, word_ins=2.964, length=3.405, ppl=9.88, wps=212605, ups=3.43, wpb=62008, bsz=1932.9, num_updates=140000, lr=0.000267261, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:13:38 | INFO | train_inner | epoch 071:   1313 / 1983 loss=3.31, nll_loss=1.149, word_ins=2.965, length=3.447, ppl=9.92, wps=210384, ups=3.44, wpb=61192, bsz=1909.4, num_updates=140100, lr=0.000267166, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:14:07 | INFO | train_inner | epoch 071:   1413 / 1983 loss=3.281, nll_loss=1.128, word_ins=2.945, length=3.356, ppl=9.72, wps=212116, ups=3.44, wpb=61739.7, bsz=1992.9, num_updates=140200, lr=0.000267071, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:14:36 | INFO | train_inner | epoch 071:   1513 / 1983 loss=3.238, nll_loss=1.087, word_ins=2.908, length=3.3, ppl=9.44, wps=211507, ups=3.42, wpb=61899.2, bsz=2124.5, num_updates=140300, lr=0.000266975, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:15:05 | INFO | train_inner | epoch 071:   1613 / 1983 loss=3.294, nll_loss=1.138, word_ins=2.955, length=3.398, ppl=9.81, wps=211372, ups=3.43, wpb=61676, bsz=1937.3, num_updates=140400, lr=0.00026688, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:15:34 | INFO | train_inner | epoch 071:   1713 / 1983 loss=3.258, nll_loss=1.104, word_ins=2.923, length=3.349, ppl=9.57, wps=212945, ups=3.45, wpb=61766.9, bsz=2034, num_updates=140500, lr=0.000266785, gnorm=0.892, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:16:03 | INFO | train_inner | epoch 071:   1813 / 1983 loss=3.321, nll_loss=1.163, word_ins=2.978, length=3.435, ppl=10, wps=210162, ups=3.44, wpb=61012.8, bsz=1887.2, num_updates=140600, lr=0.00026669, gnorm=0.928, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:16:33 | INFO | train_inner | epoch 071:   1913 / 1983 loss=3.282, nll_loss=1.126, word_ins=2.944, length=3.384, ppl=9.73, wps=209259, ups=3.43, wpb=60953.7, bsz=2038.6, num_updates=140700, lr=0.000266596, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 06:17:06 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 3.277 | nll_loss 1.049 | word_ins 2.934 | length 3.43 | ppl 9.69 | wps 111368 | wpb 41551 | bsz 1500 | num_updates 140770 | best_loss 3.259
2023-03-02 06:17:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 06:17:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint71.pt (epoch 71 @ 140770 updates, score 3.277) (writing took 5.537727789953351 seconds)
2023-03-02 06:17:11 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2023-03-02 06:17:11 | INFO | train | epoch 071 | loss 3.277 | nll_loss 1.123 | word_ins 2.942 | length 3.358 | ppl 9.7 | wps 201664 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 140770 | lr 0.000266529 | gnorm 0.897 | loss_scale 16384 | train_wall 575 | wall 0
2023-03-02 06:17:11 | INFO | fairseq.trainer | begin training epoch 72
2023-03-02 06:17:30 | INFO | train_inner | epoch 072:     30 / 1983 loss=3.336, nll_loss=1.174, word_ins=2.988, length=3.483, ppl=10.1, wps=105451, ups=1.73, wpb=60838.1, bsz=1829.3, num_updates=140800, lr=0.000266501, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:17:59 | INFO | train_inner | epoch 072:    130 / 1983 loss=3.258, nll_loss=1.106, word_ins=2.926, length=3.319, ppl=9.56, wps=210920, ups=3.44, wpb=61354, bsz=1967.4, num_updates=140900, lr=0.000266406, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:18:28 | INFO | train_inner | epoch 072:    230 / 1983 loss=3.238, nll_loss=1.084, word_ins=2.906, length=3.32, ppl=9.43, wps=209320, ups=3.44, wpb=60906.4, bsz=2077.8, num_updates=141000, lr=0.000266312, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:18:58 | INFO | train_inner | epoch 072:    330 / 1983 loss=3.251, nll_loss=1.103, word_ins=2.923, length=3.277, ppl=9.52, wps=211200, ups=3.42, wpb=61828.2, bsz=2043.4, num_updates=141100, lr=0.000266217, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:19:27 | INFO | train_inner | epoch 072:    430 / 1983 loss=3.296, nll_loss=1.138, word_ins=2.956, length=3.404, ppl=9.82, wps=210434, ups=3.43, wpb=61297, bsz=1902.5, num_updates=141200, lr=0.000266123, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:19:56 | INFO | train_inner | epoch 072:    530 / 1983 loss=3.269, nll_loss=1.115, word_ins=2.934, length=3.352, ppl=9.64, wps=212305, ups=3.42, wpb=62138.3, bsz=1990, num_updates=141300, lr=0.000266029, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:20:25 | INFO | train_inner | epoch 072:    630 / 1983 loss=3.296, nll_loss=1.137, word_ins=2.954, length=3.419, ppl=9.82, wps=209898, ups=3.42, wpb=61336.1, bsz=1931.4, num_updates=141400, lr=0.000265935, gnorm=0.912, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:20:55 | INFO | train_inner | epoch 072:    730 / 1983 loss=3.276, nll_loss=1.122, word_ins=2.94, length=3.355, ppl=9.68, wps=211906, ups=3.43, wpb=61748.1, bsz=1971.2, num_updates=141500, lr=0.000265841, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:21:24 | INFO | train_inner | epoch 072:    830 / 1983 loss=3.272, nll_loss=1.116, word_ins=2.934, length=3.371, ppl=9.66, wps=211342, ups=3.4, wpb=62096.9, bsz=2075.8, num_updates=141600, lr=0.000265747, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:21:53 | INFO | train_inner | epoch 072:    930 / 1983 loss=3.285, nll_loss=1.129, word_ins=2.946, length=3.394, ppl=9.75, wps=212077, ups=3.43, wpb=61891.1, bsz=1960.2, num_updates=141700, lr=0.000265653, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:22:22 | INFO | train_inner | epoch 072:   1030 / 1983 loss=3.256, nll_loss=1.106, word_ins=2.926, length=3.301, ppl=9.55, wps=213085, ups=3.43, wpb=62140, bsz=2040.6, num_updates=141800, lr=0.00026556, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:22:51 | INFO | train_inner | epoch 072:   1130 / 1983 loss=3.294, nll_loss=1.142, word_ins=2.958, length=3.358, ppl=9.81, wps=212534, ups=3.43, wpb=61900.7, bsz=1997.3, num_updates=141900, lr=0.000265466, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:23:21 | INFO | train_inner | epoch 072:   1230 / 1983 loss=3.288, nll_loss=1.134, word_ins=2.951, length=3.362, ppl=9.76, wps=208884, ups=3.41, wpb=61286.8, bsz=2022.3, num_updates=142000, lr=0.000265372, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:23:50 | INFO | train_inner | epoch 072:   1330 / 1983 loss=3.235, nll_loss=1.086, word_ins=2.906, length=3.283, ppl=9.41, wps=211630, ups=3.43, wpb=61624.5, bsz=2102, num_updates=142100, lr=0.000265279, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:23:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 06:24:19 | INFO | train_inner | epoch 072:   1431 / 1983 loss=3.282, nll_loss=1.125, word_ins=2.942, length=3.397, ppl=9.73, wps=209179, ups=3.38, wpb=61816.1, bsz=1973.9, num_updates=142200, lr=0.000265186, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:24:49 | INFO | train_inner | epoch 072:   1531 / 1983 loss=3.29, nll_loss=1.139, word_ins=2.955, length=3.348, ppl=9.78, wps=212286, ups=3.43, wpb=61929.1, bsz=1964.3, num_updates=142300, lr=0.000265093, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:25:18 | INFO | train_inner | epoch 072:   1631 / 1983 loss=3.283, nll_loss=1.13, word_ins=2.947, length=3.352, ppl=9.73, wps=212223, ups=3.44, wpb=61707.1, bsz=1983, num_updates=142400, lr=0.000264999, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:25:47 | INFO | train_inner | epoch 072:   1731 / 1983 loss=3.271, nll_loss=1.12, word_ins=2.938, length=3.329, ppl=9.65, wps=210635, ups=3.42, wpb=61564, bsz=2039.9, num_updates=142500, lr=0.000264906, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:26:16 | INFO | train_inner | epoch 072:   1831 / 1983 loss=3.297, nll_loss=1.14, word_ins=2.956, length=3.413, ppl=9.83, wps=210800, ups=3.41, wpb=61731, bsz=1989.1, num_updates=142600, lr=0.000264814, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:26:45 | INFO | train_inner | epoch 072:   1931 / 1983 loss=3.276, nll_loss=1.116, word_ins=2.934, length=3.417, ppl=9.68, wps=211220, ups=3.44, wpb=61407.8, bsz=1977.8, num_updates=142700, lr=0.000264721, gnorm=0.909, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:27:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 06:27:13 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 3.284 | nll_loss 1.066 | word_ins 2.949 | length 3.345 | ppl 9.74 | wps 101686 | wpb 41551 | bsz 1500 | num_updates 142752 | best_loss 3.259
2023-03-02 06:27:13 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 06:27:19 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint72.pt (epoch 72 @ 142752 updates, score 3.284) (writing took 5.436805109027773 seconds)
2023-03-02 06:27:19 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2023-03-02 06:27:19 | INFO | train | epoch 072 | loss 3.275 | nll_loss 1.121 | word_ins 2.939 | length 3.359 | ppl 9.68 | wps 201088 | ups 3.26 | wpb 61627 | bsz 1997.5 | num_updates 142752 | lr 0.000264673 | gnorm 0.891 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 06:27:19 | INFO | fairseq.trainer | begin training epoch 73
2023-03-02 06:27:42 | INFO | train_inner | epoch 073:     48 / 1983 loss=3.253, nll_loss=1.1, word_ins=2.92, length=3.336, ppl=9.54, wps=107626, ups=1.75, wpb=61332.2, bsz=2005.3, num_updates=142800, lr=0.000264628, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:28:12 | INFO | train_inner | epoch 073:    148 / 1983 loss=3.28, nll_loss=1.124, word_ins=2.942, length=3.383, ppl=9.71, wps=210238, ups=3.42, wpb=61454.9, bsz=2005.5, num_updates=142900, lr=0.000264535, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:28:41 | INFO | train_inner | epoch 073:    248 / 1983 loss=3.252, nll_loss=1.101, word_ins=2.921, length=3.306, ppl=9.53, wps=211135, ups=3.43, wpb=61545.2, bsz=2018.1, num_updates=143000, lr=0.000264443, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:29:10 | INFO | train_inner | epoch 073:    348 / 1983 loss=3.279, nll_loss=1.128, word_ins=2.945, length=3.341, ppl=9.71, wps=210431, ups=3.41, wpb=61626.1, bsz=1983.4, num_updates=143100, lr=0.000264351, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:29:39 | INFO | train_inner | epoch 073:    448 / 1983 loss=3.268, nll_loss=1.112, word_ins=2.931, length=3.368, ppl=9.64, wps=210904, ups=3.44, wpb=61266.3, bsz=1973, num_updates=143200, lr=0.000264258, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:30:08 | INFO | train_inner | epoch 073:    548 / 1983 loss=3.275, nll_loss=1.12, word_ins=2.938, length=3.367, ppl=9.68, wps=211216, ups=3.42, wpb=61699.1, bsz=1970.6, num_updates=143300, lr=0.000264166, gnorm=0.893, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:30:38 | INFO | train_inner | epoch 073:    648 / 1983 loss=3.285, nll_loss=1.125, word_ins=2.944, length=3.416, ppl=9.75, wps=210632, ups=3.41, wpb=61678.9, bsz=1953.9, num_updates=143400, lr=0.000264074, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:31:07 | INFO | train_inner | epoch 073:    748 / 1983 loss=3.245, nll_loss=1.1, word_ins=2.92, length=3.253, ppl=9.48, wps=212294, ups=3.42, wpb=62013.1, bsz=2015.6, num_updates=143500, lr=0.000263982, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:31:36 | INFO | train_inner | epoch 073:    848 / 1983 loss=3.267, nll_loss=1.108, word_ins=2.928, length=3.388, ppl=9.62, wps=211495, ups=3.43, wpb=61717.8, bsz=1970.6, num_updates=143600, lr=0.00026389, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:32:05 | INFO | train_inner | epoch 073:    948 / 1983 loss=3.257, nll_loss=1.109, word_ins=2.928, length=3.29, ppl=9.56, wps=211112, ups=3.42, wpb=61675.1, bsz=2052.2, num_updates=143700, lr=0.000263798, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:32:34 | INFO | train_inner | epoch 073:   1048 / 1983 loss=3.268, nll_loss=1.11, word_ins=2.929, length=3.392, ppl=9.63, wps=210044, ups=3.41, wpb=61539.4, bsz=2124.6, num_updates=143800, lr=0.000263706, gnorm=0.918, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:33:04 | INFO | train_inner | epoch 073:   1148 / 1983 loss=3.291, nll_loss=1.135, word_ins=2.952, length=3.392, ppl=9.79, wps=210319, ups=3.43, wpb=61309.6, bsz=1961.7, num_updates=143900, lr=0.000263615, gnorm=0.943, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:33:33 | INFO | train_inner | epoch 073:   1248 / 1983 loss=3.309, nll_loss=1.148, word_ins=2.964, length=3.452, ppl=9.91, wps=211606, ups=3.45, wpb=61321.4, bsz=1854.6, num_updates=144000, lr=0.000263523, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:34:02 | INFO | train_inner | epoch 073:   1348 / 1983 loss=3.286, nll_loss=1.131, word_ins=2.948, length=3.383, ppl=9.75, wps=211688, ups=3.44, wpb=61447.9, bsz=1959.7, num_updates=144100, lr=0.000263432, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:34:31 | INFO | train_inner | epoch 073:   1448 / 1983 loss=3.261, nll_loss=1.11, word_ins=2.929, length=3.317, ppl=9.59, wps=212993, ups=3.44, wpb=61974.3, bsz=1993.5, num_updates=144200, lr=0.00026334, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:35:00 | INFO | train_inner | epoch 073:   1548 / 1983 loss=3.265, nll_loss=1.113, word_ins=2.932, length=3.338, ppl=9.62, wps=211804, ups=3.42, wpb=61848.4, bsz=1981.5, num_updates=144300, lr=0.000263249, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:35:29 | INFO | train_inner | epoch 073:   1648 / 1983 loss=3.269, nll_loss=1.116, word_ins=2.934, length=3.346, ppl=9.64, wps=210142, ups=3.41, wpb=61661.4, bsz=2023.3, num_updates=144400, lr=0.000263158, gnorm=0.908, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:35:58 | INFO | train_inner | epoch 073:   1748 / 1983 loss=3.258, nll_loss=1.106, word_ins=2.925, length=3.324, ppl=9.57, wps=211705, ups=3.42, wpb=61832.7, bsz=2103.1, num_updates=144500, lr=0.000263067, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:36:28 | INFO | train_inner | epoch 073:   1848 / 1983 loss=3.258, nll_loss=1.107, word_ins=2.926, length=3.318, ppl=9.57, wps=211924, ups=3.43, wpb=61735.4, bsz=2043, num_updates=144600, lr=0.000262976, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:36:57 | INFO | train_inner | epoch 073:   1948 / 1983 loss=3.275, nll_loss=1.123, word_ins=2.941, length=3.349, ppl=9.68, wps=210901, ups=3.42, wpb=61645.9, bsz=1995, num_updates=144700, lr=0.000262885, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 06:37:20 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 3.261 | nll_loss 1.057 | word_ins 2.94 | length 3.21 | ppl 9.58 | wps 124288 | wpb 41551 | bsz 1500 | num_updates 144735 | best_loss 3.259
2023-03-02 06:37:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 06:37:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint73.pt (epoch 73 @ 144735 updates, score 3.261) (writing took 5.588934035971761 seconds)
2023-03-02 06:37:25 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2023-03-02 06:37:25 | INFO | train | epoch 073 | loss 3.27 | nll_loss 1.117 | word_ins 2.935 | length 3.352 | ppl 9.65 | wps 201476 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 144735 | lr 0.000262853 | gnorm 0.886 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 06:37:25 | INFO | fairseq.trainer | begin training epoch 74
2023-03-02 06:37:54 | INFO | train_inner | epoch 074:     65 / 1983 loss=3.278, nll_loss=1.124, word_ins=2.942, length=3.351, ppl=9.7, wps=106671, ups=1.75, wpb=60904.8, bsz=1972.5, num_updates=144800, lr=0.000262794, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:38:23 | INFO | train_inner | epoch 074:    165 / 1983 loss=3.26, nll_loss=1.109, word_ins=2.929, length=3.308, ppl=9.58, wps=213389, ups=3.43, wpb=62146.7, bsz=1998.8, num_updates=144900, lr=0.000262703, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:38:52 | INFO | train_inner | epoch 074:    265 / 1983 loss=3.239, nll_loss=1.09, word_ins=2.911, length=3.281, ppl=9.44, wps=212461, ups=3.44, wpb=61835.3, bsz=1984.3, num_updates=145000, lr=0.000262613, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:39:21 | INFO | train_inner | epoch 074:    365 / 1983 loss=3.288, nll_loss=1.132, word_ins=2.95, length=3.385, ppl=9.77, wps=210885, ups=3.42, wpb=61657.5, bsz=1926.9, num_updates=145100, lr=0.000262522, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:39:51 | INFO | train_inner | epoch 074:    465 / 1983 loss=3.261, nll_loss=1.111, word_ins=2.93, length=3.305, ppl=9.59, wps=212494, ups=3.42, wpb=62185.2, bsz=1961.3, num_updates=145200, lr=0.000262432, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:40:20 | INFO | train_inner | epoch 074:    565 / 1983 loss=3.272, nll_loss=1.115, word_ins=2.933, length=3.384, ppl=9.66, wps=209883, ups=3.43, wpb=61276.7, bsz=1979.8, num_updates=145300, lr=0.000262342, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:40:49 | INFO | train_inner | epoch 074:    665 / 1983 loss=3.269, nll_loss=1.115, word_ins=2.933, length=3.352, ppl=9.64, wps=210573, ups=3.42, wpb=61501.1, bsz=2032.2, num_updates=145400, lr=0.000262251, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:41:18 | INFO | train_inner | epoch 074:    765 / 1983 loss=3.271, nll_loss=1.116, word_ins=2.934, length=3.367, ppl=9.65, wps=210455, ups=3.44, wpb=61209.3, bsz=1958.7, num_updates=145500, lr=0.000262161, gnorm=0.903, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:41:47 | INFO | train_inner | epoch 074:    865 / 1983 loss=3.268, nll_loss=1.114, word_ins=2.933, length=3.36, ppl=9.64, wps=211050, ups=3.43, wpb=61549.8, bsz=1967.5, num_updates=145600, lr=0.000262071, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:42:17 | INFO | train_inner | epoch 074:    965 / 1983 loss=3.275, nll_loss=1.12, word_ins=2.938, length=3.365, ppl=9.68, wps=210648, ups=3.42, wpb=61619.1, bsz=2020.6, num_updates=145700, lr=0.000261981, gnorm=0.914, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:42:46 | INFO | train_inner | epoch 074:   1065 / 1983 loss=3.265, nll_loss=1.112, word_ins=2.932, length=3.335, ppl=9.61, wps=211345, ups=3.42, wpb=61720.6, bsz=2024.6, num_updates=145800, lr=0.000261891, gnorm=0.925, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:43:15 | INFO | train_inner | epoch 074:   1165 / 1983 loss=3.286, nll_loss=1.127, word_ins=2.944, length=3.413, ppl=9.75, wps=210874, ups=3.43, wpb=61399.1, bsz=1909.9, num_updates=145900, lr=0.000261802, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:43:44 | INFO | train_inner | epoch 074:   1265 / 1983 loss=3.265, nll_loss=1.11, word_ins=2.929, length=3.361, ppl=9.61, wps=209921, ups=3.44, wpb=61073.9, bsz=2021.7, num_updates=146000, lr=0.000261712, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:44:13 | INFO | train_inner | epoch 074:   1365 / 1983 loss=3.26, nll_loss=1.109, word_ins=2.927, length=3.323, ppl=9.58, wps=211133, ups=3.42, wpb=61780.5, bsz=2038.7, num_updates=146100, lr=0.000261622, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:44:43 | INFO | train_inner | epoch 074:   1465 / 1983 loss=3.27, nll_loss=1.119, word_ins=2.938, length=3.321, ppl=9.64, wps=212115, ups=3.42, wpb=61999.7, bsz=2088.1, num_updates=146200, lr=0.000261533, gnorm=0.915, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:44:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 06:45:12 | INFO | train_inner | epoch 074:   1566 / 1983 loss=3.249, nll_loss=1.097, word_ins=2.917, length=3.318, ppl=9.51, wps=210257, ups=3.4, wpb=61927.1, bsz=2024.2, num_updates=146300, lr=0.000261443, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:45:41 | INFO | train_inner | epoch 074:   1666 / 1983 loss=3.257, nll_loss=1.104, word_ins=2.924, length=3.329, ppl=9.56, wps=210771, ups=3.41, wpb=61820.2, bsz=2032.6, num_updates=146400, lr=0.000261354, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:46:10 | INFO | train_inner | epoch 074:   1766 / 1983 loss=3.256, nll_loss=1.102, word_ins=2.921, length=3.344, ppl=9.55, wps=213168, ups=3.45, wpb=61866.8, bsz=1988.8, num_updates=146500, lr=0.000261265, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:46:39 | INFO | train_inner | epoch 074:   1866 / 1983 loss=3.252, nll_loss=1.103, word_ins=2.922, length=3.297, ppl=9.52, wps=211792, ups=3.43, wpb=61666.8, bsz=2060.2, num_updates=146600, lr=0.000261176, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:47:09 | INFO | train_inner | epoch 074:   1966 / 1983 loss=3.283, nll_loss=1.128, word_ins=2.945, length=3.387, ppl=9.74, wps=211389, ups=3.43, wpb=61587.7, bsz=1954.5, num_updates=146700, lr=0.000261087, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 06:47:27 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 3.263 | nll_loss 1.047 | word_ins 2.932 | length 3.308 | ppl 9.6 | wps 80434 | wpb 41551 | bsz 1500 | num_updates 146717 | best_loss 3.259
2023-03-02 06:47:27 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 06:47:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint74.pt (epoch 74 @ 146717 updates, score 3.263) (writing took 5.621813169913366 seconds)
2023-03-02 06:47:33 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2023-03-02 06:47:33 | INFO | train | epoch 074 | loss 3.266 | nll_loss 1.113 | word_ins 2.931 | length 3.345 | ppl 9.62 | wps 201152 | ups 3.26 | wpb 61627.3 | bsz 1998 | num_updates 146717 | lr 0.000261072 | gnorm 0.887 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 06:47:33 | INFO | fairseq.trainer | begin training epoch 75
2023-03-02 06:48:07 | INFO | train_inner | epoch 075:     83 / 1983 loss=3.245, nll_loss=1.096, word_ins=2.916, length=3.293, ppl=9.48, wps=105981, ups=1.72, wpb=61472.7, bsz=2000.2, num_updates=146800, lr=0.000260998, gnorm=0.908, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:48:36 | INFO | train_inner | epoch 075:    183 / 1983 loss=3.259, nll_loss=1.107, word_ins=2.926, length=3.33, ppl=9.58, wps=209415, ups=3.4, wpb=61610.6, bsz=2065.4, num_updates=146900, lr=0.000260909, gnorm=0.887, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:49:05 | INFO | train_inner | epoch 075:    283 / 1983 loss=3.287, nll_loss=1.13, word_ins=2.948, length=3.384, ppl=9.76, wps=210606, ups=3.43, wpb=61445.4, bsz=1965.1, num_updates=147000, lr=0.00026082, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:49:34 | INFO | train_inner | epoch 075:    383 / 1983 loss=3.256, nll_loss=1.105, word_ins=2.924, length=3.315, ppl=9.55, wps=211491, ups=3.43, wpb=61657, bsz=2026.2, num_updates=147100, lr=0.000260732, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:50:04 | INFO | train_inner | epoch 075:    483 / 1983 loss=3.24, nll_loss=1.09, word_ins=2.911, length=3.291, ppl=9.45, wps=210482, ups=3.43, wpb=61410.7, bsz=2084.5, num_updates=147200, lr=0.000260643, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:50:33 | INFO | train_inner | epoch 075:    583 / 1983 loss=3.274, nll_loss=1.117, word_ins=2.935, length=3.386, ppl=9.67, wps=211752, ups=3.44, wpb=61560.3, bsz=1931, num_updates=147300, lr=0.000260555, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:51:02 | INFO | train_inner | epoch 075:    683 / 1983 loss=3.249, nll_loss=1.091, word_ins=2.912, length=3.364, ppl=9.5, wps=210124, ups=3.42, wpb=61374.7, bsz=1988.6, num_updates=147400, lr=0.000260466, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:51:31 | INFO | train_inner | epoch 075:    783 / 1983 loss=3.267, nll_loss=1.114, word_ins=2.933, length=3.338, ppl=9.63, wps=211542, ups=3.42, wpb=61929, bsz=1973.9, num_updates=147500, lr=0.000260378, gnorm=0.896, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:52:00 | INFO | train_inner | epoch 075:    883 / 1983 loss=3.236, nll_loss=1.086, word_ins=2.906, length=3.299, ppl=9.42, wps=213621, ups=3.45, wpb=61953.1, bsz=2029.6, num_updates=147600, lr=0.00026029, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:52:29 | INFO | train_inner | epoch 075:    983 / 1983 loss=3.235, nll_loss=1.093, word_ins=2.913, length=3.216, ppl=9.41, wps=212118, ups=3.41, wpb=62260.2, bsz=2120.9, num_updates=147700, lr=0.000260201, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:52:59 | INFO | train_inner | epoch 075:   1083 / 1983 loss=3.244, nll_loss=1.095, word_ins=2.915, length=3.288, ppl=9.47, wps=211405, ups=3.43, wpb=61569, bsz=2070.8, num_updates=147800, lr=0.000260113, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:53:28 | INFO | train_inner | epoch 075:   1183 / 1983 loss=3.269, nll_loss=1.113, word_ins=2.932, length=3.374, ppl=9.64, wps=210668, ups=3.45, wpb=61007.7, bsz=1920.6, num_updates=147900, lr=0.000260025, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:53:57 | INFO | train_inner | epoch 075:   1283 / 1983 loss=3.265, nll_loss=1.113, word_ins=2.931, length=3.339, ppl=9.61, wps=212991, ups=3.43, wpb=62107, bsz=1962.9, num_updates=148000, lr=0.000259938, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:54:26 | INFO | train_inner | epoch 075:   1383 / 1983 loss=3.267, nll_loss=1.115, word_ins=2.934, length=3.337, ppl=9.63, wps=213824, ups=3.44, wpb=62097.2, bsz=1913.7, num_updates=148100, lr=0.00025985, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:54:55 | INFO | train_inner | epoch 075:   1483 / 1983 loss=3.284, nll_loss=1.126, word_ins=2.943, length=3.404, ppl=9.74, wps=210935, ups=3.43, wpb=61585.9, bsz=1977, num_updates=148200, lr=0.000259762, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:55:24 | INFO | train_inner | epoch 075:   1583 / 1983 loss=3.289, nll_loss=1.137, word_ins=2.953, length=3.362, ppl=9.78, wps=211330, ups=3.43, wpb=61619.5, bsz=1963.3, num_updates=148300, lr=0.000259675, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:55:53 | INFO | train_inner | epoch 075:   1683 / 1983 loss=3.274, nll_loss=1.12, word_ins=2.938, length=3.351, ppl=9.67, wps=212320, ups=3.43, wpb=61905.4, bsz=1966.7, num_updates=148400, lr=0.000259587, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:56:22 | INFO | train_inner | epoch 075:   1783 / 1983 loss=3.279, nll_loss=1.121, word_ins=2.938, length=3.407, ppl=9.71, wps=211236, ups=3.44, wpb=61369.2, bsz=1953.6, num_updates=148500, lr=0.0002595, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:56:51 | INFO | train_inner | epoch 075:   1883 / 1983 loss=3.264, nll_loss=1.112, word_ins=2.931, length=3.338, ppl=9.61, wps=210284, ups=3.44, wpb=61129.9, bsz=2011.3, num_updates=148600, lr=0.000259412, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:57:21 | INFO | train_inner | epoch 075:   1983 / 1983 loss=3.258, nll_loss=1.106, word_ins=2.925, length=3.324, ppl=9.56, wps=208815, ups=3.42, wpb=61034, bsz=1997.4, num_updates=148700, lr=0.000259325, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 06:57:34 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 3.259 | nll_loss 1.057 | word_ins 2.938 | length 3.217 | ppl 9.57 | wps 124381 | wpb 41551 | bsz 1500 | num_updates 148700 | best_loss 3.259
2023-03-02 06:57:34 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 06:57:42 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint75.pt (epoch 75 @ 148700 updates, score 3.259) (writing took 8.26004689594265 seconds)
2023-03-02 06:57:42 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2023-03-02 06:57:42 | INFO | train | epoch 075 | loss 3.262 | nll_loss 1.109 | word_ins 2.928 | length 3.336 | ppl 9.59 | wps 200467 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 148700 | lr 0.000259325 | gnorm 0.872 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 06:57:42 | INFO | fairseq.trainer | begin training epoch 76
2023-03-02 06:58:21 | INFO | train_inner | epoch 076:    100 / 1983 loss=3.249, nll_loss=1.099, word_ins=2.919, length=3.3, ppl=9.51, wps=102162, ups=1.66, wpb=61522.2, bsz=2000.4, num_updates=148800, lr=0.000259238, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:58:50 | INFO | train_inner | epoch 076:    200 / 1983 loss=3.242, nll_loss=1.091, word_ins=2.912, length=3.301, ppl=9.46, wps=211883, ups=3.44, wpb=61679.5, bsz=1985.4, num_updates=148900, lr=0.000259151, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:59:19 | INFO | train_inner | epoch 076:    300 / 1983 loss=3.253, nll_loss=1.101, word_ins=2.921, length=3.328, ppl=9.54, wps=211962, ups=3.44, wpb=61675.9, bsz=1997.8, num_updates=149000, lr=0.000259064, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 06:59:48 | INFO | train_inner | epoch 076:    400 / 1983 loss=3.245, nll_loss=1.094, word_ins=2.915, length=3.31, ppl=9.48, wps=213494, ups=3.44, wpb=62079.5, bsz=1985, num_updates=149100, lr=0.000258977, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:00:17 | INFO | train_inner | epoch 076:    500 / 1983 loss=3.249, nll_loss=1.097, word_ins=2.918, length=3.309, ppl=9.5, wps=212272, ups=3.44, wpb=61627.8, bsz=1991, num_updates=149200, lr=0.00025889, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:00:46 | INFO | train_inner | epoch 076:    600 / 1983 loss=3.283, nll_loss=1.129, word_ins=2.946, length=3.367, ppl=9.73, wps=211314, ups=3.42, wpb=61719.8, bsz=1983.8, num_updates=149300, lr=0.000258803, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:01:15 | INFO | train_inner | epoch 076:    700 / 1983 loss=3.27, nll_loss=1.118, word_ins=2.936, length=3.335, ppl=9.64, wps=212709, ups=3.44, wpb=61865, bsz=1919.1, num_updates=149400, lr=0.000258717, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:01:45 | INFO | train_inner | epoch 076:    800 / 1983 loss=3.266, nll_loss=1.114, word_ins=2.933, length=3.336, ppl=9.62, wps=211619, ups=3.42, wpb=61947.3, bsz=2016.2, num_updates=149500, lr=0.00025863, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:02:14 | INFO | train_inner | epoch 076:    900 / 1983 loss=3.241, nll_loss=1.096, word_ins=2.916, length=3.251, ppl=9.45, wps=213059, ups=3.44, wpb=61973.5, bsz=2056, num_updates=149600, lr=0.000258544, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:02:43 | INFO | train_inner | epoch 076:   1000 / 1983 loss=3.282, nll_loss=1.126, word_ins=2.943, length=3.385, ppl=9.73, wps=208140, ups=3.41, wpb=61014.8, bsz=2015.4, num_updates=149700, lr=0.000258457, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:03:12 | INFO | train_inner | epoch 076:   1100 / 1983 loss=3.284, nll_loss=1.125, word_ins=2.942, length=3.411, ppl=9.74, wps=211827, ups=3.44, wpb=61543.3, bsz=1887.9, num_updates=149800, lr=0.000258371, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:03:41 | INFO | train_inner | epoch 076:   1200 / 1983 loss=3.248, nll_loss=1.096, word_ins=2.916, length=3.321, ppl=9.5, wps=210642, ups=3.42, wpb=61518.9, bsz=2081.6, num_updates=149900, lr=0.000258285, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:04:11 | INFO | train_inner | epoch 076:   1300 / 1983 loss=3.244, nll_loss=1.095, word_ins=2.915, length=3.293, ppl=9.48, wps=210641, ups=3.41, wpb=61694.1, bsz=2084.9, num_updates=150000, lr=0.000258199, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:04:40 | INFO | train_inner | epoch 076:   1400 / 1983 loss=3.247, nll_loss=1.096, word_ins=2.916, length=3.314, ppl=9.5, wps=212694, ups=3.43, wpb=61941.6, bsz=1978.9, num_updates=150100, lr=0.000258113, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:05:09 | INFO | train_inner | epoch 076:   1500 / 1983 loss=3.291, nll_loss=1.133, word_ins=2.949, length=3.421, ppl=9.79, wps=210983, ups=3.44, wpb=61367.8, bsz=1915.2, num_updates=150200, lr=0.000258027, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:05:38 | INFO | train_inner | epoch 076:   1600 / 1983 loss=3.263, nll_loss=1.108, word_ins=2.926, length=3.368, ppl=9.6, wps=210738, ups=3.43, wpb=61468.2, bsz=2044.8, num_updates=150300, lr=0.000257941, gnorm=0.865, loss_scale=32768, train_wall=29, wall=0
2023-03-02 07:05:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 07:06:08 | INFO | train_inner | epoch 076:   1701 / 1983 loss=3.264, nll_loss=1.11, word_ins=2.929, length=3.352, ppl=9.61, wps=207994, ups=3.38, wpb=61459.3, bsz=1972.2, num_updates=150400, lr=0.000257855, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:06:37 | INFO | train_inner | epoch 076:   1801 / 1983 loss=3.254, nll_loss=1.104, word_ins=2.923, length=3.306, ppl=9.54, wps=211136, ups=3.41, wpb=61851.7, bsz=2031, num_updates=150500, lr=0.00025777, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:07:06 | INFO | train_inner | epoch 076:   1901 / 1983 loss=3.239, nll_loss=1.087, word_ins=2.908, length=3.313, ppl=9.44, wps=212012, ups=3.43, wpb=61769.7, bsz=2050.7, num_updates=150600, lr=0.000257684, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 07:07:43 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 3.247 | nll_loss 1.036 | word_ins 2.918 | length 3.287 | ppl 9.49 | wps 98139 | wpb 41551 | bsz 1500 | num_updates 150682 | best_loss 3.247
2023-03-02 07:07:43 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 07:07:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint76.pt (epoch 76 @ 150682 updates, score 3.247) (writing took 8.526684124022722 seconds)
2023-03-02 07:07:52 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2023-03-02 07:07:52 | INFO | train | epoch 076 | loss 3.259 | nll_loss 1.107 | word_ins 2.926 | length 3.334 | ppl 9.57 | wps 200376 | ups 3.25 | wpb 61627 | bsz 1997.8 | num_updates 150682 | lr 0.000257614 | gnorm 0.869 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 07:07:52 | INFO | fairseq.trainer | begin training epoch 77
2023-03-02 07:08:06 | INFO | train_inner | epoch 077:     18 / 1983 loss=3.269, nll_loss=1.116, word_ins=2.934, length=3.348, ppl=9.64, wps=101396, ups=1.66, wpb=61053.5, bsz=1961.3, num_updates=150700, lr=0.000257599, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:08:36 | INFO | train_inner | epoch 077:    118 / 1983 loss=3.22, nll_loss=1.071, word_ins=2.894, length=3.26, ppl=9.32, wps=210794, ups=3.42, wpb=61551.3, bsz=2130.1, num_updates=150800, lr=0.000257513, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:09:05 | INFO | train_inner | epoch 077:    218 / 1983 loss=3.271, nll_loss=1.117, word_ins=2.935, length=3.362, ppl=9.65, wps=211350, ups=3.44, wpb=61442.7, bsz=1895.6, num_updates=150900, lr=0.000257428, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:09:34 | INFO | train_inner | epoch 077:    318 / 1983 loss=3.271, nll_loss=1.117, word_ins=2.935, length=3.358, ppl=9.65, wps=211062, ups=3.44, wpb=61369.8, bsz=1956.6, num_updates=151000, lr=0.000257343, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:10:03 | INFO | train_inner | epoch 077:    418 / 1983 loss=3.267, nll_loss=1.114, word_ins=2.933, length=3.337, ppl=9.62, wps=211346, ups=3.43, wpb=61627.6, bsz=1925.4, num_updates=151100, lr=0.000257257, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:10:32 | INFO | train_inner | epoch 077:    518 / 1983 loss=3.26, nll_loss=1.104, word_ins=2.923, length=3.368, ppl=9.58, wps=210158, ups=3.43, wpb=61325.4, bsz=2023.9, num_updates=151200, lr=0.000257172, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:11:01 | INFO | train_inner | epoch 077:    618 / 1983 loss=3.238, nll_loss=1.087, word_ins=2.908, length=3.305, ppl=9.44, wps=212154, ups=3.43, wpb=61896.2, bsz=2047.3, num_updates=151300, lr=0.000257087, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:11:31 | INFO | train_inner | epoch 077:    718 / 1983 loss=3.253, nll_loss=1.103, word_ins=2.922, length=3.308, ppl=9.53, wps=207351, ups=3.39, wpb=61121.1, bsz=2138.9, num_updates=151400, lr=0.000257002, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:12:00 | INFO | train_inner | epoch 077:    818 / 1983 loss=3.247, nll_loss=1.099, word_ins=2.918, length=3.292, ppl=9.5, wps=213330, ups=3.43, wpb=62196.5, bsz=2036.3, num_updates=151500, lr=0.000256917, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:12:29 | INFO | train_inner | epoch 077:    918 / 1983 loss=3.251, nll_loss=1.096, word_ins=2.916, length=3.346, ppl=9.52, wps=212792, ups=3.44, wpb=61809.1, bsz=1925.6, num_updates=151600, lr=0.000256833, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:12:58 | INFO | train_inner | epoch 077:   1018 / 1983 loss=3.21, nll_loss=1.065, word_ins=2.887, length=3.223, ppl=9.25, wps=211043, ups=3.41, wpb=61854.2, bsz=2165.6, num_updates=151700, lr=0.000256748, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:13:27 | INFO | train_inner | epoch 077:   1118 / 1983 loss=3.279, nll_loss=1.124, word_ins=2.941, length=3.379, ppl=9.71, wps=211790, ups=3.43, wpb=61674, bsz=1936.3, num_updates=151800, lr=0.000256664, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:13:56 | INFO | train_inner | epoch 077:   1218 / 1983 loss=3.253, nll_loss=1.098, word_ins=2.917, length=3.36, ppl=9.54, wps=210236, ups=3.43, wpb=61309.6, bsz=1990.1, num_updates=151900, lr=0.000256579, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:14:26 | INFO | train_inner | epoch 077:   1318 / 1983 loss=3.274, nll_loss=1.121, word_ins=2.939, length=3.356, ppl=9.67, wps=211388, ups=3.42, wpb=61761.9, bsz=1949.4, num_updates=152000, lr=0.000256495, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:14:55 | INFO | train_inner | epoch 077:   1418 / 1983 loss=3.275, nll_loss=1.122, word_ins=2.939, length=3.354, ppl=9.68, wps=211437, ups=3.43, wpb=61565.1, bsz=1893.4, num_updates=152100, lr=0.00025641, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:15:24 | INFO | train_inner | epoch 077:   1518 / 1983 loss=3.296, nll_loss=1.138, word_ins=2.954, length=3.412, ppl=9.82, wps=210528, ups=3.43, wpb=61372.7, bsz=1897.1, num_updates=152200, lr=0.000256326, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:15:53 | INFO | train_inner | epoch 077:   1618 / 1983 loss=3.252, nll_loss=1.096, word_ins=2.916, length=3.363, ppl=9.53, wps=213339, ups=3.45, wpb=61916, bsz=1980.5, num_updates=152300, lr=0.000256242, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:16:22 | INFO | train_inner | epoch 077:   1718 / 1983 loss=3.219, nll_loss=1.071, word_ins=2.892, length=3.267, ppl=9.31, wps=211951, ups=3.43, wpb=61818.7, bsz=2083.8, num_updates=152400, lr=0.000256158, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:16:51 | INFO | train_inner | epoch 077:   1818 / 1983 loss=3.272, nll_loss=1.116, word_ins=2.934, length=3.372, ppl=9.66, wps=211328, ups=3.42, wpb=61735, bsz=1948.4, num_updates=152500, lr=0.000256074, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:17:21 | INFO | train_inner | epoch 077:   1918 / 1983 loss=3.236, nll_loss=1.084, word_ins=2.904, length=3.314, ppl=9.42, wps=212380, ups=3.42, wpb=62185.6, bsz=2062.8, num_updates=152600, lr=0.00025599, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 07:17:53 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 3.259 | nll_loss 1.032 | word_ins 2.919 | length 3.403 | ppl 9.57 | wps 78486.3 | wpb 41551 | bsz 1500 | num_updates 152665 | best_loss 3.247
2023-03-02 07:17:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 07:17:58 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint77.pt (epoch 77 @ 152665 updates, score 3.259) (writing took 5.599056847975589 seconds)
2023-03-02 07:17:58 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2023-03-02 07:17:58 | INFO | train | epoch 077 | loss 3.255 | nll_loss 1.103 | word_ins 2.922 | length 3.332 | ppl 9.55 | wps 201425 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 152665 | lr 0.000255935 | gnorm 0.859 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 07:17:58 | INFO | fairseq.trainer | begin training epoch 78
2023-03-02 07:18:19 | INFO | train_inner | epoch 078:     35 / 1983 loss=3.27, nll_loss=1.117, word_ins=2.935, length=3.349, ppl=9.64, wps=103149, ups=1.7, wpb=60642.2, bsz=1946.2, num_updates=152700, lr=0.000255906, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:18:49 | INFO | train_inner | epoch 078:    135 / 1983 loss=3.245, nll_loss=1.096, word_ins=2.916, length=3.288, ppl=9.48, wps=211865, ups=3.43, wpb=61787.5, bsz=1960, num_updates=152800, lr=0.000255822, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:19:18 | INFO | train_inner | epoch 078:    235 / 1983 loss=3.275, nll_loss=1.123, word_ins=2.941, length=3.346, ppl=9.68, wps=208062, ups=3.4, wpb=61260.9, bsz=1982.7, num_updates=152900, lr=0.000255739, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:19:47 | INFO | train_inner | epoch 078:    335 / 1983 loss=3.239, nll_loss=1.096, word_ins=2.917, length=3.228, ppl=9.44, wps=211308, ups=3.41, wpb=61984.8, bsz=2016.8, num_updates=153000, lr=0.000255655, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:20:16 | INFO | train_inner | epoch 078:    435 / 1983 loss=3.269, nll_loss=1.114, word_ins=2.932, length=3.372, ppl=9.64, wps=213077, ups=3.45, wpb=61810.1, bsz=1946.1, num_updates=153100, lr=0.000255571, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:20:46 | INFO | train_inner | epoch 078:    535 / 1983 loss=3.256, nll_loss=1.102, word_ins=2.921, length=3.349, ppl=9.56, wps=209844, ups=3.41, wpb=61450.3, bsz=1998.6, num_updates=153200, lr=0.000255488, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:21:15 | INFO | train_inner | epoch 078:    635 / 1983 loss=3.26, nll_loss=1.106, word_ins=2.925, length=3.35, ppl=9.58, wps=212820, ups=3.44, wpb=61844.4, bsz=1986.6, num_updates=153300, lr=0.000255405, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:21:44 | INFO | train_inner | epoch 078:    735 / 1983 loss=3.263, nll_loss=1.108, word_ins=2.927, length=3.364, ppl=9.6, wps=211324, ups=3.42, wpb=61732.8, bsz=1934.6, num_updates=153400, lr=0.000255321, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:22:13 | INFO | train_inner | epoch 078:    835 / 1983 loss=3.249, nll_loss=1.093, word_ins=2.914, length=3.354, ppl=9.51, wps=211600, ups=3.44, wpb=61432.2, bsz=2053.5, num_updates=153500, lr=0.000255238, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:22:42 | INFO | train_inner | epoch 078:    935 / 1983 loss=3.276, nll_loss=1.12, word_ins=2.937, length=3.386, ppl=9.68, wps=209527, ups=3.44, wpb=60970.3, bsz=1963.2, num_updates=153600, lr=0.000255155, gnorm=0.992, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:23:12 | INFO | train_inner | epoch 078:   1035 / 1983 loss=3.214, nll_loss=1.072, word_ins=2.895, length=3.193, ppl=9.28, wps=209962, ups=3.4, wpb=61792.9, bsz=2114.6, num_updates=153700, lr=0.000255072, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:23:41 | INFO | train_inner | epoch 078:   1135 / 1983 loss=3.246, nll_loss=1.097, word_ins=2.916, length=3.297, ppl=9.49, wps=213139, ups=3.45, wpb=61833.9, bsz=1962.1, num_updates=153800, lr=0.000254989, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:24:10 | INFO | train_inner | epoch 078:   1235 / 1983 loss=3.267, nll_loss=1.109, word_ins=2.928, length=3.391, ppl=9.62, wps=212048, ups=3.43, wpb=61775.9, bsz=1936.9, num_updates=153900, lr=0.000254906, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:24:39 | INFO | train_inner | epoch 078:   1335 / 1983 loss=3.248, nll_loss=1.094, word_ins=2.914, length=3.346, ppl=9.5, wps=211759, ups=3.44, wpb=61537.9, bsz=2013.8, num_updates=154000, lr=0.000254824, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:25:08 | INFO | train_inner | epoch 078:   1435 / 1983 loss=3.236, nll_loss=1.085, word_ins=2.906, length=3.3, ppl=9.42, wps=212016, ups=3.42, wpb=61928.1, bsz=2016.9, num_updates=154100, lr=0.000254741, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:25:37 | INFO | train_inner | epoch 078:   1535 / 1983 loss=3.257, nll_loss=1.104, word_ins=2.923, length=3.342, ppl=9.56, wps=210944, ups=3.43, wpb=61451.7, bsz=1975.8, num_updates=154200, lr=0.000254658, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:26:06 | INFO | train_inner | epoch 078:   1635 / 1983 loss=3.246, nll_loss=1.098, word_ins=2.918, length=3.284, ppl=9.49, wps=211161, ups=3.43, wpb=61496.6, bsz=2019.1, num_updates=154300, lr=0.000254576, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:26:35 | INFO | train_inner | epoch 078:   1735 / 1983 loss=3.256, nll_loss=1.106, word_ins=2.925, length=3.308, ppl=9.55, wps=211010, ups=3.42, wpb=61616.9, bsz=1998.8, num_updates=154400, lr=0.000254493, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:26:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 07:27:05 | INFO | train_inner | epoch 078:   1836 / 1983 loss=3.256, nll_loss=1.105, word_ins=2.924, length=3.316, ppl=9.55, wps=209509, ups=3.4, wpb=61594.3, bsz=2027.1, num_updates=154500, lr=0.000254411, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:27:34 | INFO | train_inner | epoch 078:   1936 / 1983 loss=3.253, nll_loss=1.099, word_ins=2.919, length=3.345, ppl=9.53, wps=211901, ups=3.42, wpb=61988.8, bsz=2055.6, num_updates=154600, lr=0.000254329, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 07:28:01 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 3.237 | nll_loss 1.025 | word_ins 2.914 | length 3.232 | ppl 9.43 | wps 119903 | wpb 41551 | bsz 1500 | num_updates 154647 | best_loss 3.237
2023-03-02 07:28:01 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 07:28:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint78.pt (epoch 78 @ 154647 updates, score 3.237) (writing took 8.132989265024662 seconds)
2023-03-02 07:28:09 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2023-03-02 07:28:09 | INFO | train | epoch 078 | loss 3.253 | nll_loss 1.101 | word_ins 2.921 | length 3.324 | ppl 9.53 | wps 200074 | ups 3.25 | wpb 61628.3 | bsz 1997.8 | num_updates 154647 | lr 0.00025429 | gnorm 0.863 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 07:28:09 | INFO | fairseq.trainer | begin training epoch 79
2023-03-02 07:28:33 | INFO | train_inner | epoch 079:     53 / 1983 loss=3.253, nll_loss=1.102, word_ins=2.921, length=3.313, ppl=9.53, wps=103453, ups=1.69, wpb=61338.1, bsz=1934, num_updates=154700, lr=0.000254246, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:29:03 | INFO | train_inner | epoch 079:    153 / 1983 loss=3.222, nll_loss=1.074, word_ins=2.896, length=3.266, ppl=9.33, wps=212634, ups=3.44, wpb=61895.7, bsz=2028.4, num_updates=154800, lr=0.000254164, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:29:32 | INFO | train_inner | epoch 079:    253 / 1983 loss=3.249, nll_loss=1.098, word_ins=2.918, length=3.309, ppl=9.51, wps=209072, ups=3.42, wpb=61169.1, bsz=2004.5, num_updates=154900, lr=0.000254082, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:30:01 | INFO | train_inner | epoch 079:    353 / 1983 loss=3.238, nll_loss=1.089, word_ins=2.91, length=3.286, ppl=9.44, wps=209100, ups=3.41, wpb=61345.4, bsz=2104.2, num_updates=155000, lr=0.000254, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:30:30 | INFO | train_inner | epoch 079:    453 / 1983 loss=3.266, nll_loss=1.11, word_ins=2.929, length=3.367, ppl=9.62, wps=209084, ups=3.41, wpb=61345.5, bsz=1931, num_updates=155100, lr=0.000253918, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:31:00 | INFO | train_inner | epoch 079:    553 / 1983 loss=3.239, nll_loss=1.093, word_ins=2.913, length=3.253, ppl=9.44, wps=211892, ups=3.41, wpb=62087.9, bsz=1959.7, num_updates=155200, lr=0.000253837, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:31:29 | INFO | train_inner | epoch 079:    653 / 1983 loss=3.236, nll_loss=1.083, word_ins=2.904, length=3.323, ppl=9.42, wps=209698, ups=3.4, wpb=61605.3, bsz=2040, num_updates=155300, lr=0.000253755, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:31:58 | INFO | train_inner | epoch 079:    753 / 1983 loss=3.269, nll_loss=1.116, word_ins=2.935, length=3.34, ppl=9.64, wps=208792, ups=3.41, wpb=61185.7, bsz=1995.2, num_updates=155400, lr=0.000253673, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:32:28 | INFO | train_inner | epoch 079:    853 / 1983 loss=3.251, nll_loss=1.101, word_ins=2.921, length=3.298, ppl=9.52, wps=212242, ups=3.42, wpb=62018.3, bsz=2031.3, num_updates=155500, lr=0.000253592, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:32:57 | INFO | train_inner | epoch 079:    953 / 1983 loss=3.231, nll_loss=1.08, word_ins=2.901, length=3.301, ppl=9.39, wps=211553, ups=3.43, wpb=61677.1, bsz=1995.9, num_updates=155600, lr=0.00025351, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:33:26 | INFO | train_inner | epoch 079:   1053 / 1983 loss=3.241, nll_loss=1.092, word_ins=2.912, length=3.287, ppl=9.45, wps=212707, ups=3.43, wpb=61969.7, bsz=1996.8, num_updates=155700, lr=0.000253429, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:33:55 | INFO | train_inner | epoch 079:   1153 / 1983 loss=3.238, nll_loss=1.089, word_ins=2.91, length=3.286, ppl=9.44, wps=212360, ups=3.42, wpb=62169.7, bsz=2036.4, num_updates=155800, lr=0.000253347, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:34:25 | INFO | train_inner | epoch 079:   1253 / 1983 loss=3.251, nll_loss=1.1, word_ins=2.92, length=3.315, ppl=9.52, wps=210531, ups=3.41, wpb=61694.4, bsz=2017, num_updates=155900, lr=0.000253266, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:34:54 | INFO | train_inner | epoch 079:   1353 / 1983 loss=3.263, nll_loss=1.11, word_ins=2.928, length=3.353, ppl=9.6, wps=211534, ups=3.44, wpb=61436.3, bsz=1979.8, num_updates=156000, lr=0.000253185, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:35:23 | INFO | train_inner | epoch 079:   1453 / 1983 loss=3.248, nll_loss=1.091, word_ins=2.911, length=3.367, ppl=9.5, wps=211618, ups=3.44, wpb=61598.2, bsz=1996.2, num_updates=156100, lr=0.000253104, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:35:52 | INFO | train_inner | epoch 079:   1553 / 1983 loss=3.264, nll_loss=1.109, word_ins=2.928, length=3.356, ppl=9.61, wps=210710, ups=3.43, wpb=61515.1, bsz=1977.7, num_updates=156200, lr=0.000253023, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:36:21 | INFO | train_inner | epoch 079:   1653 / 1983 loss=3.258, nll_loss=1.107, word_ins=2.925, length=3.328, ppl=9.57, wps=211901, ups=3.42, wpb=61882, bsz=2011, num_updates=156300, lr=0.000252942, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:36:50 | INFO | train_inner | epoch 079:   1753 / 1983 loss=3.25, nll_loss=1.093, word_ins=2.913, length=3.375, ppl=9.52, wps=211526, ups=3.43, wpb=61593.2, bsz=2006.1, num_updates=156400, lr=0.000252861, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:37:19 | INFO | train_inner | epoch 079:   1853 / 1983 loss=3.255, nll_loss=1.101, word_ins=2.92, length=3.344, ppl=9.54, wps=213110, ups=3.44, wpb=61960.8, bsz=1932.8, num_updates=156500, lr=0.00025278, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:37:48 | INFO | train_inner | epoch 079:   1953 / 1983 loss=3.259, nll_loss=1.104, word_ins=2.923, length=3.36, ppl=9.57, wps=211602, ups=3.45, wpb=61401.2, bsz=1983.6, num_updates=156600, lr=0.000252699, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 07:38:09 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 3.239 | nll_loss 1.018 | word_ins 2.907 | length 3.319 | ppl 9.44 | wps 85830.3 | wpb 41551 | bsz 1500 | num_updates 156630 | best_loss 3.237
2023-03-02 07:38:09 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 07:38:14 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint79.pt (epoch 79 @ 156630 updates, score 3.239) (writing took 5.530640432029031 seconds)
2023-03-02 07:38:14 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2023-03-02 07:38:14 | INFO | train | epoch 079 | loss 3.249 | nll_loss 1.097 | word_ins 2.917 | length 3.323 | ppl 9.51 | wps 201839 | ups 3.28 | wpb 61628.5 | bsz 1997.6 | num_updates 156630 | lr 0.000252675 | gnorm 0.852 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 07:38:14 | INFO | fairseq.trainer | begin training epoch 80
2023-03-02 07:38:44 | INFO | train_inner | epoch 080:     70 / 1983 loss=3.233, nll_loss=1.083, word_ins=2.904, length=3.291, ppl=9.4, wps=109758, ups=1.79, wpb=61435.9, bsz=2026, num_updates=156700, lr=0.000252619, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:39:14 | INFO | train_inner | epoch 080:    170 / 1983 loss=3.235, nll_loss=1.087, word_ins=2.907, length=3.282, ppl=9.42, wps=210424, ups=3.42, wpb=61578, bsz=2000.9, num_updates=156800, lr=0.000252538, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:39:43 | INFO | train_inner | epoch 080:    270 / 1983 loss=3.239, nll_loss=1.084, word_ins=2.905, length=3.342, ppl=9.44, wps=212228, ups=3.44, wpb=61779.6, bsz=1977.6, num_updates=156900, lr=0.000252458, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:40:12 | INFO | train_inner | epoch 080:    370 / 1983 loss=3.261, nll_loss=1.107, word_ins=2.926, length=3.352, ppl=9.59, wps=209752, ups=3.41, wpb=61446.5, bsz=1949.5, num_updates=157000, lr=0.000252377, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:40:41 | INFO | train_inner | epoch 080:    470 / 1983 loss=3.271, nll_loss=1.116, word_ins=2.934, length=3.366, ppl=9.65, wps=211349, ups=3.44, wpb=61523.8, bsz=1899.5, num_updates=157100, lr=0.000252297, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:41:11 | INFO | train_inner | epoch 080:    570 / 1983 loss=3.244, nll_loss=1.091, word_ins=2.911, length=3.335, ppl=9.47, wps=209873, ups=3.4, wpb=61691.9, bsz=2034.6, num_updates=157200, lr=0.000252217, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:41:40 | INFO | train_inner | epoch 080:    670 / 1983 loss=3.25, nll_loss=1.095, word_ins=2.915, length=3.348, ppl=9.51, wps=212186, ups=3.45, wpb=61546.6, bsz=1947.8, num_updates=157300, lr=0.000252136, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:42:09 | INFO | train_inner | epoch 080:    770 / 1983 loss=3.259, nll_loss=1.105, word_ins=2.924, length=3.356, ppl=9.57, wps=208675, ups=3.42, wpb=60954.3, bsz=1992.2, num_updates=157400, lr=0.000252056, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:42:38 | INFO | train_inner | epoch 080:    870 / 1983 loss=3.271, nll_loss=1.117, word_ins=2.936, length=3.353, ppl=9.65, wps=209328, ups=3.43, wpb=61064.7, bsz=1940.2, num_updates=157500, lr=0.000251976, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:43:07 | INFO | train_inner | epoch 080:    970 / 1983 loss=3.234, nll_loss=1.082, word_ins=2.904, length=3.301, ppl=9.41, wps=211490, ups=3.42, wpb=61900.6, bsz=2012.6, num_updates=157600, lr=0.000251896, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:43:37 | INFO | train_inner | epoch 080:   1070 / 1983 loss=3.226, nll_loss=1.083, word_ins=2.904, length=3.223, ppl=9.36, wps=209718, ups=3.41, wpb=61483.2, bsz=2074.5, num_updates=157700, lr=0.000251816, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:44:06 | INFO | train_inner | epoch 080:   1170 / 1983 loss=3.229, nll_loss=1.079, word_ins=2.9, length=3.295, ppl=9.38, wps=213216, ups=3.43, wpb=62079.1, bsz=2019, num_updates=157800, lr=0.000251737, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:44:35 | INFO | train_inner | epoch 080:   1270 / 1983 loss=3.24, nll_loss=1.092, word_ins=2.912, length=3.288, ppl=9.45, wps=212476, ups=3.41, wpb=62324, bsz=2018.9, num_updates=157900, lr=0.000251657, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:45:04 | INFO | train_inner | epoch 080:   1370 / 1983 loss=3.29, nll_loss=1.132, word_ins=2.948, length=3.42, ppl=9.78, wps=211806, ups=3.42, wpb=61873.8, bsz=1898.2, num_updates=158000, lr=0.000251577, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:45:33 | INFO | train_inner | epoch 080:   1470 / 1983 loss=3.25, nll_loss=1.1, word_ins=2.919, length=3.314, ppl=9.52, wps=211738, ups=3.43, wpb=61680.7, bsz=1993, num_updates=158100, lr=0.000251498, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:46:03 | INFO | train_inner | epoch 080:   1570 / 1983 loss=3.23, nll_loss=1.077, word_ins=2.898, length=3.312, ppl=9.38, wps=210771, ups=3.41, wpb=61737.4, bsz=2026.8, num_updates=158200, lr=0.000251418, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:46:32 | INFO | train_inner | epoch 080:   1670 / 1983 loss=3.235, nll_loss=1.09, word_ins=2.91, length=3.248, ppl=9.42, wps=211551, ups=3.42, wpb=61905.3, bsz=2079, num_updates=158300, lr=0.000251339, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:47:01 | INFO | train_inner | epoch 080:   1770 / 1983 loss=3.251, nll_loss=1.096, word_ins=2.915, length=3.357, ppl=9.52, wps=210322, ups=3.42, wpb=61495.1, bsz=2017.8, num_updates=158400, lr=0.000251259, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:47:30 | INFO | train_inner | epoch 080:   1870 / 1983 loss=3.253, nll_loss=1.102, word_ins=2.921, length=3.318, ppl=9.53, wps=209308, ups=3.41, wpb=61307.4, bsz=2005, num_updates=158500, lr=0.00025118, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:47:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 07:48:00 | INFO | train_inner | epoch 080:   1971 / 1983 loss=3.229, nll_loss=1.081, word_ins=2.901, length=3.281, ppl=9.38, wps=209977, ups=3.39, wpb=61910.5, bsz=2045.6, num_updates=158600, lr=0.000251101, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 07:48:16 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 3.259 | nll_loss 1.049 | word_ins 2.928 | length 3.312 | ppl 9.57 | wps 94988.7 | wpb 41551 | bsz 1500 | num_updates 158612 | best_loss 3.237
2023-03-02 07:48:16 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 07:48:22 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint80.pt (epoch 80 @ 158612 updates, score 3.259) (writing took 5.406455122982152 seconds)
2023-03-02 07:48:22 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2023-03-02 07:48:22 | INFO | train | epoch 080 | loss 3.247 | nll_loss 1.095 | word_ins 2.915 | length 3.319 | ppl 9.49 | wps 201082 | ups 3.26 | wpb 61629.7 | bsz 1997.8 | num_updates 158612 | lr 0.000251091 | gnorm 0.849 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 07:48:22 | INFO | fairseq.trainer | begin training epoch 81
2023-03-02 07:48:57 | INFO | train_inner | epoch 081:     88 / 1983 loss=3.248, nll_loss=1.097, word_ins=2.917, length=3.314, ppl=9.5, wps=105695, ups=1.74, wpb=60795.1, bsz=1995.6, num_updates=158700, lr=0.000251022, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:49:27 | INFO | train_inner | epoch 081:    188 / 1983 loss=3.25, nll_loss=1.098, word_ins=2.917, length=3.332, ppl=9.51, wps=211294, ups=3.43, wpb=61675.9, bsz=1994.5, num_updates=158800, lr=0.000250943, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:49:56 | INFO | train_inner | epoch 081:    288 / 1983 loss=3.258, nll_loss=1.1, word_ins=2.92, length=3.38, ppl=9.57, wps=209482, ups=3.42, wpb=61243.1, bsz=1987.9, num_updates=158900, lr=0.000250864, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:50:25 | INFO | train_inner | epoch 081:    388 / 1983 loss=3.235, nll_loss=1.084, word_ins=2.905, length=3.299, ppl=9.41, wps=210916, ups=3.42, wpb=61587.4, bsz=2005.8, num_updates=159000, lr=0.000250785, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:50:54 | INFO | train_inner | epoch 081:    488 / 1983 loss=3.221, nll_loss=1.073, word_ins=2.895, length=3.26, ppl=9.33, wps=212737, ups=3.41, wpb=62305.3, bsz=2080.2, num_updates=159100, lr=0.000250706, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:51:24 | INFO | train_inner | epoch 081:    588 / 1983 loss=3.259, nll_loss=1.109, word_ins=2.927, length=3.318, ppl=9.57, wps=211454, ups=3.42, wpb=61775.1, bsz=1914, num_updates=159200, lr=0.000250627, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:51:53 | INFO | train_inner | epoch 081:    688 / 1983 loss=3.259, nll_loss=1.106, word_ins=2.925, length=3.346, ppl=9.57, wps=210199, ups=3.42, wpb=61459.5, bsz=1967.4, num_updates=159300, lr=0.000250549, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:52:22 | INFO | train_inner | epoch 081:    788 / 1983 loss=3.259, nll_loss=1.109, word_ins=2.927, length=3.318, ppl=9.57, wps=209671, ups=3.42, wpb=61373.2, bsz=1992.2, num_updates=159400, lr=0.00025047, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:52:51 | INFO | train_inner | epoch 081:    888 / 1983 loss=3.224, nll_loss=1.078, word_ins=2.899, length=3.256, ppl=9.35, wps=211735, ups=3.43, wpb=61820.3, bsz=2032.2, num_updates=159500, lr=0.000250392, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:53:20 | INFO | train_inner | epoch 081:    988 / 1983 loss=3.247, nll_loss=1.095, word_ins=2.914, length=3.329, ppl=9.5, wps=212362, ups=3.43, wpb=61881.6, bsz=1982, num_updates=159600, lr=0.000250313, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:53:50 | INFO | train_inner | epoch 081:   1088 / 1983 loss=3.237, nll_loss=1.089, word_ins=2.91, length=3.278, ppl=9.43, wps=210899, ups=3.42, wpb=61719.9, bsz=2006.6, num_updates=159700, lr=0.000250235, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:54:19 | INFO | train_inner | epoch 081:   1188 / 1983 loss=3.219, nll_loss=1.073, word_ins=2.895, length=3.245, ppl=9.31, wps=211447, ups=3.4, wpb=62126.7, bsz=2069.3, num_updates=159800, lr=0.000250156, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:54:48 | INFO | train_inner | epoch 081:   1288 / 1983 loss=3.265, nll_loss=1.108, word_ins=2.926, length=3.39, ppl=9.61, wps=208152, ups=3.41, wpb=60985.5, bsz=1951.9, num_updates=159900, lr=0.000250078, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:55:18 | INFO | train_inner | epoch 081:   1388 / 1983 loss=3.228, nll_loss=1.081, word_ins=2.902, length=3.258, ppl=9.37, wps=211666, ups=3.42, wpb=61857.5, bsz=1973.8, num_updates=160000, lr=0.00025, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:55:47 | INFO | train_inner | epoch 081:   1488 / 1983 loss=3.248, nll_loss=1.097, word_ins=2.917, length=3.31, ppl=9.5, wps=211993, ups=3.42, wpb=61911.2, bsz=2004.2, num_updates=160100, lr=0.000249922, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:56:16 | INFO | train_inner | epoch 081:   1588 / 1983 loss=3.258, nll_loss=1.105, word_ins=2.923, length=3.352, ppl=9.57, wps=210422, ups=3.43, wpb=61274.6, bsz=1934.2, num_updates=160200, lr=0.000249844, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:56:45 | INFO | train_inner | epoch 081:   1688 / 1983 loss=3.262, nll_loss=1.111, word_ins=2.929, length=3.334, ppl=9.59, wps=211762, ups=3.42, wpb=61837.5, bsz=1949.8, num_updates=160300, lr=0.000249766, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:57:14 | INFO | train_inner | epoch 081:   1788 / 1983 loss=3.244, nll_loss=1.094, word_ins=2.914, length=3.306, ppl=9.48, wps=210933, ups=3.42, wpb=61658, bsz=2022.8, num_updates=160400, lr=0.000249688, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:57:44 | INFO | train_inner | epoch 081:   1888 / 1983 loss=3.23, nll_loss=1.078, word_ins=2.899, length=3.302, ppl=9.38, wps=210140, ups=3.43, wpb=61348.9, bsz=2060.4, num_updates=160500, lr=0.00024961, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 07:58:24 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 3.239 | nll_loss 1.027 | word_ins 2.914 | length 3.252 | ppl 9.44 | wps 95618.9 | wpb 41551 | bsz 1500 | num_updates 160595 | best_loss 3.237
2023-03-02 07:58:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 07:58:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint81.pt (epoch 81 @ 160595 updates, score 3.239) (writing took 5.422497735940851 seconds)
2023-03-02 07:58:30 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2023-03-02 07:58:30 | INFO | train | epoch 081 | loss 3.244 | nll_loss 1.093 | word_ins 2.913 | length 3.309 | ppl 9.47 | wps 201012 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 160595 | lr 0.000249536 | gnorm 0.844 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 07:58:30 | INFO | fairseq.trainer | begin training epoch 82
2023-03-02 07:58:41 | INFO | train_inner | epoch 082:      5 / 1983 loss=3.218, nll_loss=1.071, word_ins=2.893, length=3.255, ppl=9.31, wps=107192, ups=1.75, wpb=61226.4, bsz=2031, num_updates=160600, lr=0.000249533, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:59:10 | INFO | train_inner | epoch 082:    105 / 1983 loss=3.219, nll_loss=1.072, word_ins=2.894, length=3.251, ppl=9.31, wps=210216, ups=3.42, wpb=61448, bsz=2051.8, num_updates=160700, lr=0.000249455, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 07:59:39 | INFO | train_inner | epoch 082:    205 / 1983 loss=3.246, nll_loss=1.098, word_ins=2.917, length=3.291, ppl=9.49, wps=210345, ups=3.42, wpb=61492.8, bsz=1982.6, num_updates=160800, lr=0.000249377, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:00:08 | INFO | train_inner | epoch 082:    305 / 1983 loss=3.225, nll_loss=1.074, word_ins=2.896, length=3.29, ppl=9.35, wps=212297, ups=3.44, wpb=61743.8, bsz=2013.8, num_updates=160900, lr=0.0002493, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:00:37 | INFO | train_inner | epoch 082:    405 / 1983 loss=3.221, nll_loss=1.069, word_ins=2.891, length=3.3, ppl=9.33, wps=212013, ups=3.42, wpb=61908.9, bsz=1999.2, num_updates=161000, lr=0.000249222, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:01:07 | INFO | train_inner | epoch 082:    505 / 1983 loss=3.254, nll_loss=1.103, word_ins=2.922, length=3.321, ppl=9.54, wps=210778, ups=3.42, wpb=61666.5, bsz=1942.2, num_updates=161100, lr=0.000249145, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:01:36 | INFO | train_inner | epoch 082:    605 / 1983 loss=3.247, nll_loss=1.097, word_ins=2.917, length=3.308, ppl=9.5, wps=210939, ups=3.43, wpb=61532.3, bsz=1992.9, num_updates=161200, lr=0.000249068, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:02:05 | INFO | train_inner | epoch 082:    705 / 1983 loss=3.224, nll_loss=1.075, word_ins=2.896, length=3.278, ppl=9.35, wps=211570, ups=3.43, wpb=61725.9, bsz=2052.7, num_updates=161300, lr=0.000248991, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:02:34 | INFO | train_inner | epoch 082:    805 / 1983 loss=3.24, nll_loss=1.087, word_ins=2.907, length=3.334, ppl=9.45, wps=210492, ups=3.43, wpb=61423.2, bsz=2031.8, num_updates=161400, lr=0.000248913, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:03:03 | INFO | train_inner | epoch 082:    905 / 1983 loss=3.219, nll_loss=1.07, word_ins=2.892, length=3.262, ppl=9.31, wps=212344, ups=3.42, wpb=62023.8, bsz=2011.9, num_updates=161500, lr=0.000248836, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:03:33 | INFO | train_inner | epoch 082:   1005 / 1983 loss=3.22, nll_loss=1.074, word_ins=2.895, length=3.248, ppl=9.32, wps=212739, ups=3.42, wpb=62140.4, bsz=1988.9, num_updates=161600, lr=0.000248759, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:04:02 | INFO | train_inner | epoch 082:   1105 / 1983 loss=3.247, nll_loss=1.095, word_ins=2.915, length=3.326, ppl=9.5, wps=210998, ups=3.43, wpb=61445.5, bsz=1972.8, num_updates=161700, lr=0.000248682, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:04:31 | INFO | train_inner | epoch 082:   1205 / 1983 loss=3.236, nll_loss=1.092, word_ins=2.912, length=3.246, ppl=9.42, wps=212735, ups=3.43, wpb=61978, bsz=2029, num_updates=161800, lr=0.000248606, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:05:00 | INFO | train_inner | epoch 082:   1305 / 1983 loss=3.253, nll_loss=1.101, word_ins=2.92, length=3.333, ppl=9.54, wps=211990, ups=3.43, wpb=61763, bsz=1948.6, num_updates=161900, lr=0.000248529, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:05:29 | INFO | train_inner | epoch 082:   1405 / 1983 loss=3.252, nll_loss=1.099, word_ins=2.918, length=3.334, ppl=9.52, wps=210818, ups=3.43, wpb=61551.6, bsz=1959.6, num_updates=162000, lr=0.000248452, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:05:59 | INFO | train_inner | epoch 082:   1505 / 1983 loss=3.249, nll_loss=1.098, word_ins=2.917, length=3.318, ppl=9.51, wps=210268, ups=3.4, wpb=61793.3, bsz=2034.8, num_updates=162100, lr=0.000248375, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:06:28 | INFO | train_inner | epoch 082:   1605 / 1983 loss=3.266, nll_loss=1.113, word_ins=2.931, length=3.353, ppl=9.62, wps=212552, ups=3.44, wpb=61744.4, bsz=1890.5, num_updates=162200, lr=0.000248299, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:06:57 | INFO | train_inner | epoch 082:   1705 / 1983 loss=3.291, nll_loss=1.135, word_ins=2.951, length=3.401, ppl=9.79, wps=209889, ups=3.4, wpb=61676.4, bsz=1878, num_updates=162300, lr=0.000248222, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:07:27 | INFO | train_inner | epoch 082:   1805 / 1983 loss=3.264, nll_loss=1.104, word_ins=2.922, length=3.417, ppl=9.61, wps=207938, ups=3.4, wpb=61201.7, bsz=2031.4, num_updates=162400, lr=0.000248146, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:07:56 | INFO | train_inner | epoch 082:   1905 / 1983 loss=3.243, nll_loss=1.091, word_ins=2.91, length=3.334, ppl=9.47, wps=209102, ups=3.41, wpb=61320.6, bsz=2077.8, num_updates=162500, lr=0.000248069, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 08:08:32 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 3.239 | nll_loss 1.027 | word_ins 2.91 | length 3.28 | ppl 9.44 | wps 84916.8 | wpb 41551 | bsz 1500 | num_updates 162578 | best_loss 3.237
2023-03-02 08:08:32 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 08:08:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint82.pt (epoch 82 @ 162578 updates, score 3.239) (writing took 5.684742145938799 seconds)
2023-03-02 08:08:38 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2023-03-02 08:08:38 | INFO | train | epoch 082 | loss 3.242 | nll_loss 1.091 | word_ins 2.911 | length 3.31 | ppl 9.46 | wps 200979 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 162578 | lr 0.00024801 | gnorm 0.838 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 08:08:38 | INFO | fairseq.trainer | begin training epoch 83
2023-03-02 08:08:55 | INFO | train_inner | epoch 083:     22 / 1983 loss=3.225, nll_loss=1.078, word_ins=2.899, length=3.252, ppl=9.35, wps=103198, ups=1.69, wpb=60906.9, bsz=2027.3, num_updates=162600, lr=0.000247993, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:09:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 08:09:24 | INFO | train_inner | epoch 083:    123 / 1983 loss=3.199, nll_loss=1.054, word_ins=2.878, length=3.216, ppl=9.19, wps=209550, ups=3.38, wpb=61937.1, bsz=2071, num_updates=162700, lr=0.000247917, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:09:54 | INFO | train_inner | epoch 083:    223 / 1983 loss=3.234, nll_loss=1.087, word_ins=2.908, length=3.261, ppl=9.41, wps=211454, ups=3.41, wpb=61962.8, bsz=1992.6, num_updates=162800, lr=0.000247841, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:10:23 | INFO | train_inner | epoch 083:    323 / 1983 loss=3.227, nll_loss=1.077, word_ins=2.898, length=3.29, ppl=9.36, wps=210136, ups=3.42, wpb=61452.3, bsz=1987.9, num_updates=162900, lr=0.000247765, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:10:52 | INFO | train_inner | epoch 083:    423 / 1983 loss=3.246, nll_loss=1.094, word_ins=2.914, length=3.32, ppl=9.49, wps=209372, ups=3.41, wpb=61324, bsz=1968.8, num_updates=163000, lr=0.000247689, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:11:21 | INFO | train_inner | epoch 083:    523 / 1983 loss=3.263, nll_loss=1.103, word_ins=2.922, length=3.409, ppl=9.6, wps=210208, ups=3.43, wpb=61302.3, bsz=1953, num_updates=163100, lr=0.000247613, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:11:51 | INFO | train_inner | epoch 083:    623 / 1983 loss=3.225, nll_loss=1.074, word_ins=2.895, length=3.299, ppl=9.35, wps=208956, ups=3.41, wpb=61313, bsz=2064.4, num_updates=163200, lr=0.000247537, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:12:20 | INFO | train_inner | epoch 083:    723 / 1983 loss=3.234, nll_loss=1.085, word_ins=2.905, length=3.288, ppl=9.41, wps=212436, ups=3.45, wpb=61662.7, bsz=1939, num_updates=163300, lr=0.000247461, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:12:49 | INFO | train_inner | epoch 083:    823 / 1983 loss=3.244, nll_loss=1.09, word_ins=2.91, length=3.339, ppl=9.47, wps=211847, ups=3.43, wpb=61811.8, bsz=1972.6, num_updates=163400, lr=0.000247385, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:13:18 | INFO | train_inner | epoch 083:    923 / 1983 loss=3.258, nll_loss=1.105, word_ins=2.924, length=3.339, ppl=9.56, wps=210675, ups=3.43, wpb=61475.5, bsz=1984.6, num_updates=163500, lr=0.00024731, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:13:47 | INFO | train_inner | epoch 083:   1023 / 1983 loss=3.241, nll_loss=1.092, word_ins=2.911, length=3.293, ppl=9.45, wps=211252, ups=3.42, wpb=61844.5, bsz=2064, num_updates=163600, lr=0.000247234, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:14:17 | INFO | train_inner | epoch 083:   1123 / 1983 loss=3.24, nll_loss=1.086, word_ins=2.906, length=3.342, ppl=9.45, wps=210905, ups=3.42, wpb=61705, bsz=1944.6, num_updates=163700, lr=0.000247159, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:14:46 | INFO | train_inner | epoch 083:   1223 / 1983 loss=3.236, nll_loss=1.088, word_ins=2.908, length=3.283, ppl=9.42, wps=211764, ups=3.42, wpb=61863.2, bsz=2001.2, num_updates=163800, lr=0.000247083, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:15:15 | INFO | train_inner | epoch 083:   1323 / 1983 loss=3.239, nll_loss=1.085, word_ins=2.905, length=3.333, ppl=9.44, wps=210451, ups=3.43, wpb=61399.6, bsz=1982.2, num_updates=163900, lr=0.000247008, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:15:44 | INFO | train_inner | epoch 083:   1423 / 1983 loss=3.235, nll_loss=1.084, word_ins=2.905, length=3.3, ppl=9.41, wps=209307, ups=3.42, wpb=61255.2, bsz=2036.8, num_updates=164000, lr=0.000246932, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:16:13 | INFO | train_inner | epoch 083:   1523 / 1983 loss=3.208, nll_loss=1.06, word_ins=2.882, length=3.264, ppl=9.24, wps=212227, ups=3.44, wpb=61708.8, bsz=2095.1, num_updates=164100, lr=0.000246857, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:16:43 | INFO | train_inner | epoch 083:   1623 / 1983 loss=3.217, nll_loss=1.07, word_ins=2.891, length=3.26, ppl=9.3, wps=211344, ups=3.4, wpb=62091.1, bsz=2119.5, num_updates=164200, lr=0.000246782, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:17:12 | INFO | train_inner | epoch 083:   1723 / 1983 loss=3.255, nll_loss=1.104, word_ins=2.922, length=3.324, ppl=9.55, wps=210363, ups=3.42, wpb=61544.4, bsz=1935.8, num_updates=164300, lr=0.000246707, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:17:41 | INFO | train_inner | epoch 083:   1823 / 1983 loss=3.246, nll_loss=1.09, word_ins=2.91, length=3.361, ppl=9.49, wps=210572, ups=3.42, wpb=61541.7, bsz=1944.5, num_updates=164400, lr=0.000246632, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:18:10 | INFO | train_inner | epoch 083:   1923 / 1983 loss=3.221, nll_loss=1.074, word_ins=2.895, length=3.261, ppl=9.32, wps=213712, ups=3.43, wpb=62260.6, bsz=2011, num_updates=164500, lr=0.000246557, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 08:18:41 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 3.222 | nll_loss 1.017 | word_ins 2.902 | length 3.203 | ppl 9.33 | wps 129698 | wpb 41551 | bsz 1500 | num_updates 164560 | best_loss 3.222
2023-03-02 08:18:41 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 08:18:50 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint83.pt (epoch 83 @ 164560 updates, score 3.222) (writing took 8.320521629066207 seconds)
2023-03-02 08:18:50 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2023-03-02 08:18:50 | INFO | train | epoch 083 | loss 3.236 | nll_loss 1.085 | word_ins 2.906 | length 3.306 | ppl 9.42 | wps 199667 | ups 3.24 | wpb 61628.1 | bsz 1998 | num_updates 164560 | lr 0.000246512 | gnorm 0.832 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 08:18:50 | INFO | fairseq.trainer | begin training epoch 84
2023-03-02 08:19:12 | INFO | train_inner | epoch 084:     40 / 1983 loss=3.256, nll_loss=1.103, word_ins=2.921, length=3.341, ppl=9.55, wps=100337, ups=1.64, wpb=61255.5, bsz=1871, num_updates=164600, lr=0.000246482, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:19:41 | INFO | train_inner | epoch 084:    140 / 1983 loss=3.226, nll_loss=1.076, word_ins=2.898, length=3.277, ppl=9.35, wps=211586, ups=3.43, wpb=61768.4, bsz=1995.3, num_updates=164700, lr=0.000246407, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:20:10 | INFO | train_inner | epoch 084:    240 / 1983 loss=3.206, nll_loss=1.059, word_ins=2.882, length=3.242, ppl=9.23, wps=209842, ups=3.4, wpb=61685.8, bsz=2081.2, num_updates=164800, lr=0.000246332, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:20:40 | INFO | train_inner | epoch 084:    340 / 1983 loss=3.204, nll_loss=1.056, word_ins=2.879, length=3.248, ppl=9.21, wps=209612, ups=3.4, wpb=61626.8, bsz=2091.9, num_updates=164900, lr=0.000246258, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:21:09 | INFO | train_inner | epoch 084:    440 / 1983 loss=3.25, nll_loss=1.096, word_ins=2.915, length=3.349, ppl=9.52, wps=211656, ups=3.43, wpb=61688.7, bsz=1936.4, num_updates=165000, lr=0.000246183, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:21:38 | INFO | train_inner | epoch 084:    540 / 1983 loss=3.24, nll_loss=1.089, word_ins=2.91, length=3.306, ppl=9.45, wps=212019, ups=3.42, wpb=62005, bsz=1944.9, num_updates=165100, lr=0.000246108, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:22:07 | INFO | train_inner | epoch 084:    640 / 1983 loss=3.224, nll_loss=1.071, word_ins=2.893, length=3.31, ppl=9.34, wps=209470, ups=3.45, wpb=60701.9, bsz=2073.5, num_updates=165200, lr=0.000246034, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:22:36 | INFO | train_inner | epoch 084:    740 / 1983 loss=3.239, nll_loss=1.087, word_ins=2.907, length=3.317, ppl=9.44, wps=210256, ups=3.41, wpb=61726, bsz=2016.4, num_updates=165300, lr=0.000245959, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:23:06 | INFO | train_inner | epoch 084:    840 / 1983 loss=3.238, nll_loss=1.088, word_ins=2.908, length=3.305, ppl=9.44, wps=211211, ups=3.41, wpb=61934.3, bsz=1997.8, num_updates=165400, lr=0.000245885, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:23:35 | INFO | train_inner | epoch 084:    940 / 1983 loss=3.235, nll_loss=1.084, word_ins=2.905, length=3.301, ppl=9.41, wps=210743, ups=3.43, wpb=61510.3, bsz=1987.8, num_updates=165500, lr=0.000245811, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:24:04 | INFO | train_inner | epoch 084:   1040 / 1983 loss=3.279, nll_loss=1.123, word_ins=2.94, length=3.386, ppl=9.71, wps=210108, ups=3.42, wpb=61438.2, bsz=1921.6, num_updates=165600, lr=0.000245737, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:24:33 | INFO | train_inner | epoch 084:   1140 / 1983 loss=3.235, nll_loss=1.083, word_ins=2.903, length=3.314, ppl=9.41, wps=210958, ups=3.41, wpb=61900.1, bsz=1948.3, num_updates=165700, lr=0.000245662, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:25:03 | INFO | train_inner | epoch 084:   1240 / 1983 loss=3.238, nll_loss=1.082, word_ins=2.903, length=3.353, ppl=9.44, wps=211895, ups=3.44, wpb=61676.4, bsz=1962.5, num_updates=165800, lr=0.000245588, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:25:32 | INFO | train_inner | epoch 084:   1340 / 1983 loss=3.231, nll_loss=1.078, word_ins=2.899, length=3.322, ppl=9.39, wps=210481, ups=3.43, wpb=61395, bsz=2063.4, num_updates=165900, lr=0.000245514, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:26:01 | INFO | train_inner | epoch 084:   1440 / 1983 loss=3.229, nll_loss=1.08, word_ins=2.901, length=3.282, ppl=9.38, wps=210033, ups=3.42, wpb=61463.4, bsz=2052.2, num_updates=166000, lr=0.00024544, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:26:30 | INFO | train_inner | epoch 084:   1540 / 1983 loss=3.233, nll_loss=1.079, word_ins=2.9, length=3.326, ppl=9.4, wps=212019, ups=3.43, wpb=61871.9, bsz=1982.8, num_updates=166100, lr=0.000245366, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:26:59 | INFO | train_inner | epoch 084:   1640 / 1983 loss=3.233, nll_loss=1.078, word_ins=2.899, length=3.34, ppl=9.4, wps=212404, ups=3.45, wpb=61597.5, bsz=1953, num_updates=166200, lr=0.000245293, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:27:28 | INFO | train_inner | epoch 084:   1740 / 1983 loss=3.241, nll_loss=1.096, word_ins=2.915, length=3.254, ppl=9.45, wps=211028, ups=3.41, wpb=61877.1, bsz=2007.7, num_updates=166300, lr=0.000245219, gnorm=0.807, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:27:58 | INFO | train_inner | epoch 084:   1840 / 1983 loss=3.22, nll_loss=1.074, word_ins=2.894, length=3.259, ppl=9.32, wps=212589, ups=3.43, wpb=62036.1, bsz=2039, num_updates=166400, lr=0.000245145, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:28:27 | INFO | train_inner | epoch 084:   1940 / 1983 loss=3.246, nll_loss=1.093, word_ins=2.912, length=3.337, ppl=9.49, wps=210545, ups=3.43, wpb=61343.1, bsz=1941.8, num_updates=166500, lr=0.000245072, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:28:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 08:28:53 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 3.244 | nll_loss 1.024 | word_ins 2.903 | length 3.404 | ppl 9.47 | wps 103850 | wpb 41551 | bsz 1500 | num_updates 166543 | best_loss 3.222
2023-03-02 08:28:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 08:28:58 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint84.pt (epoch 84 @ 166543 updates, score 3.244) (writing took 5.3866834320360795 seconds)
2023-03-02 08:28:58 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2023-03-02 08:28:58 | INFO | train | epoch 084 | loss 3.234 | nll_loss 1.083 | word_ins 2.903 | length 3.304 | ppl 9.41 | wps 200814 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 166543 | lr 0.00024504 | gnorm 0.828 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 08:28:58 | INFO | fairseq.trainer | begin training epoch 85
2023-03-02 08:29:25 | INFO | train_inner | epoch 085:     57 / 1983 loss=3.226, nll_loss=1.073, word_ins=2.895, length=3.318, ppl=9.36, wps=105616, ups=1.72, wpb=61374.1, bsz=1968.4, num_updates=166600, lr=0.000244998, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:29:54 | INFO | train_inner | epoch 085:    157 / 1983 loss=3.21, nll_loss=1.065, word_ins=2.887, length=3.234, ppl=9.25, wps=211865, ups=3.43, wpb=61772.5, bsz=2012.6, num_updates=166700, lr=0.000244924, gnorm=0.809, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:30:24 | INFO | train_inner | epoch 085:    257 / 1983 loss=3.217, nll_loss=1.069, word_ins=2.89, length=3.267, ppl=9.3, wps=209657, ups=3.4, wpb=61708.3, bsz=2071.4, num_updates=166800, lr=0.000244851, gnorm=0.823, loss_scale=32768, train_wall=29, wall=0
2023-03-02 08:30:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 08:30:24 | INFO | train_inner | epoch 085:    258 / 1983 loss=None, nll_loss=None, word_ins=None, length=None, ppl=0, wps=0, ups=0, wpb=None, bsz=None, num_updates=None, lr=None, gnorm=None, loss_scale=16384, train_wall=0, wall=0
2023-03-02 08:30:53 | INFO | train_inner | epoch 085:    358 / 1983 loss=3.23, nll_loss=1.078, word_ins=2.9, length=3.306, ppl=9.38, wps=213001, ups=3.43, wpb=62016.4, bsz=1982.5, num_updates=166900, lr=0.000244778, gnorm=0.812, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:31:22 | INFO | train_inner | epoch 085:    458 / 1983 loss=3.239, nll_loss=1.085, word_ins=2.906, length=3.336, ppl=9.44, wps=211043, ups=3.43, wpb=61498.1, bsz=1986.5, num_updates=167000, lr=0.000244704, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:31:51 | INFO | train_inner | epoch 085:    558 / 1983 loss=3.239, nll_loss=1.088, word_ins=2.908, length=3.307, ppl=9.44, wps=211781, ups=3.44, wpb=61643.6, bsz=1995, num_updates=167100, lr=0.000244631, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:32:20 | INFO | train_inner | epoch 085:    658 / 1983 loss=3.222, nll_loss=1.076, word_ins=2.897, length=3.244, ppl=9.33, wps=211278, ups=3.41, wpb=61892.7, bsz=2016.5, num_updates=167200, lr=0.000244558, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:32:50 | INFO | train_inner | epoch 085:    758 / 1983 loss=3.249, nll_loss=1.1, word_ins=2.919, length=3.299, ppl=9.5, wps=209098, ups=3.43, wpb=60918.3, bsz=1983.8, num_updates=167300, lr=0.000244485, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:33:19 | INFO | train_inner | epoch 085:    858 / 1983 loss=3.237, nll_loss=1.085, word_ins=2.905, length=3.318, ppl=9.43, wps=210517, ups=3.43, wpb=61363.5, bsz=1992, num_updates=167400, lr=0.000244412, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:33:48 | INFO | train_inner | epoch 085:    958 / 1983 loss=3.228, nll_loss=1.075, word_ins=2.896, length=3.322, ppl=9.37, wps=212847, ups=3.45, wpb=61770.6, bsz=2001.4, num_updates=167500, lr=0.000244339, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:34:17 | INFO | train_inner | epoch 085:   1058 / 1983 loss=3.244, nll_loss=1.093, word_ins=2.913, length=3.319, ppl=9.48, wps=210949, ups=3.43, wpb=61519.9, bsz=1956.8, num_updates=167600, lr=0.000244266, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:34:46 | INFO | train_inner | epoch 085:   1158 / 1983 loss=3.223, nll_loss=1.072, word_ins=2.893, length=3.302, ppl=9.34, wps=212739, ups=3.44, wpb=61809.3, bsz=1966, num_updates=167700, lr=0.000244193, gnorm=0.81, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:35:15 | INFO | train_inner | epoch 085:   1258 / 1983 loss=3.214, nll_loss=1.068, word_ins=2.89, length=3.244, ppl=9.28, wps=209249, ups=3.41, wpb=61379.7, bsz=2122.1, num_updates=167800, lr=0.00024412, gnorm=0.789, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:35:44 | INFO | train_inner | epoch 085:   1358 / 1983 loss=3.268, nll_loss=1.111, word_ins=2.929, length=3.392, ppl=9.63, wps=211633, ups=3.43, wpb=61729.8, bsz=1960.8, num_updates=167900, lr=0.000244048, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:36:14 | INFO | train_inner | epoch 085:   1458 / 1983 loss=3.208, nll_loss=1.063, word_ins=2.885, length=3.226, ppl=9.24, wps=211603, ups=3.42, wpb=61952.9, bsz=2057.4, num_updates=168000, lr=0.000243975, gnorm=0.801, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:36:43 | INFO | train_inner | epoch 085:   1558 / 1983 loss=3.235, nll_loss=1.085, word_ins=2.904, length=3.305, ppl=9.41, wps=210901, ups=3.43, wpb=61423.2, bsz=2009.4, num_updates=168100, lr=0.000243902, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:37:12 | INFO | train_inner | epoch 085:   1658 / 1983 loss=3.241, nll_loss=1.089, word_ins=2.909, length=3.322, ppl=9.45, wps=210806, ups=3.42, wpb=61590.6, bsz=1978.4, num_updates=168200, lr=0.00024383, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:37:41 | INFO | train_inner | epoch 085:   1758 / 1983 loss=3.236, nll_loss=1.083, word_ins=2.904, length=3.323, ppl=9.42, wps=212420, ups=3.43, wpb=61908, bsz=1976.3, num_updates=168300, lr=0.000243757, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:38:10 | INFO | train_inner | epoch 085:   1858 / 1983 loss=3.233, nll_loss=1.079, word_ins=2.899, length=3.331, ppl=9.4, wps=212601, ups=3.43, wpb=61949.3, bsz=1971.2, num_updates=168400, lr=0.000243685, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:38:40 | INFO | train_inner | epoch 085:   1958 / 1983 loss=3.249, nll_loss=1.095, word_ins=2.915, length=3.343, ppl=9.51, wps=210516, ups=3.43, wpb=61409.1, bsz=1925.6, num_updates=168500, lr=0.000243613, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 08:39:00 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 3.252 | nll_loss 1.034 | word_ins 2.924 | length 3.277 | ppl 9.53 | wps 117262 | wpb 41551 | bsz 1500 | num_updates 168525 | best_loss 3.222
2023-03-02 08:39:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 08:39:05 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint85.pt (epoch 85 @ 168525 updates, score 3.252) (writing took 5.472945380024612 seconds)
2023-03-02 08:39:05 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2023-03-02 08:39:05 | INFO | train | epoch 085 | loss 3.233 | nll_loss 1.082 | word_ins 2.902 | length 3.305 | ppl 9.4 | wps 201264 | ups 3.27 | wpb 61627 | bsz 1997.9 | num_updates 168525 | lr 0.000243595 | gnorm 0.823 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 08:39:05 | INFO | fairseq.trainer | begin training epoch 86
2023-03-02 08:39:37 | INFO | train_inner | epoch 086:     75 / 1983 loss=3.203, nll_loss=1.055, word_ins=2.878, length=3.246, ppl=9.21, wps=106735, ups=1.74, wpb=61442.6, bsz=1981.9, num_updates=168600, lr=0.000243541, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:40:06 | INFO | train_inner | epoch 086:    175 / 1983 loss=3.224, nll_loss=1.076, word_ins=2.898, length=3.261, ppl=9.34, wps=210564, ups=3.41, wpb=61692.7, bsz=2043.3, num_updates=168700, lr=0.000243468, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:40:36 | INFO | train_inner | epoch 086:    275 / 1983 loss=3.235, nll_loss=1.083, word_ins=2.904, length=3.319, ppl=9.42, wps=209994, ups=3.43, wpb=61228.8, bsz=1977.2, num_updates=168800, lr=0.000243396, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:41:05 | INFO | train_inner | epoch 086:    375 / 1983 loss=3.219, nll_loss=1.068, word_ins=2.89, length=3.29, ppl=9.31, wps=210828, ups=3.42, wpb=61578.4, bsz=2036.7, num_updates=168900, lr=0.000243324, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:41:34 | INFO | train_inner | epoch 086:    475 / 1983 loss=3.217, nll_loss=1.068, word_ins=2.89, length=3.272, ppl=9.3, wps=210329, ups=3.41, wpb=61633.6, bsz=2049.1, num_updates=169000, lr=0.000243252, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:42:03 | INFO | train_inner | epoch 086:    575 / 1983 loss=3.206, nll_loss=1.058, word_ins=2.88, length=3.26, ppl=9.23, wps=212090, ups=3.43, wpb=61771.4, bsz=2039.3, num_updates=169100, lr=0.00024318, gnorm=0.792, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:42:33 | INFO | train_inner | epoch 086:    675 / 1983 loss=3.231, nll_loss=1.081, word_ins=2.902, length=3.291, ppl=9.39, wps=210510, ups=3.42, wpb=61581.3, bsz=1999.8, num_updates=169200, lr=0.000243108, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:43:02 | INFO | train_inner | epoch 086:    775 / 1983 loss=3.227, nll_loss=1.073, word_ins=2.894, length=3.329, ppl=9.36, wps=211964, ups=3.43, wpb=61835.5, bsz=1964.7, num_updates=169300, lr=0.000243037, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:43:31 | INFO | train_inner | epoch 086:    875 / 1983 loss=3.215, nll_loss=1.064, word_ins=2.886, length=3.29, ppl=9.28, wps=213094, ups=3.44, wpb=61866, bsz=1994.6, num_updates=169400, lr=0.000242965, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:44:00 | INFO | train_inner | epoch 086:    975 / 1983 loss=3.244, nll_loss=1.092, word_ins=2.912, length=3.32, ppl=9.47, wps=209546, ups=3.43, wpb=61146.6, bsz=1992.8, num_updates=169500, lr=0.000242893, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:44:29 | INFO | train_inner | epoch 086:   1075 / 1983 loss=3.236, nll_loss=1.085, word_ins=2.905, length=3.308, ppl=9.42, wps=210971, ups=3.41, wpb=61853.4, bsz=1947.8, num_updates=169600, lr=0.000242821, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:44:59 | INFO | train_inner | epoch 086:   1175 / 1983 loss=3.213, nll_loss=1.066, word_ins=2.887, length=3.253, ppl=9.27, wps=209752, ups=3.41, wpb=61518.6, bsz=2032.4, num_updates=169700, lr=0.00024275, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:45:28 | INFO | train_inner | epoch 086:   1275 / 1983 loss=3.221, nll_loss=1.069, word_ins=2.89, length=3.306, ppl=9.32, wps=211022, ups=3.43, wpb=61546.2, bsz=2057.9, num_updates=169800, lr=0.000242678, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:45:57 | INFO | train_inner | epoch 086:   1375 / 1983 loss=3.252, nll_loss=1.097, word_ins=2.916, length=3.357, ppl=9.52, wps=211653, ups=3.42, wpb=61796.4, bsz=1941.3, num_updates=169900, lr=0.000242607, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:46:26 | INFO | train_inner | epoch 086:   1475 / 1983 loss=3.247, nll_loss=1.095, word_ins=2.914, length=3.324, ppl=9.49, wps=213074, ups=3.46, wpb=61577.4, bsz=1979.1, num_updates=170000, lr=0.000242536, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:46:55 | INFO | train_inner | epoch 086:   1575 / 1983 loss=3.234, nll_loss=1.081, word_ins=2.901, length=3.33, ppl=9.41, wps=211051, ups=3.43, wpb=61605.7, bsz=2000.4, num_updates=170100, lr=0.000242464, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:47:24 | INFO | train_inner | epoch 086:   1675 / 1983 loss=3.237, nll_loss=1.084, word_ins=2.904, length=3.33, ppl=9.43, wps=211736, ups=3.43, wpb=61752.6, bsz=1936.3, num_updates=170200, lr=0.000242393, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:47:53 | INFO | train_inner | epoch 086:   1775 / 1983 loss=3.237, nll_loss=1.082, word_ins=2.902, length=3.347, ppl=9.43, wps=212195, ups=3.44, wpb=61768.4, bsz=1991.6, num_updates=170300, lr=0.000242322, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:48:22 | INFO | train_inner | epoch 086:   1875 / 1983 loss=3.233, nll_loss=1.084, word_ins=2.904, length=3.291, ppl=9.4, wps=211484, ups=3.43, wpb=61653.5, bsz=1983.9, num_updates=170400, lr=0.000242251, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:48:52 | INFO | train_inner | epoch 086:   1975 / 1983 loss=3.23, nll_loss=1.081, word_ins=2.901, length=3.285, ppl=9.38, wps=211150, ups=3.41, wpb=61837, bsz=2019, num_updates=170500, lr=0.00024218, gnorm=0.81, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 08:49:07 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 3.243 | nll_loss 1.031 | word_ins 2.913 | length 3.294 | ppl 9.47 | wps 99287.1 | wpb 41551 | bsz 1500 | num_updates 170508 | best_loss 3.222
2023-03-02 08:49:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 08:49:12 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint86.pt (epoch 86 @ 170508 updates, score 3.243) (writing took 5.329527340014465 seconds)
2023-03-02 08:49:12 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2023-03-02 08:49:12 | INFO | train | epoch 086 | loss 3.228 | nll_loss 1.077 | word_ins 2.898 | length 3.3 | ppl 9.37 | wps 201331 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 170508 | lr 0.000242174 | gnorm 0.817 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 08:49:12 | INFO | fairseq.trainer | begin training epoch 87
2023-03-02 08:49:49 | INFO | train_inner | epoch 087:     92 / 1983 loss=3.214, nll_loss=1.069, word_ins=2.891, length=3.23, ppl=9.28, wps=106419, ups=1.74, wpb=61335.9, bsz=1972.1, num_updates=170600, lr=0.000242109, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:50:19 | INFO | train_inner | epoch 087:    192 / 1983 loss=3.203, nll_loss=1.058, word_ins=2.881, length=3.226, ppl=9.21, wps=213124, ups=3.43, wpb=62167.6, bsz=2038.4, num_updates=170700, lr=0.000242038, gnorm=0.812, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:50:48 | INFO | train_inner | epoch 087:    292 / 1983 loss=3.257, nll_loss=1.103, word_ins=2.922, length=3.35, ppl=9.56, wps=211165, ups=3.43, wpb=61649.1, bsz=1878.3, num_updates=170800, lr=0.000241967, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:51:17 | INFO | train_inner | epoch 087:    392 / 1983 loss=3.23, nll_loss=1.08, word_ins=2.901, length=3.293, ppl=9.38, wps=211803, ups=3.42, wpb=61957.4, bsz=1966.7, num_updates=170900, lr=0.000241896, gnorm=0.827, loss_scale=32768, train_wall=29, wall=0
2023-03-02 08:51:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 08:51:46 | INFO | train_inner | epoch 087:    493 / 1983 loss=3.241, nll_loss=1.087, word_ins=2.908, length=3.332, ppl=9.45, wps=209275, ups=3.4, wpb=61614.9, bsz=1905.4, num_updates=171000, lr=0.000241825, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:52:16 | INFO | train_inner | epoch 087:    593 / 1983 loss=3.226, nll_loss=1.074, word_ins=2.895, length=3.306, ppl=9.35, wps=210744, ups=3.43, wpb=61408.1, bsz=2012.3, num_updates=171100, lr=0.000241755, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:52:45 | INFO | train_inner | epoch 087:    693 / 1983 loss=3.219, nll_loss=1.069, word_ins=2.89, length=3.289, ppl=9.31, wps=210854, ups=3.41, wpb=61824.6, bsz=2040.7, num_updates=171200, lr=0.000241684, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:53:14 | INFO | train_inner | epoch 087:    793 / 1983 loss=3.217, nll_loss=1.068, word_ins=2.89, length=3.277, ppl=9.3, wps=209175, ups=3.43, wpb=60952.7, bsz=2036.8, num_updates=171300, lr=0.000241614, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:53:43 | INFO | train_inner | epoch 087:    893 / 1983 loss=3.235, nll_loss=1.084, word_ins=2.904, length=3.308, ppl=9.42, wps=211386, ups=3.44, wpb=61486.9, bsz=1946.6, num_updates=171400, lr=0.000241543, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:54:12 | INFO | train_inner | epoch 087:    993 / 1983 loss=3.256, nll_loss=1.101, word_ins=2.92, length=3.36, ppl=9.55, wps=209432, ups=3.43, wpb=61055.8, bsz=1965.4, num_updates=171500, lr=0.000241473, gnorm=0.801, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:54:42 | INFO | train_inner | epoch 087:   1093 / 1983 loss=3.227, nll_loss=1.074, word_ins=2.895, length=3.32, ppl=9.36, wps=210611, ups=3.42, wpb=61536.3, bsz=2002.4, num_updates=171600, lr=0.000241402, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:55:11 | INFO | train_inner | epoch 087:   1193 / 1983 loss=3.222, nll_loss=1.075, word_ins=2.896, length=3.268, ppl=9.33, wps=212641, ups=3.43, wpb=61936.4, bsz=1998.8, num_updates=171700, lr=0.000241332, gnorm=0.802, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:55:40 | INFO | train_inner | epoch 087:   1293 / 1983 loss=3.225, nll_loss=1.076, word_ins=2.897, length=3.288, ppl=9.35, wps=211612, ups=3.42, wpb=61850.7, bsz=2046.2, num_updates=171800, lr=0.000241262, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:56:09 | INFO | train_inner | epoch 087:   1393 / 1983 loss=3.204, nll_loss=1.056, word_ins=2.878, length=3.251, ppl=9.21, wps=210267, ups=3.42, wpb=61548.7, bsz=2103.9, num_updates=171900, lr=0.000241192, gnorm=0.802, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:56:39 | INFO | train_inner | epoch 087:   1493 / 1983 loss=3.219, nll_loss=1.077, word_ins=2.897, length=3.222, ppl=9.31, wps=210437, ups=3.41, wpb=61705.3, bsz=2035.4, num_updates=172000, lr=0.000241121, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:57:08 | INFO | train_inner | epoch 087:   1593 / 1983 loss=3.246, nll_loss=1.091, word_ins=2.91, length=3.359, ppl=9.49, wps=209496, ups=3.42, wpb=61303.6, bsz=1996.5, num_updates=172100, lr=0.000241051, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:57:37 | INFO | train_inner | epoch 087:   1693 / 1983 loss=3.198, nll_loss=1.052, word_ins=2.875, length=3.228, ppl=9.18, wps=212455, ups=3.43, wpb=62028.8, bsz=2059.8, num_updates=172200, lr=0.000240981, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:58:06 | INFO | train_inner | epoch 087:   1793 / 1983 loss=3.222, nll_loss=1.075, word_ins=2.896, length=3.261, ppl=9.33, wps=210764, ups=3.42, wpb=61583.7, bsz=2049, num_updates=172300, lr=0.000240911, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:58:35 | INFO | train_inner | epoch 087:   1893 / 1983 loss=3.256, nll_loss=1.102, word_ins=2.92, length=3.367, ppl=9.56, wps=211367, ups=3.43, wpb=61626.1, bsz=1957.9, num_updates=172400, lr=0.000240842, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 08:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 08:59:14 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 3.228 | nll_loss 1.012 | word_ins 2.901 | length 3.276 | ppl 9.37 | wps 83856.5 | wpb 41551 | bsz 1500 | num_updates 172490 | best_loss 3.222
2023-03-02 08:59:14 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 08:59:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint87.pt (epoch 87 @ 172490 updates, score 3.228) (writing took 5.556579443044029 seconds)
2023-03-02 08:59:20 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2023-03-02 08:59:20 | INFO | train | epoch 087 | loss 3.228 | nll_loss 1.078 | word_ins 2.899 | length 3.294 | ppl 9.37 | wps 201008 | ups 3.26 | wpb 61630.4 | bsz 1997.8 | num_updates 172490 | lr 0.000240779 | gnorm 0.816 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 08:59:20 | INFO | fairseq.trainer | begin training epoch 88
2023-03-02 08:59:33 | INFO | train_inner | epoch 088:     10 / 1983 loss=3.23, nll_loss=1.079, word_ins=2.899, length=3.305, ppl=9.38, wps=106940, ups=1.74, wpb=61573.2, bsz=1963.8, num_updates=172500, lr=0.000240772, gnorm=0.796, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:00:02 | INFO | train_inner | epoch 088:    110 / 1983 loss=3.215, nll_loss=1.065, word_ins=2.887, length=3.278, ppl=9.28, wps=211779, ups=3.44, wpb=61616.4, bsz=1957.4, num_updates=172600, lr=0.000240702, gnorm=0.809, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:00:31 | INFO | train_inner | epoch 088:    210 / 1983 loss=3.203, nll_loss=1.062, word_ins=2.884, length=3.183, ppl=9.21, wps=212437, ups=3.41, wpb=62282.2, bsz=2054.9, num_updates=172700, lr=0.000240632, gnorm=0.788, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:01:01 | INFO | train_inner | epoch 088:    310 / 1983 loss=3.177, nll_loss=1.033, word_ins=2.858, length=3.196, ppl=9.05, wps=211533, ups=3.41, wpb=61984.1, bsz=2140.5, num_updates=172800, lr=0.000240563, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:01:30 | INFO | train_inner | epoch 088:    410 / 1983 loss=3.218, nll_loss=1.066, word_ins=2.888, length=3.3, ppl=9.31, wps=210762, ups=3.43, wpb=61495.3, bsz=1955.9, num_updates=172900, lr=0.000240493, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:01:59 | INFO | train_inner | epoch 088:    510 / 1983 loss=3.242, nll_loss=1.084, word_ins=2.904, length=3.377, ppl=9.46, wps=208081, ups=3.41, wpb=61029.3, bsz=1954.3, num_updates=173000, lr=0.000240424, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:02:28 | INFO | train_inner | epoch 088:    610 / 1983 loss=3.206, nll_loss=1.059, word_ins=2.881, length=3.242, ppl=9.23, wps=212150, ups=3.43, wpb=61847.7, bsz=1978.5, num_updates=173100, lr=0.000240354, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:02:58 | INFO | train_inner | epoch 088:    710 / 1983 loss=3.209, nll_loss=1.064, word_ins=2.886, length=3.234, ppl=9.25, wps=211482, ups=3.42, wpb=61879.5, bsz=2098.6, num_updates=173200, lr=0.000240285, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:03:27 | INFO | train_inner | epoch 088:    810 / 1983 loss=3.227, nll_loss=1.076, word_ins=2.897, length=3.296, ppl=9.36, wps=212325, ups=3.43, wpb=61883.2, bsz=2002.3, num_updates=173300, lr=0.000240215, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:03:56 | INFO | train_inner | epoch 088:    910 / 1983 loss=3.228, nll_loss=1.075, word_ins=2.896, length=3.314, ppl=9.37, wps=213691, ups=3.45, wpb=61887, bsz=2005.6, num_updates=173400, lr=0.000240146, gnorm=0.799, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:04:25 | INFO | train_inner | epoch 088:   1010 / 1983 loss=3.244, nll_loss=1.09, word_ins=2.91, length=3.343, ppl=9.48, wps=212723, ups=3.45, wpb=61726.2, bsz=1864.2, num_updates=173500, lr=0.000240077, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:04:54 | INFO | train_inner | epoch 088:   1110 / 1983 loss=3.226, nll_loss=1.077, word_ins=2.897, length=3.289, ppl=9.36, wps=210340, ups=3.4, wpb=61821.9, bsz=1997.9, num_updates=173600, lr=0.000240008, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:05:23 | INFO | train_inner | epoch 088:   1210 / 1983 loss=3.229, nll_loss=1.077, word_ins=2.898, length=3.312, ppl=9.38, wps=210617, ups=3.42, wpb=61592.2, bsz=2017.3, num_updates=173700, lr=0.000239939, gnorm=0.807, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:05:53 | INFO | train_inner | epoch 088:   1310 / 1983 loss=3.208, nll_loss=1.06, word_ins=2.882, length=3.257, ppl=9.24, wps=210442, ups=3.42, wpb=61448, bsz=2060, num_updates=173800, lr=0.00023987, gnorm=0.774, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:06:22 | INFO | train_inner | epoch 088:   1410 / 1983 loss=3.237, nll_loss=1.088, word_ins=2.907, length=3.297, ppl=9.43, wps=209716, ups=3.42, wpb=61317.4, bsz=2008.6, num_updates=173900, lr=0.000239801, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:06:51 | INFO | train_inner | epoch 088:   1510 / 1983 loss=3.25, nll_loss=1.094, word_ins=2.914, length=3.366, ppl=9.51, wps=211142, ups=3.43, wpb=61611.2, bsz=1934.8, num_updates=174000, lr=0.000239732, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:07:20 | INFO | train_inner | epoch 088:   1610 / 1983 loss=3.235, nll_loss=1.086, word_ins=2.906, length=3.294, ppl=9.42, wps=211713, ups=3.44, wpb=61589.2, bsz=1978.6, num_updates=174100, lr=0.000239663, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:07:49 | INFO | train_inner | epoch 088:   1710 / 1983 loss=3.218, nll_loss=1.066, word_ins=2.888, length=3.296, ppl=9.3, wps=209899, ups=3.42, wpb=61297.7, bsz=2071, num_updates=174200, lr=0.000239594, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:08:18 | INFO | train_inner | epoch 088:   1810 / 1983 loss=3.26, nll_loss=1.105, word_ins=2.923, length=3.375, ppl=9.58, wps=211379, ups=3.44, wpb=61464.1, bsz=1856.5, num_updates=174300, lr=0.000239525, gnorm=0.804, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:08:48 | INFO | train_inner | epoch 088:   1910 / 1983 loss=3.252, nll_loss=1.099, word_ins=2.918, length=3.339, ppl=9.53, wps=209081, ups=3.41, wpb=61237.3, bsz=1922.8, num_updates=174400, lr=0.000239457, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:09:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 09:09:22 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 3.233 | nll_loss 1.009 | word_ins 2.9 | length 3.329 | ppl 9.4 | wps 89970.8 | wpb 41551 | bsz 1500 | num_updates 174473 | best_loss 3.222
2023-03-02 09:09:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 09:09:28 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint88.pt (epoch 88 @ 174473 updates, score 3.233) (writing took 5.618215107009746 seconds)
2023-03-02 09:09:28 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2023-03-02 09:09:28 | INFO | train | epoch 088 | loss 3.224 | nll_loss 1.074 | word_ins 2.895 | length 3.29 | ppl 9.34 | wps 201024 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 174473 | lr 0.000239406 | gnorm 0.815 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 09:09:28 | INFO | fairseq.trainer | begin training epoch 89
2023-03-02 09:09:46 | INFO | train_inner | epoch 089:     27 / 1983 loss=3.195, nll_loss=1.052, word_ins=2.875, length=3.198, ppl=9.16, wps=105914, ups=1.72, wpb=61508.4, bsz=2104.1, num_updates=174500, lr=0.000239388, gnorm=0.809, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:10:15 | INFO | train_inner | epoch 089:    127 / 1983 loss=3.236, nll_loss=1.082, word_ins=2.903, length=3.33, ppl=9.42, wps=211085, ups=3.44, wpb=61363.1, bsz=1888.6, num_updates=174600, lr=0.000239319, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:10:44 | INFO | train_inner | epoch 089:    227 / 1983 loss=3.185, nll_loss=1.046, word_ins=2.87, length=3.15, ppl=9.09, wps=211774, ups=3.4, wpb=62257.6, bsz=2044.6, num_updates=174700, lr=0.000239251, gnorm=0.791, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:11:13 | INFO | train_inner | epoch 089:    327 / 1983 loss=3.235, nll_loss=1.084, word_ins=2.904, length=3.313, ppl=9.42, wps=212920, ups=3.45, wpb=61716.7, bsz=1951.8, num_updates=174800, lr=0.000239182, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:11:43 | INFO | train_inner | epoch 089:    427 / 1983 loss=3.239, nll_loss=1.086, word_ins=2.906, length=3.325, ppl=9.44, wps=209546, ups=3.41, wpb=61369.4, bsz=2021.5, num_updates=174900, lr=0.000239114, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:12:12 | INFO | train_inner | epoch 089:    527 / 1983 loss=3.225, nll_loss=1.075, word_ins=2.896, length=3.284, ppl=9.35, wps=212443, ups=3.42, wpb=62112, bsz=1964.4, num_updates=175000, lr=0.000239046, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:12:41 | INFO | train_inner | epoch 089:    627 / 1983 loss=3.233, nll_loss=1.08, word_ins=2.9, length=3.324, ppl=9.4, wps=210217, ups=3.43, wpb=61269.3, bsz=1924.1, num_updates=175100, lr=0.000238977, gnorm=0.811, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:13:10 | INFO | train_inner | epoch 089:    727 / 1983 loss=3.216, nll_loss=1.07, word_ins=2.891, length=3.256, ppl=9.29, wps=211569, ups=3.44, wpb=61586.1, bsz=2031, num_updates=175200, lr=0.000238909, gnorm=0.793, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:13:39 | INFO | train_inner | epoch 089:    827 / 1983 loss=3.189, nll_loss=1.042, word_ins=2.866, length=3.227, ppl=9.12, wps=211297, ups=3.42, wpb=61775.1, bsz=2127.1, num_updates=175300, lr=0.000238841, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:14:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 09:14:09 | INFO | train_inner | epoch 089:    928 / 1983 loss=3.21, nll_loss=1.064, word_ins=2.886, length=3.246, ppl=9.26, wps=209886, ups=3.38, wpb=62066.3, bsz=1998.5, num_updates=175400, lr=0.000238773, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:14:38 | INFO | train_inner | epoch 089:   1028 / 1983 loss=3.206, nll_loss=1.056, word_ins=2.878, length=3.279, ppl=9.23, wps=208766, ups=3.41, wpb=61136.4, bsz=2098.5, num_updates=175500, lr=0.000238705, gnorm=0.804, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:15:08 | INFO | train_inner | epoch 089:   1128 / 1983 loss=3.216, nll_loss=1.07, word_ins=2.891, length=3.247, ppl=9.29, wps=209837, ups=3.39, wpb=61839.1, bsz=2072.8, num_updates=175600, lr=0.000238637, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:15:37 | INFO | train_inner | epoch 089:   1228 / 1983 loss=3.237, nll_loss=1.083, word_ins=2.903, length=3.345, ppl=9.43, wps=210113, ups=3.43, wpb=61229, bsz=1959.7, num_updates=175700, lr=0.000238569, gnorm=0.798, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:16:06 | INFO | train_inner | epoch 089:   1328 / 1983 loss=3.224, nll_loss=1.074, word_ins=2.895, length=3.282, ppl=9.34, wps=212026, ups=3.42, wpb=61911.6, bsz=1964.3, num_updates=175800, lr=0.000238501, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:16:35 | INFO | train_inner | epoch 089:   1428 / 1983 loss=3.214, nll_loss=1.067, word_ins=2.889, length=3.254, ppl=9.28, wps=211204, ups=3.43, wpb=61602.3, bsz=1995, num_updates=175900, lr=0.000238433, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:17:04 | INFO | train_inner | epoch 089:   1528 / 1983 loss=3.225, nll_loss=1.072, word_ins=2.893, length=3.32, ppl=9.35, wps=211178, ups=3.44, wpb=61350.2, bsz=1927.1, num_updates=176000, lr=0.000238366, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:17:33 | INFO | train_inner | epoch 089:   1628 / 1983 loss=3.237, nll_loss=1.086, word_ins=2.905, length=3.319, ppl=9.43, wps=210318, ups=3.43, wpb=61256.8, bsz=2009.6, num_updates=176100, lr=0.000238298, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:18:03 | INFO | train_inner | epoch 089:   1728 / 1983 loss=3.246, nll_loss=1.096, word_ins=2.914, length=3.318, ppl=9.49, wps=210586, ups=3.41, wpb=61828.4, bsz=1959, num_updates=176200, lr=0.00023823, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:18:32 | INFO | train_inner | epoch 089:   1828 / 1983 loss=3.221, nll_loss=1.069, word_ins=2.89, length=3.308, ppl=9.33, wps=210580, ups=3.41, wpb=61803.5, bsz=2016.9, num_updates=176300, lr=0.000238163, gnorm=0.788, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:19:01 | INFO | train_inner | epoch 089:   1928 / 1983 loss=3.221, nll_loss=1.071, word_ins=2.893, length=3.283, ppl=9.32, wps=212659, ups=3.42, wpb=62143.2, bsz=1985, num_updates=176400, lr=0.000238095, gnorm=0.809, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:19:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 09:19:30 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 3.23 | nll_loss 1.017 | word_ins 2.903 | length 3.276 | ppl 9.39 | wps 131569 | wpb 41551 | bsz 1500 | num_updates 176455 | best_loss 3.222
2023-03-02 09:19:30 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 09:19:36 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint89.pt (epoch 89 @ 176455 updates, score 3.23) (writing took 5.654611204052344 seconds)
2023-03-02 09:19:36 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2023-03-02 09:19:36 | INFO | train | epoch 089 | loss 3.221 | nll_loss 1.072 | word_ins 2.893 | length 3.284 | ppl 9.33 | wps 200931 | ups 3.26 | wpb 61628.4 | bsz 1997.7 | num_updates 176455 | lr 0.000238058 | gnorm 0.811 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 09:19:36 | INFO | fairseq.trainer | begin training epoch 90
2023-03-02 09:19:59 | INFO | train_inner | epoch 090:     45 / 1983 loss=3.226, nll_loss=1.076, word_ins=2.897, length=3.293, ppl=9.36, wps=104909, ups=1.72, wpb=60889.7, bsz=1988.1, num_updates=176500, lr=0.000238028, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:20:29 | INFO | train_inner | epoch 090:    145 / 1983 loss=3.227, nll_loss=1.071, word_ins=2.893, length=3.347, ppl=9.37, wps=209803, ups=3.41, wpb=61494.4, bsz=2016.5, num_updates=176600, lr=0.00023796, gnorm=0.812, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:20:58 | INFO | train_inner | epoch 090:    245 / 1983 loss=3.191, nll_loss=1.049, word_ins=2.872, length=3.194, ppl=9.13, wps=211893, ups=3.42, wpb=61881.3, bsz=2046.9, num_updates=176700, lr=0.000237893, gnorm=0.793, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:21:27 | INFO | train_inner | epoch 090:    345 / 1983 loss=3.175, nll_loss=1.031, word_ins=2.856, length=3.193, ppl=9.03, wps=210906, ups=3.41, wpb=61835.5, bsz=2120.8, num_updates=176800, lr=0.000237826, gnorm=0.791, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:21:56 | INFO | train_inner | epoch 090:    445 / 1983 loss=3.224, nll_loss=1.073, word_ins=2.894, length=3.3, ppl=9.35, wps=212176, ups=3.44, wpb=61736.3, bsz=1987.5, num_updates=176900, lr=0.000237759, gnorm=0.804, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:22:25 | INFO | train_inner | epoch 090:    545 / 1983 loss=3.218, nll_loss=1.065, word_ins=2.887, length=3.306, ppl=9.3, wps=211421, ups=3.43, wpb=61571.9, bsz=1974.1, num_updates=177000, lr=0.000237691, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:22:54 | INFO | train_inner | epoch 090:    645 / 1983 loss=3.201, nll_loss=1.053, word_ins=2.876, length=3.25, ppl=9.2, wps=211785, ups=3.43, wpb=61704.7, bsz=1998.2, num_updates=177100, lr=0.000237624, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:23:24 | INFO | train_inner | epoch 090:    745 / 1983 loss=3.23, nll_loss=1.077, word_ins=2.897, length=3.328, ppl=9.38, wps=211134, ups=3.43, wpb=61583, bsz=1963.1, num_updates=177200, lr=0.000237557, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:23:53 | INFO | train_inner | epoch 090:    845 / 1983 loss=3.218, nll_loss=1.069, word_ins=2.891, length=3.272, ppl=9.31, wps=210608, ups=3.42, wpb=61497.5, bsz=2048.5, num_updates=177300, lr=0.00023749, gnorm=0.786, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:24:22 | INFO | train_inner | epoch 090:    945 / 1983 loss=3.212, nll_loss=1.065, word_ins=2.886, length=3.26, ppl=9.27, wps=210296, ups=3.42, wpb=61578.3, bsz=1991, num_updates=177400, lr=0.000237423, gnorm=0.802, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:24:51 | INFO | train_inner | epoch 090:   1045 / 1983 loss=3.229, nll_loss=1.078, word_ins=2.898, length=3.307, ppl=9.38, wps=210933, ups=3.41, wpb=61796.8, bsz=1987.3, num_updates=177500, lr=0.000237356, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:25:21 | INFO | train_inner | epoch 090:   1145 / 1983 loss=3.237, nll_loss=1.084, word_ins=2.904, length=3.336, ppl=9.43, wps=210135, ups=3.43, wpb=61186.4, bsz=1899.9, num_updates=177600, lr=0.000237289, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:25:50 | INFO | train_inner | epoch 090:   1245 / 1983 loss=3.207, nll_loss=1.062, word_ins=2.883, length=3.236, ppl=9.23, wps=213692, ups=3.45, wpb=61922.5, bsz=1958, num_updates=177700, lr=0.000237223, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:26:19 | INFO | train_inner | epoch 090:   1345 / 1983 loss=3.236, nll_loss=1.087, word_ins=2.907, length=3.293, ppl=9.42, wps=209568, ups=3.4, wpb=61671.5, bsz=1944.6, num_updates=177800, lr=0.000237156, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:26:48 | INFO | train_inner | epoch 090:   1445 / 1983 loss=3.23, nll_loss=1.079, word_ins=2.899, length=3.309, ppl=9.38, wps=211408, ups=3.41, wpb=62000.9, bsz=1985.8, num_updates=177900, lr=0.000237089, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:27:18 | INFO | train_inner | epoch 090:   1545 / 1983 loss=3.219, nll_loss=1.064, word_ins=2.886, length=3.333, ppl=9.31, wps=209152, ups=3.42, wpb=61116.7, bsz=1991.4, num_updates=178000, lr=0.000237023, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:27:47 | INFO | train_inner | epoch 090:   1645 / 1983 loss=3.21, nll_loss=1.063, word_ins=2.885, length=3.255, ppl=9.25, wps=209810, ups=3.42, wpb=61283.4, bsz=2053.2, num_updates=178100, lr=0.000236956, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:28:16 | INFO | train_inner | epoch 090:   1745 / 1983 loss=3.225, nll_loss=1.071, word_ins=2.892, length=3.334, ppl=9.35, wps=212884, ups=3.44, wpb=61805.7, bsz=1950.5, num_updates=178200, lr=0.00023689, gnorm=0.797, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:28:45 | INFO | train_inner | epoch 090:   1845 / 1983 loss=3.238, nll_loss=1.09, word_ins=2.909, length=3.284, ppl=9.43, wps=212015, ups=3.41, wpb=62152.7, bsz=1943, num_updates=178300, lr=0.000236823, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:29:14 | INFO | train_inner | epoch 090:   1945 / 1983 loss=3.218, nll_loss=1.069, word_ins=2.89, length=3.273, ppl=9.3, wps=210130, ups=3.41, wpb=61675, bsz=2073.4, num_updates=178400, lr=0.000236757, gnorm=0.796, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 09:29:38 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 3.218 | nll_loss 1.009 | word_ins 2.892 | length 3.256 | ppl 9.3 | wps 94523.7 | wpb 41551 | bsz 1500 | num_updates 178438 | best_loss 3.218
2023-03-02 09:29:38 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 09:29:47 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint90.pt (epoch 90 @ 178438 updates, score 3.218) (writing took 8.399327380000614 seconds)
2023-03-02 09:29:47 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2023-03-02 09:29:47 | INFO | train | epoch 090 | loss 3.218 | nll_loss 1.069 | word_ins 2.89 | length 3.283 | ppl 9.31 | wps 199939 | ups 3.24 | wpb 61628.5 | bsz 1997.6 | num_updates 178438 | lr 0.000236732 | gnorm 0.806 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 09:29:47 | INFO | fairseq.trainer | begin training epoch 91
2023-03-02 09:30:15 | INFO | train_inner | epoch 091:     62 / 1983 loss=3.213, nll_loss=1.066, word_ins=2.887, length=3.258, ppl=9.27, wps=100649, ups=1.66, wpb=60784.9, bsz=1988.3, num_updates=178500, lr=0.000236691, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:30:44 | INFO | train_inner | epoch 091:    162 / 1983 loss=3.229, nll_loss=1.076, word_ins=2.897, length=3.314, ppl=9.38, wps=209110, ups=3.41, wpb=61302.3, bsz=1912.5, num_updates=178600, lr=0.000236624, gnorm=0.807, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:31:13 | INFO | train_inner | epoch 091:    262 / 1983 loss=3.207, nll_loss=1.057, word_ins=2.879, length=3.279, ppl=9.24, wps=211195, ups=3.43, wpb=61582.5, bsz=2006.1, num_updates=178700, lr=0.000236558, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:31:42 | INFO | train_inner | epoch 091:    362 / 1983 loss=3.202, nll_loss=1.047, word_ins=2.871, length=3.309, ppl=9.2, wps=211180, ups=3.43, wpb=61617.9, bsz=2037.8, num_updates=178800, lr=0.000236492, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:32:12 | INFO | train_inner | epoch 091:    462 / 1983 loss=3.215, nll_loss=1.062, word_ins=2.884, length=3.303, ppl=9.28, wps=210340, ups=3.43, wpb=61374.1, bsz=2013.8, num_updates=178900, lr=0.000236426, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:32:41 | INFO | train_inner | epoch 091:    562 / 1983 loss=3.218, nll_loss=1.07, word_ins=2.891, length=3.266, ppl=9.31, wps=212445, ups=3.41, wpb=62248.9, bsz=1994.3, num_updates=179000, lr=0.00023636, gnorm=0.8, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:33:10 | INFO | train_inner | epoch 091:    662 / 1983 loss=3.224, nll_loss=1.077, word_ins=2.898, length=3.26, ppl=9.34, wps=211368, ups=3.42, wpb=61729.3, bsz=1939.5, num_updates=179100, lr=0.000236294, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:33:39 | INFO | train_inner | epoch 091:    762 / 1983 loss=3.2, nll_loss=1.05, word_ins=2.873, length=3.273, ppl=9.19, wps=210715, ups=3.41, wpb=61706.8, bsz=2064.3, num_updates=179200, lr=0.000236228, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:34:09 | INFO | train_inner | epoch 091:    862 / 1983 loss=3.203, nll_loss=1.058, word_ins=2.88, length=3.228, ppl=9.21, wps=212424, ups=3.43, wpb=61892.9, bsz=2028.3, num_updates=179300, lr=0.000236162, gnorm=0.794, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:34:38 | INFO | train_inner | epoch 091:    962 / 1983 loss=3.217, nll_loss=1.066, word_ins=2.887, length=3.298, ppl=9.3, wps=209748, ups=3.4, wpb=61642.7, bsz=1941.8, num_updates=179400, lr=0.000236096, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 09:35:07 | INFO | train_inner | epoch 091:   1062 / 1983 loss=3.234, nll_loss=1.076, word_ins=2.897, length=3.369, ppl=9.41, wps=212550, ups=3.44, wpb=61701.7, bsz=1916.9, num_updates=179500, lr=0.00023603, gnorm=0.806, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:35:36 | INFO | train_inner | epoch 091:   1162 / 1983 loss=3.218, nll_loss=1.068, word_ins=2.89, length=3.288, ppl=9.31, wps=210719, ups=3.42, wpb=61524.8, bsz=1951.4, num_updates=179600, lr=0.000235965, gnorm=0.795, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:36:06 | INFO | train_inner | epoch 091:   1262 / 1983 loss=3.222, nll_loss=1.07, word_ins=2.892, length=3.302, ppl=9.33, wps=211094, ups=3.42, wpb=61778.8, bsz=1986.9, num_updates=179700, lr=0.000235899, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:36:35 | INFO | train_inner | epoch 091:   1362 / 1983 loss=3.195, nll_loss=1.05, word_ins=2.873, length=3.222, ppl=9.16, wps=210506, ups=3.4, wpb=61834.6, bsz=2098.2, num_updates=179800, lr=0.000235833, gnorm=0.781, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:37:04 | INFO | train_inner | epoch 091:   1462 / 1983 loss=3.196, nll_loss=1.053, word_ins=2.875, length=3.205, ppl=9.16, wps=212457, ups=3.41, wpb=62279.3, bsz=2062.5, num_updates=179900, lr=0.000235768, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:37:33 | INFO | train_inner | epoch 091:   1562 / 1983 loss=3.257, nll_loss=1.098, word_ins=2.917, length=3.4, ppl=9.56, wps=211265, ups=3.44, wpb=61403.8, bsz=1896.8, num_updates=180000, lr=0.000235702, gnorm=0.831, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:38:03 | INFO | train_inner | epoch 091:   1662 / 1983 loss=3.237, nll_loss=1.086, word_ins=2.905, length=3.318, ppl=9.43, wps=207892, ups=3.38, wpb=61470.9, bsz=1983.1, num_updates=180100, lr=0.000235637, gnorm=0.831, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:38:32 | INFO | train_inner | epoch 091:   1762 / 1983 loss=3.211, nll_loss=1.064, word_ins=2.885, length=3.255, ppl=9.26, wps=209797, ups=3.4, wpb=61677.3, bsz=2086.4, num_updates=180200, lr=0.000235571, gnorm=0.794, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:39:02 | INFO | train_inner | epoch 091:   1862 / 1983 loss=3.216, nll_loss=1.067, word_ins=2.888, length=3.282, ppl=9.29, wps=208834, ups=3.41, wpb=61265.8, bsz=2048.1, num_updates=180300, lr=0.000235506, gnorm=0.783, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:39:31 | INFO | train_inner | epoch 091:   1962 / 1983 loss=3.204, nll_loss=1.057, word_ins=2.879, length=3.255, ppl=9.22, wps=210328, ups=3.41, wpb=61678.7, bsz=2042.8, num_updates=180400, lr=0.000235441, gnorm=0.793, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 09:39:51 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 3.232 | nll_loss 1.023 | word_ins 2.906 | length 3.265 | ppl 9.4 | wps 82443.3 | wpb 41551 | bsz 1500 | num_updates 180421 | best_loss 3.218
2023-03-02 09:39:51 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 09:39:57 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint91.pt (epoch 91 @ 180421 updates, score 3.232) (writing took 5.70491922297515 seconds)
2023-03-02 09:39:57 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2023-03-02 09:39:57 | INFO | train | epoch 091 | loss 3.216 | nll_loss 1.066 | word_ins 2.888 | length 3.286 | ppl 9.29 | wps 200331 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 180421 | lr 0.000235427 | gnorm 0.803 | loss_scale 32768 | train_wall 578 | wall 0
2023-03-02 09:39:57 | INFO | fairseq.trainer | begin training epoch 92
2023-03-02 09:40:31 | INFO | train_inner | epoch 092:     79 / 1983 loss=3.2, nll_loss=1.049, word_ins=2.873, length=3.275, ppl=9.19, wps=103093, ups=1.67, wpb=61552.8, bsz=2011.9, num_updates=180500, lr=0.000235376, gnorm=0.81, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:41:00 | INFO | train_inner | epoch 092:    179 / 1983 loss=3.222, nll_loss=1.074, word_ins=2.895, length=3.266, ppl=9.33, wps=212739, ups=3.43, wpb=62087.5, bsz=1923.8, num_updates=180600, lr=0.00023531, gnorm=0.796, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:41:29 | INFO | train_inner | epoch 092:    279 / 1983 loss=3.226, nll_loss=1.075, word_ins=2.895, length=3.31, ppl=9.36, wps=211742, ups=3.42, wpb=61880.2, bsz=1938, num_updates=180700, lr=0.000235245, gnorm=0.82, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:41:58 | INFO | train_inner | epoch 092:    379 / 1983 loss=3.229, nll_loss=1.081, word_ins=2.902, length=3.27, ppl=9.37, wps=210127, ups=3.43, wpb=61330, bsz=2040, num_updates=180800, lr=0.00023518, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:42:27 | INFO | train_inner | epoch 092:    479 / 1983 loss=3.191, nll_loss=1.047, word_ins=2.87, length=3.211, ppl=9.13, wps=212013, ups=3.43, wpb=61801.8, bsz=2035.8, num_updates=180900, lr=0.000235115, gnorm=0.787, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:42:57 | INFO | train_inner | epoch 092:    579 / 1983 loss=3.198, nll_loss=1.048, word_ins=2.871, length=3.268, ppl=9.18, wps=211730, ups=3.42, wpb=61849.7, bsz=1999.6, num_updates=181000, lr=0.00023505, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:43:26 | INFO | train_inner | epoch 092:    679 / 1983 loss=3.195, nll_loss=1.049, word_ins=2.872, length=3.233, ppl=9.16, wps=211228, ups=3.42, wpb=61735, bsz=2051.8, num_updates=181100, lr=0.000234985, gnorm=0.809, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:43:55 | INFO | train_inner | epoch 092:    779 / 1983 loss=3.187, nll_loss=1.041, word_ins=2.865, length=3.225, ppl=9.11, wps=210984, ups=3.44, wpb=61308.6, bsz=2059.4, num_updates=181200, lr=0.00023492, gnorm=0.796, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:44:24 | INFO | train_inner | epoch 092:    879 / 1983 loss=3.207, nll_loss=1.063, word_ins=2.885, length=3.227, ppl=9.24, wps=210867, ups=3.41, wpb=61797.4, bsz=2002, num_updates=181300, lr=0.000234856, gnorm=0.787, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:44:53 | INFO | train_inner | epoch 092:    979 / 1983 loss=3.212, nll_loss=1.063, word_ins=2.884, length=3.277, ppl=9.27, wps=211952, ups=3.43, wpb=61787.3, bsz=1979, num_updates=181400, lr=0.000234791, gnorm=0.802, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:45:22 | INFO | train_inner | epoch 092:   1079 / 1983 loss=3.18, nll_loss=1.036, word_ins=2.86, length=3.194, ppl=9.06, wps=214398, ups=3.45, wpb=62179.8, bsz=2092.2, num_updates=181500, lr=0.000234726, gnorm=0.767, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:45:52 | INFO | train_inner | epoch 092:   1179 / 1983 loss=3.216, nll_loss=1.07, word_ins=2.89, length=3.257, ppl=9.29, wps=209690, ups=3.42, wpb=61266.3, bsz=2063.1, num_updates=181600, lr=0.000234662, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:46:21 | INFO | train_inner | epoch 092:   1279 / 1983 loss=3.22, nll_loss=1.073, word_ins=2.894, length=3.267, ppl=9.32, wps=209108, ups=3.41, wpb=61279.7, bsz=2020.8, num_updates=181700, lr=0.000234597, gnorm=0.809, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:46:50 | INFO | train_inner | epoch 092:   1379 / 1983 loss=3.253, nll_loss=1.099, word_ins=2.917, length=3.359, ppl=9.53, wps=208484, ups=3.42, wpb=60928.7, bsz=1932.6, num_updates=181800, lr=0.000234533, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:47:19 | INFO | train_inner | epoch 092:   1479 / 1983 loss=3.215, nll_loss=1.061, word_ins=2.883, length=3.323, ppl=9.29, wps=211781, ups=3.42, wpb=61884.3, bsz=1982.6, num_updates=181900, lr=0.000234468, gnorm=0.795, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:47:49 | INFO | train_inner | epoch 092:   1579 / 1983 loss=3.212, nll_loss=1.059, word_ins=2.88, length=3.312, ppl=9.26, wps=210345, ups=3.43, wpb=61326.7, bsz=2013.1, num_updates=182000, lr=0.000234404, gnorm=0.803, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:48:18 | INFO | train_inner | epoch 092:   1679 / 1983 loss=3.241, nll_loss=1.088, word_ins=2.908, length=3.329, ppl=9.45, wps=212970, ups=3.43, wpb=62044.2, bsz=1898.2, num_updates=182100, lr=0.000234339, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:48:47 | INFO | train_inner | epoch 092:   1779 / 1983 loss=3.229, nll_loss=1.078, word_ins=2.898, length=3.308, ppl=9.38, wps=211792, ups=3.42, wpb=61971.2, bsz=1975, num_updates=182200, lr=0.000234275, gnorm=0.795, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:49:16 | INFO | train_inner | epoch 092:   1879 / 1983 loss=3.222, nll_loss=1.069, word_ins=2.89, length=3.322, ppl=9.33, wps=210134, ups=3.43, wpb=61322.3, bsz=1992.9, num_updates=182300, lr=0.000234211, gnorm=0.791, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:49:45 | INFO | train_inner | epoch 092:   1979 / 1983 loss=3.237, nll_loss=1.083, word_ins=2.903, length=3.344, ppl=9.43, wps=211472, ups=3.45, wpb=61307.5, bsz=1936.6, num_updates=182400, lr=0.000234146, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 09:49:58 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 3.245 | nll_loss 1.029 | word_ins 2.916 | length 3.29 | ppl 9.48 | wps 119826 | wpb 41551 | bsz 1500 | num_updates 182404 | best_loss 3.218
2023-03-02 09:49:58 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 09:50:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint92.pt (epoch 92 @ 182404 updates, score 3.245) (writing took 5.756580780027434 seconds)
2023-03-02 09:50:04 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2023-03-02 09:50:04 | INFO | train | epoch 092 | loss 3.215 | nll_loss 1.065 | word_ins 2.887 | length 3.279 | ppl 9.28 | wps 201296 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 182404 | lr 0.000234144 | gnorm 0.8 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 09:50:04 | INFO | fairseq.trainer | begin training epoch 93
2023-03-02 09:50:42 | INFO | train_inner | epoch 093:     96 / 1983 loss=3.2, nll_loss=1.053, word_ins=2.876, length=3.239, ppl=9.19, wps=108190, ups=1.76, wpb=61565.9, bsz=1966.3, num_updates=182500, lr=0.000234082, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:51:11 | INFO | train_inner | epoch 093:    196 / 1983 loss=3.222, nll_loss=1.064, word_ins=2.886, length=3.356, ppl=9.33, wps=209814, ups=3.43, wpb=61109.7, bsz=1956.6, num_updates=182600, lr=0.000234018, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:51:40 | INFO | train_inner | epoch 093:    296 / 1983 loss=3.195, nll_loss=1.046, word_ins=2.869, length=3.264, ppl=9.16, wps=212665, ups=3.43, wpb=62027.9, bsz=1988.3, num_updates=182700, lr=0.000233954, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:52:09 | INFO | train_inner | epoch 093:    396 / 1983 loss=3.216, nll_loss=1.064, word_ins=2.885, length=3.312, ppl=9.29, wps=209872, ups=3.44, wpb=61078.8, bsz=2001.4, num_updates=182800, lr=0.00023389, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:52:38 | INFO | train_inner | epoch 093:    496 / 1983 loss=3.229, nll_loss=1.077, word_ins=2.898, length=3.312, ppl=9.38, wps=210217, ups=3.44, wpb=61070.4, bsz=1969.3, num_updates=182900, lr=0.000233826, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:53:08 | INFO | train_inner | epoch 093:    596 / 1983 loss=3.18, nll_loss=1.036, word_ins=2.861, length=3.191, ppl=9.06, wps=211393, ups=3.43, wpb=61637.1, bsz=2127.4, num_updates=183000, lr=0.000233762, gnorm=0.791, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:53:37 | INFO | train_inner | epoch 093:    696 / 1983 loss=3.204, nll_loss=1.053, word_ins=2.876, length=3.288, ppl=9.22, wps=211257, ups=3.44, wpb=61432.7, bsz=1959, num_updates=183100, lr=0.000233698, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:54:06 | INFO | train_inner | epoch 093:    796 / 1983 loss=3.236, nll_loss=1.082, word_ins=2.902, length=3.347, ppl=9.42, wps=210030, ups=3.41, wpb=61558.9, bsz=1942.5, num_updates=183200, lr=0.000233635, gnorm=0.819, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:54:35 | INFO | train_inner | epoch 093:    896 / 1983 loss=3.21, nll_loss=1.06, word_ins=2.881, length=3.291, ppl=9.26, wps=211080, ups=3.43, wpb=61604.1, bsz=2016.8, num_updates=183300, lr=0.000233571, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:55:04 | INFO | train_inner | epoch 093:    996 / 1983 loss=3.212, nll_loss=1.065, word_ins=2.886, length=3.256, ppl=9.27, wps=211539, ups=3.42, wpb=61917.3, bsz=2017.1, num_updates=183400, lr=0.000233507, gnorm=0.783, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:55:34 | INFO | train_inner | epoch 093:   1096 / 1983 loss=3.198, nll_loss=1.048, word_ins=2.872, length=3.26, ppl=9.17, wps=211422, ups=3.42, wpb=61759, bsz=2074.1, num_updates=183500, lr=0.000233444, gnorm=0.79, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:55:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32768.0
2023-03-02 09:56:03 | INFO | train_inner | epoch 093:   1197 / 1983 loss=3.211, nll_loss=1.063, word_ins=2.884, length=3.267, ppl=9.26, wps=208358, ups=3.4, wpb=61361.7, bsz=2020.2, num_updates=183600, lr=0.00023338, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:56:32 | INFO | train_inner | epoch 093:   1297 / 1983 loss=3.203, nll_loss=1.056, word_ins=2.878, length=3.252, ppl=9.21, wps=212436, ups=3.42, wpb=62026.5, bsz=2035.8, num_updates=183700, lr=0.000233316, gnorm=0.794, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:57:02 | INFO | train_inner | epoch 093:   1397 / 1983 loss=3.192, nll_loss=1.049, word_ins=2.872, length=3.202, ppl=9.14, wps=211735, ups=3.42, wpb=61976.5, bsz=2098.3, num_updates=183800, lr=0.000233253, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:57:31 | INFO | train_inner | epoch 093:   1497 / 1983 loss=3.227, nll_loss=1.078, word_ins=2.898, length=3.286, ppl=9.36, wps=211934, ups=3.44, wpb=61637.3, bsz=1976.6, num_updates=183900, lr=0.00023319, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:58:00 | INFO | train_inner | epoch 093:   1597 / 1983 loss=3.221, nll_loss=1.072, word_ins=2.893, length=3.282, ppl=9.32, wps=213225, ups=3.44, wpb=61912.4, bsz=1996, num_updates=184000, lr=0.000233126, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:58:29 | INFO | train_inner | epoch 093:   1697 / 1983 loss=3.224, nll_loss=1.074, word_ins=2.895, length=3.29, ppl=9.34, wps=212576, ups=3.42, wpb=62216.5, bsz=1922.4, num_updates=184100, lr=0.000233063, gnorm=0.824, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:58:58 | INFO | train_inner | epoch 093:   1797 / 1983 loss=3.237, nll_loss=1.081, word_ins=2.901, length=3.358, ppl=9.43, wps=209804, ups=3.44, wpb=61025.9, bsz=1919.2, num_updates=184200, lr=0.000233, gnorm=0.811, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:59:27 | INFO | train_inner | epoch 093:   1897 / 1983 loss=3.181, nll_loss=1.038, word_ins=2.862, length=3.195, ppl=9.07, wps=212677, ups=3.42, wpb=62155.3, bsz=2062.1, num_updates=184300, lr=0.000232936, gnorm=0.778, loss_scale=32768, train_wall=29, wall=0
2023-03-02 09:59:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 10:00:07 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 3.225 | nll_loss 1.014 | word_ins 2.899 | length 3.258 | ppl 9.35 | wps 128657 | wpb 41551 | bsz 1500 | num_updates 184386 | best_loss 3.218
2023-03-02 10:00:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 10:00:12 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint93.pt (epoch 93 @ 184386 updates, score 3.225) (writing took 5.593415834009647 seconds)
2023-03-02 10:00:12 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2023-03-02 10:00:12 | INFO | train | epoch 093 | loss 3.212 | nll_loss 1.062 | word_ins 2.884 | length 3.281 | ppl 9.27 | wps 200849 | ups 3.26 | wpb 61632.7 | bsz 1997.9 | num_updates 184386 | lr 0.000232882 | gnorm 0.8 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 10:00:12 | INFO | fairseq.trainer | begin training epoch 94
2023-03-02 10:00:27 | INFO | train_inner | epoch 094:     14 / 1983 loss=3.239, nll_loss=1.084, word_ins=2.903, length=3.355, ppl=9.44, wps=102158, ups=1.67, wpb=61201.8, bsz=1917, num_updates=184400, lr=0.000232873, gnorm=0.807, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:00:56 | INFO | train_inner | epoch 094:    114 / 1983 loss=3.185, nll_loss=1.04, word_ins=2.864, length=3.207, ppl=9.09, wps=212274, ups=3.42, wpb=61997.2, bsz=2034.6, num_updates=184500, lr=0.00023281, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:01:26 | INFO | train_inner | epoch 094:    214 / 1983 loss=3.181, nll_loss=1.038, word_ins=2.862, length=3.192, ppl=9.07, wps=211841, ups=3.41, wpb=62098.8, bsz=2075.6, num_updates=184600, lr=0.000232747, gnorm=0.78, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:01:55 | INFO | train_inner | epoch 094:    314 / 1983 loss=3.213, nll_loss=1.069, word_ins=2.89, length=3.233, ppl=9.27, wps=211624, ups=3.43, wpb=61684.7, bsz=1992.4, num_updates=184700, lr=0.000232684, gnorm=0.802, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:02:24 | INFO | train_inner | epoch 094:    414 / 1983 loss=3.235, nll_loss=1.08, word_ins=2.9, length=3.351, ppl=9.42, wps=210530, ups=3.42, wpb=61572.1, bsz=1990.3, num_updates=184800, lr=0.000232621, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:02:53 | INFO | train_inner | epoch 094:    514 / 1983 loss=3.196, nll_loss=1.048, word_ins=2.871, length=3.252, ppl=9.16, wps=210749, ups=3.42, wpb=61595.8, bsz=2030.8, num_updates=184900, lr=0.000232558, gnorm=0.766, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:03:22 | INFO | train_inner | epoch 094:    614 / 1983 loss=3.223, nll_loss=1.072, word_ins=2.893, length=3.3, ppl=9.34, wps=210833, ups=3.44, wpb=61358.2, bsz=1930.2, num_updates=185000, lr=0.000232495, gnorm=0.829, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:03:52 | INFO | train_inner | epoch 094:    714 / 1983 loss=3.188, nll_loss=1.043, word_ins=2.867, length=3.215, ppl=9.12, wps=210858, ups=3.42, wpb=61564.6, bsz=1994, num_updates=185100, lr=0.000232432, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:04:21 | INFO | train_inner | epoch 094:    814 / 1983 loss=3.202, nll_loss=1.059, word_ins=2.881, length=3.217, ppl=9.2, wps=211528, ups=3.43, wpb=61725.3, bsz=1986.6, num_updates=185200, lr=0.00023237, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:04:50 | INFO | train_inner | epoch 094:    914 / 1983 loss=3.237, nll_loss=1.078, word_ins=2.898, length=3.391, ppl=9.43, wps=213112, ups=3.46, wpb=61663.6, bsz=1890.4, num_updates=185300, lr=0.000232307, gnorm=0.807, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:05:19 | INFO | train_inner | epoch 094:   1014 / 1983 loss=3.199, nll_loss=1.047, word_ins=2.87, length=3.293, ppl=9.19, wps=213813, ups=3.46, wpb=61880.4, bsz=1996.9, num_updates=185400, lr=0.000232244, gnorm=0.776, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:05:48 | INFO | train_inner | epoch 094:   1114 / 1983 loss=3.239, nll_loss=1.09, word_ins=2.909, length=3.297, ppl=9.44, wps=211590, ups=3.45, wpb=61400.4, bsz=1914.8, num_updates=185500, lr=0.000232182, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:06:17 | INFO | train_inner | epoch 094:   1214 / 1983 loss=3.195, nll_loss=1.046, word_ins=2.869, length=3.255, ppl=9.16, wps=212660, ups=3.43, wpb=62020.9, bsz=1973.4, num_updates=185600, lr=0.000232119, gnorm=0.796, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:06:46 | INFO | train_inner | epoch 094:   1314 / 1983 loss=3.22, nll_loss=1.07, word_ins=2.891, length=3.293, ppl=9.32, wps=211495, ups=3.44, wpb=61512.9, bsz=1979.8, num_updates=185700, lr=0.000232057, gnorm=0.803, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:07:15 | INFO | train_inner | epoch 094:   1414 / 1983 loss=3.217, nll_loss=1.066, word_ins=2.888, length=3.292, ppl=9.3, wps=211483, ups=3.42, wpb=61864.8, bsz=2014.9, num_updates=185800, lr=0.000231994, gnorm=0.786, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:07:45 | INFO | train_inner | epoch 094:   1514 / 1983 loss=3.2, nll_loss=1.055, word_ins=2.878, length=3.224, ppl=9.19, wps=209915, ups=3.42, wpb=61363.2, bsz=2084.1, num_updates=185900, lr=0.000231932, gnorm=0.793, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:08:14 | INFO | train_inner | epoch 094:   1614 / 1983 loss=3.204, nll_loss=1.054, word_ins=2.876, length=3.274, ppl=9.21, wps=211602, ups=3.43, wpb=61682.6, bsz=1983.5, num_updates=186000, lr=0.000231869, gnorm=0.785, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:08:43 | INFO | train_inner | epoch 094:   1714 / 1983 loss=3.198, nll_loss=1.053, word_ins=2.875, length=3.229, ppl=9.18, wps=210843, ups=3.42, wpb=61560.6, bsz=2050.7, num_updates=186100, lr=0.000231807, gnorm=0.784, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:09:12 | INFO | train_inner | epoch 094:   1814 / 1983 loss=3.23, nll_loss=1.077, word_ins=2.897, length=3.338, ppl=9.39, wps=211656, ups=3.44, wpb=61531.3, bsz=1962.9, num_updates=186200, lr=0.000231745, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:09:41 | INFO | train_inner | epoch 094:   1914 / 1983 loss=3.2, nll_loss=1.052, word_ins=2.874, length=3.265, ppl=9.19, wps=210054, ups=3.42, wpb=61411.9, bsz=2090.7, num_updates=186300, lr=0.000231683, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 10:10:15 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 3.202 | nll_loss 1 | word_ins 2.882 | length 3.205 | ppl 9.2 | wps 97552.7 | wpb 41551 | bsz 1500 | num_updates 186369 | best_loss 3.202
2023-03-02 10:10:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 10:10:23 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint94.pt (epoch 94 @ 186369 updates, score 3.202) (writing took 8.189039587974548 seconds)
2023-03-02 10:10:23 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2023-03-02 10:10:23 | INFO | train | epoch 094 | loss 3.21 | nll_loss 1.061 | word_ins 2.882 | length 3.271 | ppl 9.25 | wps 200023 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 186369 | lr 0.00023164 | gnorm 0.798 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 10:10:23 | INFO | fairseq.trainer | begin training epoch 95
2023-03-02 10:10:43 | INFO | train_inner | epoch 095:     31 / 1983 loss=3.239, nll_loss=1.086, word_ins=2.906, length=3.327, ppl=9.44, wps=99251.6, ups=1.63, wpb=60914.6, bsz=1914.3, num_updates=186400, lr=0.000231621, gnorm=0.836, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:11:12 | INFO | train_inner | epoch 095:    131 / 1983 loss=3.213, nll_loss=1.064, word_ins=2.886, length=3.262, ppl=9.27, wps=211075, ups=3.42, wpb=61706.7, bsz=1963.8, num_updates=186500, lr=0.000231558, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:11:41 | INFO | train_inner | epoch 095:    231 / 1983 loss=3.199, nll_loss=1.045, word_ins=2.869, length=3.308, ppl=9.19, wps=211039, ups=3.45, wpb=61208.2, bsz=1965.6, num_updates=186600, lr=0.000231496, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:12:10 | INFO | train_inner | epoch 095:    331 / 1983 loss=3.184, nll_loss=1.037, word_ins=2.861, length=3.228, ppl=9.09, wps=212683, ups=3.43, wpb=62034.4, bsz=2040.4, num_updates=186700, lr=0.000231434, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:12:39 | INFO | train_inner | epoch 095:    431 / 1983 loss=3.195, nll_loss=1.046, word_ins=2.87, length=3.254, ppl=9.16, wps=210525, ups=3.4, wpb=61865.6, bsz=2005.9, num_updates=186800, lr=0.000231372, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:13:09 | INFO | train_inner | epoch 095:    531 / 1983 loss=3.206, nll_loss=1.054, word_ins=2.876, length=3.292, ppl=9.22, wps=210094, ups=3.42, wpb=61399, bsz=2002.2, num_updates=186900, lr=0.000231311, gnorm=0.801, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:13:38 | INFO | train_inner | epoch 095:    631 / 1983 loss=3.186, nll_loss=1.04, word_ins=2.864, length=3.227, ppl=9.1, wps=211929, ups=3.44, wpb=61689.4, bsz=2069, num_updates=187000, lr=0.000231249, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:14:07 | INFO | train_inner | epoch 095:    731 / 1983 loss=3.191, nll_loss=1.044, word_ins=2.867, length=3.239, ppl=9.13, wps=210734, ups=3.44, wpb=61247.3, bsz=2022.6, num_updates=187100, lr=0.000231187, gnorm=0.78, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:14:36 | INFO | train_inner | epoch 095:    831 / 1983 loss=3.194, nll_loss=1.044, word_ins=2.867, length=3.268, ppl=9.15, wps=211152, ups=3.42, wpb=61764.4, bsz=2032.5, num_updates=187200, lr=0.000231125, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:15:05 | INFO | train_inner | epoch 095:    931 / 1983 loss=3.209, nll_loss=1.055, word_ins=2.877, length=3.328, ppl=9.25, wps=211156, ups=3.46, wpb=61116.1, bsz=1941, num_updates=187300, lr=0.000231063, gnorm=0.787, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:15:34 | INFO | train_inner | epoch 095:   1031 / 1983 loss=3.2, nll_loss=1.057, word_ins=2.879, length=3.215, ppl=9.19, wps=212010, ups=3.43, wpb=61805.7, bsz=2054.2, num_updates=187400, lr=0.000231002, gnorm=0.784, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:16:03 | INFO | train_inner | epoch 095:   1131 / 1983 loss=3.224, nll_loss=1.071, word_ins=2.892, length=3.326, ppl=9.35, wps=211265, ups=3.43, wpb=61588.5, bsz=2031.2, num_updates=187500, lr=0.00023094, gnorm=0.811, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:16:32 | INFO | train_inner | epoch 095:   1231 / 1983 loss=3.224, nll_loss=1.075, word_ins=2.895, length=3.292, ppl=9.34, wps=214191, ups=3.45, wpb=62123.5, bsz=1896.7, num_updates=187600, lr=0.000230879, gnorm=0.801, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:16:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32768.0
2023-03-02 10:17:02 | INFO | train_inner | epoch 095:   1332 / 1983 loss=3.221, nll_loss=1.067, word_ins=2.888, length=3.327, ppl=9.32, wps=208459, ups=3.4, wpb=61281.8, bsz=1999.4, num_updates=187700, lr=0.000230817, gnorm=0.795, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:17:31 | INFO | train_inner | epoch 095:   1432 / 1983 loss=3.207, nll_loss=1.058, word_ins=2.879, length=3.278, ppl=9.24, wps=212564, ups=3.44, wpb=61781.7, bsz=1984, num_updates=187800, lr=0.000230756, gnorm=0.771, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:18:00 | INFO | train_inner | epoch 095:   1532 / 1983 loss=3.201, nll_loss=1.056, word_ins=2.878, length=3.229, ppl=9.19, wps=211870, ups=3.43, wpb=61850.9, bsz=2009.4, num_updates=187900, lr=0.000230694, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:18:29 | INFO | train_inner | epoch 095:   1632 / 1983 loss=3.208, nll_loss=1.064, word_ins=2.886, length=3.226, ppl=9.24, wps=210886, ups=3.41, wpb=61928.9, bsz=2025.1, num_updates=188000, lr=0.000230633, gnorm=0.812, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:18:59 | INFO | train_inner | epoch 095:   1732 / 1983 loss=3.228, nll_loss=1.075, word_ins=2.895, length=3.324, ppl=9.37, wps=212538, ups=3.43, wpb=62001.6, bsz=1988.1, num_updates=188100, lr=0.000230571, gnorm=0.782, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:19:28 | INFO | train_inner | epoch 095:   1832 / 1983 loss=3.237, nll_loss=1.085, word_ins=2.905, length=3.325, ppl=9.43, wps=211192, ups=3.43, wpb=61604.7, bsz=1934.1, num_updates=188200, lr=0.00023051, gnorm=0.813, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:19:57 | INFO | train_inner | epoch 095:   1932 / 1983 loss=3.199, nll_loss=1.05, word_ins=2.873, length=3.262, ppl=9.18, wps=211475, ups=3.43, wpb=61695, bsz=2041.3, num_updates=188300, lr=0.000230449, gnorm=0.786, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 10:20:25 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 3.239 | nll_loss 1.029 | word_ins 2.908 | length 3.307 | ppl 9.44 | wps 98123.3 | wpb 41551 | bsz 1500 | num_updates 188351 | best_loss 3.202
2023-03-02 10:20:25 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 10:20:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint95.pt (epoch 95 @ 188351 updates, score 3.239) (writing took 5.628875890048221 seconds)
2023-03-02 10:20:31 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2023-03-02 10:20:31 | INFO | train | epoch 095 | loss 3.207 | nll_loss 1.057 | word_ins 2.879 | length 3.275 | ppl 9.23 | wps 201147 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 188351 | lr 0.000230418 | gnorm 0.794 | loss_scale 32768 | train_wall 575 | wall 0
2023-03-02 10:20:31 | INFO | fairseq.trainer | begin training epoch 96
2023-03-02 10:20:55 | INFO | train_inner | epoch 096:     49 / 1983 loss=3.188, nll_loss=1.039, word_ins=2.863, length=3.249, ppl=9.11, wps=104504, ups=1.71, wpb=60977.8, bsz=2002.2, num_updates=188400, lr=0.000230388, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:21:25 | INFO | train_inner | epoch 096:    149 / 1983 loss=3.173, nll_loss=1.03, word_ins=2.855, length=3.182, ppl=9.02, wps=211526, ups=3.41, wpb=62003.6, bsz=2072.2, num_updates=188500, lr=0.000230327, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:21:54 | INFO | train_inner | epoch 096:    249 / 1983 loss=3.219, nll_loss=1.064, word_ins=2.887, length=3.321, ppl=9.31, wps=209518, ups=3.42, wpb=61182.2, bsz=1913, num_updates=188600, lr=0.000230266, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:22:23 | INFO | train_inner | epoch 096:    349 / 1983 loss=3.198, nll_loss=1.049, word_ins=2.872, length=3.264, ppl=9.18, wps=212583, ups=3.43, wpb=61927.2, bsz=1979, num_updates=188700, lr=0.000230205, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:22:52 | INFO | train_inner | epoch 096:    449 / 1983 loss=3.211, nll_loss=1.068, word_ins=2.889, length=3.217, ppl=9.26, wps=211992, ups=3.42, wpb=61947.1, bsz=2010.8, num_updates=188800, lr=0.000230144, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:23:21 | INFO | train_inner | epoch 096:    549 / 1983 loss=3.211, nll_loss=1.062, word_ins=2.884, length=3.277, ppl=9.26, wps=210810, ups=3.43, wpb=61465.6, bsz=1966.5, num_updates=188900, lr=0.000230083, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:23:54 | INFO | train_inner | epoch 096:    649 / 1983 loss=3.187, nll_loss=1.039, word_ins=2.862, length=3.242, ppl=9.1, wps=188983, ups=3.04, wpb=62106.8, bsz=2060.5, num_updates=189000, lr=0.000230022, gnorm=0.813, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:24:23 | INFO | train_inner | epoch 096:    749 / 1983 loss=3.189, nll_loss=1.046, word_ins=2.869, length=3.205, ppl=9.12, wps=212024, ups=3.42, wpb=62062.3, bsz=2077.9, num_updates=189100, lr=0.000229961, gnorm=0.789, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:24:53 | INFO | train_inner | epoch 096:    849 / 1983 loss=3.232, nll_loss=1.077, word_ins=2.898, length=3.34, ppl=9.39, wps=209482, ups=3.43, wpb=61068.7, bsz=1905.9, num_updates=189200, lr=0.0002299, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:25:22 | INFO | train_inner | epoch 096:    949 / 1983 loss=3.209, nll_loss=1.058, word_ins=2.88, length=3.296, ppl=9.25, wps=210708, ups=3.43, wpb=61409.9, bsz=2011.5, num_updates=189300, lr=0.00022984, gnorm=0.794, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:25:51 | INFO | train_inner | epoch 096:   1049 / 1983 loss=3.21, nll_loss=1.056, word_ins=2.878, length=3.314, ppl=9.25, wps=212874, ups=3.44, wpb=61886, bsz=1957.9, num_updates=189400, lr=0.000229779, gnorm=0.803, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:26:20 | INFO | train_inner | epoch 096:   1149 / 1983 loss=3.183, nll_loss=1.039, word_ins=2.862, length=3.213, ppl=9.08, wps=214033, ups=3.45, wpb=62109.1, bsz=1971, num_updates=189500, lr=0.000229718, gnorm=0.775, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:26:49 | INFO | train_inner | epoch 096:   1249 / 1983 loss=3.222, nll_loss=1.071, word_ins=2.892, length=3.306, ppl=9.33, wps=211766, ups=3.44, wpb=61569.4, bsz=1971.4, num_updates=189600, lr=0.000229658, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:27:18 | INFO | train_inner | epoch 096:   1349 / 1983 loss=3.218, nll_loss=1.068, word_ins=2.889, length=3.284, ppl=9.3, wps=210477, ups=3.43, wpb=61379.9, bsz=2000, num_updates=189700, lr=0.000229597, gnorm=0.813, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:27:47 | INFO | train_inner | epoch 096:   1449 / 1983 loss=3.191, nll_loss=1.044, word_ins=2.867, length=3.245, ppl=9.13, wps=210714, ups=3.42, wpb=61574.8, bsz=2025, num_updates=189800, lr=0.000229537, gnorm=0.786, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:28:16 | INFO | train_inner | epoch 096:   1549 / 1983 loss=3.206, nll_loss=1.054, word_ins=2.876, length=3.303, ppl=9.23, wps=209427, ups=3.44, wpb=60860.7, bsz=2008, num_updates=189900, lr=0.000229476, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:28:46 | INFO | train_inner | epoch 096:   1649 / 1983 loss=3.215, nll_loss=1.063, word_ins=2.885, length=3.306, ppl=9.29, wps=211942, ups=3.42, wpb=61962.7, bsz=1990.5, num_updates=190000, lr=0.000229416, gnorm=0.811, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:29:15 | INFO | train_inner | epoch 096:   1749 / 1983 loss=3.217, nll_loss=1.065, word_ins=2.886, length=3.31, ppl=9.3, wps=210224, ups=3.43, wpb=61310.9, bsz=1998.4, num_updates=190100, lr=0.000229355, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:29:44 | INFO | train_inner | epoch 096:   1849 / 1983 loss=3.204, nll_loss=1.055, word_ins=2.877, length=3.266, ppl=9.21, wps=212173, ups=3.42, wpb=61991.7, bsz=2015.5, num_updates=190200, lr=0.000229295, gnorm=0.793, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:30:13 | INFO | train_inner | epoch 096:   1949 / 1983 loss=3.209, nll_loss=1.06, word_ins=2.881, length=3.277, ppl=9.25, wps=211223, ups=3.44, wpb=61469.4, bsz=1997.1, num_updates=190300, lr=0.000229235, gnorm=0.789, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 10:30:37 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 3.202 | nll_loss 0.999 | word_ins 2.88 | length 3.213 | ppl 9.2 | wps 82233.3 | wpb 41551 | bsz 1500 | num_updates 190334 | best_loss 3.202
2023-03-02 10:30:37 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 10:30:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint96.pt (epoch 96 @ 190334 updates, score 3.202) (writing took 8.490828657988459 seconds)
2023-03-02 10:30:45 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2023-03-02 10:30:45 | INFO | train | epoch 096 | loss 3.205 | nll_loss 1.056 | word_ins 2.878 | length 3.271 | ppl 9.22 | wps 198844 | ups 3.23 | wpb 61628.5 | bsz 1997.6 | num_updates 190334 | lr 0.000229214 | gnorm 0.799 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 10:30:45 | INFO | fairseq.trainer | begin training epoch 97
2023-03-02 10:31:15 | INFO | train_inner | epoch 097:     66 / 1983 loss=3.185, nll_loss=1.038, word_ins=2.862, length=3.236, ppl=9.1, wps=99395.4, ups=1.62, wpb=61250.2, bsz=2027.9, num_updates=190400, lr=0.000229175, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:31:44 | INFO | train_inner | epoch 097:    166 / 1983 loss=3.179, nll_loss=1.033, word_ins=2.857, length=3.223, ppl=9.06, wps=209911, ups=3.42, wpb=61355.7, bsz=2031.4, num_updates=190500, lr=0.000229114, gnorm=0.784, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:32:13 | INFO | train_inner | epoch 097:    266 / 1983 loss=3.204, nll_loss=1.052, word_ins=2.875, length=3.29, ppl=9.21, wps=211245, ups=3.43, wpb=61640.1, bsz=2029.8, num_updates=190600, lr=0.000229054, gnorm=0.81, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:32:42 | INFO | train_inner | epoch 097:    366 / 1983 loss=3.19, nll_loss=1.041, word_ins=2.865, length=3.249, ppl=9.12, wps=211486, ups=3.42, wpb=61751.1, bsz=2054.9, num_updates=190700, lr=0.000228994, gnorm=0.786, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:33:12 | INFO | train_inner | epoch 097:    466 / 1983 loss=3.207, nll_loss=1.059, word_ins=2.881, length=3.264, ppl=9.24, wps=209190, ups=3.41, wpb=61402.1, bsz=1994.1, num_updates=190800, lr=0.000228934, gnorm=0.819, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:33:41 | INFO | train_inner | epoch 097:    566 / 1983 loss=3.203, nll_loss=1.05, word_ins=2.873, length=3.301, ppl=9.21, wps=211467, ups=3.45, wpb=61339.9, bsz=1951.2, num_updates=190900, lr=0.000228874, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:34:10 | INFO | train_inner | epoch 097:    666 / 1983 loss=3.187, nll_loss=1.038, word_ins=2.862, length=3.253, ppl=9.11, wps=211200, ups=3.42, wpb=61669.7, bsz=2048.6, num_updates=191000, lr=0.000228814, gnorm=0.775, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:34:39 | INFO | train_inner | epoch 097:    766 / 1983 loss=3.205, nll_loss=1.057, word_ins=2.879, length=3.258, ppl=9.22, wps=212105, ups=3.43, wpb=61819.8, bsz=2001.2, num_updates=191100, lr=0.000228755, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:35:08 | INFO | train_inner | epoch 097:    866 / 1983 loss=3.212, nll_loss=1.062, word_ins=2.884, length=3.279, ppl=9.26, wps=211948, ups=3.42, wpb=61912.5, bsz=1984.7, num_updates=191200, lr=0.000228695, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:35:37 | INFO | train_inner | epoch 097:    966 / 1983 loss=3.193, nll_loss=1.044, word_ins=2.867, length=3.26, ppl=9.14, wps=211636, ups=3.43, wpb=61699.2, bsz=2002.5, num_updates=191300, lr=0.000228635, gnorm=0.787, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:36:07 | INFO | train_inner | epoch 097:   1066 / 1983 loss=3.206, nll_loss=1.056, word_ins=2.878, length=3.279, ppl=9.23, wps=211357, ups=3.43, wpb=61589.4, bsz=2031, num_updates=191400, lr=0.000228575, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:36:36 | INFO | train_inner | epoch 097:   1166 / 1983 loss=3.212, nll_loss=1.059, word_ins=2.881, length=3.31, ppl=9.27, wps=210124, ups=3.43, wpb=61294.1, bsz=1967, num_updates=191500, lr=0.000228515, gnorm=0.801, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:37:05 | INFO | train_inner | epoch 097:   1266 / 1983 loss=3.196, nll_loss=1.054, word_ins=2.876, length=3.197, ppl=9.16, wps=211702, ups=3.41, wpb=62087.6, bsz=2047.4, num_updates=191600, lr=0.000228456, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:37:34 | INFO | train_inner | epoch 097:   1366 / 1983 loss=3.203, nll_loss=1.054, word_ins=2.876, length=3.272, ppl=9.21, wps=214317, ups=3.46, wpb=61997.4, bsz=1958.8, num_updates=191700, lr=0.000228396, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:37:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32768.0
2023-03-02 10:38:03 | INFO | train_inner | epoch 097:   1467 / 1983 loss=3.228, nll_loss=1.076, word_ins=2.896, length=3.319, ppl=9.37, wps=208805, ups=3.39, wpb=61531.9, bsz=1946.6, num_updates=191800, lr=0.000228337, gnorm=0.802, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:38:33 | INFO | train_inner | epoch 097:   1567 / 1983 loss=3.208, nll_loss=1.058, word_ins=2.879, length=3.289, ppl=9.24, wps=210410, ups=3.44, wpb=61127.8, bsz=1986.3, num_updates=191900, lr=0.000228277, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 10:38:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 10:39:02 | INFO | train_inner | epoch 097:   1668 / 1983 loss=3.229, nll_loss=1.077, word_ins=2.897, length=3.324, ppl=9.38, wps=210463, ups=3.41, wpb=61783, bsz=1906.5, num_updates=192000, lr=0.000228218, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:39:31 | INFO | train_inner | epoch 097:   1768 / 1983 loss=3.192, nll_loss=1.047, word_ins=2.869, length=3.224, ppl=9.14, wps=212439, ups=3.43, wpb=61981.8, bsz=2010.9, num_updates=192100, lr=0.000228158, gnorm=0.782, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:40:00 | INFO | train_inner | epoch 097:   1868 / 1983 loss=3.212, nll_loss=1.063, word_ins=2.884, length=3.277, ppl=9.27, wps=212834, ups=3.44, wpb=61785.5, bsz=1966, num_updates=192200, lr=0.000228099, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:40:29 | INFO | train_inner | epoch 097:   1968 / 1983 loss=3.216, nll_loss=1.066, word_ins=2.887, length=3.288, ppl=9.29, wps=210394, ups=3.43, wpb=61424.8, bsz=1986.6, num_updates=192300, lr=0.00022804, gnorm=0.801, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 10:40:46 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 3.229 | nll_loss 1.017 | word_ins 2.906 | length 3.233 | ppl 9.38 | wps 138047 | wpb 41551 | bsz 1500 | num_updates 192315 | best_loss 3.202
2023-03-02 10:40:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 10:40:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint97.pt (epoch 97 @ 192315 updates, score 3.229) (writing took 5.691458484041505 seconds)
2023-03-02 10:40:52 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2023-03-02 10:40:52 | INFO | train | epoch 097 | loss 3.202 | nll_loss 1.054 | word_ins 2.876 | length 3.267 | ppl 9.21 | wps 201293 | ups 3.27 | wpb 61627.5 | bsz 1998.2 | num_updates 192315 | lr 0.000228031 | gnorm 0.797 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 10:40:52 | INFO | fairseq.trainer | begin training epoch 98
2023-03-02 10:41:28 | INFO | train_inner | epoch 098:     85 / 1983 loss=3.191, nll_loss=1.045, word_ins=2.868, length=3.234, ppl=9.13, wps=104877, ups=1.72, wpb=61055.2, bsz=2004.6, num_updates=192400, lr=0.00022798, gnorm=0.802, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:41:57 | INFO | train_inner | epoch 098:    185 / 1983 loss=3.197, nll_loss=1.046, word_ins=2.869, length=3.274, ppl=9.17, wps=210172, ups=3.42, wpb=61529.7, bsz=1994.4, num_updates=192500, lr=0.000227921, gnorm=0.792, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:42:26 | INFO | train_inner | epoch 098:    285 / 1983 loss=3.173, nll_loss=1.028, word_ins=2.853, length=3.202, ppl=9.02, wps=211709, ups=3.42, wpb=61927.2, bsz=2041.9, num_updates=192600, lr=0.000227862, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:42:55 | INFO | train_inner | epoch 098:    385 / 1983 loss=3.199, nll_loss=1.05, word_ins=2.873, length=3.262, ppl=9.18, wps=211750, ups=3.42, wpb=61909.4, bsz=1981, num_updates=192700, lr=0.000227803, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:43:24 | INFO | train_inner | epoch 098:    485 / 1983 loss=3.203, nll_loss=1.055, word_ins=2.877, length=3.256, ppl=9.21, wps=211600, ups=3.43, wpb=61773.6, bsz=1995, num_updates=192800, lr=0.000227744, gnorm=0.799, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:43:54 | INFO | train_inner | epoch 098:    585 / 1983 loss=3.21, nll_loss=1.062, word_ins=2.883, length=3.271, ppl=9.26, wps=209428, ups=3.4, wpb=61563, bsz=2046.1, num_updates=192900, lr=0.000227685, gnorm=0.798, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:44:23 | INFO | train_inner | epoch 098:    685 / 1983 loss=3.203, nll_loss=1.053, word_ins=2.875, length=3.283, ppl=9.21, wps=212024, ups=3.44, wpb=61716.5, bsz=1954.8, num_updates=193000, lr=0.000227626, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:44:52 | INFO | train_inner | epoch 098:    785 / 1983 loss=3.197, nll_loss=1.046, word_ins=2.87, length=3.275, ppl=9.17, wps=210396, ups=3.43, wpb=61322.8, bsz=2004, num_updates=193100, lr=0.000227567, gnorm=0.789, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:45:21 | INFO | train_inner | epoch 098:    885 / 1983 loss=3.224, nll_loss=1.068, word_ins=2.889, length=3.352, ppl=9.34, wps=211064, ups=3.44, wpb=61290.6, bsz=1973.3, num_updates=193200, lr=0.000227508, gnorm=0.793, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:45:51 | INFO | train_inner | epoch 098:    985 / 1983 loss=3.192, nll_loss=1.046, word_ins=2.869, length=3.225, ppl=9.14, wps=208201, ups=3.41, wpb=61145.2, bsz=2084.9, num_updates=193300, lr=0.000227449, gnorm=0.782, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:46:20 | INFO | train_inner | epoch 098:   1085 / 1983 loss=3.195, nll_loss=1.046, word_ins=2.869, length=3.262, ppl=9.16, wps=210598, ups=3.41, wpb=61808.3, bsz=2053.4, num_updates=193400, lr=0.00022739, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:46:49 | INFO | train_inner | epoch 098:   1185 / 1983 loss=3.177, nll_loss=1.032, word_ins=2.856, length=3.208, ppl=9.04, wps=213883, ups=3.43, wpb=62290.2, bsz=2005, num_updates=193500, lr=0.000227331, gnorm=0.797, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:47:18 | INFO | train_inner | epoch 098:   1285 / 1983 loss=3.197, nll_loss=1.05, word_ins=2.873, length=3.24, ppl=9.17, wps=213520, ups=3.43, wpb=62339, bsz=2004.9, num_updates=193600, lr=0.000227273, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:47:47 | INFO | train_inner | epoch 098:   1385 / 1983 loss=3.205, nll_loss=1.055, word_ins=2.876, length=3.29, ppl=9.22, wps=212010, ups=3.42, wpb=61999.7, bsz=1977.2, num_updates=193700, lr=0.000227214, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:48:17 | INFO | train_inner | epoch 098:   1485 / 1983 loss=3.205, nll_loss=1.057, word_ins=2.878, length=3.269, ppl=9.22, wps=211357, ups=3.43, wpb=61655.2, bsz=1975.6, num_updates=193800, lr=0.000227155, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:48:46 | INFO | train_inner | epoch 098:   1585 / 1983 loss=3.212, nll_loss=1.062, word_ins=2.883, length=3.293, ppl=9.27, wps=211236, ups=3.44, wpb=61420.2, bsz=1993.4, num_updates=193900, lr=0.000227097, gnorm=0.802, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:49:15 | INFO | train_inner | epoch 098:   1685 / 1983 loss=3.192, nll_loss=1.045, word_ins=2.867, length=3.251, ppl=9.14, wps=209670, ups=3.42, wpb=61362.8, bsz=2025.4, num_updates=194000, lr=0.000227038, gnorm=0.792, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:49:44 | INFO | train_inner | epoch 098:   1785 / 1983 loss=3.241, nll_loss=1.082, word_ins=2.901, length=3.394, ppl=9.45, wps=210153, ups=3.44, wpb=61096.9, bsz=1883.6, num_updates=194100, lr=0.00022698, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:50:13 | INFO | train_inner | epoch 098:   1885 / 1983 loss=3.213, nll_loss=1.068, word_ins=2.888, length=3.242, ppl=9.27, wps=210915, ups=3.42, wpb=61660.7, bsz=2008.6, num_updates=194200, lr=0.000226921, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 10:50:56 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 3.217 | nll_loss 1.015 | word_ins 2.897 | length 3.202 | ppl 9.3 | wps 86919.8 | wpb 41551 | bsz 1500 | num_updates 194298 | best_loss 3.202
2023-03-02 10:50:56 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 10:51:02 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint98.pt (epoch 98 @ 194298 updates, score 3.217) (writing took 5.895215405966155 seconds)
2023-03-02 10:51:02 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2023-03-02 10:51:02 | INFO | train | epoch 098 | loss 3.203 | nll_loss 1.053 | word_ins 2.876 | length 3.27 | ppl 9.21 | wps 200329 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 194298 | lr 0.000226864 | gnorm 0.802 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 10:51:02 | INFO | fairseq.trainer | begin training epoch 99
2023-03-02 10:51:12 | INFO | train_inner | epoch 099:      2 / 1983 loss=3.216, nll_loss=1.068, word_ins=2.888, length=3.272, ppl=9.29, wps=104206, ups=1.7, wpb=61396.5, bsz=1962.4, num_updates=194300, lr=0.000226863, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:51:42 | INFO | train_inner | epoch 099:    102 / 1983 loss=3.194, nll_loss=1.042, word_ins=2.865, length=3.291, ppl=9.15, wps=211529, ups=3.41, wpb=62009.5, bsz=1996.7, num_updates=194400, lr=0.000226805, gnorm=0.807, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:52:11 | INFO | train_inner | epoch 099:    202 / 1983 loss=3.188, nll_loss=1.045, word_ins=2.868, length=3.203, ppl=9.12, wps=212219, ups=3.42, wpb=62031.6, bsz=1991.7, num_updates=194500, lr=0.000226746, gnorm=0.799, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:52:40 | INFO | train_inner | epoch 099:    302 / 1983 loss=3.209, nll_loss=1.059, word_ins=2.881, length=3.285, ppl=9.25, wps=209573, ups=3.41, wpb=61403.5, bsz=1946.9, num_updates=194600, lr=0.000226688, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:53:09 | INFO | train_inner | epoch 099:    402 / 1983 loss=3.191, nll_loss=1.039, word_ins=2.863, length=3.277, ppl=9.13, wps=209504, ups=3.41, wpb=61375.6, bsz=2035.4, num_updates=194700, lr=0.00022663, gnorm=0.793, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:53:39 | INFO | train_inner | epoch 099:    502 / 1983 loss=3.172, nll_loss=1.032, word_ins=2.856, length=3.169, ppl=9.02, wps=212543, ups=3.42, wpb=62085.1, bsz=2020.2, num_updates=194800, lr=0.000226572, gnorm=0.797, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:54:08 | INFO | train_inner | epoch 099:    602 / 1983 loss=3.205, nll_loss=1.055, word_ins=2.878, length=3.274, ppl=9.22, wps=210082, ups=3.41, wpb=61573.7, bsz=2025.8, num_updates=194900, lr=0.000226513, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:54:37 | INFO | train_inner | epoch 099:    702 / 1983 loss=3.201, nll_loss=1.052, word_ins=2.874, length=3.263, ppl=9.19, wps=210279, ups=3.43, wpb=61265.4, bsz=1942.2, num_updates=195000, lr=0.000226455, gnorm=0.801, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:55:06 | INFO | train_inner | epoch 099:    802 / 1983 loss=3.184, nll_loss=1.039, word_ins=2.862, length=3.218, ppl=9.09, wps=210632, ups=3.42, wpb=61532.5, bsz=2099.7, num_updates=195100, lr=0.000226397, gnorm=0.801, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:55:35 | INFO | train_inner | epoch 099:    902 / 1983 loss=3.213, nll_loss=1.062, word_ins=2.883, length=3.296, ppl=9.27, wps=211323, ups=3.43, wpb=61645.6, bsz=1915.4, num_updates=195200, lr=0.000226339, gnorm=0.799, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:56:05 | INFO | train_inner | epoch 099:   1002 / 1983 loss=3.199, nll_loss=1.053, word_ins=2.875, length=3.236, ppl=9.18, wps=210124, ups=3.42, wpb=61384.2, bsz=2039.5, num_updates=195300, lr=0.000226281, gnorm=0.804, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:56:34 | INFO | train_inner | epoch 099:   1102 / 1983 loss=3.17, nll_loss=1.025, word_ins=2.85, length=3.203, ppl=9, wps=210479, ups=3.41, wpb=61711, bsz=2092.2, num_updates=195400, lr=0.000226224, gnorm=0.792, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:57:03 | INFO | train_inner | epoch 099:   1202 / 1983 loss=3.21, nll_loss=1.06, word_ins=2.882, length=3.284, ppl=9.25, wps=209978, ups=3.42, wpb=61427.6, bsz=2009, num_updates=195500, lr=0.000226166, gnorm=0.794, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:57:32 | INFO | train_inner | epoch 099:   1302 / 1983 loss=3.197, nll_loss=1.046, word_ins=2.869, length=3.282, ppl=9.17, wps=212183, ups=3.43, wpb=61827.2, bsz=1985, num_updates=195600, lr=0.000226108, gnorm=0.797, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:58:02 | INFO | train_inner | epoch 099:   1402 / 1983 loss=3.204, nll_loss=1.052, word_ins=2.874, length=3.297, ppl=9.21, wps=211094, ups=3.42, wpb=61648, bsz=1938.5, num_updates=195700, lr=0.00022605, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:58:31 | INFO | train_inner | epoch 099:   1502 / 1983 loss=3.203, nll_loss=1.054, word_ins=2.876, length=3.276, ppl=9.21, wps=211161, ups=3.43, wpb=61522.5, bsz=2017.8, num_updates=195800, lr=0.000225992, gnorm=0.794, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:59:00 | INFO | train_inner | epoch 099:   1602 / 1983 loss=3.225, nll_loss=1.074, word_ins=2.894, length=3.311, ppl=9.35, wps=212465, ups=3.43, wpb=61894.2, bsz=1920.6, num_updates=195900, lr=0.000225935, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:59:29 | INFO | train_inner | epoch 099:   1702 / 1983 loss=3.228, nll_loss=1.077, word_ins=2.897, length=3.31, ppl=9.37, wps=209926, ups=3.42, wpb=61362.7, bsz=1957.8, num_updates=196000, lr=0.000225877, gnorm=0.797, loss_scale=16384, train_wall=29, wall=0
2023-03-02 10:59:58 | INFO | train_inner | epoch 099:   1802 / 1983 loss=3.193, nll_loss=1.047, word_ins=2.869, length=3.24, ppl=9.15, wps=211711, ups=3.42, wpb=61858.5, bsz=2001.8, num_updates=196100, lr=0.000225819, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:00:28 | INFO | train_inner | epoch 099:   1902 / 1983 loss=3.195, nll_loss=1.048, word_ins=2.87, length=3.249, ppl=9.16, wps=210923, ups=3.42, wpb=61721.7, bsz=2045.2, num_updates=196200, lr=0.000225762, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:00:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 11:01:04 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 3.235 | nll_loss 1.015 | word_ins 2.893 | length 3.414 | ppl 9.41 | wps 83003.3 | wpb 41551 | bsz 1500 | num_updates 196281 | best_loss 3.202
2023-03-02 11:01:04 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 11:01:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint99.pt (epoch 99 @ 196281 updates, score 3.235) (writing took 5.374315673019737 seconds)
2023-03-02 11:01:10 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2023-03-02 11:01:10 | INFO | train | epoch 099 | loss 3.199 | nll_loss 1.051 | word_ins 2.873 | length 3.263 | ppl 9.19 | wps 201048 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 196281 | lr 0.000225715 | gnorm 0.802 | loss_scale 32768 | train_wall 577 | wall 0
2023-03-02 11:01:10 | INFO | fairseq.trainer | begin training epoch 100
2023-03-02 11:01:25 | INFO | train_inner | epoch 100:     19 / 1983 loss=3.196, nll_loss=1.047, word_ins=2.87, length=3.265, ppl=9.16, wps=107355, ups=1.74, wpb=61626.4, bsz=1958.6, num_updates=196300, lr=0.000225704, gnorm=0.826, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:01:54 | INFO | train_inner | epoch 100:    119 / 1983 loss=3.179, nll_loss=1.034, word_ins=2.858, length=3.211, ppl=9.06, wps=210353, ups=3.41, wpb=61700.2, bsz=2035.2, num_updates=196400, lr=0.000225647, gnorm=0.785, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:02:24 | INFO | train_inner | epoch 100:    219 / 1983 loss=3.185, nll_loss=1.039, word_ins=2.862, length=3.23, ppl=9.1, wps=210419, ups=3.42, wpb=61494.3, bsz=2016.6, num_updates=196500, lr=0.000225589, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:02:53 | INFO | train_inner | epoch 100:    319 / 1983 loss=3.193, nll_loss=1.045, word_ins=2.868, length=3.245, ppl=9.14, wps=211963, ups=3.43, wpb=61725.4, bsz=1972.9, num_updates=196600, lr=0.000225532, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:03:22 | INFO | train_inner | epoch 100:    419 / 1983 loss=3.2, nll_loss=1.049, word_ins=2.872, length=3.28, ppl=9.19, wps=211777, ups=3.44, wpb=61524.2, bsz=1954, num_updates=196700, lr=0.000225475, gnorm=0.812, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:03:51 | INFO | train_inner | epoch 100:    519 / 1983 loss=3.182, nll_loss=1.032, word_ins=2.856, length=3.257, ppl=9.07, wps=210970, ups=3.43, wpb=61497.1, bsz=1990.6, num_updates=196800, lr=0.000225417, gnorm=0.781, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:04:20 | INFO | train_inner | epoch 100:    619 / 1983 loss=3.165, nll_loss=1.02, word_ins=2.845, length=3.205, ppl=8.97, wps=210677, ups=3.42, wpb=61640.2, bsz=2099, num_updates=196900, lr=0.00022536, gnorm=0.79, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:04:49 | INFO | train_inner | epoch 100:    719 / 1983 loss=3.193, nll_loss=1.049, word_ins=2.871, length=3.219, ppl=9.15, wps=211244, ups=3.42, wpb=61813.7, bsz=2012.6, num_updates=197000, lr=0.000225303, gnorm=0.803, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:05:19 | INFO | train_inner | epoch 100:    819 / 1983 loss=3.19, nll_loss=1.045, word_ins=2.868, length=3.227, ppl=9.13, wps=210414, ups=3.42, wpb=61525.3, bsz=2044.7, num_updates=197100, lr=0.000225246, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:05:48 | INFO | train_inner | epoch 100:    919 / 1983 loss=3.186, nll_loss=1.038, word_ins=2.861, length=3.255, ppl=9.1, wps=213652, ups=3.46, wpb=61818, bsz=1981.8, num_updates=197200, lr=0.000225189, gnorm=0.782, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:06:17 | INFO | train_inner | epoch 100:   1019 / 1983 loss=3.201, nll_loss=1.055, word_ins=2.877, length=3.247, ppl=9.2, wps=210574, ups=3.43, wpb=61402.7, bsz=1990.9, num_updates=197300, lr=0.000225132, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:06:46 | INFO | train_inner | epoch 100:   1119 / 1983 loss=3.198, nll_loss=1.049, word_ins=2.871, length=3.268, ppl=9.18, wps=212186, ups=3.42, wpb=61974.2, bsz=1993.5, num_updates=197400, lr=0.000225075, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:07:15 | INFO | train_inner | epoch 100:   1219 / 1983 loss=3.185, nll_loss=1.041, word_ins=2.863, length=3.213, ppl=9.09, wps=211628, ups=3.43, wpb=61778.5, bsz=2049, num_updates=197500, lr=0.000225018, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:07:44 | INFO | train_inner | epoch 100:   1319 / 1983 loss=3.215, nll_loss=1.066, word_ins=2.887, length=3.28, ppl=9.28, wps=210650, ups=3.43, wpb=61477.9, bsz=1966.4, num_updates=197600, lr=0.000224961, gnorm=0.824, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:08:14 | INFO | train_inner | epoch 100:   1419 / 1983 loss=3.226, nll_loss=1.073, word_ins=2.894, length=3.322, ppl=9.36, wps=209967, ups=3.43, wpb=61258.8, bsz=1951.4, num_updates=197700, lr=0.000224904, gnorm=0.796, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:08:43 | INFO | train_inner | epoch 100:   1519 / 1983 loss=3.207, nll_loss=1.058, word_ins=2.879, length=3.281, ppl=9.24, wps=210842, ups=3.43, wpb=61522.7, bsz=2041.4, num_updates=197800, lr=0.000224847, gnorm=0.823, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:09:12 | INFO | train_inner | epoch 100:   1619 / 1983 loss=3.198, nll_loss=1.046, word_ins=2.869, length=3.294, ppl=9.18, wps=212258, ups=3.44, wpb=61760.1, bsz=2016.1, num_updates=197900, lr=0.00022479, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:09:41 | INFO | train_inner | epoch 100:   1719 / 1983 loss=3.235, nll_loss=1.082, word_ins=2.901, length=3.34, ppl=9.42, wps=211166, ups=3.44, wpb=61333.2, bsz=1912.4, num_updates=198000, lr=0.000224733, gnorm=0.834, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:10:10 | INFO | train_inner | epoch 100:   1819 / 1983 loss=3.223, nll_loss=1.073, word_ins=2.893, length=3.295, ppl=9.33, wps=212152, ups=3.43, wpb=61798.6, bsz=1957.8, num_updates=198100, lr=0.000224677, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:10:39 | INFO | train_inner | epoch 100:   1919 / 1983 loss=3.192, nll_loss=1.045, word_ins=2.868, length=3.248, ppl=9.14, wps=212143, ups=3.43, wpb=61891.8, bsz=2034.3, num_updates=198200, lr=0.00022462, gnorm=0.78, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 11:11:12 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 3.205 | nll_loss 0.995 | word_ins 2.886 | length 3.196 | ppl 9.22 | wps 102145 | wpb 41551 | bsz 1500 | num_updates 198264 | best_loss 3.202
2023-03-02 11:11:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 11:11:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint100.pt (epoch 100 @ 198264 updates, score 3.205) (writing took 5.62854918197263 seconds)
2023-03-02 11:11:17 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2023-03-02 11:11:17 | INFO | train | epoch 100 | loss 3.197 | nll_loss 1.049 | word_ins 2.871 | length 3.259 | ppl 9.17 | wps 201087 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 198264 | lr 0.000224584 | gnorm 0.801 | loss_scale 32768 | train_wall 575 | wall 0
2023-03-02 11:11:17 | INFO | fairseq.trainer | begin training epoch 101
2023-03-02 11:11:39 | INFO | train_inner | epoch 101:     36 / 1983 loss=3.186, nll_loss=1.035, word_ins=2.859, length=3.276, ppl=9.1, wps=103462, ups=1.68, wpb=61508.2, bsz=1972.5, num_updates=198300, lr=0.000224563, gnorm=0.806, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:12:08 | INFO | train_inner | epoch 101:    136 / 1983 loss=3.184, nll_loss=1.037, word_ins=2.861, length=3.224, ppl=9.09, wps=210581, ups=3.42, wpb=61521.3, bsz=1979.5, num_updates=198400, lr=0.000224507, gnorm=0.792, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:12:37 | INFO | train_inner | epoch 101:    236 / 1983 loss=3.202, nll_loss=1.047, word_ins=2.871, length=3.309, ppl=9.2, wps=209661, ups=3.42, wpb=61393.4, bsz=1965.6, num_updates=198500, lr=0.00022445, gnorm=0.82, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:13:06 | INFO | train_inner | epoch 101:    336 / 1983 loss=3.209, nll_loss=1.057, word_ins=2.879, length=3.297, ppl=9.24, wps=211038, ups=3.43, wpb=61439.6, bsz=1920.3, num_updates=198600, lr=0.000224394, gnorm=0.816, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:13:36 | INFO | train_inner | epoch 101:    436 / 1983 loss=3.153, nll_loss=1.009, word_ins=2.835, length=3.183, ppl=8.89, wps=211549, ups=3.41, wpb=62001.9, bsz=2107.1, num_updates=198700, lr=0.000224337, gnorm=0.786, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:14:05 | INFO | train_inner | epoch 101:    536 / 1983 loss=3.185, nll_loss=1.044, word_ins=2.866, length=3.186, ppl=9.09, wps=211370, ups=3.42, wpb=61839.9, bsz=2053.6, num_updates=198800, lr=0.000224281, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:14:34 | INFO | train_inner | epoch 101:    636 / 1983 loss=3.183, nll_loss=1.038, word_ins=2.861, length=3.216, ppl=9.08, wps=209951, ups=3.42, wpb=61469, bsz=2054.2, num_updates=198900, lr=0.000224224, gnorm=0.791, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:15:03 | INFO | train_inner | epoch 101:    736 / 1983 loss=3.202, nll_loss=1.054, word_ins=2.876, length=3.258, ppl=9.2, wps=211510, ups=3.43, wpb=61607, bsz=1978.6, num_updates=199000, lr=0.000224168, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:15:32 | INFO | train_inner | epoch 101:    836 / 1983 loss=3.189, nll_loss=1.04, word_ins=2.863, length=3.262, ppl=9.12, wps=210486, ups=3.43, wpb=61326.5, bsz=2003.9, num_updates=199100, lr=0.000224112, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:16:02 | INFO | train_inner | epoch 101:    936 / 1983 loss=3.188, nll_loss=1.04, word_ins=2.863, length=3.243, ppl=9.11, wps=211570, ups=3.43, wpb=61699.8, bsz=2053.6, num_updates=199200, lr=0.000224055, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:16:31 | INFO | train_inner | epoch 101:   1036 / 1983 loss=3.205, nll_loss=1.057, word_ins=2.879, length=3.258, ppl=9.22, wps=212537, ups=3.44, wpb=61847.5, bsz=1969.4, num_updates=199300, lr=0.000223999, gnorm=0.802, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:17:00 | INFO | train_inner | epoch 101:   1136 / 1983 loss=3.169, nll_loss=1.023, word_ins=2.848, length=3.213, ppl=8.99, wps=212568, ups=3.44, wpb=61853.4, bsz=2054.5, num_updates=199400, lr=0.000223943, gnorm=0.788, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:17:29 | INFO | train_inner | epoch 101:   1236 / 1983 loss=3.198, nll_loss=1.049, word_ins=2.872, length=3.259, ppl=9.17, wps=213498, ups=3.44, wpb=62114.2, bsz=1962.8, num_updates=199500, lr=0.000223887, gnorm=0.81, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:17:58 | INFO | train_inner | epoch 101:   1336 / 1983 loss=3.201, nll_loss=1.052, word_ins=2.874, length=3.273, ppl=9.2, wps=212799, ups=3.45, wpb=61770.2, bsz=1933.3, num_updates=199600, lr=0.000223831, gnorm=0.78, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:18:27 | INFO | train_inner | epoch 101:   1436 / 1983 loss=3.173, nll_loss=1.026, word_ins=2.85, length=3.225, ppl=9.02, wps=209465, ups=3.42, wpb=61162, bsz=2128, num_updates=199700, lr=0.000223775, gnorm=0.795, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:18:56 | INFO | train_inner | epoch 101:   1536 / 1983 loss=3.235, nll_loss=1.079, word_ins=2.899, length=3.364, ppl=9.41, wps=210418, ups=3.43, wpb=61359.7, bsz=1920.6, num_updates=199800, lr=0.000223719, gnorm=0.832, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:19:25 | INFO | train_inner | epoch 101:   1636 / 1983 loss=3.245, nll_loss=1.091, word_ins=2.91, length=3.355, ppl=9.48, wps=212278, ups=3.45, wpb=61493.3, bsz=1841, num_updates=199900, lr=0.000223663, gnorm=0.812, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:19:55 | INFO | train_inner | epoch 101:   1736 / 1983 loss=3.19, nll_loss=1.043, word_ins=2.866, length=3.242, ppl=9.13, wps=210957, ups=3.41, wpb=61812.5, bsz=2022.4, num_updates=200000, lr=0.000223607, gnorm=0.827, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:20:24 | INFO | train_inner | epoch 101:   1836 / 1983 loss=3.218, nll_loss=1.066, word_ins=2.886, length=3.322, ppl=9.31, wps=210269, ups=3.42, wpb=61399.9, bsz=1978.6, num_updates=200100, lr=0.000223551, gnorm=0.823, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:20:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32768.0
2023-03-02 11:20:53 | INFO | train_inner | epoch 101:   1937 / 1983 loss=3.176, nll_loss=1.031, word_ins=2.855, length=3.215, ppl=9.04, wps=212206, ups=3.41, wpb=62221, bsz=2028.8, num_updates=200200, lr=0.000223495, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 11:21:20 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 3.242 | nll_loss 1.017 | word_ins 2.899 | length 3.427 | ppl 9.46 | wps 134032 | wpb 41551 | bsz 1500 | num_updates 200246 | best_loss 3.202
2023-03-02 11:21:20 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 11:21:27 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint101.pt (epoch 101 @ 200246 updates, score 3.242) (writing took 7.560622946009971 seconds)
2023-03-02 11:21:27 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2023-03-02 11:21:28 | INFO | train | epoch 101 | loss 3.195 | nll_loss 1.047 | word_ins 2.869 | length 3.259 | ppl 9.16 | wps 200192 | ups 3.25 | wpb 61634.1 | bsz 1997.1 | num_updates 200246 | lr 0.000223469 | gnorm 0.804 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 11:21:28 | INFO | fairseq.trainer | begin training epoch 102
2023-03-02 11:21:53 | INFO | train_inner | epoch 102:     54 / 1983 loss=3.201, nll_loss=1.048, word_ins=2.871, length=3.306, ppl=9.2, wps=101282, ups=1.66, wpb=61000.9, bsz=1972.3, num_updates=200300, lr=0.000223439, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:22:22 | INFO | train_inner | epoch 102:    154 / 1983 loss=3.192, nll_loss=1.043, word_ins=2.866, length=3.255, ppl=9.14, wps=212959, ups=3.43, wpb=62097.5, bsz=1938.2, num_updates=200400, lr=0.000223384, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:22:52 | INFO | train_inner | epoch 102:    254 / 1983 loss=3.166, nll_loss=1.021, word_ins=2.846, length=3.2, ppl=8.98, wps=211503, ups=3.42, wpb=61826.9, bsz=2086.8, num_updates=200500, lr=0.000223328, gnorm=0.793, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:23:21 | INFO | train_inner | epoch 102:    354 / 1983 loss=3.199, nll_loss=1.052, word_ins=2.874, length=3.248, ppl=9.18, wps=211750, ups=3.44, wpb=61582.3, bsz=1992.6, num_updates=200600, lr=0.000223272, gnorm=0.803, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:23:50 | INFO | train_inner | epoch 102:    454 / 1983 loss=3.214, nll_loss=1.064, word_ins=2.886, length=3.285, ppl=9.28, wps=211507, ups=3.43, wpb=61622.1, bsz=1914.6, num_updates=200700, lr=0.000223217, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:24:19 | INFO | train_inner | epoch 102:    554 / 1983 loss=3.177, nll_loss=1.03, word_ins=2.854, length=3.227, ppl=9.04, wps=211908, ups=3.41, wpb=62067.3, bsz=2005.9, num_updates=200800, lr=0.000223161, gnorm=0.806, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:24:48 | INFO | train_inner | epoch 102:    654 / 1983 loss=3.164, nll_loss=1.024, word_ins=2.849, length=3.153, ppl=8.96, wps=212736, ups=3.42, wpb=62219.1, bsz=2081.6, num_updates=200900, lr=0.000223105, gnorm=0.785, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:25:18 | INFO | train_inner | epoch 102:    754 / 1983 loss=3.197, nll_loss=1.049, word_ins=2.871, length=3.258, ppl=9.17, wps=211752, ups=3.42, wpb=61831.7, bsz=1915.4, num_updates=201000, lr=0.00022305, gnorm=0.805, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:25:47 | INFO | train_inner | epoch 102:    854 / 1983 loss=3.17, nll_loss=1.029, word_ins=2.853, length=3.177, ppl=9, wps=210606, ups=3.43, wpb=61334.6, bsz=2030, num_updates=201100, lr=0.000222994, gnorm=0.797, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:26:16 | INFO | train_inner | epoch 102:    954 / 1983 loss=3.205, nll_loss=1.052, word_ins=2.874, length=3.308, ppl=9.22, wps=210082, ups=3.43, wpb=61206.9, bsz=1935, num_updates=201200, lr=0.000222939, gnorm=0.819, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:26:45 | INFO | train_inner | epoch 102:   1054 / 1983 loss=3.197, nll_loss=1.05, word_ins=2.872, length=3.249, ppl=9.17, wps=212137, ups=3.44, wpb=61734.8, bsz=2027.5, num_updates=201300, lr=0.000222884, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:27:14 | INFO | train_inner | epoch 102:   1154 / 1983 loss=3.219, nll_loss=1.063, word_ins=2.884, length=3.345, ppl=9.31, wps=210307, ups=3.42, wpb=61408.6, bsz=1937.4, num_updates=201400, lr=0.000222828, gnorm=0.819, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:27:43 | INFO | train_inner | epoch 102:   1254 / 1983 loss=3.178, nll_loss=1.036, word_ins=2.859, length=3.191, ppl=9.05, wps=211076, ups=3.42, wpb=61647.4, bsz=2077.8, num_updates=201500, lr=0.000222773, gnorm=0.801, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:28:13 | INFO | train_inner | epoch 102:   1354 / 1983 loss=3.189, nll_loss=1.04, word_ins=2.863, length=3.26, ppl=9.12, wps=212014, ups=3.42, wpb=61953.5, bsz=2029.1, num_updates=201600, lr=0.000222718, gnorm=0.796, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:28:42 | INFO | train_inner | epoch 102:   1454 / 1983 loss=3.185, nll_loss=1.038, word_ins=2.861, length=3.235, ppl=9.09, wps=212352, ups=3.44, wpb=61818.9, bsz=2019.4, num_updates=201700, lr=0.000222662, gnorm=0.816, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:29:11 | INFO | train_inner | epoch 102:   1554 / 1983 loss=3.214, nll_loss=1.066, word_ins=2.887, length=3.275, ppl=9.28, wps=211452, ups=3.43, wpb=61587.2, bsz=1967.5, num_updates=201800, lr=0.000222607, gnorm=0.814, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:29:40 | INFO | train_inner | epoch 102:   1654 / 1983 loss=3.212, nll_loss=1.055, word_ins=2.877, length=3.345, ppl=9.27, wps=210972, ups=3.44, wpb=61331, bsz=1999.1, num_updates=201900, lr=0.000222552, gnorm=0.802, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:30:09 | INFO | train_inner | epoch 102:   1754 / 1983 loss=3.188, nll_loss=1.04, word_ins=2.862, length=3.257, ppl=9.11, wps=211807, ups=3.44, wpb=61598, bsz=1993.3, num_updates=202000, lr=0.000222497, gnorm=0.799, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:30:38 | INFO | train_inner | epoch 102:   1854 / 1983 loss=3.217, nll_loss=1.064, word_ins=2.884, length=3.323, ppl=9.3, wps=209887, ups=3.44, wpb=61039.3, bsz=1961.9, num_updates=202100, lr=0.000222442, gnorm=0.814, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:31:07 | INFO | train_inner | epoch 102:   1954 / 1983 loss=3.171, nll_loss=1.022, word_ins=2.847, length=3.24, ppl=9, wps=212601, ups=3.45, wpb=61623.5, bsz=2043, num_updates=202200, lr=0.000222387, gnorm=0.795, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 11:31:30 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 3.212 | nll_loss 1 | word_ins 2.884 | length 3.284 | ppl 9.27 | wps 82841.5 | wpb 41551 | bsz 1500 | num_updates 202229 | best_loss 3.202
2023-03-02 11:31:30 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 11:31:36 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint102.pt (epoch 102 @ 202229 updates, score 3.212) (writing took 5.72213073191233 seconds)
2023-03-02 11:31:36 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2023-03-02 11:31:36 | INFO | train | epoch 102 | loss 3.192 | nll_loss 1.044 | word_ins 2.867 | length 3.257 | ppl 9.14 | wps 200830 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 202229 | lr 0.000222371 | gnorm 0.805 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 11:31:36 | INFO | fairseq.trainer | begin training epoch 103
2023-03-02 11:32:09 | INFO | train_inner | epoch 103:     71 / 1983 loss=3.145, nll_loss=1.005, word_ins=2.831, length=3.138, ppl=8.84, wps=100332, ups=1.63, wpb=61733.5, bsz=2093, num_updates=202300, lr=0.000222332, gnorm=0.791, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:32:38 | INFO | train_inner | epoch 103:    171 / 1983 loss=3.212, nll_loss=1.06, word_ins=2.882, length=3.299, ppl=9.27, wps=207631, ups=3.4, wpb=61058.2, bsz=1963, num_updates=202400, lr=0.000222277, gnorm=0.8, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:33:07 | INFO | train_inner | epoch 103:    271 / 1983 loss=3.194, nll_loss=1.046, word_ins=2.869, length=3.243, ppl=9.15, wps=210615, ups=3.4, wpb=61886.6, bsz=1956.5, num_updates=202500, lr=0.000222222, gnorm=0.798, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:33:37 | INFO | train_inner | epoch 103:    371 / 1983 loss=3.185, nll_loss=1.035, word_ins=2.859, length=3.259, ppl=9.09, wps=209981, ups=3.42, wpb=61441, bsz=2012.5, num_updates=202600, lr=0.000222167, gnorm=0.827, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:34:06 | INFO | train_inner | epoch 103:    471 / 1983 loss=3.207, nll_loss=1.057, word_ins=2.879, length=3.279, ppl=9.23, wps=211756, ups=3.43, wpb=61801.6, bsz=1931.8, num_updates=202700, lr=0.000222113, gnorm=0.806, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:34:35 | INFO | train_inner | epoch 103:    571 / 1983 loss=3.194, nll_loss=1.046, word_ins=2.868, length=3.26, ppl=9.15, wps=210757, ups=3.43, wpb=61512.6, bsz=1915.8, num_updates=202800, lr=0.000222058, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:35:04 | INFO | train_inner | epoch 103:    671 / 1983 loss=3.174, nll_loss=1.025, word_ins=2.849, length=3.256, ppl=9.03, wps=212570, ups=3.44, wpb=61802.1, bsz=2001.2, num_updates=202900, lr=0.000222003, gnorm=0.808, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:35:34 | INFO | train_inner | epoch 103:    771 / 1983 loss=3.176, nll_loss=1.03, word_ins=2.855, length=3.217, ppl=9.04, wps=210706, ups=3.39, wpb=62128.8, bsz=2061.5, num_updates=203000, lr=0.000221948, gnorm=0.879, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:36:03 | INFO | train_inner | epoch 103:    871 / 1983 loss=3.173, nll_loss=1.026, word_ins=2.851, length=3.218, ppl=9.02, wps=210352, ups=3.42, wpb=61434.9, bsz=2092, num_updates=203100, lr=0.000221894, gnorm=0.806, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:36:32 | INFO | train_inner | epoch 103:    971 / 1983 loss=3.2, nll_loss=1.051, word_ins=2.874, length=3.259, ppl=9.19, wps=209113, ups=3.41, wpb=61257.4, bsz=1969.4, num_updates=203200, lr=0.000221839, gnorm=0.81, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:37:01 | INFO | train_inner | epoch 103:   1071 / 1983 loss=3.195, nll_loss=1.046, word_ins=2.868, length=3.262, ppl=9.16, wps=211281, ups=3.43, wpb=61615.8, bsz=1953, num_updates=203300, lr=0.000221785, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:37:31 | INFO | train_inner | epoch 103:   1171 / 1983 loss=3.182, nll_loss=1.036, word_ins=2.859, length=3.229, ppl=9.07, wps=211895, ups=3.42, wpb=61902.9, bsz=1997.9, num_updates=203400, lr=0.00022173, gnorm=0.811, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:38:00 | INFO | train_inner | epoch 103:   1271 / 1983 loss=3.187, nll_loss=1.043, word_ins=2.865, length=3.214, ppl=9.1, wps=212771, ups=3.43, wpb=61954, bsz=2006, num_updates=203500, lr=0.000221676, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:38:29 | INFO | train_inner | epoch 103:   1371 / 1983 loss=3.18, nll_loss=1.036, word_ins=2.86, length=3.202, ppl=9.06, wps=211808, ups=3.41, wpb=62025.3, bsz=2046, num_updates=203600, lr=0.000221621, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:38:58 | INFO | train_inner | epoch 103:   1471 / 1983 loss=3.182, nll_loss=1.035, word_ins=2.858, length=3.231, ppl=9.07, wps=210906, ups=3.42, wpb=61694.3, bsz=2037.7, num_updates=203700, lr=0.000221567, gnorm=0.807, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:39:27 | INFO | train_inner | epoch 103:   1571 / 1983 loss=3.229, nll_loss=1.079, word_ins=2.898, length=3.315, ppl=9.38, wps=212444, ups=3.45, wpb=61588.6, bsz=1856.5, num_updates=203800, lr=0.000221512, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:39:56 | INFO | train_inner | epoch 103:   1671 / 1983 loss=3.207, nll_loss=1.053, word_ins=2.875, length=3.323, ppl=9.24, wps=210088, ups=3.44, wpb=61014.6, bsz=1944.2, num_updates=203900, lr=0.000221458, gnorm=0.827, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:40:25 | INFO | train_inner | epoch 103:   1771 / 1983 loss=3.198, nll_loss=1.048, word_ins=2.87, length=3.282, ppl=9.18, wps=211254, ups=3.44, wpb=61484.6, bsz=1998.6, num_updates=204000, lr=0.000221404, gnorm=0.801, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:40:55 | INFO | train_inner | epoch 103:   1871 / 1983 loss=3.178, nll_loss=1.03, word_ins=2.854, length=3.245, ppl=9.05, wps=212326, ups=3.42, wpb=62019.4, bsz=2097.4, num_updates=204100, lr=0.000221349, gnorm=0.794, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:41:24 | INFO | train_inner | epoch 103:   1971 / 1983 loss=3.184, nll_loss=1.033, word_ins=2.856, length=3.274, ppl=9.09, wps=210661, ups=3.44, wpb=61195.7, bsz=2033.2, num_updates=204200, lr=0.000221295, gnorm=0.786, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 11:41:42 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 3.228 | nll_loss 1.02 | word_ins 2.905 | length 3.229 | ppl 9.37 | wps 94302.5 | wpb 41551 | bsz 1500 | num_updates 204212 | best_loss 3.202
2023-03-02 11:41:42 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 11:41:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint103.pt (epoch 103 @ 204212 updates, score 3.228) (writing took 11.619916380033828 seconds)
2023-03-02 11:41:54 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2023-03-02 11:41:54 | INFO | train | epoch 103 | loss 3.189 | nll_loss 1.041 | word_ins 2.864 | length 3.249 | ppl 9.12 | wps 197760 | ups 3.21 | wpb 61628.5 | bsz 1997.6 | num_updates 204212 | lr 0.000221289 | gnorm 0.812 | loss_scale 32768 | train_wall 577 | wall 0
2023-03-02 11:41:54 | INFO | fairseq.trainer | begin training epoch 104
2023-03-02 11:42:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32768.0
2023-03-02 11:42:40 | INFO | train_inner | epoch 104:     89 / 1983 loss=3.205, nll_loss=1.058, word_ins=2.88, length=3.253, ppl=9.22, wps=80692.7, ups=1.32, wpb=61268.6, bsz=1948.9, num_updates=204300, lr=0.000221241, gnorm=0.84, loss_scale=32768, train_wall=30, wall=0
2023-03-02 11:43:09 | INFO | train_inner | epoch 104:    189 / 1983 loss=3.168, nll_loss=1.021, word_ins=2.846, length=3.218, ppl=8.99, wps=210744, ups=3.42, wpb=61594, bsz=2046.2, num_updates=204400, lr=0.000221187, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:43:38 | INFO | train_inner | epoch 104:    289 / 1983 loss=3.186, nll_loss=1.038, word_ins=2.861, length=3.248, ppl=9.1, wps=210862, ups=3.43, wpb=61447, bsz=1963.5, num_updates=204500, lr=0.000221133, gnorm=0.825, loss_scale=32768, train_wall=29, wall=0
2023-03-02 11:43:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 11:44:08 | INFO | train_inner | epoch 104:    390 / 1983 loss=3.176, nll_loss=1.031, word_ins=2.855, length=3.208, ppl=9.04, wps=209678, ups=3.38, wpb=62109, bsz=2045.2, num_updates=204600, lr=0.000221079, gnorm=0.8, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:44:37 | INFO | train_inner | epoch 104:    490 / 1983 loss=3.166, nll_loss=1.022, word_ins=2.847, length=3.194, ppl=8.98, wps=211848, ups=3.43, wpb=61776.8, bsz=2074.4, num_updates=204700, lr=0.000221025, gnorm=0.812, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:45:06 | INFO | train_inner | epoch 104:    590 / 1983 loss=3.185, nll_loss=1.04, word_ins=2.863, length=3.219, ppl=9.1, wps=212925, ups=3.44, wpb=61917.7, bsz=1992.9, num_updates=204800, lr=0.000220971, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:45:35 | INFO | train_inner | epoch 104:    690 / 1983 loss=3.2, nll_loss=1.052, word_ins=2.873, length=3.263, ppl=9.19, wps=211707, ups=3.44, wpb=61544.3, bsz=1962.6, num_updates=204900, lr=0.000220917, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:46:04 | INFO | train_inner | epoch 104:    790 / 1983 loss=3.184, nll_loss=1.036, word_ins=2.859, length=3.255, ppl=9.09, wps=210054, ups=3.43, wpb=61233.9, bsz=2035.8, num_updates=205000, lr=0.000220863, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:46:33 | INFO | train_inner | epoch 104:    890 / 1983 loss=3.19, nll_loss=1.045, word_ins=2.868, length=3.225, ppl=9.13, wps=210334, ups=3.41, wpb=61613.7, bsz=2006.2, num_updates=205100, lr=0.000220809, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:47:03 | INFO | train_inner | epoch 104:    990 / 1983 loss=3.199, nll_loss=1.049, word_ins=2.871, length=3.283, ppl=9.19, wps=210700, ups=3.43, wpb=61516.6, bsz=1985, num_updates=205200, lr=0.000220755, gnorm=0.784, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:47:32 | INFO | train_inner | epoch 104:   1090 / 1983 loss=3.193, nll_loss=1.04, word_ins=2.864, length=3.293, ppl=9.14, wps=213399, ups=3.44, wpb=61985.8, bsz=1929, num_updates=205300, lr=0.000220702, gnorm=0.812, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:48:01 | INFO | train_inner | epoch 104:   1190 / 1983 loss=3.2, nll_loss=1.05, word_ins=2.872, length=3.273, ppl=9.19, wps=211637, ups=3.43, wpb=61706.3, bsz=2013.9, num_updates=205400, lr=0.000220648, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:48:30 | INFO | train_inner | epoch 104:   1290 / 1983 loss=3.2, nll_loss=1.05, word_ins=2.872, length=3.28, ppl=9.19, wps=211949, ups=3.43, wpb=61792.4, bsz=1918.6, num_updates=205500, lr=0.000220594, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:48:59 | INFO | train_inner | epoch 104:   1390 / 1983 loss=3.206, nll_loss=1.051, word_ins=2.874, length=3.318, ppl=9.22, wps=211806, ups=3.44, wpb=61519.8, bsz=1910.6, num_updates=205600, lr=0.000220541, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:49:28 | INFO | train_inner | epoch 104:   1490 / 1983 loss=3.222, nll_loss=1.073, word_ins=2.893, length=3.288, ppl=9.33, wps=208553, ups=3.43, wpb=60839.4, bsz=1929.9, num_updates=205700, lr=0.000220487, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:49:57 | INFO | train_inner | epoch 104:   1590 / 1983 loss=3.157, nll_loss=1.015, word_ins=2.84, length=3.173, ppl=8.92, wps=211440, ups=3.42, wpb=61787, bsz=2094.9, num_updates=205800, lr=0.000220433, gnorm=0.793, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:50:27 | INFO | train_inner | epoch 104:   1690 / 1983 loss=3.195, nll_loss=1.049, word_ins=2.87, length=3.248, ppl=9.16, wps=211997, ups=3.43, wpb=61855.7, bsz=1989.3, num_updates=205900, lr=0.00022038, gnorm=0.804, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:51:00 | INFO | train_inner | epoch 104:   1790 / 1983 loss=3.165, nll_loss=1.018, word_ins=2.843, length=3.22, ppl=8.97, wps=184029, ups=2.98, wpb=61726.6, bsz=2122, num_updates=206000, lr=0.000220326, gnorm=0.778, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:51:29 | INFO | train_inner | epoch 104:   1890 / 1983 loss=3.221, nll_loss=1.064, word_ins=2.884, length=3.364, ppl=9.32, wps=211842, ups=3.45, wpb=61371.9, bsz=1903.8, num_updates=206100, lr=0.000220273, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:51:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 11:52:10 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 3.206 | nll_loss 1.002 | word_ins 2.882 | length 3.247 | ppl 9.23 | wps 106511 | wpb 41551 | bsz 1500 | num_updates 206193 | best_loss 3.202
2023-03-02 11:52:10 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 11:52:15 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint104.pt (epoch 104 @ 206193 updates, score 3.206) (writing took 5.5553633329691365 seconds)
2023-03-02 11:52:15 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2023-03-02 11:52:15 | INFO | train | epoch 104 | loss 3.19 | nll_loss 1.042 | word_ins 2.865 | length 3.253 | ppl 9.12 | wps 196536 | ups 3.19 | wpb 61634.4 | bsz 1997.1 | num_updates 206193 | lr 0.000220223 | gnorm 0.813 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 11:52:15 | INFO | fairseq.trainer | begin training epoch 105
2023-03-02 11:52:42 | INFO | train_inner | epoch 105:      7 / 1983 loss=3.186, nll_loss=1.04, word_ins=2.862, length=3.236, ppl=9.1, wps=84849.2, ups=1.38, wpb=61509.4, bsz=2048.5, num_updates=206200, lr=0.000220219, gnorm=0.793, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:53:11 | INFO | train_inner | epoch 105:    107 / 1983 loss=3.193, nll_loss=1.044, word_ins=2.868, length=3.249, ppl=9.14, wps=210942, ups=3.41, wpb=61847, bsz=1985.9, num_updates=206300, lr=0.000220166, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:53:40 | INFO | train_inner | epoch 105:    207 / 1983 loss=3.165, nll_loss=1.02, word_ins=2.845, length=3.197, ppl=8.97, wps=209144, ups=3.42, wpb=61065.5, bsz=2090.4, num_updates=206400, lr=0.000220113, gnorm=0.802, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:54:09 | INFO | train_inner | epoch 105:    307 / 1983 loss=3.188, nll_loss=1.037, word_ins=2.86, length=3.275, ppl=9.11, wps=208319, ups=3.42, wpb=60977.8, bsz=2029.8, num_updates=206500, lr=0.000220059, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:54:39 | INFO | train_inner | epoch 105:    407 / 1983 loss=3.192, nll_loss=1.044, word_ins=2.867, length=3.253, ppl=9.14, wps=211945, ups=3.42, wpb=61929.8, bsz=1979.8, num_updates=206600, lr=0.000220006, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:55:08 | INFO | train_inner | epoch 105:    507 / 1983 loss=3.17, nll_loss=1.023, word_ins=2.847, length=3.23, ppl=9, wps=207928, ups=3.4, wpb=61130.1, bsz=2091.8, num_updates=206700, lr=0.000219953, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:55:37 | INFO | train_inner | epoch 105:    607 / 1983 loss=3.197, nll_loss=1.05, word_ins=2.872, length=3.25, ppl=9.17, wps=212282, ups=3.42, wpb=62074.3, bsz=1926.7, num_updates=206800, lr=0.0002199, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:56:06 | INFO | train_inner | epoch 105:    707 / 1983 loss=3.188, nll_loss=1.042, word_ins=2.865, length=3.233, ppl=9.12, wps=211206, ups=3.44, wpb=61476.3, bsz=1974.4, num_updates=206900, lr=0.000219847, gnorm=0.81, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:56:35 | INFO | train_inner | epoch 105:    807 / 1983 loss=3.187, nll_loss=1.041, word_ins=2.863, length=3.239, ppl=9.11, wps=212113, ups=3.43, wpb=61801, bsz=2004.1, num_updates=207000, lr=0.000219793, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:57:05 | INFO | train_inner | epoch 105:    907 / 1983 loss=3.178, nll_loss=1.028, word_ins=2.852, length=3.265, ppl=9.05, wps=211494, ups=3.45, wpb=61375.8, bsz=2010.6, num_updates=207100, lr=0.00021974, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:57:34 | INFO | train_inner | epoch 105:   1007 / 1983 loss=3.178, nll_loss=1.029, word_ins=2.853, length=3.255, ppl=9.05, wps=213080, ups=3.44, wpb=61983.2, bsz=1979.3, num_updates=207200, lr=0.000219687, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:58:03 | INFO | train_inner | epoch 105:   1107 / 1983 loss=3.205, nll_loss=1.056, word_ins=2.877, length=3.279, ppl=9.22, wps=211735, ups=3.43, wpb=61739.7, bsz=1929.4, num_updates=207300, lr=0.000219634, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:58:32 | INFO | train_inner | epoch 105:   1207 / 1983 loss=3.149, nll_loss=1.006, word_ins=2.832, length=3.175, ppl=8.87, wps=212548, ups=3.43, wpb=61963.7, bsz=2047, num_updates=207400, lr=0.000219581, gnorm=0.794, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:59:01 | INFO | train_inner | epoch 105:   1307 / 1983 loss=3.19, nll_loss=1.044, word_ins=2.866, length=3.235, ppl=9.12, wps=211829, ups=3.43, wpb=61794.6, bsz=1999.5, num_updates=207500, lr=0.000219529, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:59:30 | INFO | train_inner | epoch 105:   1407 / 1983 loss=3.2, nll_loss=1.049, word_ins=2.871, length=3.291, ppl=9.19, wps=213426, ups=3.45, wpb=61950.4, bsz=1937, num_updates=207600, lr=0.000219476, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 11:59:59 | INFO | train_inner | epoch 105:   1507 / 1983 loss=3.189, nll_loss=1.039, word_ins=2.862, length=3.269, ppl=9.12, wps=212796, ups=3.43, wpb=62015.4, bsz=2022.1, num_updates=207700, lr=0.000219423, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:00:28 | INFO | train_inner | epoch 105:   1607 / 1983 loss=3.207, nll_loss=1.061, word_ins=2.882, length=3.25, ppl=9.23, wps=211387, ups=3.42, wpb=61751.8, bsz=1966.9, num_updates=207800, lr=0.00021937, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:00:58 | INFO | train_inner | epoch 105:   1707 / 1983 loss=3.187, nll_loss=1.039, word_ins=2.862, length=3.255, ppl=9.11, wps=210434, ups=3.42, wpb=61443.4, bsz=2037.9, num_updates=207900, lr=0.000219317, gnorm=0.81, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:01:27 | INFO | train_inner | epoch 105:   1807 / 1983 loss=3.213, nll_loss=1.058, word_ins=2.879, length=3.338, ppl=9.27, wps=212121, ups=3.44, wpb=61749.3, bsz=1958.4, num_updates=208000, lr=0.000219265, gnorm=0.804, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:01:56 | INFO | train_inner | epoch 105:   1907 / 1983 loss=3.194, nll_loss=1.047, word_ins=2.869, length=3.251, ppl=9.15, wps=210564, ups=3.42, wpb=61478.7, bsz=1995.4, num_updates=208100, lr=0.000219212, gnorm=0.807, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 12:02:33 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 3.217 | nll_loss 1.007 | word_ins 2.886 | length 3.307 | ppl 9.3 | wps 91486.9 | wpb 41551 | bsz 1500 | num_updates 208176 | best_loss 3.202
2023-03-02 12:02:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 12:02:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint105.pt (epoch 105 @ 208176 updates, score 3.217) (writing took 5.520489078946412 seconds)
2023-03-02 12:02:38 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2023-03-02 12:02:38 | INFO | train | epoch 105 | loss 3.189 | nll_loss 1.041 | word_ins 2.864 | length 3.255 | ppl 9.12 | wps 196160 | ups 3.18 | wpb 61628.5 | bsz 1997.6 | num_updates 208176 | lr 0.000219172 | gnorm 0.815 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 12:02:38 | INFO | fairseq.trainer | begin training epoch 106
2023-03-02 12:02:56 | INFO | train_inner | epoch 106:     24 / 1983 loss=3.211, nll_loss=1.058, word_ins=2.879, length=3.32, ppl=9.26, wps=102585, ups=1.68, wpb=61158, bsz=1939.5, num_updates=208200, lr=0.000219159, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:03:25 | INFO | train_inner | epoch 106:    124 / 1983 loss=3.189, nll_loss=1.039, word_ins=2.862, length=3.27, ppl=9.12, wps=211367, ups=3.43, wpb=61622.8, bsz=1918.6, num_updates=208300, lr=0.000219107, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:03:54 | INFO | train_inner | epoch 106:    224 / 1983 loss=3.167, nll_loss=1.021, word_ins=2.846, length=3.209, ppl=8.98, wps=210999, ups=3.42, wpb=61625.8, bsz=2059.1, num_updates=208400, lr=0.000219054, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:04:23 | INFO | train_inner | epoch 106:    324 / 1983 loss=3.186, nll_loss=1.045, word_ins=2.868, length=3.182, ppl=9.1, wps=212366, ups=3.43, wpb=61893.6, bsz=1994.6, num_updates=208500, lr=0.000219001, gnorm=0.793, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:04:52 | INFO | train_inner | epoch 106:    424 / 1983 loss=3.191, nll_loss=1.043, word_ins=2.866, length=3.25, ppl=9.13, wps=211904, ups=3.44, wpb=61596.1, bsz=1923.8, num_updates=208600, lr=0.000218949, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:05:21 | INFO | train_inner | epoch 106:    524 / 1983 loss=3.189, nll_loss=1.04, word_ins=2.863, length=3.252, ppl=9.12, wps=212831, ups=3.44, wpb=61955.8, bsz=1950.6, num_updates=208700, lr=0.000218896, gnorm=0.811, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:05:51 | INFO | train_inner | epoch 106:    624 / 1983 loss=3.219, nll_loss=1.068, word_ins=2.889, length=3.298, ppl=9.31, wps=211000, ups=3.42, wpb=61626.1, bsz=1940.2, num_updates=208800, lr=0.000218844, gnorm=0.816, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:06:20 | INFO | train_inner | epoch 106:    724 / 1983 loss=3.185, nll_loss=1.037, word_ins=2.86, length=3.249, ppl=9.1, wps=210096, ups=3.41, wpb=61653.4, bsz=2062, num_updates=208900, lr=0.000218792, gnorm=0.821, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:06:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 12:06:49 | INFO | train_inner | epoch 106:    825 / 1983 loss=3.179, nll_loss=1.033, word_ins=2.856, length=3.229, ppl=9.06, wps=210584, ups=3.41, wpb=61733.8, bsz=1930.5, num_updates=209000, lr=0.000218739, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:07:19 | INFO | train_inner | epoch 106:    925 / 1983 loss=3.176, nll_loss=1.028, word_ins=2.852, length=3.235, ppl=9.04, wps=210221, ups=3.41, wpb=61592.7, bsz=2051.3, num_updates=209100, lr=0.000218687, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:07:48 | INFO | train_inner | epoch 106:   1025 / 1983 loss=3.181, nll_loss=1.032, word_ins=2.856, length=3.257, ppl=9.07, wps=211781, ups=3.43, wpb=61774.1, bsz=2058.5, num_updates=209200, lr=0.000218635, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:08:17 | INFO | train_inner | epoch 106:   1125 / 1983 loss=3.144, nll_loss=1.001, word_ins=2.827, length=3.165, ppl=8.84, wps=213037, ups=3.46, wpb=61624.9, bsz=2058.2, num_updates=209300, lr=0.000218582, gnorm=0.807, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:08:46 | INFO | train_inner | epoch 106:   1225 / 1983 loss=3.192, nll_loss=1.045, word_ins=2.867, length=3.253, ppl=9.14, wps=209678, ups=3.41, wpb=61494.4, bsz=2027.7, num_updates=209400, lr=0.00021853, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:09:15 | INFO | train_inner | epoch 106:   1325 / 1983 loss=3.187, nll_loss=1.04, word_ins=2.862, length=3.247, ppl=9.11, wps=212496, ups=3.44, wpb=61767.6, bsz=1987.1, num_updates=209500, lr=0.000218478, gnorm=0.8, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:09:44 | INFO | train_inner | epoch 106:   1425 / 1983 loss=3.176, nll_loss=1.031, word_ins=2.855, length=3.211, ppl=9.04, wps=209395, ups=3.41, wpb=61423.4, bsz=2097, num_updates=209600, lr=0.000218426, gnorm=0.809, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:10:13 | INFO | train_inner | epoch 106:   1525 / 1983 loss=3.218, nll_loss=1.066, word_ins=2.887, length=3.317, ppl=9.31, wps=212787, ups=3.45, wpb=61728.3, bsz=1891, num_updates=209700, lr=0.000218374, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:10:42 | INFO | train_inner | epoch 106:   1625 / 1983 loss=3.18, nll_loss=1.029, word_ins=2.853, length=3.263, ppl=9.06, wps=211875, ups=3.44, wpb=61508.2, bsz=2029.2, num_updates=209800, lr=0.000218322, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:11:12 | INFO | train_inner | epoch 106:   1725 / 1983 loss=3.192, nll_loss=1.04, word_ins=2.862, length=3.304, ppl=9.14, wps=210749, ups=3.43, wpb=61446.7, bsz=1995.6, num_updates=209900, lr=0.00021827, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:11:41 | INFO | train_inner | epoch 106:   1825 / 1983 loss=3.196, nll_loss=1.045, word_ins=2.867, length=3.287, ppl=9.16, wps=211367, ups=3.41, wpb=61894.4, bsz=1969, num_updates=210000, lr=0.000218218, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:12:10 | INFO | train_inner | epoch 106:   1925 / 1983 loss=3.188, nll_loss=1.04, word_ins=2.863, length=3.248, ppl=9.11, wps=211207, ups=3.43, wpb=61488.8, bsz=2021.8, num_updates=210100, lr=0.000218166, gnorm=0.81, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 12:12:40 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 3.203 | nll_loss 0.996 | word_ins 2.882 | length 3.215 | ppl 9.21 | wps 89633.4 | wpb 41551 | bsz 1500 | num_updates 210158 | best_loss 3.202
2023-03-02 12:12:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 12:12:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint106.pt (epoch 106 @ 210158 updates, score 3.203) (writing took 5.5179226119071245 seconds)
2023-03-02 12:12:46 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2023-03-02 12:12:46 | INFO | train | epoch 106 | loss 3.185 | nll_loss 1.037 | word_ins 2.86 | length 3.249 | ppl 9.1 | wps 201131 | ups 3.26 | wpb 61627.2 | bsz 1997.2 | num_updates 210158 | lr 0.000218136 | gnorm 0.815 | loss_scale 16384 | train_wall 575 | wall 0
2023-03-02 12:12:46 | INFO | fairseq.trainer | begin training epoch 107
2023-03-02 12:13:08 | INFO | train_inner | epoch 107:     42 / 1983 loss=3.138, nll_loss=0.995, word_ins=2.822, length=3.166, ppl=8.81, wps=105310, ups=1.71, wpb=61410.6, bsz=2099.9, num_updates=210200, lr=0.000218114, gnorm=0.792, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:13:37 | INFO | train_inner | epoch 107:    142 / 1983 loss=3.19, nll_loss=1.04, word_ins=2.863, length=3.269, ppl=9.13, wps=210675, ups=3.43, wpb=61390.4, bsz=1964.9, num_updates=210300, lr=0.000218062, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:14:07 | INFO | train_inner | epoch 107:    242 / 1983 loss=3.171, nll_loss=1.018, word_ins=2.843, length=3.274, ppl=9, wps=210312, ups=3.42, wpb=61564.8, bsz=2006.7, num_updates=210400, lr=0.00021801, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:14:36 | INFO | train_inner | epoch 107:    342 / 1983 loss=3.191, nll_loss=1.041, word_ins=2.864, length=3.263, ppl=9.13, wps=212134, ups=3.43, wpb=61892, bsz=1935.4, num_updates=210500, lr=0.000217959, gnorm=0.81, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:15:05 | INFO | train_inner | epoch 107:    442 / 1983 loss=3.17, nll_loss=1.023, word_ins=2.848, length=3.225, ppl=9, wps=211958, ups=3.43, wpb=61859.1, bsz=1987.8, num_updates=210600, lr=0.000217907, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:15:34 | INFO | train_inner | epoch 107:    542 / 1983 loss=3.159, nll_loss=1.015, word_ins=2.841, length=3.178, ppl=8.93, wps=210734, ups=3.42, wpb=61593.3, bsz=2065.4, num_updates=210700, lr=0.000217855, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:16:03 | INFO | train_inner | epoch 107:    642 / 1983 loss=3.171, nll_loss=1.028, word_ins=2.852, length=3.189, ppl=9.01, wps=211694, ups=3.43, wpb=61802.3, bsz=2029, num_updates=210800, lr=0.000217803, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:16:33 | INFO | train_inner | epoch 107:    742 / 1983 loss=3.215, nll_loss=1.067, word_ins=2.887, length=3.279, ppl=9.29, wps=211646, ups=3.43, wpb=61628.4, bsz=1933.4, num_updates=210900, lr=0.000217752, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:17:02 | INFO | train_inner | epoch 107:    842 / 1983 loss=3.207, nll_loss=1.053, word_ins=2.875, length=3.317, ppl=9.23, wps=209611, ups=3.42, wpb=61225.2, bsz=1979.9, num_updates=211000, lr=0.0002177, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:17:31 | INFO | train_inner | epoch 107:    942 / 1983 loss=3.217, nll_loss=1.064, word_ins=2.885, length=3.317, ppl=9.3, wps=211286, ups=3.42, wpb=61720.9, bsz=1923.9, num_updates=211100, lr=0.000217649, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:18:00 | INFO | train_inner | epoch 107:   1042 / 1983 loss=3.154, nll_loss=1.011, word_ins=2.836, length=3.178, ppl=8.9, wps=213008, ups=3.44, wpb=61940.6, bsz=2070.7, num_updates=211200, lr=0.000217597, gnorm=0.803, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:18:29 | INFO | train_inner | epoch 107:   1142 / 1983 loss=3.203, nll_loss=1.05, word_ins=2.872, length=3.312, ppl=9.21, wps=211920, ups=3.44, wpb=61539.7, bsz=1908.7, num_updates=211300, lr=0.000217546, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:18:58 | INFO | train_inner | epoch 107:   1242 / 1983 loss=3.191, nll_loss=1.043, word_ins=2.865, length=3.258, ppl=9.13, wps=210023, ups=3.42, wpb=61393.8, bsz=2020.8, num_updates=211400, lr=0.000217494, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:19:27 | INFO | train_inner | epoch 107:   1342 / 1983 loss=3.171, nll_loss=1.025, word_ins=2.849, length=3.216, ppl=9.01, wps=212570, ups=3.44, wpb=61720.2, bsz=1998.3, num_updates=211500, lr=0.000217443, gnorm=0.801, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:19:57 | INFO | train_inner | epoch 107:   1442 / 1983 loss=3.181, nll_loss=1.032, word_ins=2.856, length=3.252, ppl=9.07, wps=211906, ups=3.43, wpb=61814.1, bsz=2017.1, num_updates=211600, lr=0.000217391, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:20:26 | INFO | train_inner | epoch 107:   1542 / 1983 loss=3.18, nll_loss=1.033, word_ins=2.856, length=3.235, ppl=9.06, wps=211859, ups=3.44, wpb=61581.9, bsz=2047.2, num_updates=211700, lr=0.00021734, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:20:55 | INFO | train_inner | epoch 107:   1642 / 1983 loss=3.184, nll_loss=1.038, word_ins=2.861, length=3.232, ppl=9.09, wps=210450, ups=3.44, wpb=61212.6, bsz=1972.2, num_updates=211800, lr=0.000217289, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:21:24 | INFO | train_inner | epoch 107:   1742 / 1983 loss=3.184, nll_loss=1.039, word_ins=2.862, length=3.226, ppl=9.09, wps=212940, ups=3.44, wpb=61952.8, bsz=1988, num_updates=211900, lr=0.000217237, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:21:53 | INFO | train_inner | epoch 107:   1842 / 1983 loss=3.172, nll_loss=1.026, word_ins=2.849, length=3.226, ppl=9.01, wps=210540, ups=3.42, wpb=61644.2, bsz=2078.1, num_updates=212000, lr=0.000217186, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:22:22 | INFO | train_inner | epoch 107:   1942 / 1983 loss=3.203, nll_loss=1.054, word_ins=2.876, length=3.274, ppl=9.21, wps=210187, ups=3.42, wpb=61417.5, bsz=1967.8, num_updates=212100, lr=0.000217135, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 12:22:46 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 3.196 | nll_loss 0.987 | word_ins 2.873 | length 3.225 | ppl 9.16 | wps 119560 | wpb 41551 | bsz 1500 | num_updates 212141 | best_loss 3.196
2023-03-02 12:22:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 12:22:55 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint107.pt (epoch 107 @ 212141 updates, score 3.196) (writing took 8.21867940807715 seconds)
2023-03-02 12:22:55 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2023-03-02 12:22:55 | INFO | train | epoch 107 | loss 3.183 | nll_loss 1.036 | word_ins 2.859 | length 3.245 | ppl 9.08 | wps 200599 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 212141 | lr 0.000217114 | gnorm 0.817 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 12:22:55 | INFO | fairseq.trainer | begin training epoch 108
2023-03-02 12:23:22 | INFO | train_inner | epoch 108:     59 / 1983 loss=3.181, nll_loss=1.034, word_ins=2.857, length=3.24, ppl=9.07, wps=102792, ups=1.69, wpb=60906.3, bsz=1975.3, num_updates=212200, lr=0.000217084, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:23:51 | INFO | train_inner | epoch 108:    159 / 1983 loss=3.179, nll_loss=1.031, word_ins=2.855, length=3.234, ppl=9.05, wps=212137, ups=3.44, wpb=61746, bsz=1909.9, num_updates=212300, lr=0.000217033, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:24:20 | INFO | train_inner | epoch 108:    259 / 1983 loss=3.156, nll_loss=1.015, word_ins=2.84, length=3.159, ppl=8.91, wps=209890, ups=3.41, wpb=61622.6, bsz=2032.1, num_updates=212400, lr=0.000216982, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:24:49 | INFO | train_inner | epoch 108:    359 / 1983 loss=3.175, nll_loss=1.027, word_ins=2.852, length=3.234, ppl=9.03, wps=210830, ups=3.43, wpb=61471.8, bsz=1998, num_updates=212500, lr=0.00021693, gnorm=0.805, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:25:18 | INFO | train_inner | epoch 108:    459 / 1983 loss=3.181, nll_loss=1.029, word_ins=2.853, length=3.272, ppl=9.07, wps=212300, ups=3.43, wpb=61903, bsz=2036.7, num_updates=212600, lr=0.000216879, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:25:48 | INFO | train_inner | epoch 108:    559 / 1983 loss=3.182, nll_loss=1.037, word_ins=2.86, length=3.218, ppl=9.08, wps=212189, ups=3.44, wpb=61730.3, bsz=1939.3, num_updates=212700, lr=0.000216828, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:26:17 | INFO | train_inner | epoch 108:    659 / 1983 loss=3.168, nll_loss=1.022, word_ins=2.846, length=3.219, ppl=8.99, wps=211205, ups=3.41, wpb=61852.4, bsz=2043.3, num_updates=212800, lr=0.000216777, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:26:46 | INFO | train_inner | epoch 108:    759 / 1983 loss=3.173, nll_loss=1.024, word_ins=2.849, length=3.245, ppl=9.02, wps=210862, ups=3.43, wpb=61475.4, bsz=2060.6, num_updates=212900, lr=0.000216727, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:27:15 | INFO | train_inner | epoch 108:    859 / 1983 loss=3.189, nll_loss=1.039, word_ins=2.862, length=3.267, ppl=9.12, wps=210413, ups=3.42, wpb=61516, bsz=1997.4, num_updates=213000, lr=0.000216676, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:27:44 | INFO | train_inner | epoch 108:    959 / 1983 loss=3.196, nll_loss=1.048, word_ins=2.87, length=3.258, ppl=9.16, wps=211796, ups=3.43, wpb=61814.7, bsz=1979.4, num_updates=213100, lr=0.000216625, gnorm=0.829, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:28:13 | INFO | train_inner | epoch 108:   1059 / 1983 loss=3.171, nll_loss=1.023, word_ins=2.848, length=3.232, ppl=9.01, wps=212705, ups=3.44, wpb=61828.1, bsz=2001, num_updates=213200, lr=0.000216574, gnorm=0.804, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:28:43 | INFO | train_inner | epoch 108:   1159 / 1983 loss=3.18, nll_loss=1.033, word_ins=2.857, length=3.233, ppl=9.06, wps=212746, ups=3.44, wpb=61908.3, bsz=1950.6, num_updates=213300, lr=0.000216523, gnorm=0.819, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:29:12 | INFO | train_inner | epoch 108:   1259 / 1983 loss=3.192, nll_loss=1.042, word_ins=2.864, length=3.275, ppl=9.14, wps=212009, ups=3.44, wpb=61713.6, bsz=1958.5, num_updates=213400, lr=0.000216473, gnorm=0.825, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:29:41 | INFO | train_inner | epoch 108:   1359 / 1983 loss=3.188, nll_loss=1.039, word_ins=2.862, length=3.258, ppl=9.11, wps=211457, ups=3.43, wpb=61599.2, bsz=1971, num_updates=213500, lr=0.000216422, gnorm=0.823, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:30:10 | INFO | train_inner | epoch 108:   1459 / 1983 loss=3.183, nll_loss=1.035, word_ins=2.858, length=3.248, ppl=9.08, wps=212283, ups=3.44, wpb=61762.3, bsz=2011.8, num_updates=213600, lr=0.000216371, gnorm=0.803, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:30:39 | INFO | train_inner | epoch 108:   1559 / 1983 loss=3.215, nll_loss=1.059, word_ins=2.881, length=3.346, ppl=9.29, wps=209278, ups=3.44, wpb=60858.9, bsz=1908.9, num_updates=213700, lr=0.000216321, gnorm=0.854, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:31:08 | INFO | train_inner | epoch 108:   1659 / 1983 loss=3.166, nll_loss=1.018, word_ins=2.842, length=3.242, ppl=8.98, wps=210934, ups=3.41, wpb=61862.5, bsz=2095.9, num_updates=213800, lr=0.00021627, gnorm=0.813, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:31:38 | INFO | train_inner | epoch 108:   1759 / 1983 loss=3.197, nll_loss=1.051, word_ins=2.872, length=3.252, ppl=9.17, wps=210175, ups=3.42, wpb=61490.8, bsz=2034.4, num_updates=213900, lr=0.000216219, gnorm=0.827, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:32:07 | INFO | train_inner | epoch 108:   1859 / 1983 loss=3.194, nll_loss=1.046, word_ins=2.868, length=3.26, ppl=9.15, wps=212266, ups=3.43, wpb=61882.5, bsz=1967.7, num_updates=214000, lr=0.000216169, gnorm=0.845, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:32:36 | INFO | train_inner | epoch 108:   1959 / 1983 loss=3.183, nll_loss=1.034, word_ins=2.857, length=3.261, ppl=9.08, wps=210830, ups=3.42, wpb=61564.2, bsz=2046.5, num_updates=214100, lr=0.000216118, gnorm=0.826, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:32:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 12:32:57 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 3.196 | nll_loss 0.98 | word_ins 2.865 | length 3.306 | ppl 9.17 | wps 103455 | wpb 41551 | bsz 1500 | num_updates 214124 | best_loss 3.196
2023-03-02 12:32:57 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 12:33:06 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint108.pt (epoch 108 @ 214124 updates, score 3.196) (writing took 8.510797942057252 seconds)
2023-03-02 12:33:06 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2023-03-02 12:33:06 | INFO | train | epoch 108 | loss 3.182 | nll_loss 1.034 | word_ins 2.858 | length 3.246 | ppl 9.08 | wps 200034 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 214124 | lr 0.000216106 | gnorm 0.822 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 12:33:06 | INFO | fairseq.trainer | begin training epoch 109
2023-03-02 12:33:37 | INFO | train_inner | epoch 109:     76 / 1983 loss=3.182, nll_loss=1.041, word_ins=2.864, length=3.178, ppl=9.08, wps=100519, ups=1.63, wpb=61487.8, bsz=1991.8, num_updates=214200, lr=0.000216068, gnorm=0.841, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:34:06 | INFO | train_inner | epoch 109:    176 / 1983 loss=3.167, nll_loss=1.021, word_ins=2.846, length=3.215, ppl=8.98, wps=209842, ups=3.41, wpb=61516.3, bsz=2004.5, num_updates=214300, lr=0.000216017, gnorm=0.824, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:34:36 | INFO | train_inner | epoch 109:    276 / 1983 loss=3.181, nll_loss=1.03, word_ins=2.853, length=3.275, ppl=9.07, wps=208606, ups=3.41, wpb=61087.8, bsz=2052.4, num_updates=214400, lr=0.000215967, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:35:05 | INFO | train_inner | epoch 109:    376 / 1983 loss=3.173, nll_loss=1.029, word_ins=2.854, length=3.199, ppl=9.02, wps=211042, ups=3.4, wpb=62040.8, bsz=1999.6, num_updates=214500, lr=0.000215917, gnorm=0.826, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:35:34 | INFO | train_inner | epoch 109:    476 / 1983 loss=3.175, nll_loss=1.032, word_ins=2.855, length=3.194, ppl=9.03, wps=213552, ups=3.43, wpb=62180.6, bsz=1931.1, num_updates=214600, lr=0.000215866, gnorm=0.834, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:36:03 | INFO | train_inner | epoch 109:    576 / 1983 loss=3.167, nll_loss=1.017, word_ins=2.842, length=3.25, ppl=8.98, wps=212117, ups=3.44, wpb=61656.6, bsz=1975.8, num_updates=214700, lr=0.000215816, gnorm=0.836, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:36:33 | INFO | train_inner | epoch 109:    676 / 1983 loss=3.182, nll_loss=1.033, word_ins=2.856, length=3.262, ppl=9.08, wps=210144, ups=3.4, wpb=61746.1, bsz=2031.3, num_updates=214800, lr=0.000215766, gnorm=0.809, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:36:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 12:37:02 | INFO | train_inner | epoch 109:    777 / 1983 loss=3.174, nll_loss=1.029, word_ins=2.853, length=3.206, ppl=9.02, wps=210122, ups=3.39, wpb=61909.1, bsz=2040.1, num_updates=214900, lr=0.000215716, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:37:31 | INFO | train_inner | epoch 109:    877 / 1983 loss=3.172, nll_loss=1.027, word_ins=2.851, length=3.21, ppl=9.01, wps=210176, ups=3.43, wpb=61203.5, bsz=2090.9, num_updates=215000, lr=0.000215666, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:38:00 | INFO | train_inner | epoch 109:    977 / 1983 loss=3.19, nll_loss=1.037, word_ins=2.86, length=3.298, ppl=9.13, wps=212885, ups=3.45, wpb=61738.4, bsz=1937.1, num_updates=215100, lr=0.000215615, gnorm=0.816, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:38:30 | INFO | train_inner | epoch 109:   1077 / 1983 loss=3.163, nll_loss=1.02, word_ins=2.844, length=3.184, ppl=8.95, wps=209458, ups=3.41, wpb=61494.1, bsz=2051.3, num_updates=215200, lr=0.000215565, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:38:59 | INFO | train_inner | epoch 109:   1177 / 1983 loss=3.176, nll_loss=1.026, word_ins=2.849, length=3.267, ppl=9.04, wps=209277, ups=3.41, wpb=61334.2, bsz=2079.1, num_updates=215300, lr=0.000215515, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:39:28 | INFO | train_inner | epoch 109:   1277 / 1983 loss=3.165, nll_loss=1.019, word_ins=2.844, length=3.21, ppl=8.97, wps=210563, ups=3.41, wpb=61737, bsz=2081.5, num_updates=215400, lr=0.000215465, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:39:57 | INFO | train_inner | epoch 109:   1377 / 1983 loss=3.196, nll_loss=1.042, word_ins=2.864, length=3.313, ppl=9.16, wps=212226, ups=3.44, wpb=61624.8, bsz=1892.4, num_updates=215500, lr=0.000215415, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:40:27 | INFO | train_inner | epoch 109:   1477 / 1983 loss=3.191, nll_loss=1.044, word_ins=2.866, length=3.242, ppl=9.13, wps=209431, ups=3.41, wpb=61419, bsz=1959, num_updates=215600, lr=0.000215365, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:40:56 | INFO | train_inner | epoch 109:   1577 / 1983 loss=3.193, nll_loss=1.044, word_ins=2.866, length=3.268, ppl=9.15, wps=212035, ups=3.43, wpb=61779.2, bsz=1963, num_updates=215700, lr=0.000215315, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:41:25 | INFO | train_inner | epoch 109:   1677 / 1983 loss=3.178, nll_loss=1.031, word_ins=2.855, length=3.228, ppl=9.05, wps=211435, ups=3.43, wpb=61664.7, bsz=2022.1, num_updates=215800, lr=0.000215265, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:41:54 | INFO | train_inner | epoch 109:   1777 / 1983 loss=3.184, nll_loss=1.034, word_ins=2.857, length=3.273, ppl=9.09, wps=210718, ups=3.43, wpb=61358, bsz=1993.4, num_updates=215900, lr=0.000215216, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:42:23 | INFO | train_inner | epoch 109:   1877 / 1983 loss=3.196, nll_loss=1.045, word_ins=2.868, length=3.285, ppl=9.16, wps=211958, ups=3.44, wpb=61671.3, bsz=1942.6, num_updates=216000, lr=0.000215166, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:42:52 | INFO | train_inner | epoch 109:   1977 / 1983 loss=3.18, nll_loss=1.032, word_ins=2.855, length=3.25, ppl=9.07, wps=214665, ups=3.46, wpb=62088.7, bsz=1937.4, num_updates=216100, lr=0.000215116, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 12:43:07 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 3.209 | nll_loss 0.999 | word_ins 2.882 | length 3.276 | ppl 9.25 | wps 108489 | wpb 41551 | bsz 1500 | num_updates 216106 | best_loss 3.196
2023-03-02 12:43:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 12:43:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint109.pt (epoch 109 @ 216106 updates, score 3.209) (writing took 5.590590148931369 seconds)
2023-03-02 12:43:13 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2023-03-02 12:43:13 | INFO | train | epoch 109 | loss 3.179 | nll_loss 1.032 | word_ins 2.855 | length 3.241 | ppl 9.06 | wps 201194 | ups 3.26 | wpb 61627 | bsz 1997.8 | num_updates 216106 | lr 0.000215113 | gnorm 0.824 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 12:43:13 | INFO | fairseq.trainer | begin training epoch 110
2023-03-02 12:43:50 | INFO | train_inner | epoch 110:     94 / 1983 loss=3.176, nll_loss=1.026, word_ins=2.85, length=3.267, ppl=9.04, wps=104950, ups=1.71, wpb=61250.6, bsz=1915.7, num_updates=216200, lr=0.000215066, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:44:20 | INFO | train_inner | epoch 110:    194 / 1983 loss=3.182, nll_loss=1.033, word_ins=2.856, length=3.258, ppl=9.08, wps=213090, ups=3.43, wpb=62045.6, bsz=1937.8, num_updates=216300, lr=0.000215016, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:44:49 | INFO | train_inner | epoch 110:    294 / 1983 loss=3.171, nll_loss=1.027, word_ins=2.851, length=3.197, ppl=9.01, wps=210961, ups=3.42, wpb=61745, bsz=2004, num_updates=216400, lr=0.000214967, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:45:18 | INFO | train_inner | epoch 110:    394 / 1983 loss=3.176, nll_loss=1.026, word_ins=2.85, length=3.261, ppl=9.04, wps=210919, ups=3.44, wpb=61314.7, bsz=1959.8, num_updates=216500, lr=0.000214917, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:45:47 | INFO | train_inner | epoch 110:    494 / 1983 loss=3.138, nll_loss=0.993, word_ins=2.821, length=3.175, ppl=8.8, wps=212439, ups=3.42, wpb=62174.3, bsz=2067.5, num_updates=216600, lr=0.000214868, gnorm=0.813, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:46:17 | INFO | train_inner | epoch 110:    594 / 1983 loss=3.168, nll_loss=1.027, word_ins=2.851, length=3.174, ppl=8.99, wps=209957, ups=3.41, wpb=61638.4, bsz=2033.8, num_updates=216700, lr=0.000214818, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:46:46 | INFO | train_inner | epoch 110:    694 / 1983 loss=3.163, nll_loss=1.022, word_ins=2.846, length=3.17, ppl=8.96, wps=210485, ups=3.42, wpb=61533.2, bsz=2063, num_updates=216800, lr=0.000214768, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:47:15 | INFO | train_inner | epoch 110:    794 / 1983 loss=3.187, nll_loss=1.039, word_ins=2.862, length=3.251, ppl=9.11, wps=209410, ups=3.41, wpb=61497.3, bsz=2044.2, num_updates=216900, lr=0.000214719, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:47:44 | INFO | train_inner | epoch 110:    894 / 1983 loss=3.192, nll_loss=1.04, word_ins=2.863, length=3.288, ppl=9.14, wps=212308, ups=3.44, wpb=61705.2, bsz=1943, num_updates=217000, lr=0.000214669, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:48:14 | INFO | train_inner | epoch 110:    994 / 1983 loss=3.187, nll_loss=1.038, word_ins=2.861, length=3.26, ppl=9.1, wps=212036, ups=3.42, wpb=62018.3, bsz=1950.9, num_updates=217100, lr=0.00021462, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:48:43 | INFO | train_inner | epoch 110:   1094 / 1983 loss=3.187, nll_loss=1.042, word_ins=2.864, length=3.228, ppl=9.11, wps=209938, ups=3.41, wpb=61618.9, bsz=1990.7, num_updates=217200, lr=0.000214571, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:49:12 | INFO | train_inner | epoch 110:   1194 / 1983 loss=3.174, nll_loss=1.026, word_ins=2.85, length=3.238, ppl=9.02, wps=210931, ups=3.43, wpb=61570.7, bsz=2038.8, num_updates=217300, lr=0.000214521, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:49:41 | INFO | train_inner | epoch 110:   1294 / 1983 loss=3.164, nll_loss=1.019, word_ins=2.844, length=3.205, ppl=8.96, wps=211509, ups=3.42, wpb=61835.9, bsz=2070.2, num_updates=217400, lr=0.000214472, gnorm=0.811, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:50:10 | INFO | train_inner | epoch 110:   1394 / 1983 loss=3.187, nll_loss=1.041, word_ins=2.863, length=3.236, ppl=9.11, wps=210136, ups=3.44, wpb=61145, bsz=2002, num_updates=217500, lr=0.000214423, gnorm=0.806, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:50:39 | INFO | train_inner | epoch 110:   1494 / 1983 loss=3.182, nll_loss=1.032, word_ins=2.855, length=3.266, ppl=9.07, wps=212194, ups=3.44, wpb=61702.3, bsz=1987.4, num_updates=217600, lr=0.000214373, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:51:09 | INFO | train_inner | epoch 110:   1594 / 1983 loss=3.187, nll_loss=1.034, word_ins=2.857, length=3.297, ppl=9.11, wps=210303, ups=3.43, wpb=61367.1, bsz=2022.1, num_updates=217700, lr=0.000214324, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:51:38 | INFO | train_inner | epoch 110:   1694 / 1983 loss=3.187, nll_loss=1.039, word_ins=2.862, length=3.253, ppl=9.11, wps=212354, ups=3.43, wpb=61851.4, bsz=1948.1, num_updates=217800, lr=0.000214275, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:52:07 | INFO | train_inner | epoch 110:   1794 / 1983 loss=3.183, nll_loss=1.031, word_ins=2.854, length=3.289, ppl=9.08, wps=209568, ups=3.43, wpb=61060.6, bsz=2000.6, num_updates=217900, lr=0.000214226, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:52:36 | INFO | train_inner | epoch 110:   1894 / 1983 loss=3.189, nll_loss=1.044, word_ins=2.866, length=3.228, ppl=9.12, wps=211510, ups=3.43, wpb=61633.7, bsz=1957.2, num_updates=218000, lr=0.000214176, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 12:53:15 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 3.213 | nll_loss 1.012 | word_ins 2.889 | length 3.242 | ppl 9.27 | wps 134286 | wpb 41551 | bsz 1500 | num_updates 218089 | best_loss 3.196
2023-03-02 12:53:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 12:53:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint110.pt (epoch 110 @ 218089 updates, score 3.213) (writing took 5.502135764923878 seconds)
2023-03-02 12:53:20 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2023-03-02 12:53:20 | INFO | train | epoch 110 | loss 3.177 | nll_loss 1.03 | word_ins 2.853 | length 3.239 | ppl 9.05 | wps 201110 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 218089 | lr 0.000214133 | gnorm 0.828 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 12:53:20 | INFO | fairseq.trainer | begin training epoch 111
2023-03-02 12:53:33 | INFO | train_inner | epoch 111:     11 / 1983 loss=3.165, nll_loss=1.018, word_ins=2.842, length=3.224, ppl=8.97, wps=107766, ups=1.75, wpb=61600, bsz=1983.9, num_updates=218100, lr=0.000214127, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:54:02 | INFO | train_inner | epoch 111:    111 / 1983 loss=3.165, nll_loss=1.02, word_ins=2.844, length=3.208, ppl=8.97, wps=213965, ups=3.44, wpb=62174.5, bsz=1945.8, num_updates=218200, lr=0.000214078, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:54:32 | INFO | train_inner | epoch 111:    211 / 1983 loss=3.151, nll_loss=1.009, word_ins=2.835, length=3.164, ppl=8.88, wps=208900, ups=3.41, wpb=61221.4, bsz=2095.6, num_updates=218300, lr=0.000214029, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:55:01 | INFO | train_inner | epoch 111:    311 / 1983 loss=3.182, nll_loss=1.037, word_ins=2.861, length=3.214, ppl=9.08, wps=210990, ups=3.42, wpb=61741.4, bsz=1965.5, num_updates=218400, lr=0.00021398, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:55:30 | INFO | train_inner | epoch 111:    411 / 1983 loss=3.173, nll_loss=1.025, word_ins=2.849, length=3.237, ppl=9.02, wps=209866, ups=3.42, wpb=61311.6, bsz=1983.9, num_updates=218500, lr=0.000213931, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:55:59 | INFO | train_inner | epoch 111:    511 / 1983 loss=3.174, nll_loss=1.028, word_ins=2.851, length=3.233, ppl=9.03, wps=209434, ups=3.43, wpb=61053, bsz=2035.4, num_updates=218600, lr=0.000213882, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:56:29 | INFO | train_inner | epoch 111:    611 / 1983 loss=3.173, nll_loss=1.024, word_ins=2.848, length=3.24, ppl=9.02, wps=209088, ups=3.42, wpb=61167.6, bsz=2000, num_updates=218700, lr=0.000213833, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:56:58 | INFO | train_inner | epoch 111:    711 / 1983 loss=3.179, nll_loss=1.034, word_ins=2.857, length=3.22, ppl=9.06, wps=211343, ups=3.43, wpb=61700.2, bsz=2012.2, num_updates=218800, lr=0.000213785, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:57:27 | INFO | train_inner | epoch 111:    811 / 1983 loss=3.2, nll_loss=1.051, word_ins=2.872, length=3.272, ppl=9.19, wps=209303, ups=3.42, wpb=61271.2, bsz=1952.7, num_updates=218900, lr=0.000213736, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 12:57:56 | INFO | train_inner | epoch 111:    911 / 1983 loss=3.191, nll_loss=1.037, word_ins=2.86, length=3.311, ppl=9.13, wps=212532, ups=3.45, wpb=61577.9, bsz=1909.4, num_updates=219000, lr=0.000213687, gnorm=0.836, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:58:25 | INFO | train_inner | epoch 111:   1011 / 1983 loss=3.171, nll_loss=1.026, word_ins=2.85, length=3.213, ppl=9.01, wps=209989, ups=3.41, wpb=61644.2, bsz=2040.1, num_updates=219100, lr=0.000213638, gnorm=0.815, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:58:55 | INFO | train_inner | epoch 111:   1111 / 1983 loss=3.176, nll_loss=1.027, word_ins=2.851, length=3.245, ppl=9.04, wps=212455, ups=3.42, wpb=62170.7, bsz=2028, num_updates=219200, lr=0.000213589, gnorm=0.818, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:59:24 | INFO | train_inner | epoch 111:   1211 / 1983 loss=3.183, nll_loss=1.036, word_ins=2.858, length=3.249, ppl=9.08, wps=211054, ups=3.43, wpb=61528.4, bsz=2024.6, num_updates=219300, lr=0.000213541, gnorm=0.829, loss_scale=32768, train_wall=29, wall=0
2023-03-02 12:59:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 12:59:53 | INFO | train_inner | epoch 111:   1312 / 1983 loss=3.191, nll_loss=1.039, word_ins=2.861, length=3.302, ppl=9.14, wps=208779, ups=3.41, wpb=61159.8, bsz=1931, num_updates=219400, lr=0.000213492, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:00:22 | INFO | train_inner | epoch 111:   1412 / 1983 loss=3.15, nll_loss=1.01, word_ins=2.835, length=3.149, ppl=8.87, wps=213620, ups=3.43, wpb=62337.2, bsz=2062.6, num_updates=219500, lr=0.000213443, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:00:51 | INFO | train_inner | epoch 111:   1512 / 1983 loss=3.168, nll_loss=1.025, word_ins=2.849, length=3.193, ppl=8.99, wps=211929, ups=3.42, wpb=62013, bsz=2021.2, num_updates=219600, lr=0.000213395, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:01:21 | INFO | train_inner | epoch 111:   1612 / 1983 loss=3.199, nll_loss=1.047, word_ins=2.869, length=3.298, ppl=9.18, wps=209838, ups=3.43, wpb=61162.5, bsz=1972.5, num_updates=219700, lr=0.000213346, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:01:50 | INFO | train_inner | epoch 111:   1712 / 1983 loss=3.175, nll_loss=1.024, word_ins=2.848, length=3.265, ppl=9.03, wps=213071, ups=3.45, wpb=61827.1, bsz=1953, num_updates=219800, lr=0.000213298, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:02:19 | INFO | train_inner | epoch 111:   1812 / 1983 loss=3.184, nll_loss=1.035, word_ins=2.858, length=3.256, ppl=9.09, wps=212306, ups=3.42, wpb=62081.6, bsz=1949.1, num_updates=219900, lr=0.000213249, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:02:48 | INFO | train_inner | epoch 111:   1912 / 1983 loss=3.181, nll_loss=1.032, word_ins=2.855, length=3.265, ppl=9.07, wps=211900, ups=3.44, wpb=61633.4, bsz=1995.4, num_updates=220000, lr=0.000213201, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:03:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 13:03:23 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 3.199 | nll_loss 0.993 | word_ins 2.873 | length 3.265 | ppl 9.18 | wps 77826.6 | wpb 41551 | bsz 1500 | num_updates 220071 | best_loss 3.196
2023-03-02 13:03:23 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 13:03:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint111.pt (epoch 111 @ 220071 updates, score 3.199) (writing took 5.641723427921534 seconds)
2023-03-02 13:03:29 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2023-03-02 13:03:29 | INFO | train | epoch 111 | loss 3.176 | nll_loss 1.029 | word_ins 2.853 | length 3.235 | ppl 9.04 | wps 200829 | ups 3.26 | wpb 61628.6 | bsz 1997.2 | num_updates 220071 | lr 0.000213166 | gnorm 0.831 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 13:03:29 | INFO | fairseq.trainer | begin training epoch 112
2023-03-02 13:03:48 | INFO | train_inner | epoch 112:     29 / 1983 loss=3.148, nll_loss=1.011, word_ins=2.835, length=3.125, ppl=8.86, wps=103821, ups=1.68, wpb=61898.6, bsz=2165.5, num_updates=220100, lr=0.000213152, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:04:17 | INFO | train_inner | epoch 112:    129 / 1983 loss=3.16, nll_loss=1.013, word_ins=2.838, length=3.222, ppl=8.94, wps=209052, ups=3.41, wpb=61251.3, bsz=2050.5, num_updates=220200, lr=0.000213104, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:04:46 | INFO | train_inner | epoch 112:    229 / 1983 loss=3.161, nll_loss=1.014, word_ins=2.839, length=3.223, ppl=8.95, wps=211714, ups=3.43, wpb=61806.3, bsz=2010.1, num_updates=220300, lr=0.000213056, gnorm=0.812, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:05:15 | INFO | train_inner | epoch 112:    329 / 1983 loss=3.157, nll_loss=1.015, word_ins=2.841, length=3.16, ppl=8.92, wps=212200, ups=3.43, wpb=61903.9, bsz=2023, num_updates=220400, lr=0.000213007, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:05:44 | INFO | train_inner | epoch 112:    429 / 1983 loss=3.168, nll_loss=1.02, word_ins=2.845, length=3.235, ppl=8.99, wps=211731, ups=3.43, wpb=61693.8, bsz=1963.7, num_updates=220500, lr=0.000212959, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:06:14 | INFO | train_inner | epoch 112:    529 / 1983 loss=3.183, nll_loss=1.033, word_ins=2.857, length=3.258, ppl=9.08, wps=211728, ups=3.44, wpb=61598.2, bsz=1880.8, num_updates=220600, lr=0.000212911, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:06:43 | INFO | train_inner | epoch 112:    629 / 1983 loss=3.146, nll_loss=1.003, word_ins=2.829, length=3.167, ppl=8.85, wps=211211, ups=3.42, wpb=61692.3, bsz=2127.9, num_updates=220700, lr=0.000212862, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:07:12 | INFO | train_inner | epoch 112:    729 / 1983 loss=3.185, nll_loss=1.035, word_ins=2.858, length=3.273, ppl=9.09, wps=211217, ups=3.43, wpb=61625, bsz=1922.3, num_updates=220800, lr=0.000212814, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:07:41 | INFO | train_inner | epoch 112:    829 / 1983 loss=3.197, nll_loss=1.049, word_ins=2.871, length=3.263, ppl=9.17, wps=210576, ups=3.41, wpb=61663.1, bsz=1958.6, num_updates=220900, lr=0.000212766, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:08:10 | INFO | train_inner | epoch 112:    929 / 1983 loss=3.183, nll_loss=1.032, word_ins=2.855, length=3.272, ppl=9.08, wps=212543, ups=3.45, wpb=61690.3, bsz=1935.8, num_updates=221000, lr=0.000212718, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:08:39 | INFO | train_inner | epoch 112:   1029 / 1983 loss=3.2, nll_loss=1.047, word_ins=2.869, length=3.312, ppl=9.19, wps=207660, ups=3.43, wpb=60587.4, bsz=1969, num_updates=221100, lr=0.00021267, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:09:08 | INFO | train_inner | epoch 112:   1129 / 1983 loss=3.17, nll_loss=1.022, word_ins=2.846, length=3.237, ppl=9, wps=213165, ups=3.44, wpb=61964.6, bsz=1962.6, num_updates=221200, lr=0.000212622, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:09:38 | INFO | train_inner | epoch 112:   1229 / 1983 loss=3.21, nll_loss=1.06, word_ins=2.88, length=3.303, ppl=9.26, wps=210964, ups=3.44, wpb=61390.7, bsz=1934.2, num_updates=221300, lr=0.000212574, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:10:07 | INFO | train_inner | epoch 112:   1329 / 1983 loss=3.167, nll_loss=1.026, word_ins=2.85, length=3.173, ppl=8.98, wps=211363, ups=3.42, wpb=61789.8, bsz=2027.6, num_updates=221400, lr=0.000212526, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:10:36 | INFO | train_inner | epoch 112:   1429 / 1983 loss=3.179, nll_loss=1.029, word_ins=2.852, length=3.272, ppl=9.06, wps=211286, ups=3.44, wpb=61362.2, bsz=1966.6, num_updates=221500, lr=0.000212478, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:11:05 | INFO | train_inner | epoch 112:   1529 / 1983 loss=3.186, nll_loss=1.042, word_ins=2.864, length=3.221, ppl=9.1, wps=213545, ups=3.44, wpb=62120.3, bsz=1933.7, num_updates=221600, lr=0.00021243, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:11:34 | INFO | train_inner | epoch 112:   1629 / 1983 loss=3.164, nll_loss=1.021, word_ins=2.845, length=3.195, ppl=8.96, wps=210866, ups=3.42, wpb=61743.4, bsz=2087.4, num_updates=221700, lr=0.000212382, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:12:04 | INFO | train_inner | epoch 112:   1729 / 1983 loss=3.192, nll_loss=1.044, word_ins=2.866, length=3.261, ppl=9.14, wps=209592, ups=3.42, wpb=61327.7, bsz=1983.6, num_updates=221800, lr=0.000212334, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:12:33 | INFO | train_inner | epoch 112:   1829 / 1983 loss=3.14, nll_loss=1.003, word_ins=2.828, length=3.121, ppl=8.82, wps=212359, ups=3.41, wpb=62188.7, bsz=2116, num_updates=221900, lr=0.000212286, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:13:02 | INFO | train_inner | epoch 112:   1929 / 1983 loss=3.17, nll_loss=1.023, word_ins=2.847, length=3.236, ppl=9, wps=213244, ups=3.44, wpb=62007.9, bsz=2024.1, num_updates=222000, lr=0.000212238, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 13:13:31 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 3.231 | nll_loss 1.005 | word_ins 2.889 | length 3.423 | ppl 9.39 | wps 126071 | wpb 41551 | bsz 1500 | num_updates 222054 | best_loss 3.196
2023-03-02 13:13:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 13:13:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint112.pt (epoch 112 @ 222054 updates, score 3.231) (writing took 6.181419329019263 seconds)
2023-03-02 13:13:37 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2023-03-02 13:13:37 | INFO | train | epoch 112 | loss 3.175 | nll_loss 1.028 | word_ins 2.852 | length 3.232 | ppl 9.03 | wps 200934 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 222054 | lr 0.000212212 | gnorm 0.836 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 13:13:37 | INFO | fairseq.trainer | begin training epoch 113
2023-03-02 13:14:00 | INFO | train_inner | epoch 113:     46 / 1983 loss=3.175, nll_loss=1.028, word_ins=2.852, length=3.234, ppl=9.03, wps=104385, ups=1.71, wpb=61042.4, bsz=2004.4, num_updates=222100, lr=0.00021219, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:14:30 | INFO | train_inner | epoch 113:    146 / 1983 loss=3.135, nll_loss=0.995, word_ins=2.822, length=3.128, ppl=8.78, wps=211823, ups=3.41, wpb=62156.8, bsz=2052.2, num_updates=222200, lr=0.000212143, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:14:59 | INFO | train_inner | epoch 113:    246 / 1983 loss=3.172, nll_loss=1.023, word_ins=2.847, length=3.247, ppl=9.01, wps=211416, ups=3.42, wpb=61768.8, bsz=1994.6, num_updates=222300, lr=0.000212095, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:15:28 | INFO | train_inner | epoch 113:    346 / 1983 loss=3.129, nll_loss=0.991, word_ins=2.817, length=3.113, ppl=8.75, wps=210918, ups=3.42, wpb=61689.9, bsz=2136.6, num_updates=222400, lr=0.000212047, gnorm=0.795, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:15:57 | INFO | train_inner | epoch 113:    446 / 1983 loss=3.154, nll_loss=1.006, word_ins=2.832, length=3.215, ppl=8.9, wps=210431, ups=3.42, wpb=61571.8, bsz=2046.8, num_updates=222500, lr=0.000212, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:16:27 | INFO | train_inner | epoch 113:    546 / 1983 loss=3.203, nll_loss=1.052, word_ins=2.873, length=3.302, ppl=9.21, wps=211867, ups=3.42, wpb=61875.3, bsz=1898.6, num_updates=222600, lr=0.000211952, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:16:56 | INFO | train_inner | epoch 113:    646 / 1983 loss=3.16, nll_loss=1.013, word_ins=2.838, length=3.22, ppl=8.94, wps=213973, ups=3.43, wpb=62385.8, bsz=1980, num_updates=222700, lr=0.000211904, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:17:25 | INFO | train_inner | epoch 113:    746 / 1983 loss=3.198, nll_loss=1.049, word_ins=2.871, length=3.263, ppl=9.17, wps=210715, ups=3.43, wpb=61419.1, bsz=1897.1, num_updates=222800, lr=0.000211857, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:17:54 | INFO | train_inner | epoch 113:    846 / 1983 loss=3.179, nll_loss=1.03, word_ins=2.854, length=3.253, ppl=9.06, wps=210290, ups=3.43, wpb=61297.9, bsz=1968.8, num_updates=222900, lr=0.000211809, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:18:23 | INFO | train_inner | epoch 113:    946 / 1983 loss=3.171, nll_loss=1.026, word_ins=2.85, length=3.211, ppl=9.01, wps=212177, ups=3.44, wpb=61692.4, bsz=1956.8, num_updates=223000, lr=0.000211762, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:18:52 | INFO | train_inner | epoch 113:   1046 / 1983 loss=3.182, nll_loss=1.032, word_ins=2.855, length=3.272, ppl=9.08, wps=210857, ups=3.43, wpb=61539.8, bsz=1966.5, num_updates=223100, lr=0.000211714, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:19:22 | INFO | train_inner | epoch 113:   1146 / 1983 loss=3.185, nll_loss=1.042, word_ins=2.864, length=3.209, ppl=9.1, wps=209693, ups=3.41, wpb=61548.2, bsz=1993.4, num_updates=223200, lr=0.000211667, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:19:51 | INFO | train_inner | epoch 113:   1246 / 1983 loss=3.193, nll_loss=1.04, word_ins=2.863, length=3.295, ppl=9.14, wps=209167, ups=3.43, wpb=61035.9, bsz=1972.3, num_updates=223300, lr=0.000211619, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:20:20 | INFO | train_inner | epoch 113:   1346 / 1983 loss=3.196, nll_loss=1.043, word_ins=2.865, length=3.301, ppl=9.16, wps=211542, ups=3.44, wpb=61503.1, bsz=1913.9, num_updates=223400, lr=0.000211572, gnorm=0.899, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:20:49 | INFO | train_inner | epoch 113:   1446 / 1983 loss=3.164, nll_loss=1.019, word_ins=2.843, length=3.212, ppl=8.96, wps=209355, ups=3.4, wpb=61594.4, bsz=2017.4, num_updates=223500, lr=0.000211525, gnorm=0.814, loss_scale=32768, train_wall=29, wall=0
2023-03-02 13:21:19 | INFO | train_inner | epoch 113:   1546 / 1983 loss=3.172, nll_loss=1.026, word_ins=2.85, length=3.22, ppl=9.01, wps=210801, ups=3.41, wpb=61864.2, bsz=2045.1, num_updates=223600, lr=0.000211477, gnorm=0.848, loss_scale=32768, train_wall=29, wall=0
2023-03-02 13:21:48 | INFO | train_inner | epoch 113:   1646 / 1983 loss=3.163, nll_loss=1.016, word_ins=2.841, length=3.223, ppl=8.96, wps=211320, ups=3.43, wpb=61655.3, bsz=2039.7, num_updates=223700, lr=0.00021143, gnorm=0.832, loss_scale=32768, train_wall=29, wall=0
2023-03-02 13:22:17 | INFO | train_inner | epoch 113:   1746 / 1983 loss=3.181, nll_loss=1.035, word_ins=2.858, length=3.235, ppl=9.07, wps=210268, ups=3.41, wpb=61630.2, bsz=2013.4, num_updates=223800, lr=0.000211383, gnorm=0.827, loss_scale=32768, train_wall=29, wall=0
2023-03-02 13:22:46 | INFO | train_inner | epoch 113:   1846 / 1983 loss=3.178, nll_loss=1.031, word_ins=2.854, length=3.246, ppl=9.05, wps=209768, ups=3.43, wpb=61118.6, bsz=1992.5, num_updates=223900, lr=0.000211336, gnorm=0.828, loss_scale=32768, train_wall=29, wall=0
2023-03-02 13:22:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 13:23:16 | INFO | train_inner | epoch 113:   1947 / 1983 loss=3.16, nll_loss=1.016, word_ins=2.84, length=3.202, ppl=8.94, wps=208151, ups=3.38, wpb=61618.8, bsz=2094.4, num_updates=224000, lr=0.000211289, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 13:23:40 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 3.199 | nll_loss 0.986 | word_ins 2.871 | length 3.281 | ppl 9.18 | wps 122531 | wpb 41551 | bsz 1500 | num_updates 224036 | best_loss 3.196
2023-03-02 13:23:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 13:23:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint113.pt (epoch 113 @ 224036 updates, score 3.199) (writing took 5.6321802829625085 seconds)
2023-03-02 13:23:46 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2023-03-02 13:23:46 | INFO | train | epoch 113 | loss 3.173 | nll_loss 1.026 | word_ins 2.85 | length 3.231 | ppl 9.02 | wps 200688 | ups 3.26 | wpb 61626.9 | bsz 1997.8 | num_updates 224036 | lr 0.000211272 | gnorm 0.84 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 13:23:46 | INFO | fairseq.trainer | begin training epoch 114
2023-03-02 13:24:14 | INFO | train_inner | epoch 114:     64 / 1983 loss=3.184, nll_loss=1.033, word_ins=2.856, length=3.278, ppl=9.09, wps=105685, ups=1.71, wpb=61722.5, bsz=1925.8, num_updates=224100, lr=0.000211241, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:24:44 | INFO | train_inner | epoch 114:    164 / 1983 loss=3.152, nll_loss=1.011, word_ins=2.836, length=3.166, ppl=8.89, wps=212677, ups=3.42, wpb=62229, bsz=2004.5, num_updates=224200, lr=0.000211194, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:25:13 | INFO | train_inner | epoch 114:    264 / 1983 loss=3.17, nll_loss=1.023, word_ins=2.847, length=3.235, ppl=9, wps=211235, ups=3.42, wpb=61704, bsz=1962.2, num_updates=224300, lr=0.000211147, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:25:42 | INFO | train_inner | epoch 114:    364 / 1983 loss=3.173, nll_loss=1.024, word_ins=2.847, length=3.253, ppl=9.02, wps=211040, ups=3.42, wpb=61708.2, bsz=1974, num_updates=224400, lr=0.0002111, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:26:11 | INFO | train_inner | epoch 114:    464 / 1983 loss=3.168, nll_loss=1.024, word_ins=2.848, length=3.203, ppl=8.99, wps=209923, ups=3.41, wpb=61621.3, bsz=2025.8, num_updates=224500, lr=0.000211053, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:26:41 | INFO | train_inner | epoch 114:    564 / 1983 loss=3.161, nll_loss=1.014, word_ins=2.839, length=3.219, ppl=8.94, wps=212755, ups=3.44, wpb=61885.8, bsz=2030.9, num_updates=224600, lr=0.000211006, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:27:10 | INFO | train_inner | epoch 114:    664 / 1983 loss=3.174, nll_loss=1.024, word_ins=2.848, length=3.253, ppl=9.02, wps=209662, ups=3.42, wpb=61244.1, bsz=1989.2, num_updates=224700, lr=0.000210959, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:27:39 | INFO | train_inner | epoch 114:    764 / 1983 loss=3.175, nll_loss=1.028, word_ins=2.851, length=3.236, ppl=9.03, wps=211655, ups=3.43, wpb=61717.1, bsz=1967.8, num_updates=224800, lr=0.000210912, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:28:08 | INFO | train_inner | epoch 114:    864 / 1983 loss=3.147, nll_loss=1.008, word_ins=2.833, length=3.135, ppl=8.86, wps=211993, ups=3.44, wpb=61701.6, bsz=2098.3, num_updates=224900, lr=0.000210865, gnorm=0.794, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:28:37 | INFO | train_inner | epoch 114:    964 / 1983 loss=3.185, nll_loss=1.037, word_ins=2.86, length=3.25, ppl=9.09, wps=209665, ups=3.42, wpb=61375.6, bsz=2028.7, num_updates=225000, lr=0.000210819, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:29:07 | INFO | train_inner | epoch 114:   1064 / 1983 loss=3.171, nll_loss=1.023, word_ins=2.847, length=3.236, ppl=9.01, wps=210944, ups=3.41, wpb=61788.2, bsz=2004.2, num_updates=225100, lr=0.000210772, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:29:36 | INFO | train_inner | epoch 114:   1164 / 1983 loss=3.143, nll_loss=1, word_ins=2.826, length=3.172, ppl=8.83, wps=212888, ups=3.43, wpb=62108.3, bsz=2045.4, num_updates=225200, lr=0.000210725, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:30:05 | INFO | train_inner | epoch 114:   1264 / 1983 loss=3.184, nll_loss=1.035, word_ins=2.858, length=3.262, ppl=9.09, wps=212903, ups=3.44, wpb=61906, bsz=1971.5, num_updates=225300, lr=0.000210678, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:30:34 | INFO | train_inner | epoch 114:   1364 / 1983 loss=3.162, nll_loss=1.02, word_ins=2.843, length=3.19, ppl=8.95, wps=211910, ups=3.43, wpb=61819.9, bsz=2019.8, num_updates=225400, lr=0.000210631, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:31:03 | INFO | train_inner | epoch 114:   1464 / 1983 loss=3.18, nll_loss=1.033, word_ins=2.856, length=3.242, ppl=9.06, wps=209859, ups=3.43, wpb=61131.5, bsz=1991.9, num_updates=225500, lr=0.000210585, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:31:32 | INFO | train_inner | epoch 114:   1564 / 1983 loss=3.177, nll_loss=1.031, word_ins=2.854, length=3.229, ppl=9.04, wps=211198, ups=3.44, wpb=61374.2, bsz=1949.7, num_updates=225600, lr=0.000210538, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:32:01 | INFO | train_inner | epoch 114:   1664 / 1983 loss=3.198, nll_loss=1.046, word_ins=2.868, length=3.295, ppl=9.17, wps=210269, ups=3.42, wpb=61421.3, bsz=1959.5, num_updates=225700, lr=0.000210491, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:32:31 | INFO | train_inner | epoch 114:   1764 / 1983 loss=3.186, nll_loss=1.038, word_ins=2.861, length=3.249, ppl=9.1, wps=211093, ups=3.44, wpb=61437.8, bsz=1979.8, num_updates=225800, lr=0.000210445, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:33:00 | INFO | train_inner | epoch 114:   1864 / 1983 loss=3.182, nll_loss=1.033, word_ins=2.857, length=3.26, ppl=9.08, wps=211084, ups=3.43, wpb=61478.8, bsz=1999.8, num_updates=225900, lr=0.000210398, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:33:29 | INFO | train_inner | epoch 114:   1964 / 1983 loss=3.186, nll_loss=1.036, word_ins=2.859, length=3.275, ppl=9.1, wps=210210, ups=3.42, wpb=61378.1, bsz=1955.1, num_updates=226000, lr=0.000210352, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 13:33:49 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 3.212 | nll_loss 1.002 | word_ins 2.886 | length 3.256 | ppl 9.27 | wps 119628 | wpb 41551 | bsz 1500 | num_updates 226019 | best_loss 3.196
2023-03-02 13:33:49 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 13:33:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint114.pt (epoch 114 @ 226019 updates, score 3.212) (writing took 5.669346718932502 seconds)
2023-03-02 13:33:54 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2023-03-02 13:33:54 | INFO | train | epoch 114 | loss 3.172 | nll_loss 1.025 | word_ins 2.849 | length 3.229 | ppl 9.01 | wps 200736 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 226019 | lr 0.000210343 | gnorm 0.84 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 13:33:54 | INFO | fairseq.trainer | begin training epoch 115
2023-03-02 13:34:29 | INFO | train_inner | epoch 115:     81 / 1983 loss=3.145, nll_loss=0.998, word_ins=2.824, length=3.21, ppl=8.84, wps=102538, ups=1.67, wpb=61242.3, bsz=2054.1, num_updates=226100, lr=0.000210305, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:34:58 | INFO | train_inner | epoch 115:    181 / 1983 loss=3.144, nll_loss=1.001, word_ins=2.828, length=3.161, ppl=8.84, wps=210188, ups=3.41, wpb=61552.2, bsz=2030.8, num_updates=226200, lr=0.000210259, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:35:27 | INFO | train_inner | epoch 115:    281 / 1983 loss=3.176, nll_loss=1.029, word_ins=2.852, length=3.23, ppl=9.03, wps=210837, ups=3.42, wpb=61720.8, bsz=1943.8, num_updates=226300, lr=0.000210212, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:35:56 | INFO | train_inner | epoch 115:    381 / 1983 loss=3.153, nll_loss=1.007, word_ins=2.832, length=3.207, ppl=8.9, wps=211608, ups=3.42, wpb=61900.7, bsz=2059.1, num_updates=226400, lr=0.000210166, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:36:26 | INFO | train_inner | epoch 115:    481 / 1983 loss=3.189, nll_loss=1.039, word_ins=2.862, length=3.27, ppl=9.12, wps=211372, ups=3.44, wpb=61480, bsz=1919.7, num_updates=226500, lr=0.000210119, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:36:55 | INFO | train_inner | epoch 115:    581 / 1983 loss=3.181, nll_loss=1.032, word_ins=2.856, length=3.255, ppl=9.07, wps=210463, ups=3.41, wpb=61711.2, bsz=1943.6, num_updates=226600, lr=0.000210073, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:37:24 | INFO | train_inner | epoch 115:    681 / 1983 loss=3.174, nll_loss=1.028, word_ins=2.852, length=3.221, ppl=9.02, wps=209505, ups=3.42, wpb=61318.3, bsz=1979.8, num_updates=226700, lr=0.000210027, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:37:54 | INFO | train_inner | epoch 115:    781 / 1983 loss=3.19, nll_loss=1.042, word_ins=2.865, length=3.249, ppl=9.12, wps=210100, ups=3.4, wpb=61819.1, bsz=1983.6, num_updates=226800, lr=0.00020998, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:38:23 | INFO | train_inner | epoch 115:    881 / 1983 loss=3.177, nll_loss=1.03, word_ins=2.854, length=3.232, ppl=9.04, wps=211106, ups=3.41, wpb=61912.4, bsz=1948.9, num_updates=226900, lr=0.000209934, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:38:52 | INFO | train_inner | epoch 115:    981 / 1983 loss=3.157, nll_loss=1.012, word_ins=2.837, length=3.205, ppl=8.92, wps=211445, ups=3.43, wpb=61733.8, bsz=2084.3, num_updates=227000, lr=0.000209888, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:39:21 | INFO | train_inner | epoch 115:   1081 / 1983 loss=3.167, nll_loss=1.024, word_ins=2.848, length=3.197, ppl=8.98, wps=210027, ups=3.4, wpb=61701.7, bsz=2037.8, num_updates=227100, lr=0.000209842, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:39:51 | INFO | train_inner | epoch 115:   1181 / 1983 loss=3.148, nll_loss=1.003, word_ins=2.829, length=3.195, ppl=8.86, wps=209785, ups=3.42, wpb=61382.5, bsz=2097.6, num_updates=227200, lr=0.000209795, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:40:20 | INFO | train_inner | epoch 115:   1281 / 1983 loss=3.16, nll_loss=1.016, word_ins=2.84, length=3.2, ppl=8.94, wps=213743, ups=3.43, wpb=62352.6, bsz=1971, num_updates=227300, lr=0.000209749, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:40:49 | INFO | train_inner | epoch 115:   1381 / 1983 loss=3.205, nll_loss=1.051, word_ins=2.873, length=3.32, ppl=9.22, wps=210616, ups=3.44, wpb=61243.5, bsz=1897, num_updates=227400, lr=0.000209703, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:41:18 | INFO | train_inner | epoch 115:   1481 / 1983 loss=3.188, nll_loss=1.037, word_ins=2.859, length=3.287, ppl=9.11, wps=210270, ups=3.43, wpb=61280.3, bsz=1971.3, num_updates=227500, lr=0.000209657, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:41:47 | INFO | train_inner | epoch 115:   1581 / 1983 loss=3.169, nll_loss=1.022, word_ins=2.846, length=3.23, ppl=8.99, wps=212536, ups=3.43, wpb=62050.1, bsz=1990.4, num_updates=227600, lr=0.000209611, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:42:17 | INFO | train_inner | epoch 115:   1681 / 1983 loss=3.155, nll_loss=1.013, word_ins=2.838, length=3.171, ppl=8.91, wps=209891, ups=3.41, wpb=61506.6, bsz=2108.8, num_updates=227700, lr=0.000209565, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:42:46 | INFO | train_inner | epoch 115:   1781 / 1983 loss=3.189, nll_loss=1.039, word_ins=2.861, length=3.28, ppl=9.12, wps=210024, ups=3.43, wpb=61180.8, bsz=1967.4, num_updates=227800, lr=0.000209519, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:43:15 | INFO | train_inner | epoch 115:   1881 / 1983 loss=3.167, nll_loss=1.022, word_ins=2.845, length=3.222, ppl=8.98, wps=211367, ups=3.43, wpb=61583.8, bsz=2010.6, num_updates=227900, lr=0.000209473, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:43:44 | INFO | train_inner | epoch 115:   1981 / 1983 loss=3.15, nll_loss=1.009, word_ins=2.833, length=3.162, ppl=8.87, wps=212289, ups=3.43, wpb=61978.4, bsz=2005.1, num_updates=228000, lr=0.000209427, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 13:43:59 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 3.224 | nll_loss 1.01 | word_ins 2.894 | length 3.302 | ppl 9.35 | wps 132976 | wpb 41551 | bsz 1500 | num_updates 228002 | best_loss 3.196
2023-03-02 13:43:59 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 13:44:05 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint115.pt (epoch 115 @ 228002 updates, score 3.224) (writing took 6.035953472019173 seconds)
2023-03-02 13:44:05 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2023-03-02 13:44:05 | INFO | train | epoch 115 | loss 3.17 | nll_loss 1.023 | word_ins 2.847 | length 3.227 | ppl 9 | wps 200212 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 228002 | lr 0.000209426 | gnorm 0.842 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 13:44:05 | INFO | fairseq.trainer | begin training epoch 116
2023-03-02 13:44:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 13:44:44 | INFO | train_inner | epoch 116:     99 / 1983 loss=3.157, nll_loss=1.01, word_ins=2.835, length=3.221, ppl=8.92, wps=102233, ups=1.67, wpb=61099.3, bsz=2010.5, num_updates=228100, lr=0.000209381, gnorm=0.819, loss_scale=16384, train_wall=30, wall=0
2023-03-02 13:45:13 | INFO | train_inner | epoch 116:    199 / 1983 loss=3.158, nll_loss=1.01, word_ins=2.835, length=3.232, ppl=8.93, wps=211186, ups=3.43, wpb=61498.4, bsz=1973.7, num_updates=228200, lr=0.000209335, gnorm=0.815, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:45:42 | INFO | train_inner | epoch 116:    299 / 1983 loss=3.14, nll_loss=0.999, word_ins=2.825, length=3.159, ppl=8.82, wps=213315, ups=3.44, wpb=62083.7, bsz=2016.5, num_updates=228300, lr=0.000209289, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:46:11 | INFO | train_inner | epoch 116:    399 / 1983 loss=3.169, nll_loss=1.023, word_ins=2.847, length=3.219, ppl=8.99, wps=210766, ups=3.41, wpb=61841.4, bsz=2032, num_updates=228400, lr=0.000209243, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:46:41 | INFO | train_inner | epoch 116:    499 / 1983 loss=3.159, nll_loss=1.014, word_ins=2.839, length=3.201, ppl=8.93, wps=210303, ups=3.41, wpb=61718.5, bsz=2033, num_updates=228500, lr=0.000209198, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:47:10 | INFO | train_inner | epoch 116:    599 / 1983 loss=3.177, nll_loss=1.028, word_ins=2.852, length=3.256, ppl=9.05, wps=211297, ups=3.43, wpb=61605.5, bsz=1954.4, num_updates=228600, lr=0.000209152, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:47:39 | INFO | train_inner | epoch 116:    699 / 1983 loss=3.176, nll_loss=1.028, word_ins=2.851, length=3.245, ppl=9.04, wps=208640, ups=3.41, wpb=61105.5, bsz=1995.5, num_updates=228700, lr=0.000209106, gnorm=0.947, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:48:09 | INFO | train_inner | epoch 116:    799 / 1983 loss=3.164, nll_loss=1.018, word_ins=2.842, length=3.219, ppl=8.96, wps=211493, ups=3.41, wpb=61997.5, bsz=2043, num_updates=228800, lr=0.000209061, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:48:38 | INFO | train_inner | epoch 116:    899 / 1983 loss=3.17, nll_loss=1.023, word_ins=2.846, length=3.232, ppl=9, wps=211254, ups=3.43, wpb=61648.5, bsz=1981.4, num_updates=228900, lr=0.000209015, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:49:07 | INFO | train_inner | epoch 116:    999 / 1983 loss=3.159, nll_loss=1.012, word_ins=2.837, length=3.222, ppl=8.93, wps=210747, ups=3.43, wpb=61463.8, bsz=1981, num_updates=229000, lr=0.000208969, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:49:36 | INFO | train_inner | epoch 116:   1099 / 1983 loss=3.124, nll_loss=0.985, word_ins=2.812, length=3.114, ppl=8.72, wps=212405, ups=3.43, wpb=61951.7, bsz=2073.8, num_updates=229100, lr=0.000208924, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:50:05 | INFO | train_inner | epoch 116:   1199 / 1983 loss=3.164, nll_loss=1.025, word_ins=2.849, length=3.15, ppl=8.97, wps=211878, ups=3.4, wpb=62233.5, bsz=2019, num_updates=229200, lr=0.000208878, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:50:35 | INFO | train_inner | epoch 116:   1299 / 1983 loss=3.195, nll_loss=1.042, word_ins=2.864, length=3.308, ppl=9.16, wps=209516, ups=3.43, wpb=61162.8, bsz=1993.4, num_updates=229300, lr=0.000208832, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:51:04 | INFO | train_inner | epoch 116:   1399 / 1983 loss=3.185, nll_loss=1.035, word_ins=2.858, length=3.272, ppl=9.1, wps=213100, ups=3.45, wpb=61781.7, bsz=1945.6, num_updates=229400, lr=0.000208787, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:51:33 | INFO | train_inner | epoch 116:   1499 / 1983 loss=3.166, nll_loss=1.019, word_ins=2.843, length=3.233, ppl=8.98, wps=211277, ups=3.42, wpb=61690.4, bsz=2032.1, num_updates=229500, lr=0.000208741, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:52:02 | INFO | train_inner | epoch 116:   1599 / 1983 loss=3.187, nll_loss=1.04, word_ins=2.863, length=3.243, ppl=9.11, wps=211095, ups=3.43, wpb=61573.8, bsz=1935.4, num_updates=229600, lr=0.000208696, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:52:31 | INFO | train_inner | epoch 116:   1699 / 1983 loss=3.177, nll_loss=1.027, word_ins=2.85, length=3.271, ppl=9.05, wps=211541, ups=3.44, wpb=61526, bsz=1985.6, num_updates=229700, lr=0.000208651, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:53:00 | INFO | train_inner | epoch 116:   1799 / 1983 loss=3.183, nll_loss=1.037, word_ins=2.859, length=3.234, ppl=9.08, wps=210977, ups=3.42, wpb=61663.7, bsz=2006.7, num_updates=229800, lr=0.000208605, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:53:30 | INFO | train_inner | epoch 116:   1899 / 1983 loss=3.173, nll_loss=1.025, word_ins=2.849, length=3.246, ppl=9.02, wps=210610, ups=3.43, wpb=61429.3, bsz=1922.8, num_updates=229900, lr=0.00020856, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:53:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 13:54:07 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 3.224 | nll_loss 0.999 | word_ins 2.882 | length 3.414 | ppl 9.34 | wps 127231 | wpb 41551 | bsz 1500 | num_updates 229984 | best_loss 3.196
2023-03-02 13:54:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 13:54:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint116.pt (epoch 116 @ 229984 updates, score 3.224) (writing took 5.636346695944667 seconds)
2023-03-02 13:54:13 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2023-03-02 13:54:13 | INFO | train | epoch 116 | loss 3.168 | nll_loss 1.022 | word_ins 2.846 | length 3.226 | ppl 8.99 | wps 200776 | ups 3.26 | wpb 61626.7 | bsz 1997.6 | num_updates 229984 | lr 0.000208522 | gnorm 0.846 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 13:54:13 | INFO | fairseq.trainer | begin training epoch 117
2023-03-02 13:54:28 | INFO | train_inner | epoch 117:     16 / 1983 loss=3.185, nll_loss=1.037, word_ins=2.86, length=3.252, ppl=9.09, wps=105230, ups=1.72, wpb=61087.1, bsz=1983.4, num_updates=230000, lr=0.000208514, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:54:57 | INFO | train_inner | epoch 117:    116 / 1983 loss=3.159, nll_loss=1.009, word_ins=2.835, length=3.235, ppl=8.93, wps=212619, ups=3.42, wpb=62095.8, bsz=1946.7, num_updates=230100, lr=0.000208469, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:55:26 | INFO | train_inner | epoch 117:    216 / 1983 loss=3.15, nll_loss=1.008, word_ins=2.834, length=3.166, ppl=8.88, wps=210340, ups=3.41, wpb=61760.8, bsz=2019.5, num_updates=230200, lr=0.000208424, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:55:55 | INFO | train_inner | epoch 117:    316 / 1983 loss=3.171, nll_loss=1.023, word_ins=2.847, length=3.238, ppl=9, wps=210668, ups=3.42, wpb=61522.7, bsz=1982.6, num_updates=230300, lr=0.000208379, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:56:25 | INFO | train_inner | epoch 117:    416 / 1983 loss=3.141, nll_loss=1.003, word_ins=2.828, length=3.129, ppl=8.82, wps=211702, ups=3.4, wpb=62217.5, bsz=2044.3, num_updates=230400, lr=0.000208333, gnorm=0.814, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:56:54 | INFO | train_inner | epoch 117:    516 / 1983 loss=3.191, nll_loss=1.038, word_ins=2.861, length=3.296, ppl=9.13, wps=212945, ups=3.44, wpb=61954.5, bsz=1892.3, num_updates=230500, lr=0.000208288, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:57:23 | INFO | train_inner | epoch 117:    616 / 1983 loss=3.171, nll_loss=1.02, word_ins=2.845, length=3.263, ppl=9.01, wps=210936, ups=3.42, wpb=61707.5, bsz=1935, num_updates=230600, lr=0.000208243, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:57:52 | INFO | train_inner | epoch 117:    716 / 1983 loss=3.17, nll_loss=1.021, word_ins=2.845, length=3.247, ppl=9, wps=210578, ups=3.43, wpb=61355.8, bsz=1988.9, num_updates=230700, lr=0.000208198, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:58:21 | INFO | train_inner | epoch 117:    816 / 1983 loss=3.164, nll_loss=1.016, word_ins=2.84, length=3.242, ppl=8.97, wps=209953, ups=3.43, wpb=61162.8, bsz=1971.9, num_updates=230800, lr=0.000208153, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:58:51 | INFO | train_inner | epoch 117:    916 / 1983 loss=3.162, nll_loss=1.014, word_ins=2.839, length=3.232, ppl=8.95, wps=207797, ups=3.41, wpb=60886.3, bsz=2076.3, num_updates=230900, lr=0.000208108, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:59:20 | INFO | train_inner | epoch 117:   1016 / 1983 loss=3.143, nll_loss=0.998, word_ins=2.824, length=3.192, ppl=8.84, wps=210386, ups=3.42, wpb=61582.7, bsz=2082.4, num_updates=231000, lr=0.000208063, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 13:59:49 | INFO | train_inner | epoch 117:   1116 / 1983 loss=3.152, nll_loss=1.008, word_ins=2.833, length=3.19, ppl=8.89, wps=211526, ups=3.43, wpb=61605.6, bsz=2040, num_updates=231100, lr=0.000208018, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:00:18 | INFO | train_inner | epoch 117:   1216 / 1983 loss=3.16, nll_loss=1.021, word_ins=2.845, length=3.152, ppl=8.94, wps=210192, ups=3.4, wpb=61804.9, bsz=2074.8, num_updates=231200, lr=0.000207973, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:00:48 | INFO | train_inner | epoch 117:   1316 / 1983 loss=3.184, nll_loss=1.036, word_ins=2.859, length=3.246, ppl=9.09, wps=209830, ups=3.42, wpb=61429.2, bsz=1960.3, num_updates=231300, lr=0.000207928, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:01:17 | INFO | train_inner | epoch 117:   1416 / 1983 loss=3.183, nll_loss=1.03, word_ins=2.853, length=3.3, ppl=9.08, wps=212663, ups=3.43, wpb=62011.1, bsz=1929.8, num_updates=231400, lr=0.000207883, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:01:46 | INFO | train_inner | epoch 117:   1516 / 1983 loss=3.158, nll_loss=1.01, word_ins=2.834, length=3.237, ppl=8.93, wps=211519, ups=3.43, wpb=61750.5, bsz=2073.5, num_updates=231500, lr=0.000207838, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:02:15 | INFO | train_inner | epoch 117:   1616 / 1983 loss=3.177, nll_loss=1.032, word_ins=2.854, length=3.228, ppl=9.04, wps=211789, ups=3.44, wpb=61481.6, bsz=1953.7, num_updates=231600, lr=0.000207793, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:02:44 | INFO | train_inner | epoch 117:   1716 / 1983 loss=3.178, nll_loss=1.033, word_ins=2.856, length=3.217, ppl=9.05, wps=211289, ups=3.44, wpb=61441.8, bsz=1994.2, num_updates=231700, lr=0.000207748, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:03:13 | INFO | train_inner | epoch 117:   1816 / 1983 loss=3.195, nll_loss=1.041, word_ins=2.863, length=3.321, ppl=9.16, wps=211057, ups=3.44, wpb=61399.9, bsz=1943.4, num_updates=231800, lr=0.000207703, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:03:43 | INFO | train_inner | epoch 117:   1916 / 1983 loss=3.15, nll_loss=1.007, word_ins=2.832, length=3.177, ppl=8.87, wps=213461, ups=3.42, wpb=62361.2, bsz=2040.8, num_updates=231900, lr=0.000207658, gnorm=0.818, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 14:04:15 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 3.202 | nll_loss 0.988 | word_ins 2.874 | length 3.276 | ppl 9.2 | wps 96178.5 | wpb 41551 | bsz 1500 | num_updates 231967 | best_loss 3.196
2023-03-02 14:04:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 14:04:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint117.pt (epoch 117 @ 231967 updates, score 3.202) (writing took 5.4843201680341735 seconds)
2023-03-02 14:04:21 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2023-03-02 14:04:21 | INFO | train | epoch 117 | loss 3.166 | nll_loss 1.019 | word_ins 2.843 | length 3.225 | ppl 8.97 | wps 201143 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 231967 | lr 0.000207628 | gnorm 0.846 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 14:04:21 | INFO | fairseq.trainer | begin training epoch 118
2023-03-02 14:04:40 | INFO | train_inner | epoch 118:     33 / 1983 loss=3.143, nll_loss=0.999, word_ins=2.825, length=3.182, ppl=8.83, wps=105624, ups=1.73, wpb=61144.8, bsz=2023, num_updates=232000, lr=0.000207614, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:05:10 | INFO | train_inner | epoch 118:    133 / 1983 loss=3.166, nll_loss=1.019, word_ins=2.844, length=3.218, ppl=8.97, wps=209784, ups=3.41, wpb=61471.7, bsz=1996.9, num_updates=232100, lr=0.000207569, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:05:39 | INFO | train_inner | epoch 118:    233 / 1983 loss=3.166, nll_loss=1.019, word_ins=2.843, length=3.236, ppl=8.98, wps=211035, ups=3.43, wpb=61573.5, bsz=1970, num_updates=232200, lr=0.000207524, gnorm=0.834, loss_scale=32768, train_wall=29, wall=0
2023-03-02 14:05:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 14:06:08 | INFO | train_inner | epoch 118:    334 / 1983 loss=3.185, nll_loss=1.032, word_ins=2.855, length=3.304, ppl=9.1, wps=207423, ups=3.4, wpb=61066.7, bsz=1922.8, num_updates=232300, lr=0.00020748, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:06:38 | INFO | train_inner | epoch 118:    434 / 1983 loss=3.146, nll_loss=1.004, word_ins=2.829, length=3.167, ppl=8.85, wps=210845, ups=3.41, wpb=61796.3, bsz=2083.1, num_updates=232400, lr=0.000207435, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:07:07 | INFO | train_inner | epoch 118:    534 / 1983 loss=3.193, nll_loss=1.041, word_ins=2.864, length=3.297, ppl=9.15, wps=210398, ups=3.43, wpb=61419.5, bsz=1920.1, num_updates=232500, lr=0.00020739, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:07:36 | INFO | train_inner | epoch 118:    634 / 1983 loss=3.161, nll_loss=1.017, word_ins=2.841, length=3.194, ppl=8.94, wps=212637, ups=3.43, wpb=61952.2, bsz=1995.1, num_updates=232600, lr=0.000207346, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:08:05 | INFO | train_inner | epoch 118:    734 / 1983 loss=3.151, nll_loss=1.006, word_ins=2.832, length=3.188, ppl=8.88, wps=211809, ups=3.42, wpb=61944.8, bsz=1990.3, num_updates=232700, lr=0.000207301, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:08:35 | INFO | train_inner | epoch 118:    834 / 1983 loss=3.158, nll_loss=1.015, word_ins=2.839, length=3.187, ppl=8.93, wps=210397, ups=3.41, wpb=61734.1, bsz=1985, num_updates=232800, lr=0.000207257, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:09:04 | INFO | train_inner | epoch 118:    934 / 1983 loss=3.177, nll_loss=1.03, word_ins=2.853, length=3.237, ppl=9.04, wps=210792, ups=3.42, wpb=61604.4, bsz=1974.3, num_updates=232900, lr=0.000207212, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:09:33 | INFO | train_inner | epoch 118:   1034 / 1983 loss=3.171, nll_loss=1.022, word_ins=2.846, length=3.253, ppl=9.01, wps=210329, ups=3.42, wpb=61418.8, bsz=2029.4, num_updates=233000, lr=0.000207168, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:10:02 | INFO | train_inner | epoch 118:   1134 / 1983 loss=3.156, nll_loss=1.014, word_ins=2.839, length=3.176, ppl=8.92, wps=212150, ups=3.42, wpb=62066.6, bsz=2007.1, num_updates=233100, lr=0.000207123, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:10:32 | INFO | train_inner | epoch 118:   1234 / 1983 loss=3.17, nll_loss=1.023, word_ins=2.846, length=3.238, ppl=9, wps=209511, ups=3.42, wpb=61211.5, bsz=1958.6, num_updates=233200, lr=0.000207079, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:11:01 | INFO | train_inner | epoch 118:   1334 / 1983 loss=3.151, nll_loss=1.005, word_ins=2.831, length=3.199, ppl=8.88, wps=210455, ups=3.42, wpb=61478.1, bsz=2016.6, num_updates=233300, lr=0.000207034, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:11:30 | INFO | train_inner | epoch 118:   1434 / 1983 loss=3.163, nll_loss=1.017, word_ins=2.842, length=3.211, ppl=8.95, wps=211796, ups=3.41, wpb=62200.2, bsz=2009, num_updates=233400, lr=0.00020699, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:11:59 | INFO | train_inner | epoch 118:   1534 / 1983 loss=3.15, nll_loss=1.007, word_ins=2.832, length=3.177, ppl=8.87, wps=210563, ups=3.42, wpb=61506.5, bsz=2077.8, num_updates=233500, lr=0.000206946, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:12:28 | INFO | train_inner | epoch 118:   1634 / 1983 loss=3.187, nll_loss=1.034, word_ins=2.857, length=3.299, ppl=9.11, wps=211309, ups=3.44, wpb=61447.5, bsz=1881.1, num_updates=233600, lr=0.000206901, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:12:58 | INFO | train_inner | epoch 118:   1734 / 1983 loss=3.157, nll_loss=1.014, word_ins=2.838, length=3.195, ppl=8.92, wps=210090, ups=3.41, wpb=61576.4, bsz=2018.3, num_updates=233700, lr=0.000206857, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:13:27 | INFO | train_inner | epoch 118:   1834 / 1983 loss=3.166, nll_loss=1.02, word_ins=2.844, length=3.221, ppl=8.98, wps=211052, ups=3.4, wpb=62054.7, bsz=2081.7, num_updates=233800, lr=0.000206813, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:13:56 | INFO | train_inner | epoch 118:   1934 / 1983 loss=3.152, nll_loss=1.009, word_ins=2.834, length=3.182, ppl=8.89, wps=213125, ups=3.44, wpb=61934.5, bsz=2019.4, num_updates=233900, lr=0.000206769, gnorm=0.819, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 14:14:24 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 3.249 | nll_loss 1.019 | word_ins 2.904 | length 3.451 | ppl 9.51 | wps 135137 | wpb 41551 | bsz 1500 | num_updates 233949 | best_loss 3.196
2023-03-02 14:14:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 14:14:30 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint118.pt (epoch 118 @ 233949 updates, score 3.249) (writing took 6.016422360087745 seconds)
2023-03-02 14:14:30 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2023-03-02 14:14:30 | INFO | train | epoch 118 | loss 3.164 | nll_loss 1.018 | word_ins 2.842 | length 3.22 | ppl 8.97 | wps 200550 | ups 3.25 | wpb 61629.8 | bsz 1997.6 | num_updates 233949 | lr 0.000206747 | gnorm 0.847 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 14:14:30 | INFO | fairseq.trainer | begin training epoch 119
2023-03-02 14:14:55 | INFO | train_inner | epoch 119:     51 / 1983 loss=3.167, nll_loss=1.018, word_ins=2.842, length=3.251, ppl=8.98, wps=103039, ups=1.69, wpb=60962.3, bsz=1995.1, num_updates=234000, lr=0.000206725, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:15:25 | INFO | train_inner | epoch 119:    151 / 1983 loss=3.14, nll_loss=0.999, word_ins=2.826, length=3.14, ppl=8.81, wps=211150, ups=3.43, wpb=61635.3, bsz=2021.7, num_updates=234100, lr=0.00020668, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:15:54 | INFO | train_inner | epoch 119:    251 / 1983 loss=3.171, nll_loss=1.02, word_ins=2.844, length=3.271, ppl=9.01, wps=211104, ups=3.44, wpb=61436.3, bsz=1940.9, num_updates=234200, lr=0.000206636, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:16:23 | INFO | train_inner | epoch 119:    351 / 1983 loss=3.15, nll_loss=1.005, word_ins=2.831, length=3.194, ppl=8.88, wps=210579, ups=3.43, wpb=61456.6, bsz=2048, num_updates=234300, lr=0.000206592, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:16:52 | INFO | train_inner | epoch 119:    451 / 1983 loss=3.16, nll_loss=1.012, word_ins=2.837, length=3.23, ppl=8.94, wps=211432, ups=3.42, wpb=61781.4, bsz=2004.9, num_updates=234400, lr=0.000206548, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:17:21 | INFO | train_inner | epoch 119:    551 / 1983 loss=3.175, nll_loss=1.027, word_ins=2.85, length=3.249, ppl=9.03, wps=213225, ups=3.43, wpb=62180.5, bsz=1906.4, num_updates=234500, lr=0.000206504, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:17:50 | INFO | train_inner | epoch 119:    651 / 1983 loss=3.153, nll_loss=1.007, word_ins=2.832, length=3.208, ppl=8.89, wps=210110, ups=3.44, wpb=61162.4, bsz=2048.2, num_updates=234600, lr=0.00020646, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:18:20 | INFO | train_inner | epoch 119:    751 / 1983 loss=3.164, nll_loss=1.02, word_ins=2.844, length=3.199, ppl=8.96, wps=211498, ups=3.42, wpb=61814.3, bsz=1967, num_updates=234700, lr=0.000206416, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:18:49 | INFO | train_inner | epoch 119:    851 / 1983 loss=3.164, nll_loss=1.02, word_ins=2.843, length=3.207, ppl=8.96, wps=211001, ups=3.42, wpb=61762.5, bsz=1967.8, num_updates=234800, lr=0.000206372, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:19:18 | INFO | train_inner | epoch 119:    951 / 1983 loss=3.143, nll_loss=0.999, word_ins=2.825, length=3.18, ppl=8.83, wps=211044, ups=3.44, wpb=61439, bsz=2076, num_updates=234900, lr=0.000206328, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:19:47 | INFO | train_inner | epoch 119:   1051 / 1983 loss=3.178, nll_loss=1.036, word_ins=2.858, length=3.198, ppl=9.05, wps=211736, ups=3.43, wpb=61771.8, bsz=1980.7, num_updates=235000, lr=0.000206284, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:20:16 | INFO | train_inner | epoch 119:   1151 / 1983 loss=3.159, nll_loss=1.015, word_ins=2.839, length=3.196, ppl=8.93, wps=210565, ups=3.42, wpb=61629.2, bsz=2020.6, num_updates=235100, lr=0.00020624, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:20:46 | INFO | train_inner | epoch 119:   1251 / 1983 loss=3.156, nll_loss=1.01, word_ins=2.835, length=3.21, ppl=8.91, wps=210894, ups=3.41, wpb=61808.9, bsz=2002.7, num_updates=235200, lr=0.000206197, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:21:15 | INFO | train_inner | epoch 119:   1351 / 1983 loss=3.175, nll_loss=1.022, word_ins=2.846, length=3.288, ppl=9.03, wps=210925, ups=3.45, wpb=61179.8, bsz=1995, num_updates=235300, lr=0.000206153, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:21:44 | INFO | train_inner | epoch 119:   1451 / 1983 loss=3.153, nll_loss=1.01, word_ins=2.835, length=3.184, ppl=8.9, wps=212350, ups=3.42, wpb=62072.5, bsz=2048.3, num_updates=235400, lr=0.000206109, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:22:13 | INFO | train_inner | epoch 119:   1551 / 1983 loss=3.155, nll_loss=1.007, word_ins=2.832, length=3.225, ppl=8.9, wps=209406, ups=3.41, wpb=61327.7, bsz=2038.8, num_updates=235500, lr=0.000206065, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:22:42 | INFO | train_inner | epoch 119:   1651 / 1983 loss=3.168, nll_loss=1.022, word_ins=2.845, length=3.226, ppl=8.99, wps=213122, ups=3.44, wpb=61883, bsz=1993.8, num_updates=235600, lr=0.000206021, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:23:12 | INFO | train_inner | epoch 119:   1751 / 1983 loss=3.19, nll_loss=1.044, word_ins=2.865, length=3.246, ppl=9.13, wps=210797, ups=3.42, wpb=61605.7, bsz=1994, num_updates=235700, lr=0.000205978, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:23:41 | INFO | train_inner | epoch 119:   1851 / 1983 loss=3.178, nll_loss=1.028, word_ins=2.851, length=3.27, ppl=9.05, wps=212492, ups=3.43, wpb=61989.9, bsz=1965.4, num_updates=235800, lr=0.000205934, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:24:10 | INFO | train_inner | epoch 119:   1951 / 1983 loss=3.182, nll_loss=1.03, word_ins=2.853, length=3.284, ppl=9.08, wps=210186, ups=3.43, wpb=61367.9, bsz=1969.2, num_updates=235900, lr=0.00020589, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:24:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 14:24:33 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 3.211 | nll_loss 1.008 | word_ins 2.891 | length 3.204 | ppl 9.26 | wps 116983 | wpb 41551 | bsz 1500 | num_updates 235932 | best_loss 3.196
2023-03-02 14:24:33 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 14:24:38 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint119.pt (epoch 119 @ 235932 updates, score 3.211) (writing took 5.592670366982929 seconds)
2023-03-02 14:24:39 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2023-03-02 14:24:39 | INFO | train | epoch 119 | loss 3.164 | nll_loss 1.018 | word_ins 2.842 | length 3.222 | ppl 8.96 | wps 200742 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 235932 | lr 0.000205876 | gnorm 0.85 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 14:24:39 | INFO | fairseq.trainer | begin training epoch 120
2023-03-02 14:25:08 | INFO | train_inner | epoch 120:     68 / 1983 loss=3.17, nll_loss=1.027, word_ins=2.85, length=3.192, ppl=9, wps=105267, ups=1.72, wpb=61194.8, bsz=1971, num_updates=236000, lr=0.000205847, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:25:37 | INFO | train_inner | epoch 120:    168 / 1983 loss=3.146, nll_loss=1.001, word_ins=2.828, length=3.185, ppl=8.85, wps=210612, ups=3.41, wpb=61685.6, bsz=2058.3, num_updates=236100, lr=0.000205803, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:26:06 | INFO | train_inner | epoch 120:    268 / 1983 loss=3.149, nll_loss=1.002, word_ins=2.828, length=3.216, ppl=8.87, wps=211202, ups=3.43, wpb=61526.2, bsz=2024.1, num_updates=236200, lr=0.00020576, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:26:36 | INFO | train_inner | epoch 120:    368 / 1983 loss=3.149, nll_loss=1.004, word_ins=2.829, length=3.194, ppl=8.87, wps=211819, ups=3.44, wpb=61542.1, bsz=1955.9, num_updates=236300, lr=0.000205716, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:26:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 14:27:05 | INFO | train_inner | epoch 120:    469 / 1983 loss=3.146, nll_loss=1.003, word_ins=2.828, length=3.176, ppl=8.85, wps=209236, ups=3.4, wpb=61610, bsz=2019.8, num_updates=236400, lr=0.000205673, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:27:34 | INFO | train_inner | epoch 120:    569 / 1983 loss=3.157, nll_loss=1.009, word_ins=2.834, length=3.223, ppl=8.92, wps=210230, ups=3.42, wpb=61556.9, bsz=1995.5, num_updates=236500, lr=0.000205629, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:28:04 | INFO | train_inner | epoch 120:    669 / 1983 loss=3.172, nll_loss=1.022, word_ins=2.845, length=3.261, ppl=9.01, wps=210749, ups=3.42, wpb=61632.4, bsz=1948.8, num_updates=236600, lr=0.000205586, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:28:33 | INFO | train_inner | epoch 120:    769 / 1983 loss=3.144, nll_loss=1, word_ins=2.826, length=3.188, ppl=8.84, wps=211648, ups=3.42, wpb=61809.1, bsz=2088.2, num_updates=236700, lr=0.000205542, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:29:02 | INFO | train_inner | epoch 120:    869 / 1983 loss=3.169, nll_loss=1.023, word_ins=2.846, length=3.229, ppl=8.99, wps=212868, ups=3.44, wpb=61927.7, bsz=1968.5, num_updates=236800, lr=0.000205499, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:29:31 | INFO | train_inner | epoch 120:    969 / 1983 loss=3.165, nll_loss=1.013, word_ins=2.838, length=3.272, ppl=8.97, wps=210375, ups=3.43, wpb=61390.8, bsz=1934.3, num_updates=236900, lr=0.000205455, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:30:00 | INFO | train_inner | epoch 120:   1069 / 1983 loss=3.193, nll_loss=1.045, word_ins=2.867, length=3.26, ppl=9.14, wps=211038, ups=3.42, wpb=61638.1, bsz=1895.2, num_updates=237000, lr=0.000205412, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:30:29 | INFO | train_inner | epoch 120:   1169 / 1983 loss=3.153, nll_loss=1.01, word_ins=2.835, length=3.184, ppl=8.9, wps=209927, ups=3.42, wpb=61410.6, bsz=2067.3, num_updates=237100, lr=0.000205369, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:30:59 | INFO | train_inner | epoch 120:   1269 / 1983 loss=3.186, nll_loss=1.036, word_ins=2.858, length=3.279, ppl=9.1, wps=210820, ups=3.44, wpb=61314.4, bsz=1942.3, num_updates=237200, lr=0.000205325, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:31:28 | INFO | train_inner | epoch 120:   1369 / 1983 loss=3.178, nll_loss=1.028, word_ins=2.851, length=3.267, ppl=9.05, wps=210807, ups=3.42, wpb=61639.3, bsz=1932.1, num_updates=237300, lr=0.000205282, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:31:57 | INFO | train_inner | epoch 120:   1469 / 1983 loss=3.168, nll_loss=1.016, word_ins=2.841, length=3.271, ppl=8.99, wps=210870, ups=3.42, wpb=61709.1, bsz=1983.6, num_updates=237400, lr=0.000205239, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:32:26 | INFO | train_inner | epoch 120:   1569 / 1983 loss=3.142, nll_loss=1, word_ins=2.826, length=3.158, ppl=8.83, wps=213656, ups=3.43, wpb=62239, bsz=2005.8, num_updates=237500, lr=0.000205196, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:32:56 | INFO | train_inner | epoch 120:   1669 / 1983 loss=3.2, nll_loss=1.048, word_ins=2.869, length=3.309, ppl=9.19, wps=209340, ups=3.41, wpb=61354.1, bsz=1951.7, num_updates=237600, lr=0.000205152, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:33:25 | INFO | train_inner | epoch 120:   1769 / 1983 loss=3.152, nll_loss=1.009, word_ins=2.834, length=3.182, ppl=8.89, wps=211973, ups=3.42, wpb=61953.9, bsz=2042.8, num_updates=237700, lr=0.000205109, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:33:54 | INFO | train_inner | epoch 120:   1869 / 1983 loss=3.137, nll_loss=0.99, word_ins=2.817, length=3.203, ppl=8.8, wps=212409, ups=3.43, wpb=62007, bsz=2125, num_updates=237800, lr=0.000205066, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:34:23 | INFO | train_inner | epoch 120:   1969 / 1983 loss=3.17, nll_loss=1.022, word_ins=2.845, length=3.243, ppl=9, wps=210863, ups=3.43, wpb=61558.7, bsz=2040.6, num_updates=237900, lr=0.000205023, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 14:34:40 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 3.22 | nll_loss 0.992 | word_ins 2.878 | length 3.416 | ppl 9.32 | wps 91877.2 | wpb 41551 | bsz 1500 | num_updates 237914 | best_loss 3.196
2023-03-02 14:34:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 14:34:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint120.pt (epoch 120 @ 237914 updates, score 3.22) (writing took 5.483168617007323 seconds)
2023-03-02 14:34:45 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2023-03-02 14:34:45 | INFO | train | epoch 120 | loss 3.162 | nll_loss 1.015 | word_ins 2.84 | length 3.224 | ppl 8.95 | wps 201312 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 237914 | lr 0.000205017 | gnorm 0.852 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 14:34:45 | INFO | fairseq.trainer | begin training epoch 121
2023-03-02 14:35:20 | INFO | train_inner | epoch 121:     86 / 1983 loss=3.183, nll_loss=1.035, word_ins=2.858, length=3.25, ppl=9.08, wps=107241, ups=1.76, wpb=61090, bsz=1872.6, num_updates=238000, lr=0.00020498, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:35:49 | INFO | train_inner | epoch 121:    186 / 1983 loss=3.141, nll_loss=0.999, word_ins=2.825, length=3.158, ppl=8.82, wps=211287, ups=3.41, wpb=61893.7, bsz=2055.4, num_updates=238100, lr=0.000204937, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:36:19 | INFO | train_inner | epoch 121:    286 / 1983 loss=3.158, nll_loss=1.013, word_ins=2.838, length=3.201, ppl=8.92, wps=210698, ups=3.42, wpb=61566.2, bsz=1996.6, num_updates=238200, lr=0.000204894, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:36:48 | INFO | train_inner | epoch 121:    386 / 1983 loss=3.153, nll_loss=1.006, word_ins=2.831, length=3.222, ppl=8.9, wps=211803, ups=3.43, wpb=61781.5, bsz=1969.6, num_updates=238300, lr=0.000204851, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:37:17 | INFO | train_inner | epoch 121:    486 / 1983 loss=3.142, nll_loss=0.995, word_ins=2.822, length=3.204, ppl=8.83, wps=211534, ups=3.44, wpb=61510.8, bsz=2003.8, num_updates=238400, lr=0.000204808, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:37:46 | INFO | train_inner | epoch 121:    586 / 1983 loss=3.144, nll_loss=1.005, word_ins=2.83, length=3.133, ppl=8.84, wps=212022, ups=3.42, wpb=61990.1, bsz=2047.2, num_updates=238500, lr=0.000204765, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:38:15 | INFO | train_inner | epoch 121:    686 / 1983 loss=3.19, nll_loss=1.038, word_ins=2.86, length=3.3, ppl=9.13, wps=210779, ups=3.42, wpb=61599.6, bsz=1883.6, num_updates=238600, lr=0.000204722, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:38:44 | INFO | train_inner | epoch 121:    786 / 1983 loss=3.132, nll_loss=0.987, word_ins=2.813, length=3.183, ppl=8.77, wps=212127, ups=3.44, wpb=61623.3, bsz=2061, num_updates=238700, lr=0.000204679, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:39:14 | INFO | train_inner | epoch 121:    886 / 1983 loss=3.165, nll_loss=1.018, word_ins=2.842, length=3.232, ppl=8.97, wps=210574, ups=3.42, wpb=61594, bsz=1980.7, num_updates=238800, lr=0.000204636, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:39:43 | INFO | train_inner | epoch 121:    986 / 1983 loss=3.174, nll_loss=1.024, word_ins=2.848, length=3.262, ppl=9.03, wps=211540, ups=3.44, wpb=61552.7, bsz=1921.4, num_updates=238900, lr=0.000204594, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:40:12 | INFO | train_inner | epoch 121:   1086 / 1983 loss=3.168, nll_loss=1.021, word_ins=2.845, length=3.233, ppl=8.99, wps=211006, ups=3.43, wpb=61490.1, bsz=1974.7, num_updates=239000, lr=0.000204551, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:40:41 | INFO | train_inner | epoch 121:   1186 / 1983 loss=3.153, nll_loss=1.01, word_ins=2.835, length=3.18, ppl=8.89, wps=210661, ups=3.41, wpb=61813.4, bsz=2037, num_updates=239100, lr=0.000204508, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:41:10 | INFO | train_inner | epoch 121:   1286 / 1983 loss=3.165, nll_loss=1.017, word_ins=2.841, length=3.243, ppl=8.97, wps=213766, ups=3.44, wpb=62101.6, bsz=1961.7, num_updates=239200, lr=0.000204465, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:41:40 | INFO | train_inner | epoch 121:   1386 / 1983 loss=3.144, nll_loss=0.999, word_ins=2.825, length=3.189, ppl=8.84, wps=210704, ups=3.42, wpb=61581.1, bsz=2085.4, num_updates=239300, lr=0.000204422, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:42:09 | INFO | train_inner | epoch 121:   1486 / 1983 loss=3.174, nll_loss=1.022, word_ins=2.846, length=3.279, ppl=9.02, wps=211049, ups=3.43, wpb=61592.2, bsz=1947.9, num_updates=239400, lr=0.00020438, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:42:38 | INFO | train_inner | epoch 121:   1586 / 1983 loss=3.128, nll_loss=0.987, word_ins=2.813, length=3.147, ppl=8.74, wps=212006, ups=3.43, wpb=61874.5, bsz=2090.7, num_updates=239500, lr=0.000204337, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:43:07 | INFO | train_inner | epoch 121:   1686 / 1983 loss=3.148, nll_loss=1.005, word_ins=2.829, length=3.184, ppl=8.86, wps=210370, ups=3.41, wpb=61749.4, bsz=2106.9, num_updates=239600, lr=0.000204294, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:43:36 | INFO | train_inner | epoch 121:   1786 / 1983 loss=3.163, nll_loss=1.014, word_ins=2.838, length=3.248, ppl=8.96, wps=211253, ups=3.43, wpb=61642.9, bsz=1973.1, num_updates=239700, lr=0.000204252, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:44:06 | INFO | train_inner | epoch 121:   1886 / 1983 loss=3.188, nll_loss=1.036, word_ins=2.858, length=3.304, ppl=9.11, wps=208540, ups=3.44, wpb=60675.1, bsz=2007.8, num_updates=239800, lr=0.000204209, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 14:44:47 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 3.214 | nll_loss 1.001 | word_ins 2.885 | length 3.295 | ppl 9.28 | wps 82394.4 | wpb 41551 | bsz 1500 | num_updates 239897 | best_loss 3.196
2023-03-02 14:44:47 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 14:44:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint121.pt (epoch 121 @ 239897 updates, score 3.214) (writing took 5.31138578907121 seconds)
2023-03-02 14:44:53 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2023-03-02 14:44:53 | INFO | train | epoch 121 | loss 3.159 | nll_loss 1.013 | word_ins 2.837 | length 3.22 | ppl 8.93 | wps 201235 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 239897 | lr 0.000204168 | gnorm 0.852 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 14:44:53 | INFO | fairseq.trainer | begin training epoch 122
2023-03-02 14:45:03 | INFO | train_inner | epoch 122:      3 / 1983 loss=3.167, nll_loss=1.02, word_ins=2.844, length=3.233, ppl=8.98, wps=106132, ups=1.73, wpb=61379.2, bsz=1950.7, num_updates=239900, lr=0.000204167, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:45:33 | INFO | train_inner | epoch 122:    103 / 1983 loss=3.143, nll_loss=1, word_ins=2.826, length=3.167, ppl=8.83, wps=212329, ups=3.43, wpb=61962.2, bsz=1981, num_updates=240000, lr=0.000204124, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:46:02 | INFO | train_inner | epoch 122:    203 / 1983 loss=3.163, nll_loss=1.013, word_ins=2.838, length=3.247, ppl=8.95, wps=209505, ups=3.43, wpb=61097, bsz=1987.1, num_updates=240100, lr=0.000204082, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:46:31 | INFO | train_inner | epoch 122:    303 / 1983 loss=3.149, nll_loss=1.008, word_ins=2.833, length=3.156, ppl=8.87, wps=213536, ups=3.43, wpb=62177.5, bsz=1952.3, num_updates=240200, lr=0.000204039, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:47:00 | INFO | train_inner | epoch 122:    403 / 1983 loss=3.135, nll_loss=0.992, word_ins=2.819, length=3.163, ppl=8.78, wps=212187, ups=3.42, wpb=62029.1, bsz=2010.7, num_updates=240300, lr=0.000203997, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:47:29 | INFO | train_inner | epoch 122:    503 / 1983 loss=3.162, nll_loss=1.012, word_ins=2.837, length=3.251, ppl=8.95, wps=210906, ups=3.42, wpb=61591.5, bsz=2014.3, num_updates=240400, lr=0.000203954, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:47:59 | INFO | train_inner | epoch 122:    603 / 1983 loss=3.145, nll_loss=1.004, word_ins=2.83, length=3.149, ppl=8.84, wps=208812, ups=3.4, wpb=61505.4, bsz=2067.4, num_updates=240500, lr=0.000203912, gnorm=0.842, loss_scale=32768, train_wall=29, wall=0
2023-03-02 14:48:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 14:48:28 | INFO | train_inner | epoch 122:    704 / 1983 loss=3.155, nll_loss=1.012, word_ins=2.837, length=3.179, ppl=8.9, wps=209511, ups=3.39, wpb=61884.1, bsz=2045.4, num_updates=240600, lr=0.000203869, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:48:57 | INFO | train_inner | epoch 122:    804 / 1983 loss=3.165, nll_loss=1.018, word_ins=2.842, length=3.233, ppl=8.97, wps=211147, ups=3.43, wpb=61578.2, bsz=1978.3, num_updates=240700, lr=0.000203827, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:49:27 | INFO | train_inner | epoch 122:    904 / 1983 loss=3.192, nll_loss=1.043, word_ins=2.865, length=3.269, ppl=9.14, wps=209406, ups=3.4, wpb=61579, bsz=1959.1, num_updates=240800, lr=0.000203785, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:49:56 | INFO | train_inner | epoch 122:   1004 / 1983 loss=3.172, nll_loss=1.024, word_ins=2.848, length=3.24, ppl=9.01, wps=211950, ups=3.43, wpb=61824.9, bsz=1940.7, num_updates=240900, lr=0.000203742, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:50:25 | INFO | train_inner | epoch 122:   1104 / 1983 loss=3.159, nll_loss=1.011, word_ins=2.836, length=3.232, ppl=8.93, wps=210831, ups=3.43, wpb=61551, bsz=1978.5, num_updates=241000, lr=0.0002037, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:50:54 | INFO | train_inner | epoch 122:   1204 / 1983 loss=3.151, nll_loss=1.008, word_ins=2.833, length=3.186, ppl=8.89, wps=211204, ups=3.43, wpb=61653.7, bsz=2019.4, num_updates=241100, lr=0.000203658, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:51:24 | INFO | train_inner | epoch 122:   1304 / 1983 loss=3.145, nll_loss=0.999, word_ins=2.825, length=3.202, ppl=8.85, wps=212747, ups=3.44, wpb=61917, bsz=2042.6, num_updates=241200, lr=0.000203616, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:51:53 | INFO | train_inner | epoch 122:   1404 / 1983 loss=3.189, nll_loss=1.041, word_ins=2.863, length=3.261, ppl=9.12, wps=208520, ups=3.42, wpb=61053.1, bsz=1979.5, num_updates=241300, lr=0.000203574, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:52:22 | INFO | train_inner | epoch 122:   1504 / 1983 loss=3.174, nll_loss=1.025, word_ins=2.849, length=3.25, ppl=9.02, wps=212179, ups=3.44, wpb=61747.7, bsz=1967.8, num_updates=241400, lr=0.000203531, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:52:51 | INFO | train_inner | epoch 122:   1604 / 1983 loss=3.147, nll_loss=1.002, word_ins=2.827, length=3.205, ppl=8.86, wps=210653, ups=3.43, wpb=61464.4, bsz=2049.5, num_updates=241500, lr=0.000203489, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:53:20 | INFO | train_inner | epoch 122:   1704 / 1983 loss=3.158, nll_loss=1.012, word_ins=2.837, length=3.21, ppl=8.92, wps=210006, ups=3.42, wpb=61416.6, bsz=2014.3, num_updates=241600, lr=0.000203447, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:53:50 | INFO | train_inner | epoch 122:   1804 / 1983 loss=3.166, nll_loss=1.02, word_ins=2.843, length=3.227, ppl=8.98, wps=210850, ups=3.42, wpb=61611.1, bsz=2003.2, num_updates=241700, lr=0.000203405, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:54:19 | INFO | train_inner | epoch 122:   1904 / 1983 loss=3.164, nll_loss=1.014, word_ins=2.838, length=3.252, ppl=8.96, wps=212758, ups=3.44, wpb=61933.5, bsz=1968.7, num_updates=241800, lr=0.000203363, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:54:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 14:54:56 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 3.202 | nll_loss 0.983 | word_ins 2.869 | length 3.334 | ppl 9.2 | wps 93338.5 | wpb 41551 | bsz 1500 | num_updates 241879 | best_loss 3.196
2023-03-02 14:54:56 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 14:55:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint122.pt (epoch 122 @ 241879 updates, score 3.202) (writing took 5.519799133995548 seconds)
2023-03-02 14:55:01 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2023-03-02 14:55:02 | INFO | train | epoch 122 | loss 3.16 | nll_loss 1.014 | word_ins 2.838 | length 3.214 | ppl 8.94 | wps 200532 | ups 3.25 | wpb 61627.7 | bsz 1997.4 | num_updates 241879 | lr 0.00020333 | gnorm 0.853 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 14:55:02 | INFO | fairseq.trainer | begin training epoch 123
2023-03-02 14:55:20 | INFO | train_inner | epoch 123:     21 / 1983 loss=3.166, nll_loss=1.018, word_ins=2.842, length=3.249, ppl=8.98, wps=98541.3, ups=1.62, wpb=60650.5, bsz=1975.4, num_updates=241900, lr=0.000203321, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:55:49 | INFO | train_inner | epoch 123:    121 / 1983 loss=3.15, nll_loss=1.009, word_ins=2.835, length=3.152, ppl=8.88, wps=212122, ups=3.44, wpb=61712.6, bsz=1942.2, num_updates=242000, lr=0.000203279, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:56:19 | INFO | train_inner | epoch 123:    221 / 1983 loss=3.175, nll_loss=1.028, word_ins=2.852, length=3.232, ppl=9.03, wps=210408, ups=3.41, wpb=61653.5, bsz=1958.1, num_updates=242100, lr=0.000203237, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:56:48 | INFO | train_inner | epoch 123:    321 / 1983 loss=3.12, nll_loss=0.982, word_ins=2.809, length=3.111, ppl=8.69, wps=211861, ups=3.4, wpb=62300.3, bsz=2122.3, num_updates=242200, lr=0.000203195, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:57:17 | INFO | train_inner | epoch 123:    421 / 1983 loss=3.131, nll_loss=0.987, word_ins=2.814, length=3.177, ppl=8.76, wps=211797, ups=3.42, wpb=61922, bsz=2020.6, num_updates=242300, lr=0.000203153, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:57:46 | INFO | train_inner | epoch 123:    521 / 1983 loss=3.181, nll_loss=1.031, word_ins=2.854, length=3.271, ppl=9.07, wps=212201, ups=3.43, wpb=61818, bsz=1892.2, num_updates=242400, lr=0.000203111, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:58:15 | INFO | train_inner | epoch 123:    621 / 1983 loss=3.149, nll_loss=1.004, word_ins=2.829, length=3.194, ppl=8.87, wps=213474, ups=3.44, wpb=62019.3, bsz=1970.6, num_updates=242500, lr=0.000203069, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:58:45 | INFO | train_inner | epoch 123:    721 / 1983 loss=3.142, nll_loss=0.997, word_ins=2.823, length=3.19, ppl=8.83, wps=211508, ups=3.43, wpb=61649.9, bsz=2066.2, num_updates=242600, lr=0.000203027, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:59:14 | INFO | train_inner | epoch 123:    821 / 1983 loss=3.16, nll_loss=1.016, word_ins=2.84, length=3.204, ppl=8.94, wps=210569, ups=3.43, wpb=61476, bsz=2106.7, num_updates=242700, lr=0.000202986, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 14:59:43 | INFO | train_inner | epoch 123:    921 / 1983 loss=3.159, nll_loss=1.01, word_ins=2.834, length=3.247, ppl=8.93, wps=211990, ups=3.44, wpb=61682, bsz=1930.6, num_updates=242800, lr=0.000202944, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:00:12 | INFO | train_inner | epoch 123:   1021 / 1983 loss=3.127, nll_loss=0.982, word_ins=2.809, length=3.174, ppl=8.73, wps=214018, ups=3.45, wpb=62093.7, bsz=2021.9, num_updates=242900, lr=0.000202902, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:00:41 | INFO | train_inner | epoch 123:   1121 / 1983 loss=3.171, nll_loss=1.023, word_ins=2.847, length=3.246, ppl=9.01, wps=208604, ups=3.42, wpb=61074.6, bsz=2009.3, num_updates=243000, lr=0.00020286, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:01:11 | INFO | train_inner | epoch 123:   1221 / 1983 loss=3.15, nll_loss=1.006, word_ins=2.831, length=3.19, ppl=8.88, wps=210496, ups=3.42, wpb=61626.3, bsz=2062.7, num_updates=243100, lr=0.000202818, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:01:40 | INFO | train_inner | epoch 123:   1321 / 1983 loss=3.167, nll_loss=1.02, word_ins=2.844, length=3.23, ppl=8.98, wps=210604, ups=3.42, wpb=61559.4, bsz=1929.5, num_updates=243200, lr=0.000202777, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:02:09 | INFO | train_inner | epoch 123:   1421 / 1983 loss=3.148, nll_loss=1.005, word_ins=2.829, length=3.188, ppl=8.87, wps=211167, ups=3.42, wpb=61811.9, bsz=2071.2, num_updates=243300, lr=0.000202735, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:02:38 | INFO | train_inner | epoch 123:   1521 / 1983 loss=3.156, nll_loss=1.015, word_ins=2.838, length=3.175, ppl=8.91, wps=211864, ups=3.42, wpb=61953.9, bsz=2057.5, num_updates=243400, lr=0.000202693, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:03:07 | INFO | train_inner | epoch 123:   1621 / 1983 loss=3.195, nll_loss=1.044, word_ins=2.866, length=3.287, ppl=9.16, wps=210917, ups=3.43, wpb=61487.6, bsz=1915.7, num_updates=243500, lr=0.000202652, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:03:37 | INFO | train_inner | epoch 123:   1721 / 1983 loss=3.171, nll_loss=1.021, word_ins=2.845, length=3.266, ppl=9.01, wps=210766, ups=3.43, wpb=61373.8, bsz=1953.1, num_updates=243600, lr=0.00020261, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:04:06 | INFO | train_inner | epoch 123:   1821 / 1983 loss=3.164, nll_loss=1.015, word_ins=2.839, length=3.243, ppl=8.96, wps=210164, ups=3.42, wpb=61403.5, bsz=2007.3, num_updates=243700, lr=0.000202569, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:04:35 | INFO | train_inner | epoch 123:   1921 / 1983 loss=3.181, nll_loss=1.033, word_ins=2.855, length=3.262, ppl=9.07, wps=210168, ups=3.43, wpb=61333, bsz=1905.4, num_updates=243800, lr=0.000202527, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 15:05:07 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 3.215 | nll_loss 0.987 | word_ins 2.876 | length 3.4 | ppl 9.29 | wps 82523.4 | wpb 41551 | bsz 1500 | num_updates 243862 | best_loss 3.196
2023-03-02 15:05:07 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 15:05:13 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint123.pt (epoch 123 @ 243862 updates, score 3.215) (writing took 5.449547350988723 seconds)
2023-03-02 15:05:13 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2023-03-02 15:05:13 | INFO | train | epoch 123 | loss 3.158 | nll_loss 1.012 | word_ins 2.837 | length 3.214 | ppl 8.93 | wps 199957 | ups 3.24 | wpb 61628.5 | bsz 1997.6 | num_updates 243862 | lr 0.000202501 | gnorm 0.853 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 15:05:13 | INFO | fairseq.trainer | begin training epoch 124
2023-03-02 15:05:34 | INFO | train_inner | epoch 124:     38 / 1983 loss=3.151, nll_loss=1.005, word_ins=2.83, length=3.211, ppl=8.88, wps=103837, ups=1.7, wpb=60944.8, bsz=1975.3, num_updates=243900, lr=0.000202486, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:06:03 | INFO | train_inner | epoch 124:    138 / 1983 loss=3.156, nll_loss=1.009, word_ins=2.834, length=3.214, ppl=8.91, wps=209961, ups=3.43, wpb=61261.9, bsz=1953, num_updates=244000, lr=0.000202444, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:06:32 | INFO | train_inner | epoch 124:    238 / 1983 loss=3.153, nll_loss=1.007, word_ins=2.833, length=3.201, ppl=8.89, wps=211818, ups=3.42, wpb=61897.8, bsz=1979.8, num_updates=244100, lr=0.000202403, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:07:02 | INFO | train_inner | epoch 124:    338 / 1983 loss=3.132, nll_loss=0.993, word_ins=2.819, length=3.131, ppl=8.77, wps=208674, ups=3.38, wpb=61669.9, bsz=2135.4, num_updates=244200, lr=0.000202361, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:07:31 | INFO | train_inner | epoch 124:    438 / 1983 loss=3.16, nll_loss=1.012, word_ins=2.837, length=3.227, ppl=8.94, wps=210030, ups=3.43, wpb=61292.5, bsz=1972.6, num_updates=244300, lr=0.00020232, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:08:00 | INFO | train_inner | epoch 124:    538 / 1983 loss=3.136, nll_loss=0.995, word_ins=2.821, length=3.156, ppl=8.79, wps=212650, ups=3.42, wpb=62148.3, bsz=2051.7, num_updates=244400, lr=0.000202278, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:08:29 | INFO | train_inner | epoch 124:    638 / 1983 loss=3.163, nll_loss=1.011, word_ins=2.836, length=3.266, ppl=8.95, wps=211334, ups=3.43, wpb=61604.5, bsz=1997.8, num_updates=244500, lr=0.000202237, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:08:58 | INFO | train_inner | epoch 124:    738 / 1983 loss=3.168, nll_loss=1.023, word_ins=2.846, length=3.219, ppl=8.99, wps=210308, ups=3.42, wpb=61522.6, bsz=1978, num_updates=244600, lr=0.000202196, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:09:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 15:09:28 | INFO | train_inner | epoch 124:    839 / 1983 loss=3.168, nll_loss=1.023, word_ins=2.847, length=3.21, ppl=8.99, wps=208810, ups=3.39, wpb=61522.1, bsz=1981.4, num_updates=244700, lr=0.000202154, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:09:57 | INFO | train_inner | epoch 124:    939 / 1983 loss=3.151, nll_loss=1.002, word_ins=2.828, length=3.229, ppl=8.88, wps=210733, ups=3.42, wpb=61604.2, bsz=1997.2, num_updates=244800, lr=0.000202113, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:10:26 | INFO | train_inner | epoch 124:   1039 / 1983 loss=3.157, nll_loss=1.011, word_ins=2.835, length=3.219, ppl=8.92, wps=210012, ups=3.42, wpb=61465.9, bsz=2023, num_updates=244900, lr=0.000202072, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:10:56 | INFO | train_inner | epoch 124:   1139 / 1983 loss=3.144, nll_loss=1.004, word_ins=2.829, length=3.148, ppl=8.84, wps=210312, ups=3.4, wpb=61926.6, bsz=2077.4, num_updates=245000, lr=0.000202031, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:11:25 | INFO | train_inner | epoch 124:   1239 / 1983 loss=3.188, nll_loss=1.041, word_ins=2.863, length=3.251, ppl=9.11, wps=210735, ups=3.4, wpb=61946.1, bsz=1921.7, num_updates=245100, lr=0.000201989, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:11:54 | INFO | train_inner | epoch 124:   1339 / 1983 loss=3.141, nll_loss=0.997, word_ins=2.823, length=3.18, ppl=8.82, wps=211929, ups=3.43, wpb=61828.5, bsz=2011.1, num_updates=245200, lr=0.000201948, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:12:24 | INFO | train_inner | epoch 124:   1439 / 1983 loss=3.167, nll_loss=1.017, word_ins=2.841, length=3.264, ppl=8.98, wps=210010, ups=3.43, wpb=61276.4, bsz=1978.2, num_updates=245300, lr=0.000201907, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:12:53 | INFO | train_inner | epoch 124:   1539 / 1983 loss=3.151, nll_loss=1.006, word_ins=2.831, length=3.202, ppl=8.88, wps=210084, ups=3.44, wpb=61058.4, bsz=2049.4, num_updates=245400, lr=0.000201866, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:13:22 | INFO | train_inner | epoch 124:   1639 / 1983 loss=3.151, nll_loss=1.006, word_ins=2.831, length=3.203, ppl=8.88, wps=211953, ups=3.43, wpb=61778.7, bsz=2035.9, num_updates=245500, lr=0.000201825, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:13:51 | INFO | train_inner | epoch 124:   1739 / 1983 loss=3.153, nll_loss=1.006, word_ins=2.831, length=3.216, ppl=8.89, wps=212581, ups=3.43, wpb=62053.5, bsz=2002.3, num_updates=245600, lr=0.000201784, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:14:20 | INFO | train_inner | epoch 124:   1839 / 1983 loss=3.149, nll_loss=1.009, word_ins=2.833, length=3.157, ppl=8.87, wps=212074, ups=3.42, wpb=62089.1, bsz=1988.2, num_updates=245700, lr=0.000201743, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:14:50 | INFO | train_inner | epoch 124:   1939 / 1983 loss=3.19, nll_loss=1.039, word_ins=2.861, length=3.291, ppl=9.13, wps=209170, ups=3.42, wpb=61188.6, bsz=1938.6, num_updates=245800, lr=0.000201701, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 15:15:15 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 3.202 | nll_loss 0.994 | word_ins 2.877 | length 3.248 | ppl 9.2 | wps 99138.1 | wpb 41551 | bsz 1500 | num_updates 245844 | best_loss 3.196
2023-03-02 15:15:15 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 15:15:20 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint124.pt (epoch 124 @ 245844 updates, score 3.202) (writing took 5.354770221048966 seconds)
2023-03-02 15:15:20 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2023-03-02 15:15:20 | INFO | train | epoch 124 | loss 3.156 | nll_loss 1.011 | word_ins 2.836 | length 3.21 | ppl 8.92 | wps 201035 | ups 3.26 | wpb 61627.7 | bsz 1998 | num_updates 245844 | lr 0.000201683 | gnorm 0.856 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 15:15:20 | INFO | fairseq.trainer | begin training epoch 125
2023-03-02 15:15:46 | INFO | train_inner | epoch 125:     56 / 1983 loss=3.175, nll_loss=1.026, word_ins=2.849, length=3.253, ppl=9.03, wps=108085, ups=1.76, wpb=61357.8, bsz=1835, num_updates=245900, lr=0.00020166, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:16:16 | INFO | train_inner | epoch 125:    156 / 1983 loss=3.14, nll_loss=0.994, word_ins=2.82, length=3.201, ppl=8.82, wps=212332, ups=3.42, wpb=61998.2, bsz=2037.4, num_updates=246000, lr=0.000201619, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:16:45 | INFO | train_inner | epoch 125:    256 / 1983 loss=3.148, nll_loss=1.002, word_ins=2.828, length=3.203, ppl=8.86, wps=209829, ups=3.4, wpb=61708.8, bsz=1959.8, num_updates=246100, lr=0.000201578, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:17:15 | INFO | train_inner | epoch 125:    356 / 1983 loss=3.135, nll_loss=0.995, word_ins=2.821, length=3.139, ppl=8.78, wps=209797, ups=3.38, wpb=62046.1, bsz=2069.9, num_updates=246200, lr=0.000201538, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:17:44 | INFO | train_inner | epoch 125:    456 / 1983 loss=3.123, nll_loss=0.981, word_ins=2.808, length=3.152, ppl=8.71, wps=210429, ups=3.43, wpb=61395.1, bsz=2067.6, num_updates=246300, lr=0.000201497, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:18:13 | INFO | train_inner | epoch 125:    556 / 1983 loss=3.162, nll_loss=1.014, word_ins=2.838, length=3.236, ppl=8.95, wps=211839, ups=3.42, wpb=61883.8, bsz=1974.6, num_updates=246400, lr=0.000201456, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:18:42 | INFO | train_inner | epoch 125:    656 / 1983 loss=3.153, nll_loss=1.008, word_ins=2.832, length=3.211, ppl=8.9, wps=211754, ups=3.44, wpb=61522.2, bsz=1974.8, num_updates=246500, lr=0.000201415, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:19:11 | INFO | train_inner | epoch 125:    756 / 1983 loss=3.187, nll_loss=1.036, word_ins=2.858, length=3.286, ppl=9.11, wps=210981, ups=3.44, wpb=61259.4, bsz=1876.1, num_updates=246600, lr=0.000201374, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:19:40 | INFO | train_inner | epoch 125:    856 / 1983 loss=3.169, nll_loss=1.019, word_ins=2.843, length=3.256, ppl=8.99, wps=209586, ups=3.42, wpb=61270, bsz=1969.8, num_updates=246700, lr=0.000201333, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:20:09 | INFO | train_inner | epoch 125:    956 / 1983 loss=3.144, nll_loss=1.002, word_ins=2.827, length=3.173, ppl=8.84, wps=214044, ups=3.45, wpb=62062.4, bsz=1986.1, num_updates=246800, lr=0.000201292, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:20:39 | INFO | train_inner | epoch 125:   1056 / 1983 loss=3.17, nll_loss=1.021, word_ins=2.845, length=3.25, ppl=9, wps=210547, ups=3.4, wpb=61847.8, bsz=1948.7, num_updates=246900, lr=0.000201252, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:21:08 | INFO | train_inner | epoch 125:   1156 / 1983 loss=3.153, nll_loss=1.002, word_ins=2.828, length=3.246, ppl=8.89, wps=212961, ups=3.45, wpb=61682.3, bsz=1980, num_updates=247000, lr=0.000201211, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:21:37 | INFO | train_inner | epoch 125:   1256 / 1983 loss=3.129, nll_loss=0.985, word_ins=2.812, length=3.172, ppl=8.75, wps=210191, ups=3.41, wpb=61700.6, bsz=2146.1, num_updates=247100, lr=0.00020117, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:22:06 | INFO | train_inner | epoch 125:   1356 / 1983 loss=3.14, nll_loss=0.995, word_ins=2.821, length=3.193, ppl=8.82, wps=213040, ups=3.42, wpb=62249.9, bsz=2038.2, num_updates=247200, lr=0.000201129, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:22:36 | INFO | train_inner | epoch 125:   1456 / 1983 loss=3.184, nll_loss=1.041, word_ins=2.862, length=3.223, ppl=9.09, wps=208942, ups=3.41, wpb=61287.7, bsz=2022.3, num_updates=247300, lr=0.000201089, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:23:05 | INFO | train_inner | epoch 125:   1556 / 1983 loss=3.143, nll_loss=1.001, word_ins=2.826, length=3.172, ppl=8.84, wps=211070, ups=3.43, wpb=61475.9, bsz=2044.3, num_updates=247400, lr=0.000201048, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:23:34 | INFO | train_inner | epoch 125:   1656 / 1983 loss=3.164, nll_loss=1.017, word_ins=2.841, length=3.234, ppl=8.96, wps=210774, ups=3.43, wpb=61456.8, bsz=2037.2, num_updates=247500, lr=0.000201008, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:24:03 | INFO | train_inner | epoch 125:   1756 / 1983 loss=3.167, nll_loss=1.016, word_ins=2.84, length=3.268, ppl=8.98, wps=211851, ups=3.44, wpb=61553.1, bsz=1944.6, num_updates=247600, lr=0.000200967, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:24:32 | INFO | train_inner | epoch 125:   1856 / 1983 loss=3.174, nll_loss=1.026, word_ins=2.85, length=3.245, ppl=9.03, wps=210924, ups=3.42, wpb=61617.7, bsz=1906.8, num_updates=247700, lr=0.000200926, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:25:01 | INFO | train_inner | epoch 125:   1956 / 1983 loss=3.148, nll_loss=1.003, word_ins=2.828, length=3.2, ppl=8.87, wps=210321, ups=3.41, wpb=61588.8, bsz=2075.4, num_updates=247800, lr=0.000200886, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 15:25:22 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 3.201 | nll_loss 0.991 | word_ins 2.876 | length 3.247 | ppl 9.19 | wps 97710 | wpb 41551 | bsz 1500 | num_updates 247827 | best_loss 3.196
2023-03-02 15:25:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 15:25:27 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint125.pt (epoch 125 @ 247827 updates, score 3.201) (writing took 5.433347673970275 seconds)
2023-03-02 15:25:27 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2023-03-02 15:25:27 | INFO | train | epoch 125 | loss 3.155 | nll_loss 1.009 | word_ins 2.834 | length 3.217 | ppl 8.91 | wps 201468 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 247827 | lr 0.000200875 | gnorm 0.861 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 15:25:27 | INFO | fairseq.trainer | begin training epoch 126
2023-03-02 15:25:58 | INFO | train_inner | epoch 126:     73 / 1983 loss=3.164, nll_loss=1.016, word_ins=2.841, length=3.233, ppl=8.96, wps=106536, ups=1.75, wpb=60766.6, bsz=1965.2, num_updates=247900, lr=0.000200845, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:26:27 | INFO | train_inner | epoch 126:    173 / 1983 loss=3.149, nll_loss=1.004, word_ins=2.829, length=3.202, ppl=8.87, wps=210686, ups=3.44, wpb=61264.4, bsz=1969, num_updates=248000, lr=0.000200805, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:26:57 | INFO | train_inner | epoch 126:    273 / 1983 loss=3.148, nll_loss=1.004, word_ins=2.829, length=3.183, ppl=8.86, wps=212431, ups=3.44, wpb=61737.5, bsz=1901.6, num_updates=248100, lr=0.000200764, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:27:26 | INFO | train_inner | epoch 126:    373 / 1983 loss=3.138, nll_loss=0.994, word_ins=2.82, length=3.18, ppl=8.81, wps=209561, ups=3.41, wpb=61368.9, bsz=2082.7, num_updates=248200, lr=0.000200724, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:27:55 | INFO | train_inner | epoch 126:    473 / 1983 loss=3.153, nll_loss=1.004, word_ins=2.829, length=3.237, ppl=8.89, wps=210768, ups=3.42, wpb=61638.3, bsz=2049, num_updates=248300, lr=0.000200683, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:28:24 | INFO | train_inner | epoch 126:    573 / 1983 loss=3.13, nll_loss=0.988, word_ins=2.814, length=3.157, ppl=8.76, wps=211870, ups=3.41, wpb=62047.3, bsz=2086.2, num_updates=248400, lr=0.000200643, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:28:54 | INFO | train_inner | epoch 126:    673 / 1983 loss=3.152, nll_loss=1.004, word_ins=2.83, length=3.225, ppl=8.89, wps=212296, ups=3.42, wpb=62111.5, bsz=1979.8, num_updates=248500, lr=0.000200603, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:29:23 | INFO | train_inner | epoch 126:    773 / 1983 loss=3.132, nll_loss=0.989, word_ins=2.816, length=3.16, ppl=8.76, wps=212587, ups=3.43, wpb=62001.4, bsz=2018, num_updates=248600, lr=0.000200562, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:29:52 | INFO | train_inner | epoch 126:    873 / 1983 loss=3.162, nll_loss=1.017, word_ins=2.841, length=3.206, ppl=8.95, wps=213530, ups=3.44, wpb=62156.7, bsz=1906.6, num_updates=248700, lr=0.000200522, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:30:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 15:30:21 | INFO | train_inner | epoch 126:    974 / 1983 loss=3.151, nll_loss=1.004, word_ins=2.829, length=3.224, ppl=8.89, wps=209385, ups=3.4, wpb=61520.4, bsz=1976.2, num_updates=248800, lr=0.000200482, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:30:50 | INFO | train_inner | epoch 126:   1074 / 1983 loss=3.166, nll_loss=1.016, word_ins=2.84, length=3.257, ppl=8.98, wps=212312, ups=3.43, wpb=61911.1, bsz=1968.8, num_updates=248900, lr=0.000200441, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:31:20 | INFO | train_inner | epoch 126:   1174 / 1983 loss=3.145, nll_loss=0.999, word_ins=2.824, length=3.205, ppl=8.84, wps=212070, ups=3.44, wpb=61672.1, bsz=2048.2, num_updates=249000, lr=0.000200401, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:31:49 | INFO | train_inner | epoch 126:   1274 / 1983 loss=3.137, nll_loss=0.995, word_ins=2.82, length=3.171, ppl=8.8, wps=212043, ups=3.42, wpb=61915.4, bsz=2049.2, num_updates=249100, lr=0.000200361, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:32:18 | INFO | train_inner | epoch 126:   1374 / 1983 loss=3.147, nll_loss=0.998, word_ins=2.823, length=3.238, ppl=8.86, wps=209874, ups=3.43, wpb=61272, bsz=2053.5, num_updates=249200, lr=0.000200321, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:32:47 | INFO | train_inner | epoch 126:   1474 / 1983 loss=3.162, nll_loss=1.015, word_ins=2.839, length=3.224, ppl=8.95, wps=211679, ups=3.42, wpb=61823.1, bsz=2023.6, num_updates=249300, lr=0.000200281, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:33:16 | INFO | train_inner | epoch 126:   1574 / 1983 loss=3.177, nll_loss=1.027, word_ins=2.849, length=3.272, ppl=9.04, wps=210449, ups=3.44, wpb=61180.8, bsz=1965.2, num_updates=249400, lr=0.00020024, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:33:45 | INFO | train_inner | epoch 126:   1674 / 1983 loss=3.182, nll_loss=1.033, word_ins=2.856, length=3.262, ppl=9.08, wps=209966, ups=3.42, wpb=61406.7, bsz=1920.6, num_updates=249500, lr=0.0002002, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:34:15 | INFO | train_inner | epoch 126:   1774 / 1983 loss=3.161, nll_loss=1.013, word_ins=2.838, length=3.228, ppl=8.94, wps=212123, ups=3.43, wpb=61861.8, bsz=1973.1, num_updates=249600, lr=0.00020016, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:34:44 | INFO | train_inner | epoch 126:   1874 / 1983 loss=3.165, nll_loss=1.021, word_ins=2.844, length=3.213, ppl=8.97, wps=209680, ups=3.41, wpb=61445.5, bsz=1989, num_updates=249700, lr=0.00020012, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:35:13 | INFO | train_inner | epoch 126:   1974 / 1983 loss=3.151, nll_loss=1.004, word_ins=2.829, length=3.217, ppl=8.88, wps=210764, ups=3.44, wpb=61355.7, bsz=2020.2, num_updates=249800, lr=0.00020008, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 15:35:29 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 3.198 | nll_loss 0.989 | word_ins 2.873 | length 3.256 | ppl 9.18 | wps 106896 | wpb 41551 | bsz 1500 | num_updates 249809 | best_loss 3.196
2023-03-02 15:35:29 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 15:35:34 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint126.pt (epoch 126 @ 249809 updates, score 3.198) (writing took 5.248208750970662 seconds)
2023-03-02 15:35:35 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2023-03-02 15:35:35 | INFO | train | epoch 126 | loss 3.153 | nll_loss 1.007 | word_ins 2.832 | length 3.214 | ppl 8.9 | wps 201082 | ups 3.26 | wpb 61627.3 | bsz 1997.3 | num_updates 249809 | lr 0.000200076 | gnorm 0.864 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 15:35:35 | INFO | fairseq.trainer | begin training epoch 127
2023-03-02 15:36:11 | INFO | train_inner | epoch 127:     91 / 1983 loss=3.127, nll_loss=0.985, word_ins=2.812, length=3.143, ppl=8.73, wps=105746, ups=1.73, wpb=61149.2, bsz=2023.1, num_updates=249900, lr=0.00020004, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:36:40 | INFO | train_inner | epoch 127:    191 / 1983 loss=3.143, nll_loss=0.997, word_ins=2.823, length=3.196, ppl=8.83, wps=211604, ups=3.43, wpb=61724.3, bsz=2036.7, num_updates=250000, lr=0.0002, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:37:09 | INFO | train_inner | epoch 127:    291 / 1983 loss=3.154, nll_loss=1.011, word_ins=2.836, length=3.187, ppl=8.9, wps=210649, ups=3.42, wpb=61541.1, bsz=1997.3, num_updates=250100, lr=0.00019996, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:37:38 | INFO | train_inner | epoch 127:    391 / 1983 loss=3.135, nll_loss=0.988, word_ins=2.815, length=3.202, ppl=8.79, wps=210252, ups=3.43, wpb=61327.3, bsz=2046.4, num_updates=250200, lr=0.00019992, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:38:08 | INFO | train_inner | epoch 127:    491 / 1983 loss=3.141, nll_loss=1.001, word_ins=2.827, length=3.149, ppl=8.82, wps=213433, ups=3.43, wpb=62149.8, bsz=1996.6, num_updates=250300, lr=0.00019988, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:38:37 | INFO | train_inner | epoch 127:    591 / 1983 loss=3.142, nll_loss=0.999, word_ins=2.824, length=3.178, ppl=8.83, wps=211819, ups=3.42, wpb=61860.2, bsz=2041.9, num_updates=250400, lr=0.00019984, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:39:06 | INFO | train_inner | epoch 127:    691 / 1983 loss=3.159, nll_loss=1.009, word_ins=2.834, length=3.253, ppl=8.93, wps=211090, ups=3.43, wpb=61621.1, bsz=1975.6, num_updates=250500, lr=0.0001998, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:39:35 | INFO | train_inner | epoch 127:    791 / 1983 loss=3.148, nll_loss=1.001, word_ins=2.827, length=3.215, ppl=8.87, wps=212534, ups=3.43, wpb=61913.8, bsz=1950.9, num_updates=250600, lr=0.00019976, gnorm=0.901, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:40:04 | INFO | train_inner | epoch 127:    891 / 1983 loss=3.129, nll_loss=0.987, word_ins=2.814, length=3.155, ppl=8.75, wps=211538, ups=3.42, wpb=61870.8, bsz=2117.4, num_updates=250700, lr=0.000199721, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:40:33 | INFO | train_inner | epoch 127:    991 / 1983 loss=3.166, nll_loss=1.018, word_ins=2.841, length=3.247, ppl=8.98, wps=211779, ups=3.44, wpb=61558.2, bsz=1955.1, num_updates=250800, lr=0.000199681, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:41:03 | INFO | train_inner | epoch 127:   1091 / 1983 loss=3.152, nll_loss=1.007, word_ins=2.831, length=3.215, ppl=8.89, wps=210604, ups=3.42, wpb=61538.1, bsz=1953, num_updates=250900, lr=0.000199641, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:41:32 | INFO | train_inner | epoch 127:   1191 / 1983 loss=3.147, nll_loss=1, word_ins=2.825, length=3.213, ppl=8.86, wps=209991, ups=3.42, wpb=61478.2, bsz=1990.6, num_updates=251000, lr=0.000199601, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:42:01 | INFO | train_inner | epoch 127:   1291 / 1983 loss=3.152, nll_loss=1.005, word_ins=2.829, length=3.224, ppl=8.89, wps=210079, ups=3.41, wpb=61546.5, bsz=2025.4, num_updates=251100, lr=0.000199561, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:42:30 | INFO | train_inner | epoch 127:   1391 / 1983 loss=3.173, nll_loss=1.026, word_ins=2.85, length=3.24, ppl=9.02, wps=211855, ups=3.44, wpb=61568.9, bsz=1892.6, num_updates=251200, lr=0.000199522, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:43:00 | INFO | train_inner | epoch 127:   1491 / 1983 loss=3.14, nll_loss=0.994, word_ins=2.819, length=3.208, ppl=8.81, wps=210574, ups=3.42, wpb=61540.8, bsz=2079.1, num_updates=251300, lr=0.000199482, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:43:29 | INFO | train_inner | epoch 127:   1591 / 1983 loss=3.182, nll_loss=1.035, word_ins=2.857, length=3.245, ppl=9.07, wps=210934, ups=3.44, wpb=61396.6, bsz=1941.7, num_updates=251400, lr=0.000199442, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:43:58 | INFO | train_inner | epoch 127:   1691 / 1983 loss=3.161, nll_loss=1.011, word_ins=2.835, length=3.257, ppl=8.95, wps=209797, ups=3.42, wpb=61291.4, bsz=1999.5, num_updates=251500, lr=0.000199403, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:44:27 | INFO | train_inner | epoch 127:   1791 / 1983 loss=3.178, nll_loss=1.027, word_ins=2.849, length=3.284, ppl=9.05, wps=211672, ups=3.43, wpb=61717, bsz=1940.5, num_updates=251600, lr=0.000199363, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:44:56 | INFO | train_inner | epoch 127:   1891 / 1983 loss=3.147, nll_loss=1.003, word_ins=2.828, length=3.194, ppl=8.86, wps=209533, ups=3.42, wpb=61346.3, bsz=2035.9, num_updates=251700, lr=0.000199323, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 15:45:35 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 3.199 | nll_loss 0.978 | word_ins 2.865 | length 3.344 | ppl 9.18 | wps 129595 | wpb 41551 | bsz 1500 | num_updates 251792 | best_loss 3.196
2023-03-02 15:45:35 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 15:45:41 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint127.pt (epoch 127 @ 251792 updates, score 3.199) (writing took 5.344051316031255 seconds)
2023-03-02 15:45:41 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2023-03-02 15:45:41 | INFO | train | epoch 127 | loss 3.152 | nll_loss 1.006 | word_ins 2.831 | length 3.212 | ppl 8.89 | wps 201573 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 251792 | lr 0.000199287 | gnorm 0.864 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 15:45:41 | INFO | fairseq.trainer | begin training epoch 128
2023-03-02 15:45:54 | INFO | train_inner | epoch 128:      8 / 1983 loss=3.167, nll_loss=1.019, word_ins=2.842, length=3.243, ppl=8.98, wps=106930, ups=1.73, wpb=61858.7, bsz=1947.7, num_updates=251800, lr=0.000199284, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:46:23 | INFO | train_inner | epoch 128:    108 / 1983 loss=3.131, nll_loss=0.988, word_ins=2.814, length=3.169, ppl=8.76, wps=212015, ups=3.43, wpb=61878.8, bsz=2021.9, num_updates=251900, lr=0.000199244, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:46:53 | INFO | train_inner | epoch 128:    208 / 1983 loss=3.161, nll_loss=1.012, word_ins=2.837, length=3.244, ppl=8.95, wps=210064, ups=3.42, wpb=61352.4, bsz=1930.5, num_updates=252000, lr=0.000199205, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:47:22 | INFO | train_inner | epoch 128:    308 / 1983 loss=3.15, nll_loss=1.003, word_ins=2.829, length=3.214, ppl=8.88, wps=209108, ups=3.41, wpb=61296.8, bsz=1998.1, num_updates=252100, lr=0.000199165, gnorm=0.879, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:47:51 | INFO | train_inner | epoch 128:    408 / 1983 loss=3.161, nll_loss=1.013, word_ins=2.838, length=3.232, ppl=8.94, wps=210794, ups=3.41, wpb=61772.8, bsz=1959.5, num_updates=252200, lr=0.000199126, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:48:20 | INFO | train_inner | epoch 128:    508 / 1983 loss=3.124, nll_loss=0.985, word_ins=2.812, length=3.127, ppl=8.72, wps=210808, ups=3.42, wpb=61700.3, bsz=2103.8, num_updates=252300, lr=0.000199086, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:48:50 | INFO | train_inner | epoch 128:    608 / 1983 loss=3.159, nll_loss=1.009, word_ins=2.834, length=3.255, ppl=8.93, wps=211159, ups=3.42, wpb=61691.2, bsz=1941.3, num_updates=252400, lr=0.000199047, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:49:19 | INFO | train_inner | epoch 128:    708 / 1983 loss=3.149, nll_loss=1, word_ins=2.825, length=3.238, ppl=8.87, wps=210079, ups=3.43, wpb=61178, bsz=1959, num_updates=252500, lr=0.000199007, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:49:48 | INFO | train_inner | epoch 128:    808 / 1983 loss=3.149, nll_loss=1.005, word_ins=2.83, length=3.19, ppl=8.87, wps=212238, ups=3.43, wpb=61944, bsz=1958.9, num_updates=252600, lr=0.000198968, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:50:17 | INFO | train_inner | epoch 128:    908 / 1983 loss=3.133, nll_loss=0.989, word_ins=2.815, length=3.178, ppl=8.77, wps=210931, ups=3.42, wpb=61643.8, bsz=2037.1, num_updates=252700, lr=0.000198929, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:50:46 | INFO | train_inner | epoch 128:   1008 / 1983 loss=3.146, nll_loss=1.003, word_ins=2.828, length=3.177, ppl=8.85, wps=212990, ups=3.44, wpb=61892.7, bsz=1952.2, num_updates=252800, lr=0.000198889, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:51:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 15:51:16 | INFO | train_inner | epoch 128:   1109 / 1983 loss=3.141, nll_loss=0.997, word_ins=2.823, length=3.186, ppl=8.82, wps=211409, ups=3.4, wpb=62268.1, bsz=2035.7, num_updates=252900, lr=0.00019885, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:51:45 | INFO | train_inner | epoch 128:   1209 / 1983 loss=3.153, nll_loss=1.01, word_ins=2.835, length=3.184, ppl=8.89, wps=211748, ups=3.42, wpb=61955.2, bsz=1984.1, num_updates=253000, lr=0.000198811, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:52:14 | INFO | train_inner | epoch 128:   1309 / 1983 loss=3.158, nll_loss=1.008, word_ins=2.833, length=3.252, ppl=8.93, wps=208350, ups=3.42, wpb=60928.3, bsz=2032.8, num_updates=253100, lr=0.000198771, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 15:52:42 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2023-03-02 15:52:44 | INFO | train_inner | epoch 128:   1410 / 1983 loss=3.148, nll_loss=1.004, word_ins=2.829, length=3.194, ppl=8.87, wps=208099, ups=3.38, wpb=61489.1, bsz=2062.3, num_updates=253200, lr=0.000198732, gnorm=0.855, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:53:13 | INFO | train_inner | epoch 128:   1510 / 1983 loss=3.173, nll_loss=1.021, word_ins=2.844, length=3.282, ppl=9.02, wps=211562, ups=3.44, wpb=61470.5, bsz=1893.8, num_updates=253300, lr=0.000198693, gnorm=0.875, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:53:42 | INFO | train_inner | epoch 128:   1610 / 1983 loss=3.161, nll_loss=1.013, word_ins=2.837, length=3.239, ppl=8.95, wps=211869, ups=3.43, wpb=61849.7, bsz=2027.6, num_updates=253400, lr=0.000198654, gnorm=0.876, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:54:11 | INFO | train_inner | epoch 128:   1710 / 1983 loss=3.139, nll_loss=0.996, word_ins=2.822, length=3.178, ppl=8.81, wps=211963, ups=3.43, wpb=61850.7, bsz=2063.2, num_updates=253500, lr=0.000198615, gnorm=0.858, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:54:40 | INFO | train_inner | epoch 128:   1810 / 1983 loss=3.188, nll_loss=1.034, word_ins=2.855, length=3.327, ppl=9.11, wps=211869, ups=3.45, wpb=61479.9, bsz=1868.2, num_updates=253600, lr=0.000198575, gnorm=0.889, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:55:10 | INFO | train_inner | epoch 128:   1910 / 1983 loss=3.14, nll_loss=0.999, word_ins=2.824, length=3.161, ppl=8.81, wps=210924, ups=3.42, wpb=61713.7, bsz=2073.9, num_updates=253700, lr=0.000198536, gnorm=0.857, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:55:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 15:55:46 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 3.202 | nll_loss 0.999 | word_ins 2.878 | length 3.244 | ppl 9.2 | wps 108666 | wpb 41551 | bsz 1500 | num_updates 253773 | best_loss 3.196
2023-03-02 15:55:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 15:55:51 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint128.pt (epoch 128 @ 253773 updates, score 3.202) (writing took 5.7225112449377775 seconds)
2023-03-02 15:55:51 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2023-03-02 15:55:51 | INFO | train | epoch 128 | loss 3.15 | nll_loss 1.004 | word_ins 2.829 | length 3.21 | ppl 8.88 | wps 199937 | ups 3.24 | wpb 61636.6 | bsz 1997.4 | num_updates 253773 | lr 0.000198508 | gnorm 0.865 | loss_scale 8192 | train_wall 576 | wall 0
2023-03-02 15:55:51 | INFO | fairseq.trainer | begin training epoch 129
2023-03-02 15:56:10 | INFO | train_inner | epoch 129:     27 / 1983 loss=3.126, nll_loss=0.984, word_ins=2.811, length=3.155, ppl=8.73, wps=101333, ups=1.66, wpb=60875.1, bsz=2060, num_updates=253800, lr=0.000198497, gnorm=0.86, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:56:39 | INFO | train_inner | epoch 129:    127 / 1983 loss=3.117, nll_loss=0.974, word_ins=2.802, length=3.145, ppl=8.67, wps=211869, ups=3.43, wpb=61816.5, bsz=2066.5, num_updates=253900, lr=0.000198458, gnorm=0.858, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:57:08 | INFO | train_inner | epoch 129:    227 / 1983 loss=3.14, nll_loss=0.995, word_ins=2.821, length=3.194, ppl=8.82, wps=211751, ups=3.42, wpb=61852.9, bsz=1970.2, num_updates=254000, lr=0.000198419, gnorm=0.867, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:57:37 | INFO | train_inner | epoch 129:    327 / 1983 loss=3.147, nll_loss=1.003, word_ins=2.828, length=3.19, ppl=8.86, wps=210218, ups=3.42, wpb=61407.6, bsz=1986.6, num_updates=254100, lr=0.00019838, gnorm=0.852, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:58:06 | INFO | train_inner | epoch 129:    427 / 1983 loss=3.122, nll_loss=0.981, word_ins=2.807, length=3.143, ppl=8.71, wps=211271, ups=3.44, wpb=61481.6, bsz=2064.8, num_updates=254200, lr=0.000198341, gnorm=0.836, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:58:35 | INFO | train_inner | epoch 129:    527 / 1983 loss=3.166, nll_loss=1.019, word_ins=2.842, length=3.232, ppl=8.97, wps=213466, ups=3.43, wpb=62197.6, bsz=1917.5, num_updates=254300, lr=0.000198302, gnorm=0.854, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:59:05 | INFO | train_inner | epoch 129:    627 / 1983 loss=3.165, nll_loss=1.018, word_ins=2.842, length=3.226, ppl=8.97, wps=209588, ups=3.4, wpb=61580.2, bsz=1976, num_updates=254400, lr=0.000198263, gnorm=0.887, loss_scale=8192, train_wall=29, wall=0
2023-03-02 15:59:34 | INFO | train_inner | epoch 129:    727 / 1983 loss=3.142, nll_loss=1, word_ins=2.825, length=3.163, ppl=8.82, wps=210155, ups=3.41, wpb=61679.9, bsz=2008.5, num_updates=254500, lr=0.000198224, gnorm=0.868, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:00:03 | INFO | train_inner | epoch 129:    827 / 1983 loss=3.135, nll_loss=0.991, word_ins=2.818, length=3.18, ppl=8.79, wps=212515, ups=3.44, wpb=61857.8, bsz=2020.9, num_updates=254600, lr=0.000198185, gnorm=0.848, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:00:32 | INFO | train_inner | epoch 129:    927 / 1983 loss=3.157, nll_loss=1.006, word_ins=2.831, length=3.258, ppl=8.92, wps=211907, ups=3.44, wpb=61671.5, bsz=1940.5, num_updates=254700, lr=0.000198146, gnorm=0.889, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:01:02 | INFO | train_inner | epoch 129:   1027 / 1983 loss=3.163, nll_loss=1.016, word_ins=2.84, length=3.238, ppl=8.96, wps=210251, ups=3.44, wpb=61197.5, bsz=1992, num_updates=254800, lr=0.000198107, gnorm=0.868, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:01:31 | INFO | train_inner | epoch 129:   1127 / 1983 loss=3.165, nll_loss=1.013, word_ins=2.838, length=3.271, ppl=8.97, wps=210054, ups=3.44, wpb=61123.1, bsz=1956.6, num_updates=254900, lr=0.000198068, gnorm=0.862, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:02:00 | INFO | train_inner | epoch 129:   1227 / 1983 loss=3.125, nll_loss=0.984, word_ins=2.81, length=3.151, ppl=8.72, wps=212555, ups=3.42, wpb=62231.2, bsz=2069.4, num_updates=255000, lr=0.00019803, gnorm=0.86, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:02:29 | INFO | train_inner | epoch 129:   1327 / 1983 loss=3.14, nll_loss=0.996, word_ins=2.821, length=3.188, ppl=8.82, wps=210030, ups=3.41, wpb=61502.6, bsz=2019.4, num_updates=255100, lr=0.000197991, gnorm=0.852, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:02:58 | INFO | train_inner | epoch 129:   1427 / 1983 loss=3.174, nll_loss=1.027, word_ins=2.85, length=3.249, ppl=9.03, wps=208285, ups=3.42, wpb=60978.9, bsz=2025.7, num_updates=255200, lr=0.000197952, gnorm=0.868, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:03:28 | INFO | train_inner | epoch 129:   1527 / 1983 loss=3.142, nll_loss=0.995, word_ins=2.82, length=3.216, ppl=8.83, wps=211878, ups=3.42, wpb=61913, bsz=2033.8, num_updates=255300, lr=0.000197913, gnorm=0.884, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:03:57 | INFO | train_inner | epoch 129:   1627 / 1983 loss=3.138, nll_loss=0.996, word_ins=2.821, length=3.166, ppl=8.8, wps=211441, ups=3.42, wpb=61914, bsz=2115, num_updates=255400, lr=0.000197874, gnorm=0.865, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:04:26 | INFO | train_inner | epoch 129:   1727 / 1983 loss=3.148, nll_loss=1.004, word_ins=2.829, length=3.188, ppl=8.86, wps=212041, ups=3.42, wpb=61914.2, bsz=1999.2, num_updates=255500, lr=0.000197836, gnorm=0.857, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:04:55 | INFO | train_inner | epoch 129:   1827 / 1983 loss=3.178, nll_loss=1.034, word_ins=2.856, length=3.226, ppl=9.05, wps=210787, ups=3.42, wpb=61624.6, bsz=1933.5, num_updates=255600, lr=0.000197797, gnorm=0.881, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:05:25 | INFO | train_inner | epoch 129:   1927 / 1983 loss=3.173, nll_loss=1.02, word_ins=2.843, length=3.295, ppl=9.02, wps=212706, ups=3.43, wpb=62010.7, bsz=1909.8, num_updates=255700, lr=0.000197758, gnorm=0.894, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 16:05:53 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 3.189 | nll_loss 0.98 | word_ins 2.861 | length 3.282 | ppl 9.12 | wps 78637.5 | wpb 41551 | bsz 1500 | num_updates 255756 | best_loss 3.189
2023-03-02 16:05:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 16:06:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint129.pt (epoch 129 @ 255756 updates, score 3.189) (writing took 8.332810725085437 seconds)
2023-03-02 16:06:01 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2023-03-02 16:06:01 | INFO | train | epoch 129 | loss 3.15 | nll_loss 1.004 | word_ins 2.829 | length 3.205 | ppl 8.87 | wps 200355 | ups 3.25 | wpb 61628.5 | bsz 1997.6 | num_updates 255756 | lr 0.000197737 | gnorm 0.865 | loss_scale 8192 | train_wall 576 | wall 0
2023-03-02 16:06:01 | INFO | fairseq.trainer | begin training epoch 130
2023-03-02 16:06:24 | INFO | train_inner | epoch 130:     44 / 1983 loss=3.149, nll_loss=1.01, word_ins=2.835, length=3.143, ppl=8.87, wps=103161, ups=1.68, wpb=61373.4, bsz=1939.8, num_updates=255800, lr=0.00019772, gnorm=0.869, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:06:53 | INFO | train_inner | epoch 130:    144 / 1983 loss=3.126, nll_loss=0.982, word_ins=2.809, length=3.17, ppl=8.73, wps=210920, ups=3.42, wpb=61670, bsz=2056.4, num_updates=255900, lr=0.000197681, gnorm=0.846, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:07:22 | INFO | train_inner | epoch 130:    244 / 1983 loss=3.157, nll_loss=1.006, word_ins=2.831, length=3.26, ppl=8.92, wps=210559, ups=3.44, wpb=61251.1, bsz=1942.5, num_updates=256000, lr=0.000197642, gnorm=0.871, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:07:52 | INFO | train_inner | epoch 130:    344 / 1983 loss=3.144, nll_loss=1.005, word_ins=2.83, length=3.138, ppl=8.84, wps=210709, ups=3.4, wpb=61954.4, bsz=2035.8, num_updates=256100, lr=0.000197604, gnorm=0.871, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:08:21 | INFO | train_inner | epoch 130:    444 / 1983 loss=3.15, nll_loss=1.011, word_ins=2.836, length=3.144, ppl=8.88, wps=210326, ups=3.41, wpb=61609.6, bsz=2015.9, num_updates=256200, lr=0.000197565, gnorm=0.866, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:08:50 | INFO | train_inner | epoch 130:    544 / 1983 loss=3.129, nll_loss=0.985, word_ins=2.812, length=3.166, ppl=8.75, wps=211477, ups=3.42, wpb=61877.8, bsz=2082, num_updates=256300, lr=0.000197527, gnorm=0.868, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:09:20 | INFO | train_inner | epoch 130:    644 / 1983 loss=3.141, nll_loss=0.999, word_ins=2.825, length=3.164, ppl=8.82, wps=211445, ups=3.43, wpb=61623.3, bsz=2018.2, num_updates=256400, lr=0.000197488, gnorm=0.845, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:09:49 | INFO | train_inner | epoch 130:    744 / 1983 loss=3.137, nll_loss=0.994, word_ins=2.819, length=3.172, ppl=8.79, wps=212403, ups=3.42, wpb=62104.2, bsz=1995.4, num_updates=256500, lr=0.00019745, gnorm=0.847, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:10:18 | INFO | train_inner | epoch 130:    844 / 1983 loss=3.148, nll_loss=1, word_ins=2.826, length=3.227, ppl=8.87, wps=210143, ups=3.42, wpb=61356.8, bsz=1986.6, num_updates=256600, lr=0.000197411, gnorm=0.867, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:10:47 | INFO | train_inner | epoch 130:    944 / 1983 loss=3.142, nll_loss=0.996, word_ins=2.822, length=3.199, ppl=8.83, wps=210844, ups=3.43, wpb=61506.9, bsz=1961.6, num_updates=256700, lr=0.000197373, gnorm=0.852, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:11:16 | INFO | train_inner | epoch 130:   1044 / 1983 loss=3.156, nll_loss=1.009, word_ins=2.833, length=3.228, ppl=8.91, wps=210535, ups=3.42, wpb=61533.5, bsz=1994.4, num_updates=256800, lr=0.000197334, gnorm=0.859, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:11:46 | INFO | train_inner | epoch 130:   1144 / 1983 loss=3.13, nll_loss=0.986, word_ins=2.813, length=3.169, ppl=8.75, wps=211149, ups=3.42, wpb=61694.5, bsz=2072.6, num_updates=256900, lr=0.000197296, gnorm=0.841, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:12:15 | INFO | train_inner | epoch 130:   1244 / 1983 loss=3.151, nll_loss=1.006, word_ins=2.831, length=3.201, ppl=8.88, wps=210557, ups=3.41, wpb=61696.7, bsz=2023.8, num_updates=257000, lr=0.000197257, gnorm=0.846, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:12:44 | INFO | train_inner | epoch 130:   1344 / 1983 loss=3.168, nll_loss=1.021, word_ins=2.844, length=3.236, ppl=8.99, wps=212662, ups=3.44, wpb=61789, bsz=1883.3, num_updates=257100, lr=0.000197219, gnorm=0.894, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:13:13 | INFO | train_inner | epoch 130:   1444 / 1983 loss=3.157, nll_loss=1.009, word_ins=2.833, length=3.233, ppl=8.92, wps=212680, ups=3.44, wpb=61794, bsz=1953.5, num_updates=257200, lr=0.000197181, gnorm=0.885, loss_scale=8192, train_wall=29, wall=0
2023-03-02 16:13:42 | INFO | train_inner | epoch 130:   1544 / 1983 loss=3.157, nll_loss=1.01, word_ins=2.834, length=3.234, ppl=8.92, wps=209231, ups=3.41, wpb=61281.3, bsz=2007.9, num_updates=257300, lr=0.000197142, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:14:12 | INFO | train_inner | epoch 130:   1644 / 1983 loss=3.146, nll_loss=1.002, word_ins=2.827, length=3.197, ppl=8.85, wps=211491, ups=3.42, wpb=61835.3, bsz=1991.7, num_updates=257400, lr=0.000197104, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:14:41 | INFO | train_inner | epoch 130:   1744 / 1983 loss=3.167, nll_loss=1.015, word_ins=2.838, length=3.287, ppl=8.98, wps=211670, ups=3.44, wpb=61447.1, bsz=1951.3, num_updates=257500, lr=0.000197066, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:15:10 | INFO | train_inner | epoch 130:   1844 / 1983 loss=3.153, nll_loss=1.006, word_ins=2.831, length=3.221, ppl=8.89, wps=211249, ups=3.44, wpb=61360.8, bsz=1983.2, num_updates=257600, lr=0.000197028, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:15:39 | INFO | train_inner | epoch 130:   1944 / 1983 loss=3.121, nll_loss=0.978, word_ins=2.805, length=3.158, ppl=8.7, wps=212727, ups=3.44, wpb=61847.2, bsz=2030, num_updates=257700, lr=0.000196989, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 16:16:04 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 3.192 | nll_loss 0.985 | word_ins 2.868 | length 3.238 | ppl 9.14 | wps 92184.8 | wpb 41551 | bsz 1500 | num_updates 257739 | best_loss 3.189
2023-03-02 16:16:04 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 16:16:10 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint130.pt (epoch 130 @ 257739 updates, score 3.192) (writing took 5.352927783038467 seconds)
2023-03-02 16:16:10 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2023-03-02 16:16:10 | INFO | train | epoch 130 | loss 3.146 | nll_loss 1.001 | word_ins 2.826 | length 3.2 | ppl 8.85 | wps 200939 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 257739 | lr 0.000196974 | gnorm 0.862 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 16:16:10 | INFO | fairseq.trainer | begin training epoch 131
2023-03-02 16:16:37 | INFO | train_inner | epoch 131:     61 / 1983 loss=3.169, nll_loss=1.017, word_ins=2.841, length=3.28, ppl=9, wps=104379, ups=1.71, wpb=61141, bsz=1889.4, num_updates=257800, lr=0.000196951, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:17:07 | INFO | train_inner | epoch 131:    161 / 1983 loss=3.161, nll_loss=1.015, word_ins=2.839, length=3.215, ppl=8.94, wps=209786, ups=3.41, wpb=61511.2, bsz=1914.1, num_updates=257900, lr=0.000196913, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:17:36 | INFO | train_inner | epoch 131:    261 / 1983 loss=3.133, nll_loss=0.992, word_ins=2.818, length=3.153, ppl=8.77, wps=211398, ups=3.43, wpb=61691.7, bsz=1995.4, num_updates=258000, lr=0.000196875, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:18:05 | INFO | train_inner | epoch 131:    361 / 1983 loss=3.126, nll_loss=0.984, word_ins=2.811, length=3.147, ppl=8.73, wps=212325, ups=3.41, wpb=62268.2, bsz=2052.9, num_updates=258100, lr=0.000196837, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:18:34 | INFO | train_inner | epoch 131:    461 / 1983 loss=3.11, nll_loss=0.966, word_ins=2.794, length=3.151, ppl=8.63, wps=211834, ups=3.42, wpb=61868.2, bsz=2074.7, num_updates=258200, lr=0.000196799, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:19:04 | INFO | train_inner | epoch 131:    561 / 1983 loss=3.106, nll_loss=0.966, word_ins=2.794, length=3.122, ppl=8.61, wps=210590, ups=3.42, wpb=61661.8, bsz=2085.1, num_updates=258300, lr=0.00019676, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:19:33 | INFO | train_inner | epoch 131:    661 / 1983 loss=3.148, nll_loss=1.007, word_ins=2.831, length=3.175, ppl=8.86, wps=212562, ups=3.43, wpb=62051.3, bsz=2008.6, num_updates=258400, lr=0.000196722, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:20:02 | INFO | train_inner | epoch 131:    761 / 1983 loss=3.157, nll_loss=1.009, word_ins=2.834, length=3.227, ppl=8.92, wps=209681, ups=3.41, wpb=61553.4, bsz=2007.7, num_updates=258500, lr=0.000196684, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:20:32 | INFO | train_inner | epoch 131:    861 / 1983 loss=3.162, nll_loss=1.017, word_ins=2.841, length=3.206, ppl=8.95, wps=208708, ups=3.4, wpb=61300.7, bsz=1990.2, num_updates=258600, lr=0.000196646, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:21:01 | INFO | train_inner | epoch 131:    961 / 1983 loss=3.126, nll_loss=0.982, word_ins=2.809, length=3.173, ppl=8.73, wps=212437, ups=3.44, wpb=61840.8, bsz=2117.1, num_updates=258700, lr=0.000196608, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:21:30 | INFO | train_inner | epoch 131:   1061 / 1983 loss=3.16, nll_loss=1.013, word_ins=2.838, length=3.221, ppl=8.94, wps=209539, ups=3.41, wpb=61392.5, bsz=1968, num_updates=258800, lr=0.00019657, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:21:59 | INFO | train_inner | epoch 131:   1161 / 1983 loss=3.164, nll_loss=1.017, word_ins=2.84, length=3.24, ppl=8.97, wps=209744, ups=3.42, wpb=61388.9, bsz=1987.7, num_updates=258900, lr=0.000196532, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:22:29 | INFO | train_inner | epoch 131:   1261 / 1983 loss=3.158, nll_loss=1.012, word_ins=2.836, length=3.216, ppl=8.92, wps=209514, ups=3.41, wpb=61422.4, bsz=1956.9, num_updates=259000, lr=0.000196494, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:22:58 | INFO | train_inner | epoch 131:   1361 / 1983 loss=3.143, nll_loss=1, word_ins=2.825, length=3.175, ppl=8.83, wps=211214, ups=3.42, wpb=61690.3, bsz=2037.3, num_updates=259100, lr=0.000196456, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:23:27 | INFO | train_inner | epoch 131:   1461 / 1983 loss=3.143, nll_loss=1.004, word_ins=2.829, length=3.142, ppl=8.83, wps=210487, ups=3.41, wpb=61810.4, bsz=2059.5, num_updates=259200, lr=0.000196419, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:23:56 | INFO | train_inner | epoch 131:   1561 / 1983 loss=3.162, nll_loss=1.009, word_ins=2.834, length=3.287, ppl=8.95, wps=212192, ups=3.45, wpb=61484.8, bsz=1935.1, num_updates=259300, lr=0.000196381, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:24:25 | INFO | train_inner | epoch 131:   1661 / 1983 loss=3.165, nll_loss=1.016, word_ins=2.839, length=3.259, ppl=8.97, wps=211159, ups=3.44, wpb=61359.8, bsz=1916.2, num_updates=259400, lr=0.000196343, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:24:54 | INFO | train_inner | epoch 131:   1761 / 1983 loss=3.155, nll_loss=1.005, word_ins=2.83, length=3.254, ppl=8.91, wps=211571, ups=3.43, wpb=61612.4, bsz=1947, num_updates=259500, lr=0.000196305, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:25:24 | INFO | train_inner | epoch 131:   1861 / 1983 loss=3.126, nll_loss=0.982, word_ins=2.809, length=3.171, ppl=8.73, wps=211673, ups=3.42, wpb=61818.7, bsz=2044.6, num_updates=259600, lr=0.000196267, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:25:53 | INFO | train_inner | epoch 131:   1961 / 1983 loss=3.169, nll_loss=1.017, word_ins=2.84, length=3.285, ppl=8.99, wps=211216, ups=3.43, wpb=61654.9, bsz=1931.5, num_updates=259700, lr=0.000196229, gnorm=0.891, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 16:26:12 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 3.222 | nll_loss 1.011 | word_ins 2.895 | length 3.276 | ppl 9.33 | wps 111720 | wpb 41551 | bsz 1500 | num_updates 259722 | best_loss 3.189
2023-03-02 16:26:12 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 16:26:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint131.pt (epoch 131 @ 259722 updates, score 3.222) (writing took 5.406115099904127 seconds)
2023-03-02 16:26:17 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2023-03-02 16:26:17 | INFO | train | epoch 131 | loss 3.146 | nll_loss 1.001 | word_ins 2.826 | length 3.203 | ppl 8.85 | wps 201200 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 259722 | lr 0.000196221 | gnorm 0.863 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 16:26:17 | INFO | fairseq.trainer | begin training epoch 132
2023-03-02 16:26:50 | INFO | train_inner | epoch 132:     78 / 1983 loss=3.15, nll_loss=1.004, word_ins=2.829, length=3.206, ppl=8.87, wps=107192, ups=1.76, wpb=60926.3, bsz=1958.9, num_updates=259800, lr=0.000196192, gnorm=0.883, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:27:19 | INFO | train_inner | epoch 132:    178 / 1983 loss=3.131, nll_loss=0.986, word_ins=2.812, length=3.186, ppl=8.76, wps=211791, ups=3.42, wpb=61930.6, bsz=2029.5, num_updates=259900, lr=0.000196154, gnorm=0.894, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:27:48 | INFO | train_inner | epoch 132:    278 / 1983 loss=3.147, nll_loss=1.003, word_ins=2.828, length=3.192, ppl=8.86, wps=210971, ups=3.44, wpb=61328.8, bsz=1965.5, num_updates=260000, lr=0.000196116, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:28:17 | INFO | train_inner | epoch 132:    378 / 1983 loss=3.141, nll_loss=0.993, word_ins=2.819, length=3.222, ppl=8.82, wps=210584, ups=3.43, wpb=61327.4, bsz=1982.9, num_updates=260100, lr=0.000196078, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:28:46 | INFO | train_inner | epoch 132:    478 / 1983 loss=3.108, nll_loss=0.971, word_ins=2.798, length=3.101, ppl=8.62, wps=211683, ups=3.42, wpb=61978, bsz=2103.8, num_updates=260200, lr=0.000196041, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:29:16 | INFO | train_inner | epoch 132:    578 / 1983 loss=3.142, nll_loss=1.001, word_ins=2.826, length=3.162, ppl=8.83, wps=210215, ups=3.42, wpb=61522.4, bsz=2052.5, num_updates=260300, lr=0.000196003, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:29:45 | INFO | train_inner | epoch 132:    678 / 1983 loss=3.15, nll_loss=1.007, word_ins=2.832, length=3.184, ppl=8.88, wps=211558, ups=3.42, wpb=61875.8, bsz=1971.4, num_updates=260400, lr=0.000195965, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:30:14 | INFO | train_inner | epoch 132:    778 / 1983 loss=3.142, nll_loss=0.996, word_ins=2.821, length=3.206, ppl=8.83, wps=209872, ups=3.42, wpb=61437.2, bsz=2060.6, num_updates=260500, lr=0.000195928, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:30:43 | INFO | train_inner | epoch 132:    878 / 1983 loss=3.144, nll_loss=0.997, word_ins=2.822, length=3.214, ppl=8.84, wps=210555, ups=3.42, wpb=61516.2, bsz=1987.3, num_updates=260600, lr=0.00019589, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:31:12 | INFO | train_inner | epoch 132:    978 / 1983 loss=3.146, nll_loss=0.999, word_ins=2.825, length=3.217, ppl=8.85, wps=213725, ups=3.44, wpb=62087.3, bsz=1963.4, num_updates=260700, lr=0.000195853, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:31:41 | INFO | train_inner | epoch 132:   1078 / 1983 loss=3.152, nll_loss=1.004, word_ins=2.829, length=3.237, ppl=8.89, wps=210807, ups=3.44, wpb=61298.8, bsz=1984.5, num_updates=260800, lr=0.000195815, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:32:11 | INFO | train_inner | epoch 132:   1178 / 1983 loss=3.166, nll_loss=1.016, word_ins=2.84, length=3.256, ppl=8.97, wps=211972, ups=3.43, wpb=61875.6, bsz=1923.5, num_updates=260900, lr=0.000195778, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:32:40 | INFO | train_inner | epoch 132:   1278 / 1983 loss=3.121, nll_loss=0.982, word_ins=2.808, length=3.126, ppl=8.7, wps=209862, ups=3.4, wpb=61689.8, bsz=2129.5, num_updates=261000, lr=0.00019574, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:33:09 | INFO | train_inner | epoch 132:   1378 / 1983 loss=3.16, nll_loss=1.014, word_ins=2.838, length=3.223, ppl=8.94, wps=213793, ups=3.43, wpb=62266, bsz=1921.1, num_updates=261100, lr=0.000195703, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:33:38 | INFO | train_inner | epoch 132:   1478 / 1983 loss=3.17, nll_loss=1.02, word_ins=2.843, length=3.267, ppl=9, wps=212937, ups=3.45, wpb=61686.8, bsz=1889, num_updates=261200, lr=0.000195665, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:34:07 | INFO | train_inner | epoch 132:   1578 / 1983 loss=3.13, nll_loss=0.987, word_ins=2.813, length=3.177, ppl=8.76, wps=211030, ups=3.44, wpb=61356.5, bsz=2018.9, num_updates=261300, lr=0.000195628, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:34:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 16:34:37 | INFO | train_inner | epoch 132:   1679 / 1983 loss=3.126, nll_loss=0.984, word_ins=2.81, length=3.158, ppl=8.73, wps=209868, ups=3.39, wpb=61823.8, bsz=2055.8, num_updates=261400, lr=0.00019559, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:35:06 | INFO | train_inner | epoch 132:   1779 / 1983 loss=3.19, nll_loss=1.038, word_ins=2.86, length=3.296, ppl=9.12, wps=210145, ups=3.44, wpb=61121.8, bsz=1862.2, num_updates=261500, lr=0.000195553, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:35:35 | INFO | train_inner | epoch 132:   1879 / 1983 loss=3.128, nll_loss=0.982, word_ins=2.809, length=3.188, ppl=8.74, wps=210162, ups=3.41, wpb=61613.6, bsz=2056.4, num_updates=261600, lr=0.000195515, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:36:04 | INFO | train_inner | epoch 132:   1979 / 1983 loss=3.149, nll_loss=1.005, word_ins=2.83, length=3.19, ppl=8.87, wps=212311, ups=3.43, wpb=61972.9, bsz=2038.1, num_updates=261700, lr=0.000195478, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:36:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 16:36:18 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 3.218 | nll_loss 1.009 | word_ins 2.891 | length 3.27 | ppl 9.31 | wps 84292.4 | wpb 41551 | bsz 1500 | num_updates 261704 | best_loss 3.189
2023-03-02 16:36:18 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 16:36:24 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint132.pt (epoch 132 @ 261704 updates, score 3.218) (writing took 5.397854859009385 seconds)
2023-03-02 16:36:24 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2023-03-02 16:36:24 | INFO | train | epoch 132 | loss 3.145 | nll_loss 0.999 | word_ins 2.825 | length 3.2 | ppl 8.84 | wps 201273 | ups 3.27 | wpb 61628.5 | bsz 1997.9 | num_updates 261704 | lr 0.000195477 | gnorm 0.864 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 16:36:24 | INFO | fairseq.trainer | begin training epoch 133
2023-03-02 16:37:02 | INFO | train_inner | epoch 133:     96 / 1983 loss=3.14, nll_loss=0.99, word_ins=2.817, length=3.232, ppl=8.82, wps=105113, ups=1.73, wpb=60778.8, bsz=1958.9, num_updates=261800, lr=0.000195441, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:37:31 | INFO | train_inner | epoch 133:    196 / 1983 loss=3.133, nll_loss=0.992, word_ins=2.817, length=3.151, ppl=8.77, wps=210729, ups=3.4, wpb=61928.9, bsz=2031.4, num_updates=261900, lr=0.000195403, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:38:01 | INFO | train_inner | epoch 133:    296 / 1983 loss=3.129, nll_loss=0.986, word_ins=2.813, length=3.161, ppl=8.75, wps=211023, ups=3.41, wpb=61827.3, bsz=2030.6, num_updates=262000, lr=0.000195366, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:38:30 | INFO | train_inner | epoch 133:    396 / 1983 loss=3.154, nll_loss=1.008, word_ins=2.833, length=3.21, ppl=8.9, wps=212319, ups=3.44, wpb=61746.4, bsz=1922.4, num_updates=262100, lr=0.000195329, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:38:59 | INFO | train_inner | epoch 133:    496 / 1983 loss=3.126, nll_loss=0.982, word_ins=2.808, length=3.173, ppl=8.73, wps=210024, ups=3.41, wpb=61507.8, bsz=2088.6, num_updates=262200, lr=0.000195292, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:39:29 | INFO | train_inner | epoch 133:    596 / 1983 loss=3.14, nll_loss=0.994, word_ins=2.82, length=3.193, ppl=8.81, wps=209894, ups=3.41, wpb=61570.7, bsz=2065.5, num_updates=262300, lr=0.000195254, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:39:58 | INFO | train_inner | epoch 133:    696 / 1983 loss=3.132, nll_loss=0.99, word_ins=2.815, length=3.169, ppl=8.77, wps=212086, ups=3.44, wpb=61736.1, bsz=2041.6, num_updates=262400, lr=0.000195217, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:40:27 | INFO | train_inner | epoch 133:    796 / 1983 loss=3.146, nll_loss=1.001, word_ins=2.826, length=3.196, ppl=8.85, wps=211580, ups=3.42, wpb=61788.4, bsz=1998.3, num_updates=262500, lr=0.00019518, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:40:56 | INFO | train_inner | epoch 133:    896 / 1983 loss=3.141, nll_loss=0.998, word_ins=2.823, length=3.181, ppl=8.82, wps=211386, ups=3.43, wpb=61679.3, bsz=1971.1, num_updates=262600, lr=0.000195143, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:41:25 | INFO | train_inner | epoch 133:    996 / 1983 loss=3.131, nll_loss=0.992, word_ins=2.817, length=3.14, ppl=8.76, wps=212012, ups=3.42, wpb=61951.5, bsz=1995.8, num_updates=262700, lr=0.000195106, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:41:54 | INFO | train_inner | epoch 133:   1096 / 1983 loss=3.164, nll_loss=1.016, word_ins=2.84, length=3.245, ppl=8.96, wps=213649, ups=3.45, wpb=61881.7, bsz=1878.5, num_updates=262800, lr=0.000195069, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:42:23 | INFO | train_inner | epoch 133:   1196 / 1983 loss=3.145, nll_loss=0.997, word_ins=2.822, length=3.232, ppl=8.85, wps=210546, ups=3.43, wpb=61363.2, bsz=1966.3, num_updates=262900, lr=0.000195031, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:42:52 | INFO | train_inner | epoch 133:   1296 / 1983 loss=3.146, nll_loss=1.003, word_ins=2.828, length=3.18, ppl=8.85, wps=211567, ups=3.43, wpb=61658.8, bsz=2033.8, num_updates=263000, lr=0.000194994, gnorm=0.902, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:43:22 | INFO | train_inner | epoch 133:   1396 / 1983 loss=3.154, nll_loss=1.01, word_ins=2.834, length=3.2, ppl=8.9, wps=210964, ups=3.42, wpb=61618.4, bsz=2035.5, num_updates=263100, lr=0.000194957, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:43:51 | INFO | train_inner | epoch 133:   1496 / 1983 loss=3.153, nll_loss=1.006, word_ins=2.83, length=3.234, ppl=8.9, wps=211578, ups=3.43, wpb=61724.4, bsz=1967, num_updates=263200, lr=0.00019492, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:44:20 | INFO | train_inner | epoch 133:   1596 / 1983 loss=3.145, nll_loss=0.997, word_ins=2.822, length=3.226, ppl=8.85, wps=210562, ups=3.43, wpb=61348.7, bsz=1996, num_updates=263300, lr=0.000194883, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:44:49 | INFO | train_inner | epoch 133:   1696 / 1983 loss=3.136, nll_loss=0.989, word_ins=2.815, length=3.215, ppl=8.79, wps=209955, ups=3.41, wpb=61538.5, bsz=2047.3, num_updates=263400, lr=0.000194846, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:45:19 | INFO | train_inner | epoch 133:   1796 / 1983 loss=3.142, nll_loss=0.997, word_ins=2.822, length=3.203, ppl=8.83, wps=210816, ups=3.42, wpb=61648.8, bsz=2010.6, num_updates=263500, lr=0.000194809, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:45:48 | INFO | train_inner | epoch 133:   1896 / 1983 loss=3.139, nll_loss=0.994, word_ins=2.819, length=3.197, ppl=8.81, wps=212388, ups=3.44, wpb=61694.9, bsz=1968.3, num_updates=263600, lr=0.000194772, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 16:46:26 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 3.208 | nll_loss 0.994 | word_ins 2.88 | length 3.284 | ppl 9.24 | wps 121567 | wpb 41551 | bsz 1500 | num_updates 263687 | best_loss 3.189
2023-03-02 16:46:26 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 16:46:32 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint133.pt (epoch 133 @ 263687 updates, score 3.208) (writing took 5.5129696489311755 seconds)
2023-03-02 16:46:32 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2023-03-02 16:46:32 | INFO | train | epoch 133 | loss 3.143 | nll_loss 0.998 | word_ins 2.823 | length 3.198 | ppl 8.83 | wps 201011 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 263687 | lr 0.00019474 | gnorm 0.865 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 16:46:32 | INFO | fairseq.trainer | begin training epoch 134
2023-03-02 16:46:46 | INFO | train_inner | epoch 134:     13 / 1983 loss=3.162, nll_loss=1.014, word_ins=2.838, length=3.233, ppl=8.95, wps=105246, ups=1.72, wpb=61137, bsz=1899.3, num_updates=263700, lr=0.000194735, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:47:15 | INFO | train_inner | epoch 134:    113 / 1983 loss=3.118, nll_loss=0.979, word_ins=2.806, length=3.116, ppl=8.68, wps=208803, ups=3.4, wpb=61425.6, bsz=2115.2, num_updates=263800, lr=0.000194698, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:47:44 | INFO | train_inner | epoch 134:    213 / 1983 loss=3.136, nll_loss=0.991, word_ins=2.817, length=3.192, ppl=8.79, wps=211455, ups=3.41, wpb=62052.5, bsz=1999.5, num_updates=263900, lr=0.000194662, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:48:14 | INFO | train_inner | epoch 134:    313 / 1983 loss=3.123, nll_loss=0.979, word_ins=2.807, length=3.165, ppl=8.71, wps=209533, ups=3.42, wpb=61257, bsz=2041.2, num_updates=264000, lr=0.000194625, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:48:43 | INFO | train_inner | epoch 134:    413 / 1983 loss=3.149, nll_loss=1.003, word_ins=2.828, length=3.212, ppl=8.87, wps=211616, ups=3.43, wpb=61665.7, bsz=1972.6, num_updates=264100, lr=0.000194588, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:49:12 | INFO | train_inner | epoch 134:    513 / 1983 loss=3.119, nll_loss=0.98, word_ins=2.808, length=3.111, ppl=8.69, wps=210228, ups=3.41, wpb=61700.6, bsz=2067, num_updates=264200, lr=0.000194551, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:49:42 | INFO | train_inner | epoch 134:    613 / 1983 loss=3.138, nll_loss=0.994, word_ins=2.819, length=3.187, ppl=8.8, wps=210119, ups=3.4, wpb=61855.8, bsz=2065, num_updates=264300, lr=0.000194514, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:50:11 | INFO | train_inner | epoch 134:    713 / 1983 loss=3.143, nll_loss=0.998, word_ins=2.823, length=3.195, ppl=8.83, wps=212523, ups=3.42, wpb=62112.2, bsz=1964.1, num_updates=264400, lr=0.000194477, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:50:40 | INFO | train_inner | epoch 134:    813 / 1983 loss=3.154, nll_loss=1.001, word_ins=2.827, length=3.271, ppl=8.9, wps=211656, ups=3.44, wpb=61548.7, bsz=1922.1, num_updates=264500, lr=0.000194441, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:51:09 | INFO | train_inner | epoch 134:    913 / 1983 loss=3.14, nll_loss=0.994, word_ins=2.819, length=3.211, ppl=8.82, wps=211464, ups=3.44, wpb=61503.7, bsz=2018.7, num_updates=264600, lr=0.000194404, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:51:38 | INFO | train_inner | epoch 134:   1013 / 1983 loss=3.146, nll_loss=1.001, word_ins=2.826, length=3.195, ppl=8.85, wps=211548, ups=3.43, wpb=61664.4, bsz=2017.7, num_updates=264700, lr=0.000194367, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:52:08 | INFO | train_inner | epoch 134:   1113 / 1983 loss=3.124, nll_loss=0.981, word_ins=2.808, length=3.16, ppl=8.72, wps=210081, ups=3.41, wpb=61609.5, bsz=2090.7, num_updates=264800, lr=0.000194331, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:52:37 | INFO | train_inner | epoch 134:   1213 / 1983 loss=3.165, nll_loss=1.018, word_ins=2.841, length=3.232, ppl=8.97, wps=210672, ups=3.44, wpb=61321.5, bsz=1903.4, num_updates=264900, lr=0.000194294, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:53:06 | INFO | train_inner | epoch 134:   1313 / 1983 loss=3.15, nll_loss=1.002, word_ins=2.827, length=3.229, ppl=8.88, wps=210783, ups=3.41, wpb=61744, bsz=2037.4, num_updates=265000, lr=0.000194257, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:53:35 | INFO | train_inner | epoch 134:   1413 / 1983 loss=3.136, nll_loss=0.994, word_ins=2.819, length=3.168, ppl=8.79, wps=210134, ups=3.41, wpb=61556.4, bsz=2000.9, num_updates=265100, lr=0.000194221, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:54:04 | INFO | train_inner | epoch 134:   1513 / 1983 loss=3.192, nll_loss=1.039, word_ins=2.861, length=3.315, ppl=9.14, wps=211985, ups=3.44, wpb=61667.5, bsz=1814.7, num_updates=265200, lr=0.000194184, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:54:34 | INFO | train_inner | epoch 134:   1613 / 1983 loss=3.146, nll_loss=1.004, word_ins=2.829, length=3.175, ppl=8.85, wps=211331, ups=3.41, wpb=61947.1, bsz=1989.5, num_updates=265300, lr=0.000194147, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:55:03 | INFO | train_inner | epoch 134:   1713 / 1983 loss=3.133, nll_loss=0.989, word_ins=2.814, length=3.191, ppl=8.78, wps=211211, ups=3.41, wpb=61939.9, bsz=2021.1, num_updates=265400, lr=0.000194111, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:55:32 | INFO | train_inner | epoch 134:   1813 / 1983 loss=3.162, nll_loss=1.016, word_ins=2.839, length=3.229, ppl=8.95, wps=210209, ups=3.44, wpb=61155.2, bsz=1975.4, num_updates=265500, lr=0.000194074, gnorm=0.884, loss_scale=32768, train_wall=29, wall=0
2023-03-02 16:55:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 16:56:02 | INFO | train_inner | epoch 134:   1914 / 1983 loss=3.139, nll_loss=0.997, word_ins=2.822, length=3.175, ppl=8.81, wps=209039, ups=3.4, wpb=61533.3, bsz=2004, num_updates=265600, lr=0.000194038, gnorm=0.875, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:56:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 16:56:35 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 3.176 | nll_loss 0.976 | word_ins 2.858 | length 3.176 | ppl 9.04 | wps 81486.3 | wpb 41551 | bsz 1500 | num_updates 265669 | best_loss 3.176
2023-03-02 16:56:35 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 16:56:44 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint134.pt (epoch 134 @ 265669 updates, score 3.176) (writing took 8.526470151962712 seconds)
2023-03-02 16:56:44 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2023-03-02 16:56:44 | INFO | train | epoch 134 | loss 3.143 | nll_loss 0.998 | word_ins 2.823 | length 3.198 | ppl 8.83 | wps 199584 | ups 3.24 | wpb 61627.2 | bsz 1997.4 | num_updates 265669 | lr 0.000194012 | gnorm 0.861 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 16:56:44 | INFO | fairseq.trainer | begin training epoch 135
2023-03-02 16:57:02 | INFO | train_inner | epoch 135:     31 / 1983 loss=3.147, nll_loss=1, word_ins=2.825, length=3.223, ppl=8.86, wps=100536, ups=1.64, wpb=61176.6, bsz=1943.4, num_updates=265700, lr=0.000194001, gnorm=0.886, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:57:32 | INFO | train_inner | epoch 135:    131 / 1983 loss=3.165, nll_loss=1.017, word_ins=2.841, length=3.242, ppl=8.97, wps=208193, ups=3.41, wpb=61095.1, bsz=1950.2, num_updates=265800, lr=0.000193965, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:58:01 | INFO | train_inner | epoch 135:    231 / 1983 loss=3.105, nll_loss=0.969, word_ins=2.797, length=3.077, ppl=8.6, wps=209928, ups=3.4, wpb=61740.8, bsz=2119.7, num_updates=265900, lr=0.000193928, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:58:30 | INFO | train_inner | epoch 135:    331 / 1983 loss=3.135, nll_loss=0.987, word_ins=2.813, length=3.213, ppl=8.78, wps=211876, ups=3.43, wpb=61830.7, bsz=1981.1, num_updates=266000, lr=0.000193892, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:59:00 | INFO | train_inner | epoch 135:    431 / 1983 loss=3.133, nll_loss=0.993, word_ins=2.818, length=3.144, ppl=8.77, wps=211651, ups=3.42, wpb=61895.5, bsz=2021.8, num_updates=266100, lr=0.000193855, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:59:29 | INFO | train_inner | epoch 135:    531 / 1983 loss=3.144, nll_loss=0.996, word_ins=2.822, length=3.223, ppl=8.84, wps=211302, ups=3.42, wpb=61793.6, bsz=1952.5, num_updates=266200, lr=0.000193819, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 16:59:58 | INFO | train_inner | epoch 135:    631 / 1983 loss=3.179, nll_loss=1.024, word_ins=2.848, length=3.317, ppl=9.06, wps=208271, ups=3.42, wpb=60906.4, bsz=1917.6, num_updates=266300, lr=0.000193782, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:00:27 | INFO | train_inner | epoch 135:    731 / 1983 loss=3.146, nll_loss=1, word_ins=2.825, length=3.204, ppl=8.85, wps=212473, ups=3.43, wpb=61989.7, bsz=1923.1, num_updates=266400, lr=0.000193746, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:00:56 | INFO | train_inner | epoch 135:    831 / 1983 loss=3.138, nll_loss=0.993, word_ins=2.819, length=3.191, ppl=8.8, wps=211623, ups=3.43, wpb=61613.3, bsz=2022.6, num_updates=266500, lr=0.00019371, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:01:26 | INFO | train_inner | epoch 135:    931 / 1983 loss=3.145, nll_loss=0.997, word_ins=2.822, length=3.227, ppl=8.85, wps=211840, ups=3.43, wpb=61755, bsz=1962.7, num_updates=266600, lr=0.000193673, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:01:55 | INFO | train_inner | epoch 135:   1031 / 1983 loss=3.122, nll_loss=0.981, word_ins=2.807, length=3.153, ppl=8.71, wps=210739, ups=3.41, wpb=61749.7, bsz=2069.8, num_updates=266700, lr=0.000193637, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:02:24 | INFO | train_inner | epoch 135:   1131 / 1983 loss=3.157, nll_loss=1.01, word_ins=2.834, length=3.23, ppl=8.92, wps=209846, ups=3.44, wpb=61042.7, bsz=1950.8, num_updates=266800, lr=0.000193601, gnorm=0.888, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:02:53 | INFO | train_inner | epoch 135:   1231 / 1983 loss=3.135, nll_loss=0.992, word_ins=2.818, length=3.167, ppl=8.78, wps=212878, ups=3.43, wpb=62034.8, bsz=2011.1, num_updates=266900, lr=0.000193565, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:03:22 | INFO | train_inner | epoch 135:   1331 / 1983 loss=3.155, nll_loss=1.005, word_ins=2.83, length=3.25, ppl=8.91, wps=212183, ups=3.44, wpb=61643.4, bsz=1921.4, num_updates=267000, lr=0.000193528, gnorm=0.882, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:03:51 | INFO | train_inner | epoch 135:   1431 / 1983 loss=3.138, nll_loss=0.995, word_ins=2.82, length=3.178, ppl=8.8, wps=209992, ups=3.41, wpb=61569.9, bsz=2090.6, num_updates=267100, lr=0.000193492, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:04:21 | INFO | train_inner | epoch 135:   1531 / 1983 loss=3.124, nll_loss=0.978, word_ins=2.805, length=3.194, ppl=8.72, wps=210460, ups=3.42, wpb=61508.5, bsz=2039.4, num_updates=267200, lr=0.000193456, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:04:50 | INFO | train_inner | epoch 135:   1631 / 1983 loss=3.143, nll_loss=1.002, word_ins=2.827, length=3.162, ppl=8.84, wps=211651, ups=3.43, wpb=61770.6, bsz=1986.2, num_updates=267300, lr=0.00019342, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:05:19 | INFO | train_inner | epoch 135:   1731 / 1983 loss=3.133, nll_loss=0.991, word_ins=2.817, length=3.167, ppl=8.77, wps=209773, ups=3.42, wpb=61410.9, bsz=2071.8, num_updates=267400, lr=0.000193383, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:05:48 | INFO | train_inner | epoch 135:   1831 / 1983 loss=3.127, nll_loss=0.983, word_ins=2.809, length=3.184, ppl=8.74, wps=212193, ups=3.43, wpb=61912, bsz=2002.1, num_updates=267500, lr=0.000193347, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:06:18 | INFO | train_inner | epoch 135:   1931 / 1983 loss=3.143, nll_loss=0.999, word_ins=2.824, length=3.191, ppl=8.83, wps=211396, ups=3.42, wpb=61884.6, bsz=2045.9, num_updates=267600, lr=0.000193311, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 17:06:44 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 3.208 | nll_loss 0.988 | word_ins 2.874 | length 3.348 | ppl 9.24 | wps 116818 | wpb 41551 | bsz 1500 | num_updates 267652 | best_loss 3.176
2023-03-02 17:06:44 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 17:06:50 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint135.pt (epoch 135 @ 267652 updates, score 3.208) (writing took 5.350258813006803 seconds)
2023-03-02 17:06:50 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2023-03-02 17:06:50 | INFO | train | epoch 135 | loss 3.141 | nll_loss 0.996 | word_ins 2.822 | length 3.195 | ppl 8.82 | wps 201689 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 267652 | lr 0.000193292 | gnorm 0.862 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 17:06:50 | INFO | fairseq.trainer | begin training epoch 136
2023-03-02 17:07:14 | INFO | train_inner | epoch 136:     48 / 1983 loss=3.156, nll_loss=1.017, word_ins=2.841, length=3.148, ppl=8.91, wps=109371, ups=1.78, wpb=61479.2, bsz=1933.9, num_updates=267700, lr=0.000193275, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:07:43 | INFO | train_inner | epoch 136:    148 / 1983 loss=3.145, nll_loss=0.995, word_ins=2.821, length=3.235, ppl=8.84, wps=209696, ups=3.41, wpb=61443.4, bsz=1947.1, num_updates=267800, lr=0.000193239, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:08:12 | INFO | train_inner | epoch 136:    248 / 1983 loss=3.118, nll_loss=0.973, word_ins=2.801, length=3.173, ppl=8.68, wps=209572, ups=3.43, wpb=61067.2, bsz=1990.3, num_updates=267900, lr=0.000193203, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:08:42 | INFO | train_inner | epoch 136:    348 / 1983 loss=3.142, nll_loss=0.997, word_ins=2.823, length=3.197, ppl=8.83, wps=210858, ups=3.42, wpb=61624.3, bsz=1954.2, num_updates=268000, lr=0.000193167, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:09:11 | INFO | train_inner | epoch 136:    448 / 1983 loss=3.131, nll_loss=0.985, word_ins=2.811, length=3.198, ppl=8.76, wps=210892, ups=3.43, wpb=61472.3, bsz=2049.4, num_updates=268100, lr=0.000193131, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:09:40 | INFO | train_inner | epoch 136:    548 / 1983 loss=3.145, nll_loss=1, word_ins=2.825, length=3.196, ppl=8.85, wps=211312, ups=3.42, wpb=61702.8, bsz=1952.4, num_updates=268200, lr=0.000193095, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:10:09 | INFO | train_inner | epoch 136:    648 / 1983 loss=3.16, nll_loss=1.011, word_ins=2.835, length=3.244, ppl=8.94, wps=210198, ups=3.43, wpb=61356.6, bsz=1947, num_updates=268300, lr=0.000193059, gnorm=0.884, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:10:38 | INFO | train_inner | epoch 136:    748 / 1983 loss=3.155, nll_loss=1.008, word_ins=2.832, length=3.226, ppl=8.91, wps=211668, ups=3.43, wpb=61655, bsz=1971.3, num_updates=268400, lr=0.000193023, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:11:07 | INFO | train_inner | epoch 136:    848 / 1983 loss=3.119, nll_loss=0.977, word_ins=2.804, length=3.157, ppl=8.69, wps=211399, ups=3.43, wpb=61694.4, bsz=2116.6, num_updates=268500, lr=0.000192987, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:11:37 | INFO | train_inner | epoch 136:    948 / 1983 loss=3.138, nll_loss=0.993, word_ins=2.819, length=3.192, ppl=8.8, wps=210022, ups=3.42, wpb=61471.3, bsz=2017.7, num_updates=268600, lr=0.000192951, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:12:06 | INFO | train_inner | epoch 136:   1048 / 1983 loss=3.156, nll_loss=1.009, word_ins=2.833, length=3.222, ppl=8.91, wps=210733, ups=3.42, wpb=61691.6, bsz=1934.9, num_updates=268700, lr=0.000192915, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:12:35 | INFO | train_inner | epoch 136:   1148 / 1983 loss=3.128, nll_loss=0.988, word_ins=2.814, length=3.144, ppl=8.75, wps=214037, ups=3.43, wpb=62318.5, bsz=2005.6, num_updates=268800, lr=0.000192879, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:13:04 | INFO | train_inner | epoch 136:   1248 / 1983 loss=3.174, nll_loss=1.025, word_ins=2.847, length=3.27, ppl=9.03, wps=211482, ups=3.42, wpb=61767.2, bsz=1889.8, num_updates=268900, lr=0.000192843, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:13:34 | INFO | train_inner | epoch 136:   1348 / 1983 loss=3.141, nll_loss=0.996, word_ins=2.821, length=3.196, ppl=8.82, wps=211837, ups=3.42, wpb=61949.7, bsz=2004.2, num_updates=269000, lr=0.000192807, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:14:03 | INFO | train_inner | epoch 136:   1448 / 1983 loss=3.136, nll_loss=0.994, word_ins=2.819, length=3.165, ppl=8.79, wps=211440, ups=3.42, wpb=61734.7, bsz=2042.2, num_updates=269100, lr=0.000192772, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:14:32 | INFO | train_inner | epoch 136:   1548 / 1983 loss=3.131, nll_loss=0.989, word_ins=2.815, length=3.162, ppl=8.76, wps=211868, ups=3.44, wpb=61617.5, bsz=1990.2, num_updates=269200, lr=0.000192736, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:15:01 | INFO | train_inner | epoch 136:   1648 / 1983 loss=3.166, nll_loss=1.016, word_ins=2.84, length=3.259, ppl=8.97, wps=210833, ups=3.41, wpb=61781.9, bsz=1973.7, num_updates=269300, lr=0.0001927, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:15:30 | INFO | train_inner | epoch 136:   1748 / 1983 loss=3.122, nll_loss=0.976, word_ins=2.803, length=3.194, ppl=8.71, wps=211853, ups=3.44, wpb=61673.9, bsz=2132.7, num_updates=269400, lr=0.000192664, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:15:59 | INFO | train_inner | epoch 136:   1848 / 1983 loss=3.116, nll_loss=0.977, word_ins=2.804, length=3.125, ppl=8.67, wps=211540, ups=3.43, wpb=61610.5, bsz=2072.1, num_updates=269500, lr=0.000192629, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:16:29 | INFO | train_inner | epoch 136:   1948 / 1983 loss=3.141, nll_loss=0.999, word_ins=2.824, length=3.175, ppl=8.82, wps=211278, ups=3.42, wpb=61757.7, bsz=2006.2, num_updates=269600, lr=0.000192593, gnorm=0.856, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:16:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 17:16:52 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 3.18 | nll_loss 0.979 | word_ins 2.862 | length 3.183 | ppl 9.07 | wps 104702 | wpb 41551 | bsz 1500 | num_updates 269635 | best_loss 3.176
2023-03-02 17:16:52 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 17:16:58 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint136.pt (epoch 136 @ 269635 updates, score 3.18) (writing took 5.1538568049436435 seconds)
2023-03-02 17:16:58 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2023-03-02 17:16:58 | INFO | train | epoch 136 | loss 3.141 | nll_loss 0.996 | word_ins 2.821 | length 3.196 | ppl 8.82 | wps 201042 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 269635 | lr 0.00019258 | gnorm 0.859 | loss_scale 32768 | train_wall 576 | wall 0
2023-03-02 17:16:58 | INFO | fairseq.trainer | begin training epoch 137
2023-03-02 17:17:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 17:17:27 | INFO | train_inner | epoch 137:     66 / 1983 loss=3.153, nll_loss=1.007, word_ins=2.831, length=3.215, ppl=8.89, wps=105116, ups=1.72, wpb=61160.5, bsz=1927.3, num_updates=269700, lr=0.000192557, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:17:56 | INFO | train_inner | epoch 137:    166 / 1983 loss=3.149, nll_loss=1.007, word_ins=2.831, length=3.183, ppl=8.87, wps=208560, ups=3.41, wpb=61239.7, bsz=2010, num_updates=269800, lr=0.000192521, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:18:25 | INFO | train_inner | epoch 137:    266 / 1983 loss=3.142, nll_loss=0.994, word_ins=2.82, length=3.219, ppl=8.83, wps=212265, ups=3.44, wpb=61702.5, bsz=1929, num_updates=269900, lr=0.000192486, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:18:54 | INFO | train_inner | epoch 137:    366 / 1983 loss=3.1, nll_loss=0.959, word_ins=2.788, length=3.128, ppl=8.58, wps=212408, ups=3.43, wpb=62003.6, bsz=2101.9, num_updates=270000, lr=0.00019245, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:19:24 | INFO | train_inner | epoch 137:    466 / 1983 loss=3.126, nll_loss=0.982, word_ins=2.809, length=3.167, ppl=8.73, wps=212000, ups=3.43, wpb=61844.8, bsz=2009.5, num_updates=270100, lr=0.000192414, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:19:53 | INFO | train_inner | epoch 137:    566 / 1983 loss=3.132, nll_loss=0.989, word_ins=2.816, length=3.168, ppl=8.77, wps=211065, ups=3.43, wpb=61495.3, bsz=1981, num_updates=270200, lr=0.000192379, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:20:22 | INFO | train_inner | epoch 137:    666 / 1983 loss=3.143, nll_loss=0.999, word_ins=2.824, length=3.191, ppl=8.83, wps=209277, ups=3.42, wpb=61188.7, bsz=2014.6, num_updates=270300, lr=0.000192343, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:20:51 | INFO | train_inner | epoch 137:    766 / 1983 loss=3.13, nll_loss=0.983, word_ins=2.81, length=3.199, ppl=8.76, wps=212497, ups=3.44, wpb=61690.8, bsz=1972.6, num_updates=270400, lr=0.000192308, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:21:20 | INFO | train_inner | epoch 137:    866 / 1983 loss=3.137, nll_loss=0.994, word_ins=2.819, length=3.177, ppl=8.8, wps=209921, ups=3.42, wpb=61422.4, bsz=2028.7, num_updates=270500, lr=0.000192272, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:21:50 | INFO | train_inner | epoch 137:    966 / 1983 loss=3.137, nll_loss=0.996, word_ins=2.821, length=3.161, ppl=8.8, wps=209424, ups=3.39, wpb=61820, bsz=2083.5, num_updates=270600, lr=0.000192237, gnorm=0.88, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:22:19 | INFO | train_inner | epoch 137:   1066 / 1983 loss=3.143, nll_loss=0.996, word_ins=2.822, length=3.217, ppl=8.84, wps=211133, ups=3.41, wpb=61831.7, bsz=1959.5, num_updates=270700, lr=0.000192201, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:22:48 | INFO | train_inner | epoch 137:   1166 / 1983 loss=3.153, nll_loss=1.006, word_ins=2.831, length=3.226, ppl=8.9, wps=212191, ups=3.44, wpb=61603.8, bsz=1956.1, num_updates=270800, lr=0.000192166, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:23:17 | INFO | train_inner | epoch 137:   1266 / 1983 loss=3.133, nll_loss=0.99, word_ins=2.816, length=3.168, ppl=8.77, wps=212477, ups=3.43, wpb=61971.1, bsz=1978.8, num_updates=270900, lr=0.00019213, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:23:46 | INFO | train_inner | epoch 137:   1366 / 1983 loss=3.161, nll_loss=1.014, word_ins=2.838, length=3.238, ppl=8.95, wps=210021, ups=3.42, wpb=61358.3, bsz=1983.9, num_updates=271000, lr=0.000192095, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:24:16 | INFO | train_inner | epoch 137:   1466 / 1983 loss=3.129, nll_loss=0.986, word_ins=2.812, length=3.171, ppl=8.75, wps=209744, ups=3.42, wpb=61403.3, bsz=2026.4, num_updates=271100, lr=0.000192059, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:24:45 | INFO | train_inner | epoch 137:   1566 / 1983 loss=3.133, nll_loss=0.992, word_ins=2.817, length=3.164, ppl=8.77, wps=212733, ups=3.43, wpb=62070.9, bsz=2009.3, num_updates=271200, lr=0.000192024, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:25:14 | INFO | train_inner | epoch 137:   1666 / 1983 loss=3.124, nll_loss=0.981, word_ins=2.808, length=3.166, ppl=8.72, wps=211076, ups=3.43, wpb=61578.5, bsz=2051.1, num_updates=271300, lr=0.000191988, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:25:43 | INFO | train_inner | epoch 137:   1766 / 1983 loss=3.142, nll_loss=0.995, word_ins=2.821, length=3.214, ppl=8.83, wps=210990, ups=3.42, wpb=61692, bsz=2010.9, num_updates=271400, lr=0.000191953, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:26:12 | INFO | train_inner | epoch 137:   1866 / 1983 loss=3.151, nll_loss=1.006, word_ins=2.83, length=3.211, ppl=8.88, wps=211599, ups=3.44, wpb=61500, bsz=1923.4, num_updates=271500, lr=0.000191918, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:26:42 | INFO | train_inner | epoch 137:   1966 / 1983 loss=3.15, nll_loss=1.003, word_ins=2.828, length=3.225, ppl=8.88, wps=212663, ups=3.44, wpb=61838, bsz=1945.5, num_updates=271600, lr=0.000191882, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 17:26:59 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 3.188 | nll_loss 0.978 | word_ins 2.862 | length 3.258 | ppl 9.11 | wps 91092.7 | wpb 41551 | bsz 1500 | num_updates 271617 | best_loss 3.176
2023-03-02 17:26:59 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 17:27:04 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint137.pt (epoch 137 @ 271617 updates, score 3.188) (writing took 5.274392636027187 seconds)
2023-03-02 17:27:04 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2023-03-02 17:27:04 | INFO | train | epoch 137 | loss 3.138 | nll_loss 0.993 | word_ins 2.819 | length 3.188 | ppl 8.8 | wps 201312 | ups 3.27 | wpb 61627.5 | bsz 1997.5 | num_updates 271617 | lr 0.000191876 | gnorm 0.856 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 17:27:04 | INFO | fairseq.trainer | begin training epoch 138
2023-03-02 17:27:38 | INFO | train_inner | epoch 138:     83 / 1983 loss=3.116, nll_loss=0.976, word_ins=2.804, length=3.118, ppl=8.67, wps=108520, ups=1.76, wpb=61590.6, bsz=2008.6, num_updates=271700, lr=0.000191847, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:28:08 | INFO | train_inner | epoch 138:    183 / 1983 loss=3.104, nll_loss=0.962, word_ins=2.79, length=3.133, ppl=8.6, wps=211730, ups=3.41, wpb=62061.3, bsz=2046.6, num_updates=271800, lr=0.000191812, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:28:37 | INFO | train_inner | epoch 138:    283 / 1983 loss=3.149, nll_loss=1.004, word_ins=2.829, length=3.202, ppl=8.87, wps=210105, ups=3.44, wpb=61089.8, bsz=1941, num_updates=271900, lr=0.000191777, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:29:06 | INFO | train_inner | epoch 138:    383 / 1983 loss=3.137, nll_loss=0.994, word_ins=2.819, length=3.176, ppl=8.8, wps=211161, ups=3.43, wpb=61568.9, bsz=2010.2, num_updates=272000, lr=0.000191741, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:29:35 | INFO | train_inner | epoch 138:    483 / 1983 loss=3.134, nll_loss=0.988, word_ins=2.814, length=3.196, ppl=8.78, wps=211799, ups=3.43, wpb=61659.9, bsz=1995.4, num_updates=272100, lr=0.000191706, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:30:04 | INFO | train_inner | epoch 138:    583 / 1983 loss=3.13, nll_loss=0.985, word_ins=2.812, length=3.181, ppl=8.75, wps=214375, ups=3.45, wpb=62207.7, bsz=1974.1, num_updates=272200, lr=0.000191671, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:30:33 | INFO | train_inner | epoch 138:    683 / 1983 loss=3.145, nll_loss=0.997, word_ins=2.822, length=3.228, ppl=8.85, wps=211414, ups=3.45, wpb=61358.9, bsz=1928.5, num_updates=272300, lr=0.000191636, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:31:02 | INFO | train_inner | epoch 138:    783 / 1983 loss=3.134, nll_loss=0.991, word_ins=2.817, length=3.172, ppl=8.78, wps=211624, ups=3.43, wpb=61632.6, bsz=1970.4, num_updates=272400, lr=0.0001916, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:31:31 | INFO | train_inner | epoch 138:    883 / 1983 loss=3.127, nll_loss=0.982, word_ins=2.809, length=3.174, ppl=8.74, wps=210072, ups=3.41, wpb=61636.9, bsz=2039.6, num_updates=272500, lr=0.000191565, gnorm=0.881, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:32:01 | INFO | train_inner | epoch 138:    983 / 1983 loss=3.136, nll_loss=0.994, word_ins=2.819, length=3.175, ppl=8.79, wps=210858, ups=3.42, wpb=61573.7, bsz=2072.5, num_updates=272600, lr=0.00019153, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:32:30 | INFO | train_inner | epoch 138:   1083 / 1983 loss=3.155, nll_loss=1.008, word_ins=2.832, length=3.229, ppl=8.91, wps=210154, ups=3.43, wpb=61209.2, bsz=1970.2, num_updates=272700, lr=0.000191495, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:32:59 | INFO | train_inner | epoch 138:   1183 / 1983 loss=3.155, nll_loss=1.009, word_ins=2.833, length=3.219, ppl=8.91, wps=212625, ups=3.42, wpb=62084, bsz=1924.1, num_updates=272800, lr=0.00019146, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:33:28 | INFO | train_inner | epoch 138:   1283 / 1983 loss=3.161, nll_loss=1.016, word_ins=2.839, length=3.222, ppl=8.95, wps=210715, ups=3.41, wpb=61754.6, bsz=1971.8, num_updates=272900, lr=0.000191425, gnorm=0.91, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:33:58 | INFO | train_inner | epoch 138:   1383 / 1983 loss=3.107, nll_loss=0.972, word_ins=2.799, length=3.079, ppl=8.62, wps=213249, ups=3.42, wpb=62305.4, bsz=2075.2, num_updates=273000, lr=0.00019139, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:34:27 | INFO | train_inner | epoch 138:   1483 / 1983 loss=3.126, nll_loss=0.978, word_ins=2.805, length=3.212, ppl=8.73, wps=211404, ups=3.44, wpb=61440.9, bsz=2035.8, num_updates=273100, lr=0.000191355, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:34:56 | INFO | train_inner | epoch 138:   1583 / 1983 loss=3.147, nll_loss=1.004, word_ins=2.829, length=3.183, ppl=8.86, wps=210698, ups=3.42, wpb=61682.8, bsz=1962.4, num_updates=273200, lr=0.00019132, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:35:25 | INFO | train_inner | epoch 138:   1683 / 1983 loss=3.129, nll_loss=0.987, word_ins=2.813, length=3.159, ppl=8.75, wps=212245, ups=3.42, wpb=62015.9, bsz=2012.4, num_updates=273300, lr=0.000191285, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:35:54 | INFO | train_inner | epoch 138:   1783 / 1983 loss=3.168, nll_loss=1.021, word_ins=2.844, length=3.24, ppl=8.99, wps=208948, ups=3.43, wpb=60975, bsz=1969.1, num_updates=273400, lr=0.00019125, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:36:24 | INFO | train_inner | epoch 138:   1883 / 1983 loss=3.142, nll_loss=0.996, word_ins=2.822, length=3.204, ppl=8.83, wps=209745, ups=3.41, wpb=61419.8, bsz=2066.7, num_updates=273500, lr=0.000191215, gnorm=0.828, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:36:53 | INFO | train_inner | epoch 138:   1983 / 1983 loss=3.14, nll_loss=0.995, word_ins=2.82, length=3.204, ppl=8.82, wps=209136, ups=3.43, wpb=60949.4, bsz=1977.4, num_updates=273600, lr=0.00019118, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 17:37:06 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 3.21 | nll_loss 0.983 | word_ins 2.865 | length 3.451 | ppl 9.25 | wps 82654.1 | wpb 41551 | bsz 1500 | num_updates 273600 | best_loss 3.176
2023-03-02 17:37:06 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 17:37:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint138.pt (epoch 138 @ 273600 updates, score 3.21) (writing took 5.469738709973171 seconds)
2023-03-02 17:37:11 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2023-03-02 17:37:11 | INFO | train | epoch 138 | loss 3.137 | nll_loss 0.993 | word_ins 2.819 | length 3.186 | ppl 8.8 | wps 201488 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 273600 | lr 0.00019118 | gnorm 0.857 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 17:37:11 | INFO | fairseq.trainer | begin training epoch 139
2023-03-02 17:37:50 | INFO | train_inner | epoch 139:    100 / 1983 loss=3.123, nll_loss=0.986, word_ins=2.812, length=3.105, ppl=8.71, wps=108252, ups=1.74, wpb=62090.2, bsz=2021.7, num_updates=273700, lr=0.000191145, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:38:19 | INFO | train_inner | epoch 139:    200 / 1983 loss=3.145, nll_loss=1.001, word_ins=2.826, length=3.196, ppl=8.85, wps=210138, ups=3.41, wpb=61689.3, bsz=1991.4, num_updates=273800, lr=0.00019111, gnorm=0.898, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:38:49 | INFO | train_inner | epoch 139:    300 / 1983 loss=3.149, nll_loss=1, word_ins=2.825, length=3.233, ppl=8.87, wps=209253, ups=3.42, wpb=61201, bsz=1981, num_updates=273900, lr=0.000191075, gnorm=0.835, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:39:18 | INFO | train_inner | epoch 139:    400 / 1983 loss=3.141, nll_loss=0.996, word_ins=2.821, length=3.191, ppl=8.82, wps=211656, ups=3.42, wpb=61969.4, bsz=1992.3, num_updates=274000, lr=0.00019104, gnorm=0.841, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:39:47 | INFO | train_inner | epoch 139:    500 / 1983 loss=3.142, nll_loss=0.998, word_ins=2.823, length=3.189, ppl=8.83, wps=210864, ups=3.42, wpb=61586.9, bsz=1962.9, num_updates=274100, lr=0.000191005, gnorm=0.847, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:40:16 | INFO | train_inner | epoch 139:    600 / 1983 loss=3.123, nll_loss=0.98, word_ins=2.807, length=3.159, ppl=8.71, wps=211862, ups=3.44, wpb=61647, bsz=2020.6, num_updates=274200, lr=0.00019097, gnorm=0.851, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:40:45 | INFO | train_inner | epoch 139:    700 / 1983 loss=3.143, nll_loss=0.996, word_ins=2.821, length=3.223, ppl=8.83, wps=210353, ups=3.44, wpb=61202, bsz=1997.6, num_updates=274300, lr=0.000190936, gnorm=0.858, loss_scale=32768, train_wall=29, wall=0
2023-03-02 17:41:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 17:41:15 | INFO | train_inner | epoch 139:    801 / 1983 loss=3.142, nll_loss=0.995, word_ins=2.82, length=3.217, ppl=8.83, wps=206688, ups=3.38, wpb=61091.3, bsz=1944.3, num_updates=274400, lr=0.000190901, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:41:44 | INFO | train_inner | epoch 139:    901 / 1983 loss=3.128, nll_loss=0.987, word_ins=2.813, length=3.151, ppl=8.75, wps=210544, ups=3.42, wpb=61518.3, bsz=2056.6, num_updates=274500, lr=0.000190866, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:42:13 | INFO | train_inner | epoch 139:   1001 / 1983 loss=3.101, nll_loss=0.963, word_ins=2.791, length=3.1, ppl=8.58, wps=212203, ups=3.42, wpb=62001.1, bsz=2052.1, num_updates=274600, lr=0.000190831, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:42:43 | INFO | train_inner | epoch 139:   1101 / 1983 loss=3.109, nll_loss=0.971, word_ins=2.798, length=3.111, ppl=8.63, wps=211221, ups=3.42, wpb=61734.1, bsz=2093.7, num_updates=274700, lr=0.000190797, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:43:12 | INFO | train_inner | epoch 139:   1201 / 1983 loss=3.128, nll_loss=0.983, word_ins=2.81, length=3.184, ppl=8.74, wps=211971, ups=3.44, wpb=61571.1, bsz=2007.8, num_updates=274800, lr=0.000190762, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:43:41 | INFO | train_inner | epoch 139:   1301 / 1983 loss=3.153, nll_loss=1.005, word_ins=2.829, length=3.236, ppl=8.89, wps=211006, ups=3.44, wpb=61378.6, bsz=1921, num_updates=274900, lr=0.000190727, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:44:10 | INFO | train_inner | epoch 139:   1401 / 1983 loss=3.137, nll_loss=0.991, word_ins=2.816, length=3.207, ppl=8.8, wps=211330, ups=3.42, wpb=61758, bsz=2023.6, num_updates=275000, lr=0.000190693, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:44:39 | INFO | train_inner | epoch 139:   1501 / 1983 loss=3.154, nll_loss=1.007, word_ins=2.831, length=3.225, ppl=8.9, wps=210353, ups=3.44, wpb=61200.9, bsz=1927.2, num_updates=275100, lr=0.000190658, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:45:08 | INFO | train_inner | epoch 139:   1601 / 1983 loss=3.129, nll_loss=0.986, word_ins=2.812, length=3.171, ppl=8.75, wps=211977, ups=3.42, wpb=61950.1, bsz=2005.8, num_updates=275200, lr=0.000190623, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:45:37 | INFO | train_inner | epoch 139:   1701 / 1983 loss=3.126, nll_loss=0.984, word_ins=2.81, length=3.159, ppl=8.73, wps=212145, ups=3.43, wpb=61911.4, bsz=2030.8, num_updates=275300, lr=0.000190589, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:46:07 | INFO | train_inner | epoch 139:   1801 / 1983 loss=3.154, nll_loss=1.004, word_ins=2.829, length=3.249, ppl=8.9, wps=212917, ups=3.45, wpb=61779, bsz=1950.1, num_updates=275400, lr=0.000190554, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:46:36 | INFO | train_inner | epoch 139:   1901 / 1983 loss=3.138, nll_loss=0.995, word_ins=2.82, length=3.176, ppl=8.8, wps=211119, ups=3.41, wpb=61918.3, bsz=1993.5, num_updates=275500, lr=0.000190519, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 17:47:13 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 3.174 | nll_loss 0.966 | word_ins 2.851 | length 3.235 | ppl 9.03 | wps 107436 | wpb 41551 | bsz 1500 | num_updates 275582 | best_loss 3.174
2023-03-02 17:47:13 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 17:47:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint139.pt (epoch 139 @ 275582 updates, score 3.174) (writing took 8.232939284993336 seconds)
2023-03-02 17:47:21 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2023-03-02 17:47:21 | INFO | train | epoch 139 | loss 3.135 | nll_loss 0.991 | word_ins 2.817 | length 3.184 | ppl 8.79 | wps 200290 | ups 3.25 | wpb 61627.4 | bsz 1997.8 | num_updates 275582 | lr 0.000190491 | gnorm 0.853 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 17:47:21 | INFO | fairseq.trainer | begin training epoch 140
2023-03-02 17:47:35 | INFO | train_inner | epoch 140:     18 / 1983 loss=3.14, nll_loss=0.997, word_ins=2.822, length=3.175, ppl=8.81, wps=103337, ups=1.68, wpb=61348.5, bsz=2004.8, num_updates=275600, lr=0.000190485, gnorm=0.898, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:48:05 | INFO | train_inner | epoch 140:    118 / 1983 loss=3.133, nll_loss=0.988, word_ins=2.814, length=3.183, ppl=8.77, wps=208572, ups=3.4, wpb=61358.9, bsz=1983.8, num_updates=275700, lr=0.00019045, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:48:34 | INFO | train_inner | epoch 140:    218 / 1983 loss=3.12, nll_loss=0.976, word_ins=2.804, length=3.163, ppl=8.69, wps=211279, ups=3.42, wpb=61723.7, bsz=2036.2, num_updates=275800, lr=0.000190416, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:49:03 | INFO | train_inner | epoch 140:    318 / 1983 loss=3.148, nll_loss=1.001, word_ins=2.826, length=3.222, ppl=8.86, wps=209073, ups=3.42, wpb=61050.9, bsz=1988.5, num_updates=275900, lr=0.000190381, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:49:32 | INFO | train_inner | epoch 140:    418 / 1983 loss=3.125, nll_loss=0.983, word_ins=2.809, length=3.157, ppl=8.72, wps=211861, ups=3.42, wpb=61868.8, bsz=2007, num_updates=276000, lr=0.000190347, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:50:01 | INFO | train_inner | epoch 140:    518 / 1983 loss=3.127, nll_loss=0.983, word_ins=2.81, length=3.175, ppl=8.74, wps=212725, ups=3.45, wpb=61716.2, bsz=1962.2, num_updates=276100, lr=0.000190312, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:50:31 | INFO | train_inner | epoch 140:    618 / 1983 loss=3.148, nll_loss=1.004, word_ins=2.829, length=3.187, ppl=8.86, wps=212461, ups=3.42, wpb=62141.9, bsz=1949.8, num_updates=276200, lr=0.000190278, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:51:00 | INFO | train_inner | epoch 140:    718 / 1983 loss=3.142, nll_loss=0.996, word_ins=2.821, length=3.21, ppl=8.83, wps=211822, ups=3.43, wpb=61693.5, bsz=1920.6, num_updates=276300, lr=0.000190243, gnorm=0.872, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:51:29 | INFO | train_inner | epoch 140:    818 / 1983 loss=3.118, nll_loss=0.975, word_ins=2.802, length=3.163, ppl=8.68, wps=211104, ups=3.42, wpb=61777.2, bsz=2032.9, num_updates=276400, lr=0.000190209, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:51:58 | INFO | train_inner | epoch 140:    918 / 1983 loss=3.14, nll_loss=0.991, word_ins=2.816, length=3.238, ppl=8.82, wps=210646, ups=3.42, wpb=61512, bsz=2020, num_updates=276500, lr=0.000190175, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:52:27 | INFO | train_inner | epoch 140:   1018 / 1983 loss=3.15, nll_loss=1.001, word_ins=2.826, length=3.236, ppl=8.87, wps=210836, ups=3.44, wpb=61292.8, bsz=1977.2, num_updates=276600, lr=0.00019014, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:52:56 | INFO | train_inner | epoch 140:   1118 / 1983 loss=3.116, nll_loss=0.977, word_ins=2.804, length=3.123, ppl=8.67, wps=211398, ups=3.42, wpb=61842.1, bsz=2113, num_updates=276700, lr=0.000190106, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:53:26 | INFO | train_inner | epoch 140:   1218 / 1983 loss=3.12, nll_loss=0.978, word_ins=2.804, length=3.158, ppl=8.69, wps=210359, ups=3.43, wpb=61297.6, bsz=2043.9, num_updates=276800, lr=0.000190071, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:53:55 | INFO | train_inner | epoch 140:   1318 / 1983 loss=3.125, nll_loss=0.981, word_ins=2.807, length=3.175, ppl=8.72, wps=210611, ups=3.43, wpb=61471.6, bsz=2008.3, num_updates=276900, lr=0.000190037, gnorm=0.862, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:54:24 | INFO | train_inner | epoch 140:   1418 / 1983 loss=3.118, nll_loss=0.978, word_ins=2.805, length=3.133, ppl=8.68, wps=210362, ups=3.41, wpb=61779.6, bsz=2092.6, num_updates=277000, lr=0.000190003, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:54:53 | INFO | train_inner | epoch 140:   1518 / 1983 loss=3.166, nll_loss=1.02, word_ins=2.843, length=3.238, ppl=8.98, wps=211821, ups=3.44, wpb=61494, bsz=1882.7, num_updates=277100, lr=0.000189969, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:55:23 | INFO | train_inner | epoch 140:   1618 / 1983 loss=3.143, nll_loss=1.001, word_ins=2.825, length=3.178, ppl=8.83, wps=209837, ups=3.41, wpb=61600.6, bsz=2048.9, num_updates=277200, lr=0.000189934, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:55:52 | INFO | train_inner | epoch 140:   1718 / 1983 loss=3.15, nll_loss=1.006, word_ins=2.83, length=3.199, ppl=8.88, wps=211720, ups=3.42, wpb=61897.1, bsz=1978.7, num_updates=277300, lr=0.0001899, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:56:21 | INFO | train_inner | epoch 140:   1818 / 1983 loss=3.127, nll_loss=0.986, word_ins=2.812, length=3.154, ppl=8.74, wps=213488, ups=3.43, wpb=62277.1, bsz=1974.6, num_updates=277400, lr=0.000189866, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:56:50 | INFO | train_inner | epoch 140:   1918 / 1983 loss=3.147, nll_loss=1.004, word_ins=2.829, length=3.18, ppl=8.86, wps=212489, ups=3.44, wpb=61709.7, bsz=1931.4, num_updates=277500, lr=0.000189832, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 17:57:22 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 3.187 | nll_loss 0.983 | word_ins 2.865 | length 3.214 | ppl 9.1 | wps 110119 | wpb 41551 | bsz 1500 | num_updates 277565 | best_loss 3.174
2023-03-02 17:57:22 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 17:57:27 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint140.pt (epoch 140 @ 277565 updates, score 3.187) (writing took 5.218401609105058 seconds)
2023-03-02 17:57:27 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2023-03-02 17:57:27 | INFO | train | epoch 140 | loss 3.135 | nll_loss 0.991 | word_ins 2.816 | length 3.183 | ppl 8.78 | wps 201550 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 277565 | lr 0.000189809 | gnorm 0.853 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 17:57:27 | INFO | fairseq.trainer | begin training epoch 141
2023-03-02 17:57:47 | INFO | train_inner | epoch 141:     35 / 1983 loss=3.122, nll_loss=0.979, word_ins=2.806, length=3.163, ppl=8.71, wps=107937, ups=1.76, wpb=61296.8, bsz=2007.1, num_updates=277600, lr=0.000189797, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:58:16 | INFO | train_inner | epoch 141:    135 / 1983 loss=3.106, nll_loss=0.966, word_ins=2.795, length=3.113, ppl=8.61, wps=210652, ups=3.41, wpb=61731.5, bsz=2020.6, num_updates=277700, lr=0.000189763, gnorm=0.821, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:58:45 | INFO | train_inner | epoch 141:    235 / 1983 loss=3.112, nll_loss=0.972, word_ins=2.8, length=3.125, ppl=8.65, wps=211568, ups=3.41, wpb=62121.4, bsz=1985.2, num_updates=277800, lr=0.000189729, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:59:15 | INFO | train_inner | epoch 141:    335 / 1983 loss=3.116, nll_loss=0.975, word_ins=2.802, length=3.143, ppl=8.67, wps=211142, ups=3.43, wpb=61638, bsz=2046.8, num_updates=277900, lr=0.000189695, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 17:59:44 | INFO | train_inner | epoch 141:    435 / 1983 loss=3.111, nll_loss=0.972, word_ins=2.799, length=3.121, ppl=8.64, wps=210665, ups=3.4, wpb=62022, bsz=2090.5, num_updates=278000, lr=0.000189661, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:00:14 | INFO | train_inner | epoch 141:    535 / 1983 loss=3.129, nll_loss=0.984, word_ins=2.811, length=3.184, ppl=8.75, wps=208414, ups=3.39, wpb=61491.4, bsz=2025.3, num_updates=278100, lr=0.000189627, gnorm=0.994, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:00:43 | INFO | train_inner | epoch 141:    635 / 1983 loss=3.164, nll_loss=1.017, word_ins=2.84, length=3.242, ppl=8.97, wps=210956, ups=3.43, wpb=61514.9, bsz=1879.9, num_updates=278200, lr=0.000189593, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:01:12 | INFO | train_inner | epoch 141:    735 / 1983 loss=3.134, nll_loss=0.989, word_ins=2.815, length=3.186, ppl=8.78, wps=211414, ups=3.43, wpb=61589.1, bsz=1987.8, num_updates=278300, lr=0.000189559, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:01:41 | INFO | train_inner | epoch 141:    835 / 1983 loss=3.111, nll_loss=0.97, word_ins=2.798, length=3.132, ppl=8.64, wps=210914, ups=3.42, wpb=61593.3, bsz=2073.5, num_updates=278400, lr=0.000189525, gnorm=0.808, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:02:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 18:02:11 | INFO | train_inner | epoch 141:    936 / 1983 loss=3.146, nll_loss=1.005, word_ins=2.83, length=3.157, ppl=8.85, wps=208281, ups=3.37, wpb=61722.9, bsz=1973.8, num_updates=278500, lr=0.00018949, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:02:40 | INFO | train_inner | epoch 141:   1036 / 1983 loss=3.133, nll_loss=0.99, word_ins=2.816, length=3.173, ppl=8.77, wps=212058, ups=3.43, wpb=61782.2, bsz=1987.4, num_updates=278600, lr=0.000189456, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:03:09 | INFO | train_inner | epoch 141:   1136 / 1983 loss=3.136, nll_loss=0.991, word_ins=2.817, length=3.195, ppl=8.79, wps=210764, ups=3.43, wpb=61386.6, bsz=2053, num_updates=278700, lr=0.000189422, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:03:38 | INFO | train_inner | epoch 141:   1236 / 1983 loss=3.135, nll_loss=0.993, word_ins=2.819, length=3.166, ppl=8.79, wps=208601, ups=3.41, wpb=61096.1, bsz=2093.9, num_updates=278800, lr=0.000189389, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:04:08 | INFO | train_inner | epoch 141:   1336 / 1983 loss=3.156, nll_loss=1.01, word_ins=2.834, length=3.22, ppl=8.91, wps=211990, ups=3.43, wpb=61812.8, bsz=1905.2, num_updates=278900, lr=0.000189355, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:04:37 | INFO | train_inner | epoch 141:   1436 / 1983 loss=3.146, nll_loss=0.994, word_ins=2.819, length=3.263, ppl=8.85, wps=209655, ups=3.43, wpb=61151, bsz=1979.3, num_updates=279000, lr=0.000189321, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:05:06 | INFO | train_inner | epoch 141:   1536 / 1983 loss=3.13, nll_loss=0.987, word_ins=2.812, length=3.181, ppl=8.75, wps=211025, ups=3.42, wpb=61688.1, bsz=2053.4, num_updates=279100, lr=0.000189287, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:05:35 | INFO | train_inner | epoch 141:   1636 / 1983 loss=3.176, nll_loss=1.025, word_ins=2.848, length=3.286, ppl=9.04, wps=211186, ups=3.44, wpb=61331, bsz=1835.5, num_updates=279200, lr=0.000189253, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:06:04 | INFO | train_inner | epoch 141:   1736 / 1983 loss=3.114, nll_loss=0.976, word_ins=2.802, length=3.122, ppl=8.66, wps=212452, ups=3.43, wpb=61898.9, bsz=2052.5, num_updates=279300, lr=0.000189219, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:06:33 | INFO | train_inner | epoch 141:   1836 / 1983 loss=3.133, nll_loss=0.985, word_ins=2.811, length=3.224, ppl=8.77, wps=210066, ups=3.43, wpb=61188.1, bsz=2011.2, num_updates=279400, lr=0.000189185, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:07:02 | INFO | train_inner | epoch 141:   1936 / 1983 loss=3.146, nll_loss=1.004, word_ins=2.828, length=3.174, ppl=8.85, wps=214113, ups=3.43, wpb=62340.1, bsz=1981.7, num_updates=279500, lr=0.000189151, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 18:07:29 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 3.182 | nll_loss 0.975 | word_ins 2.858 | length 3.239 | ppl 9.08 | wps 116693 | wpb 41551 | bsz 1500 | num_updates 279547 | best_loss 3.174
2023-03-02 18:07:29 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 18:07:35 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint141.pt (epoch 141 @ 279547 updates, score 3.182) (writing took 5.620036056963727 seconds)
2023-03-02 18:07:35 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2023-03-02 18:07:35 | INFO | train | epoch 141 | loss 3.134 | nll_loss 0.991 | word_ins 2.816 | length 3.18 | ppl 8.78 | wps 201080 | ups 3.26 | wpb 61627 | bsz 1998.1 | num_updates 279547 | lr 0.000189135 | gnorm 0.857 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 18:07:35 | INFO | fairseq.trainer | begin training epoch 142
2023-03-02 18:08:00 | INFO | train_inner | epoch 142:     53 / 1983 loss=3.168, nll_loss=1.024, word_ins=2.847, length=3.216, ppl=8.99, wps=106647, ups=1.74, wpb=61428.7, bsz=1838.2, num_updates=279600, lr=0.000189117, gnorm=0.895, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:08:29 | INFO | train_inner | epoch 142:    153 / 1983 loss=3.115, nll_loss=0.97, word_ins=2.798, length=3.164, ppl=8.66, wps=210936, ups=3.43, wpb=61584.3, bsz=2075.4, num_updates=279700, lr=0.000189084, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:08:58 | INFO | train_inner | epoch 142:    253 / 1983 loss=3.142, nll_loss=0.997, word_ins=2.822, length=3.198, ppl=8.83, wps=211107, ups=3.42, wpb=61698.7, bsz=1930.8, num_updates=279800, lr=0.00018905, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:09:27 | INFO | train_inner | epoch 142:    353 / 1983 loss=3.095, nll_loss=0.959, word_ins=2.787, length=3.079, ppl=8.55, wps=213686, ups=3.44, wpb=62089.6, bsz=2058.4, num_updates=279900, lr=0.000189016, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:09:57 | INFO | train_inner | epoch 142:    453 / 1983 loss=3.13, nll_loss=0.988, word_ins=2.814, length=3.162, ppl=8.75, wps=210119, ups=3.4, wpb=61768.8, bsz=2012.4, num_updates=280000, lr=0.000188982, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:10:26 | INFO | train_inner | epoch 142:    553 / 1983 loss=3.116, nll_loss=0.977, word_ins=2.803, length=3.123, ppl=8.67, wps=211478, ups=3.43, wpb=61727.8, bsz=2041.5, num_updates=280100, lr=0.000188948, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:10:55 | INFO | train_inner | epoch 142:    653 / 1983 loss=3.116, nll_loss=0.973, word_ins=2.8, length=3.16, ppl=8.67, wps=209887, ups=3.42, wpb=61407.9, bsz=2073.8, num_updates=280200, lr=0.000188915, gnorm=0.823, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:11:24 | INFO | train_inner | epoch 142:    753 / 1983 loss=3.137, nll_loss=0.992, word_ins=2.817, length=3.202, ppl=8.8, wps=211862, ups=3.44, wpb=61549.1, bsz=1961.5, num_updates=280300, lr=0.000188881, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:11:54 | INFO | train_inner | epoch 142:    853 / 1983 loss=3.131, nll_loss=0.987, word_ins=2.813, length=3.183, ppl=8.76, wps=211819, ups=3.43, wpb=61798.5, bsz=1996.9, num_updates=280400, lr=0.000188847, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:12:23 | INFO | train_inner | epoch 142:    953 / 1983 loss=3.141, nll_loss=0.995, word_ins=2.82, length=3.203, ppl=8.82, wps=212094, ups=3.43, wpb=61752, bsz=1961, num_updates=280500, lr=0.000188814, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:12:52 | INFO | train_inner | epoch 142:   1053 / 1983 loss=3.139, nll_loss=0.995, word_ins=2.821, length=3.183, ppl=8.81, wps=211404, ups=3.42, wpb=61732.4, bsz=1992.2, num_updates=280600, lr=0.00018878, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:13:21 | INFO | train_inner | epoch 142:   1153 / 1983 loss=3.095, nll_loss=0.957, word_ins=2.786, length=3.094, ppl=8.55, wps=211059, ups=3.42, wpb=61737.5, bsz=2102.6, num_updates=280700, lr=0.000188746, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:13:50 | INFO | train_inner | epoch 142:   1253 / 1983 loss=3.126, nll_loss=0.986, word_ins=2.812, length=3.147, ppl=8.73, wps=211973, ups=3.42, wpb=61972.3, bsz=2002, num_updates=280800, lr=0.000188713, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:14:19 | INFO | train_inner | epoch 142:   1353 / 1983 loss=3.147, nll_loss=0.998, word_ins=2.823, length=3.242, ppl=8.86, wps=210186, ups=3.45, wpb=60944, bsz=1950.8, num_updates=280900, lr=0.000188679, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:14:48 | INFO | train_inner | epoch 142:   1453 / 1983 loss=3.17, nll_loss=1.022, word_ins=2.844, length=3.255, ppl=9, wps=211209, ups=3.44, wpb=61479.3, bsz=1937.5, num_updates=281000, lr=0.000188646, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:15:17 | INFO | train_inner | epoch 142:   1553 / 1983 loss=3.147, nll_loss=1.004, word_ins=2.828, length=3.191, ppl=8.86, wps=213666, ups=3.45, wpb=61855.1, bsz=1894.1, num_updates=281100, lr=0.000188612, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:15:47 | INFO | train_inner | epoch 142:   1653 / 1983 loss=3.119, nll_loss=0.977, word_ins=2.804, length=3.151, ppl=8.69, wps=210873, ups=3.42, wpb=61707.6, bsz=2063.3, num_updates=281200, lr=0.000188579, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:16:16 | INFO | train_inner | epoch 142:   1753 / 1983 loss=3.114, nll_loss=0.974, word_ins=2.801, length=3.137, ppl=8.66, wps=212551, ups=3.44, wpb=61783.3, bsz=2005.7, num_updates=281300, lr=0.000188545, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:16:45 | INFO | train_inner | epoch 142:   1853 / 1983 loss=3.165, nll_loss=1.014, word_ins=2.837, length=3.276, ppl=8.97, wps=209543, ups=3.43, wpb=61120, bsz=1928.6, num_updates=281400, lr=0.000188512, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:17:14 | INFO | train_inner | epoch 142:   1953 / 1983 loss=3.146, nll_loss=1, word_ins=2.825, length=3.218, ppl=8.85, wps=210289, ups=3.42, wpb=61398.7, bsz=2000.8, num_updates=281500, lr=0.000188478, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 18:17:36 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 3.188 | nll_loss 0.982 | word_ins 2.867 | length 3.212 | ppl 9.12 | wps 81147.1 | wpb 41551 | bsz 1500 | num_updates 281530 | best_loss 3.174
2023-03-02 18:17:36 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 18:17:41 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint142.pt (epoch 142 @ 281530 updates, score 3.188) (writing took 5.580957575002685 seconds)
2023-03-02 18:17:41 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2023-03-02 18:17:41 | INFO | train | epoch 142 | loss 3.131 | nll_loss 0.988 | word_ins 2.814 | length 3.176 | ppl 8.76 | wps 201480 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 281530 | lr 0.000188468 | gnorm 0.852 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 18:17:41 | INFO | fairseq.trainer | begin training epoch 143
2023-03-02 18:18:12 | INFO | train_inner | epoch 143:     70 / 1983 loss=3.118, nll_loss=0.977, word_ins=2.804, length=3.136, ppl=8.68, wps=106673, ups=1.74, wpb=61242.8, bsz=2073.8, num_updates=281600, lr=0.000188445, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:18:41 | INFO | train_inner | epoch 143:    170 / 1983 loss=3.114, nll_loss=0.973, word_ins=2.8, length=3.136, ppl=8.66, wps=210276, ups=3.43, wpb=61325.9, bsz=2052.2, num_updates=281700, lr=0.000188411, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:19:10 | INFO | train_inner | epoch 143:    270 / 1983 loss=3.114, nll_loss=0.974, word_ins=2.801, length=3.131, ppl=8.66, wps=210951, ups=3.41, wpb=61813.7, bsz=2013.6, num_updates=281800, lr=0.000188378, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:19:39 | INFO | train_inner | epoch 143:    370 / 1983 loss=3.139, nll_loss=0.992, word_ins=2.818, length=3.211, ppl=8.81, wps=210056, ups=3.41, wpb=61630.6, bsz=1984, num_updates=281900, lr=0.000188344, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:20:09 | INFO | train_inner | epoch 143:    470 / 1983 loss=3.132, nll_loss=0.987, word_ins=2.813, length=3.187, ppl=8.76, wps=210957, ups=3.42, wpb=61655.6, bsz=1952.2, num_updates=282000, lr=0.000188311, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:20:38 | INFO | train_inner | epoch 143:    570 / 1983 loss=3.128, nll_loss=0.986, word_ins=2.813, length=3.154, ppl=8.74, wps=210735, ups=3.42, wpb=61669.3, bsz=2011.2, num_updates=282100, lr=0.000188278, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:21:07 | INFO | train_inner | epoch 143:    670 / 1983 loss=3.137, nll_loss=0.995, word_ins=2.82, length=3.169, ppl=8.8, wps=210570, ups=3.42, wpb=61579.4, bsz=1995, num_updates=282200, lr=0.000188244, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:21:36 | INFO | train_inner | epoch 143:    770 / 1983 loss=3.132, nll_loss=0.988, word_ins=2.814, length=3.18, ppl=8.77, wps=209186, ups=3.43, wpb=60985.5, bsz=1964.6, num_updates=282300, lr=0.000188211, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:22:05 | INFO | train_inner | epoch 143:    870 / 1983 loss=3.155, nll_loss=1.007, word_ins=2.831, length=3.236, ppl=8.91, wps=211339, ups=3.42, wpb=61803.6, bsz=1954.9, num_updates=282400, lr=0.000188177, gnorm=0.878, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:22:35 | INFO | train_inner | epoch 143:    970 / 1983 loss=3.123, nll_loss=0.983, word_ins=2.81, length=3.136, ppl=8.71, wps=209460, ups=3.42, wpb=61295.9, bsz=2002.4, num_updates=282500, lr=0.000188144, gnorm=0.817, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:23:04 | INFO | train_inner | epoch 143:   1070 / 1983 loss=3.139, nll_loss=0.993, word_ins=2.819, length=3.208, ppl=8.81, wps=211968, ups=3.44, wpb=61590.1, bsz=1917.8, num_updates=282600, lr=0.000188111, gnorm=0.843, loss_scale=32768, train_wall=29, wall=0
2023-03-02 18:23:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 18:23:33 | INFO | train_inner | epoch 143:   1171 / 1983 loss=3.127, nll_loss=0.987, word_ins=2.813, length=3.134, ppl=8.73, wps=210221, ups=3.39, wpb=61925.5, bsz=1974.2, num_updates=282700, lr=0.000188078, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:24:02 | INFO | train_inner | epoch 143:   1271 / 1983 loss=3.134, nll_loss=0.987, word_ins=2.813, length=3.215, ppl=8.78, wps=212422, ups=3.44, wpb=61825.1, bsz=2011.7, num_updates=282800, lr=0.000188044, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:24:32 | INFO | train_inner | epoch 143:   1371 / 1983 loss=3.126, nll_loss=0.981, word_ins=2.808, length=3.184, ppl=8.73, wps=212155, ups=3.43, wpb=61911.7, bsz=2010.6, num_updates=282900, lr=0.000188011, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:25:01 | INFO | train_inner | epoch 143:   1471 / 1983 loss=3.12, nll_loss=0.976, word_ins=2.803, length=3.175, ppl=8.7, wps=211531, ups=3.43, wpb=61628.2, bsz=2003.6, num_updates=283000, lr=0.000187978, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:25:30 | INFO | train_inner | epoch 143:   1571 / 1983 loss=3.125, nll_loss=0.983, word_ins=2.809, length=3.154, ppl=8.72, wps=211898, ups=3.42, wpb=62001.8, bsz=2009, num_updates=283100, lr=0.000187945, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:25:59 | INFO | train_inner | epoch 143:   1671 / 1983 loss=3.128, nll_loss=0.984, word_ins=2.81, length=3.18, ppl=8.74, wps=211229, ups=3.43, wpb=61622.6, bsz=2050.8, num_updates=283200, lr=0.000187912, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:26:28 | INFO | train_inner | epoch 143:   1771 / 1983 loss=3.118, nll_loss=0.98, word_ins=2.806, length=3.124, ppl=8.68, wps=211736, ups=3.42, wpb=61971.9, bsz=2022.8, num_updates=283300, lr=0.000187878, gnorm=0.867, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:26:58 | INFO | train_inner | epoch 143:   1871 / 1983 loss=3.121, nll_loss=0.978, word_ins=2.804, length=3.164, ppl=8.7, wps=211278, ups=3.42, wpb=61797.3, bsz=2040.4, num_updates=283400, lr=0.000187845, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:27:27 | INFO | train_inner | epoch 143:   1971 / 1983 loss=3.151, nll_loss=1.011, word_ins=2.834, length=3.163, ppl=8.88, wps=210671, ups=3.43, wpb=61442, bsz=1954.8, num_updates=283500, lr=0.000187812, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:27:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 18:27:42 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 3.172 | nll_loss 0.972 | word_ins 2.853 | length 3.183 | ppl 9.01 | wps 81895.1 | wpb 41551 | bsz 1500 | num_updates 283512 | best_loss 3.172
2023-03-02 18:27:42 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 18:27:51 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint143.pt (epoch 143 @ 283512 updates, score 3.172) (writing took 8.414008349995129 seconds)
2023-03-02 18:27:51 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2023-03-02 18:27:51 | INFO | train | epoch 143 | loss 3.13 | nll_loss 0.987 | word_ins 2.813 | length 3.17 | ppl 8.75 | wps 200422 | ups 3.25 | wpb 61627.1 | bsz 1998 | num_updates 283512 | lr 0.000187808 | gnorm 0.846 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 18:27:51 | INFO | fairseq.trainer | begin training epoch 144
2023-03-02 18:28:26 | INFO | train_inner | epoch 144:     88 / 1983 loss=3.116, nll_loss=0.976, word_ins=2.803, length=3.134, ppl=8.67, wps=103478, ups=1.69, wpb=61066.8, bsz=2065.4, num_updates=283600, lr=0.000187779, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:28:55 | INFO | train_inner | epoch 144:    188 / 1983 loss=3.121, nll_loss=0.977, word_ins=2.804, length=3.165, ppl=8.7, wps=210728, ups=3.42, wpb=61692.4, bsz=2005.4, num_updates=283700, lr=0.000187746, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:29:24 | INFO | train_inner | epoch 144:    288 / 1983 loss=3.109, nll_loss=0.971, word_ins=2.798, length=3.105, ppl=8.63, wps=213184, ups=3.42, wpb=62261.6, bsz=2025.3, num_updates=283800, lr=0.000187713, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:29:54 | INFO | train_inner | epoch 144:    388 / 1983 loss=3.105, nll_loss=0.965, word_ins=2.793, length=3.129, ppl=8.61, wps=211181, ups=3.42, wpb=61791.7, bsz=2075.4, num_updates=283900, lr=0.00018768, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:30:23 | INFO | train_inner | epoch 144:    488 / 1983 loss=3.144, nll_loss=0.996, word_ins=2.821, length=3.229, ppl=8.84, wps=209790, ups=3.42, wpb=61275.8, bsz=1973.8, num_updates=284000, lr=0.000187647, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:30:52 | INFO | train_inner | epoch 144:    588 / 1983 loss=3.121, nll_loss=0.981, word_ins=2.808, length=3.134, ppl=8.7, wps=213309, ups=3.43, wpb=62106.9, bsz=1953, num_updates=284100, lr=0.000187614, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:31:21 | INFO | train_inner | epoch 144:    688 / 1983 loss=3.116, nll_loss=0.971, word_ins=2.799, length=3.166, ppl=8.67, wps=211404, ups=3.41, wpb=61952.1, bsz=2020.1, num_updates=284200, lr=0.000187581, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:31:51 | INFO | train_inner | epoch 144:    788 / 1983 loss=3.142, nll_loss=0.997, word_ins=2.823, length=3.196, ppl=8.83, wps=210514, ups=3.42, wpb=61583.3, bsz=1949.2, num_updates=284300, lr=0.000187548, gnorm=0.832, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:32:20 | INFO | train_inner | epoch 144:    888 / 1983 loss=3.121, nll_loss=0.979, word_ins=2.806, length=3.157, ppl=8.7, wps=210886, ups=3.43, wpb=61424.6, bsz=1959.7, num_updates=284400, lr=0.000187515, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:32:49 | INFO | train_inner | epoch 144:    988 / 1983 loss=3.117, nll_loss=0.975, word_ins=2.802, length=3.149, ppl=8.68, wps=212060, ups=3.43, wpb=61862.9, bsz=2059.6, num_updates=284500, lr=0.000187482, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:33:18 | INFO | train_inner | epoch 144:   1088 / 1983 loss=3.12, nll_loss=0.979, word_ins=2.805, length=3.143, ppl=8.69, wps=212847, ups=3.44, wpb=61870.8, bsz=2010.8, num_updates=284600, lr=0.000187449, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:33:47 | INFO | train_inner | epoch 144:   1188 / 1983 loss=3.122, nll_loss=0.98, word_ins=2.806, length=3.164, ppl=8.71, wps=212046, ups=3.42, wpb=61916.8, bsz=1976.6, num_updates=284700, lr=0.000187416, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:34:16 | INFO | train_inner | epoch 144:   1288 / 1983 loss=3.148, nll_loss=1.003, word_ins=2.828, length=3.207, ppl=8.87, wps=208589, ups=3.42, wpb=60929.7, bsz=1930, num_updates=284800, lr=0.000187383, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:34:46 | INFO | train_inner | epoch 144:   1388 / 1983 loss=3.152, nll_loss=1.007, word_ins=2.831, length=3.213, ppl=8.89, wps=211091, ups=3.42, wpb=61672.5, bsz=1941.1, num_updates=284900, lr=0.00018735, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:35:15 | INFO | train_inner | epoch 144:   1488 / 1983 loss=3.136, nll_loss=0.994, word_ins=2.819, length=3.176, ppl=8.79, wps=211604, ups=3.44, wpb=61556.6, bsz=1985.8, num_updates=285000, lr=0.000187317, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:35:44 | INFO | train_inner | epoch 144:   1588 / 1983 loss=3.126, nll_loss=0.978, word_ins=2.805, length=3.212, ppl=8.73, wps=209339, ups=3.43, wpb=61103.7, bsz=2028.6, num_updates=285100, lr=0.000187284, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:36:13 | INFO | train_inner | epoch 144:   1688 / 1983 loss=3.108, nll_loss=0.971, word_ins=2.798, length=3.105, ppl=8.62, wps=212088, ups=3.43, wpb=61791.1, bsz=2073.1, num_updates=285200, lr=0.000187251, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:36:42 | INFO | train_inner | epoch 144:   1788 / 1983 loss=3.144, nll_loss=1, word_ins=2.825, length=3.191, ppl=8.84, wps=211881, ups=3.44, wpb=61602.9, bsz=1973, num_updates=285300, lr=0.000187219, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:37:11 | INFO | train_inner | epoch 144:   1888 / 1983 loss=3.16, nll_loss=1.012, word_ins=2.836, length=3.246, ppl=8.94, wps=209644, ups=3.42, wpb=61232.8, bsz=1925.4, num_updates=285400, lr=0.000187186, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 18:37:53 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 3.179 | nll_loss 0.974 | word_ins 2.856 | length 3.225 | ppl 9.06 | wps 112085 | wpb 41551 | bsz 1500 | num_updates 285495 | best_loss 3.172
2023-03-02 18:37:53 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 18:37:59 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint144.pt (epoch 144 @ 285495 updates, score 3.179) (writing took 5.664686153992079 seconds)
2023-03-02 18:37:59 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2023-03-02 18:37:59 | INFO | train | epoch 144 | loss 3.128 | nll_loss 0.985 | word_ins 2.811 | length 3.169 | ppl 8.74 | wps 200878 | ups 3.26 | wpb 61628.5 | bsz 1997.6 | num_updates 285495 | lr 0.000187155 | gnorm 0.848 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 18:37:59 | INFO | fairseq.trainer | begin training epoch 145
2023-03-02 18:38:10 | INFO | train_inner | epoch 145:      5 / 1983 loss=3.137, nll_loss=0.995, word_ins=2.82, length=3.164, ppl=8.8, wps=103663, ups=1.69, wpb=61296.2, bsz=1999.3, num_updates=285500, lr=0.000187153, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:38:40 | INFO | train_inner | epoch 145:    105 / 1983 loss=3.098, nll_loss=0.96, word_ins=2.788, length=3.099, ppl=8.56, wps=209350, ups=3.4, wpb=61641.5, bsz=2127.5, num_updates=285600, lr=0.00018712, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:39:09 | INFO | train_inner | epoch 145:    205 / 1983 loss=3.121, nll_loss=0.98, word_ins=2.807, length=3.142, ppl=8.7, wps=212847, ups=3.44, wpb=61885.5, bsz=1954, num_updates=285700, lr=0.000187088, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:39:38 | INFO | train_inner | epoch 145:    305 / 1983 loss=3.102, nll_loss=0.965, word_ins=2.792, length=3.1, ppl=8.59, wps=210858, ups=3.42, wpb=61607.3, bsz=2063, num_updates=285800, lr=0.000187055, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:40:07 | INFO | train_inner | epoch 145:    405 / 1983 loss=3.097, nll_loss=0.958, word_ins=2.786, length=3.101, ppl=8.55, wps=211761, ups=3.42, wpb=61834.7, bsz=2128.6, num_updates=285900, lr=0.000187022, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:40:37 | INFO | train_inner | epoch 145:    505 / 1983 loss=3.122, nll_loss=0.98, word_ins=2.807, length=3.155, ppl=8.71, wps=211089, ups=3.42, wpb=61681.2, bsz=2004.4, num_updates=286000, lr=0.000186989, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:41:06 | INFO | train_inner | epoch 145:    605 / 1983 loss=3.119, nll_loss=0.979, word_ins=2.805, length=3.141, ppl=8.69, wps=211540, ups=3.44, wpb=61547.7, bsz=2027.6, num_updates=286100, lr=0.000186957, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:41:35 | INFO | train_inner | epoch 145:    705 / 1983 loss=3.139, nll_loss=0.99, word_ins=2.816, length=3.232, ppl=8.81, wps=210957, ups=3.43, wpb=61517.6, bsz=1951.7, num_updates=286200, lr=0.000186924, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:42:04 | INFO | train_inner | epoch 145:    805 / 1983 loss=3.136, nll_loss=0.991, word_ins=2.817, length=3.193, ppl=8.79, wps=212020, ups=3.44, wpb=61693.8, bsz=1995.6, num_updates=286300, lr=0.000186891, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:42:33 | INFO | train_inner | epoch 145:    905 / 1983 loss=3.136, nll_loss=0.989, word_ins=2.815, length=3.208, ppl=8.79, wps=209774, ups=3.41, wpb=61463.7, bsz=1957.2, num_updates=286400, lr=0.000186859, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:43:02 | INFO | train_inner | epoch 145:   1005 / 1983 loss=3.13, nll_loss=0.986, word_ins=2.812, length=3.183, ppl=8.76, wps=212666, ups=3.44, wpb=61859.3, bsz=1973.6, num_updates=286500, lr=0.000186826, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:43:32 | INFO | train_inner | epoch 145:   1105 / 1983 loss=3.135, nll_loss=0.993, word_ins=2.819, length=3.162, ppl=8.79, wps=211182, ups=3.42, wpb=61780.4, bsz=1953.4, num_updates=286600, lr=0.000186794, gnorm=0.877, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:44:01 | INFO | train_inner | epoch 145:   1205 / 1983 loss=3.128, nll_loss=0.985, word_ins=2.81, length=3.176, ppl=8.74, wps=212834, ups=3.44, wpb=61789.6, bsz=2005.8, num_updates=286700, lr=0.000186761, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:44:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 18:44:30 | INFO | train_inner | epoch 145:   1306 / 1983 loss=3.161, nll_loss=1.011, word_ins=2.835, length=3.258, ppl=8.95, wps=208924, ups=3.4, wpb=61434.7, bsz=1884.9, num_updates=286800, lr=0.000186728, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:44:59 | INFO | train_inner | epoch 145:   1406 / 1983 loss=3.13, nll_loss=0.986, word_ins=2.812, length=3.182, ppl=8.75, wps=211328, ups=3.44, wpb=61437.4, bsz=1980.2, num_updates=286900, lr=0.000186696, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:45:28 | INFO | train_inner | epoch 145:   1506 / 1983 loss=3.156, nll_loss=1.013, word_ins=2.836, length=3.199, ppl=8.92, wps=211216, ups=3.44, wpb=61449.4, bsz=1892.6, num_updates=287000, lr=0.000186663, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:45:57 | INFO | train_inner | epoch 145:   1606 / 1983 loss=3.11, nll_loss=0.971, word_ins=2.798, length=3.125, ppl=8.64, wps=211853, ups=3.42, wpb=61997.2, bsz=2093.3, num_updates=287100, lr=0.000186631, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:46:27 | INFO | train_inner | epoch 145:   1706 / 1983 loss=3.135, nll_loss=0.992, word_ins=2.817, length=3.178, ppl=8.78, wps=212133, ups=3.43, wpb=61786.8, bsz=1987.4, num_updates=287200, lr=0.000186598, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:46:56 | INFO | train_inner | epoch 145:   1806 / 1983 loss=3.153, nll_loss=1.005, word_ins=2.829, length=3.242, ppl=8.89, wps=212204, ups=3.44, wpb=61723.5, bsz=1931.2, num_updates=287300, lr=0.000186566, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:47:25 | INFO | train_inner | epoch 145:   1906 / 1983 loss=3.15, nll_loss=1.007, word_ins=2.831, length=3.19, ppl=8.88, wps=209654, ups=3.42, wpb=61295.8, bsz=1980.9, num_updates=287400, lr=0.000186533, gnorm=0.874, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 18:48:00 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 3.168 | nll_loss 0.961 | word_ins 2.846 | length 3.218 | ppl 8.99 | wps 81773.4 | wpb 41551 | bsz 1500 | num_updates 287477 | best_loss 3.168
2023-03-02 18:48:00 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 18:48:09 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint145.pt (epoch 145 @ 287477 updates, score 3.168) (writing took 8.922524656984024 seconds)
2023-03-02 18:48:09 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2023-03-02 18:48:09 | INFO | train | epoch 145 | loss 3.129 | nll_loss 0.986 | word_ins 2.812 | length 3.171 | ppl 8.75 | wps 200155 | ups 3.25 | wpb 61627.7 | bsz 1997.6 | num_updates 287477 | lr 0.000186508 | gnorm 0.851 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 18:48:09 | INFO | fairseq.trainer | begin training epoch 146
2023-03-02 18:48:25 | INFO | train_inner | epoch 146:     23 / 1983 loss=3.122, nll_loss=0.98, word_ins=2.807, length=3.148, ppl=8.7, wps=102201, ups=1.67, wpb=61153.2, bsz=2050.9, num_updates=287500, lr=0.000186501, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:48:54 | INFO | train_inner | epoch 146:    123 / 1983 loss=3.116, nll_loss=0.977, word_ins=2.804, length=3.12, ppl=8.67, wps=210983, ups=3.4, wpb=61965.6, bsz=2017.2, num_updates=287600, lr=0.000186469, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:49:23 | INFO | train_inner | epoch 146:    223 / 1983 loss=3.127, nll_loss=0.983, word_ins=2.809, length=3.173, ppl=8.73, wps=211654, ups=3.41, wpb=61998.2, bsz=1970.8, num_updates=287700, lr=0.000186436, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:49:52 | INFO | train_inner | epoch 146:    323 / 1983 loss=3.132, nll_loss=0.986, word_ins=2.812, length=3.2, ppl=8.76, wps=211936, ups=3.44, wpb=61572.5, bsz=1930.2, num_updates=287800, lr=0.000186404, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:50:22 | INFO | train_inner | epoch 146:    423 / 1983 loss=3.126, nll_loss=0.982, word_ins=2.809, length=3.171, ppl=8.73, wps=210049, ups=3.42, wpb=61455.3, bsz=1988, num_updates=287900, lr=0.000186371, gnorm=0.876, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:50:51 | INFO | train_inner | epoch 146:    523 / 1983 loss=3.138, nll_loss=0.991, word_ins=2.816, length=3.213, ppl=8.8, wps=211226, ups=3.44, wpb=61357.6, bsz=1941.9, num_updates=288000, lr=0.000186339, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:51:20 | INFO | train_inner | epoch 146:    623 / 1983 loss=3.145, nll_loss=0.996, word_ins=2.822, length=3.229, ppl=8.84, wps=208245, ups=3.42, wpb=60932, bsz=1902.1, num_updates=288100, lr=0.000186307, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:51:49 | INFO | train_inner | epoch 146:    723 / 1983 loss=3.13, nll_loss=0.993, word_ins=2.819, length=3.105, ppl=8.75, wps=210430, ups=3.4, wpb=61883.2, bsz=1966, num_updates=288200, lr=0.000186274, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:52:19 | INFO | train_inner | epoch 146:    823 / 1983 loss=3.101, nll_loss=0.961, word_ins=2.789, length=3.115, ppl=8.58, wps=210592, ups=3.42, wpb=61628.8, bsz=2145.6, num_updates=288300, lr=0.000186242, gnorm=0.83, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:52:48 | INFO | train_inner | epoch 146:    923 / 1983 loss=3.108, nll_loss=0.969, word_ins=2.796, length=3.114, ppl=8.62, wps=213350, ups=3.43, wpb=62260.8, bsz=1993.1, num_updates=288400, lr=0.00018621, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:53:17 | INFO | train_inner | epoch 146:   1023 / 1983 loss=3.128, nll_loss=0.984, word_ins=2.81, length=3.182, ppl=8.74, wps=208240, ups=3.4, wpb=61283.3, bsz=2046.1, num_updates=288500, lr=0.000186177, gnorm=0.873, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:53:47 | INFO | train_inner | epoch 146:   1123 / 1983 loss=3.101, nll_loss=0.962, word_ins=2.79, length=3.114, ppl=8.58, wps=209842, ups=3.39, wpb=61814.2, bsz=2124.8, num_updates=288600, lr=0.000186145, gnorm=0.822, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:54:16 | INFO | train_inner | epoch 146:   1223 / 1983 loss=3.113, nll_loss=0.972, word_ins=2.798, length=3.148, ppl=8.65, wps=211559, ups=3.42, wpb=61925.9, bsz=2014.1, num_updates=288700, lr=0.000186113, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:54:45 | INFO | train_inner | epoch 146:   1323 / 1983 loss=3.125, nll_loss=0.985, word_ins=2.811, length=3.145, ppl=8.72, wps=211530, ups=3.42, wpb=61768.9, bsz=1974.8, num_updates=288800, lr=0.000186081, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:55:15 | INFO | train_inner | epoch 146:   1423 / 1983 loss=3.14, nll_loss=1.002, word_ins=2.827, length=3.132, ppl=8.82, wps=210340, ups=3.41, wpb=61702.5, bsz=2011.8, num_updates=288900, lr=0.000186049, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:55:44 | INFO | train_inner | epoch 146:   1523 / 1983 loss=3.129, nll_loss=0.991, word_ins=2.815, length=3.134, ppl=8.75, wps=214013, ups=3.44, wpb=62177.9, bsz=1998.4, num_updates=289000, lr=0.000186016, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:56:13 | INFO | train_inner | epoch 146:   1623 / 1983 loss=3.137, nll_loss=0.995, word_ins=2.82, length=3.171, ppl=8.8, wps=211018, ups=3.44, wpb=61402.5, bsz=1973, num_updates=289100, lr=0.000185984, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:56:42 | INFO | train_inner | epoch 146:   1723 / 1983 loss=3.143, nll_loss=0.996, word_ins=2.821, length=3.228, ppl=8.84, wps=209252, ups=3.42, wpb=61159.4, bsz=1992, num_updates=289200, lr=0.000185952, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:57:11 | INFO | train_inner | epoch 146:   1823 / 1983 loss=3.117, nll_loss=0.972, word_ins=2.799, length=3.183, ppl=8.68, wps=212988, ups=3.44, wpb=61872.3, bsz=1983.2, num_updates=289300, lr=0.00018592, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:57:40 | INFO | train_inner | epoch 146:   1923 / 1983 loss=3.135, nll_loss=0.988, word_ins=2.813, length=3.216, ppl=8.78, wps=209420, ups=3.43, wpb=61084.8, bsz=2025.4, num_updates=289400, lr=0.000185888, gnorm=0.82, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 18:58:10 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 3.175 | nll_loss 0.962 | word_ins 2.848 | length 3.279 | ppl 9.03 | wps 79983.3 | wpb 41551 | bsz 1500 | num_updates 289460 | best_loss 3.168
2023-03-02 18:58:10 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 18:58:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint146.pt (epoch 146 @ 289460 updates, score 3.175) (writing took 5.474628965952434 seconds)
2023-03-02 18:58:16 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2023-03-02 18:58:16 | INFO | train | epoch 146 | loss 3.126 | nll_loss 0.984 | word_ins 2.81 | length 3.165 | ppl 8.73 | wps 201451 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 289460 | lr 0.000185868 | gnorm 0.848 | loss_scale 16384 | train_wall 577 | wall 0
2023-03-02 18:58:16 | INFO | fairseq.trainer | begin training epoch 147
2023-03-02 18:58:37 | INFO | train_inner | epoch 147:     40 / 1983 loss=3.114, nll_loss=0.973, word_ins=2.8, length=3.144, ppl=8.66, wps=108146, ups=1.76, wpb=61392.7, bsz=2020.2, num_updates=289500, lr=0.000185856, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:59:06 | INFO | train_inner | epoch 147:    140 / 1983 loss=3.137, nll_loss=0.995, word_ins=2.82, length=3.17, ppl=8.79, wps=213359, ups=3.45, wpb=61863, bsz=1872.9, num_updates=289600, lr=0.000185824, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 18:59:35 | INFO | train_inner | epoch 147:    240 / 1983 loss=3.111, nll_loss=0.97, word_ins=2.797, length=3.142, ppl=8.64, wps=209768, ups=3.42, wpb=61373.5, bsz=2082.7, num_updates=289700, lr=0.000185791, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:00:04 | INFO | train_inner | epoch 147:    340 / 1983 loss=3.122, nll_loss=0.979, word_ins=2.806, length=3.162, ppl=8.71, wps=211856, ups=3.42, wpb=61906.2, bsz=1958.7, num_updates=289800, lr=0.000185759, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:00:33 | INFO | train_inner | epoch 147:    440 / 1983 loss=3.131, nll_loss=0.981, word_ins=2.808, length=3.231, ppl=8.76, wps=212160, ups=3.45, wpb=61492, bsz=1913.4, num_updates=289900, lr=0.000185727, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:01:03 | INFO | train_inner | epoch 147:    540 / 1983 loss=3.143, nll_loss=0.992, word_ins=2.818, length=3.251, ppl=8.83, wps=209247, ups=3.43, wpb=60995.9, bsz=1921.4, num_updates=290000, lr=0.000185695, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:01:32 | INFO | train_inner | epoch 147:    640 / 1983 loss=3.127, nll_loss=0.983, word_ins=2.809, length=3.18, ppl=8.74, wps=210850, ups=3.44, wpb=61377.6, bsz=1975.1, num_updates=290100, lr=0.000185663, gnorm=0.839, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:02:01 | INFO | train_inner | epoch 147:    740 / 1983 loss=3.113, nll_loss=0.971, word_ins=2.798, length=3.156, ppl=8.65, wps=211985, ups=3.44, wpb=61651.3, bsz=2066.7, num_updates=290200, lr=0.000185631, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:02:30 | INFO | train_inner | epoch 147:    840 / 1983 loss=3.14, nll_loss=0.992, word_ins=2.818, length=3.218, ppl=8.81, wps=209948, ups=3.44, wpb=61106.8, bsz=1975.3, num_updates=290300, lr=0.000185599, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:02:59 | INFO | train_inner | epoch 147:    940 / 1983 loss=3.129, nll_loss=0.987, word_ins=2.812, length=3.169, ppl=8.75, wps=210207, ups=3.44, wpb=61138.3, bsz=2025.6, num_updates=290400, lr=0.000185567, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:03:28 | INFO | train_inner | epoch 147:   1040 / 1983 loss=3.126, nll_loss=0.984, word_ins=2.81, length=3.164, ppl=8.73, wps=210594, ups=3.42, wpb=61593.1, bsz=2063.8, num_updates=290500, lr=0.000185535, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:03:58 | INFO | train_inner | epoch 147:   1140 / 1983 loss=3.109, nll_loss=0.966, word_ins=2.794, length=3.152, ppl=8.63, wps=210632, ups=3.4, wpb=61881.5, bsz=2032.5, num_updates=290600, lr=0.000185504, gnorm=0.829, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:04:27 | INFO | train_inner | epoch 147:   1240 / 1983 loss=3.095, nll_loss=0.96, word_ins=2.788, length=3.076, ppl=8.55, wps=212837, ups=3.42, wpb=62151.3, bsz=2077.4, num_updates=290700, lr=0.000185472, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:04:56 | INFO | train_inner | epoch 147:   1340 / 1983 loss=3.122, nll_loss=0.988, word_ins=2.813, length=3.095, ppl=8.71, wps=210819, ups=3.43, wpb=61446.5, bsz=2075.1, num_updates=290800, lr=0.00018544, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:05:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 19:05:25 | INFO | train_inner | epoch 147:   1441 / 1983 loss=3.13, nll_loss=0.987, word_ins=2.813, length=3.174, ppl=8.75, wps=211150, ups=3.41, wpb=61949, bsz=1968.4, num_updates=290900, lr=0.000185408, gnorm=0.826, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:05:55 | INFO | train_inner | epoch 147:   1541 / 1983 loss=3.144, nll_loss=0.999, word_ins=2.824, length=3.206, ppl=8.84, wps=211649, ups=3.42, wpb=61933.8, bsz=1934.2, num_updates=291000, lr=0.000185376, gnorm=0.864, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:06:24 | INFO | train_inner | epoch 147:   1641 / 1983 loss=3.16, nll_loss=1.017, word_ins=2.84, length=3.201, ppl=8.94, wps=211280, ups=3.41, wpb=61900.7, bsz=1902.4, num_updates=291100, lr=0.000185344, gnorm=0.897, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:06:53 | INFO | train_inner | epoch 147:   1741 / 1983 loss=3.113, nll_loss=0.975, word_ins=2.802, length=3.109, ppl=8.65, wps=212181, ups=3.41, wpb=62285.1, bsz=2080.1, num_updates=291200, lr=0.000185312, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:07:22 | INFO | train_inner | epoch 147:   1841 / 1983 loss=3.13, nll_loss=0.985, word_ins=2.811, length=3.193, ppl=8.76, wps=210600, ups=3.42, wpb=61547.9, bsz=1987.1, num_updates=291300, lr=0.000185281, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:07:52 | INFO | train_inner | epoch 147:   1941 / 1983 loss=3.14, nll_loss=0.99, word_ins=2.815, length=3.249, ppl=8.82, wps=212084, ups=3.44, wpb=61693.8, bsz=1961, num_updates=291400, lr=0.000185249, gnorm=0.85, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 19:08:17 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 3.177 | nll_loss 0.966 | word_ins 2.852 | length 3.24 | ppl 9.04 | wps 81674 | wpb 41551 | bsz 1500 | num_updates 291442 | best_loss 3.168
2023-03-02 19:08:17 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 19:08:23 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint147.pt (epoch 147 @ 291442 updates, score 3.177) (writing took 5.590454248944297 seconds)
2023-03-02 19:08:23 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2023-03-02 19:08:23 | INFO | train | epoch 147 | loss 3.126 | nll_loss 0.983 | word_ins 2.809 | length 3.169 | ppl 8.73 | wps 201349 | ups 3.27 | wpb 61629.4 | bsz 1997.4 | num_updates 291442 | lr 0.000185235 | gnorm 0.849 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 19:08:23 | INFO | fairseq.trainer | begin training epoch 148
2023-03-02 19:08:50 | INFO | train_inner | epoch 148:     58 / 1983 loss=3.113, nll_loss=0.975, word_ins=2.802, length=3.106, ppl=8.65, wps=105095, ups=1.72, wpb=61112.2, bsz=1975.3, num_updates=291500, lr=0.000185217, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:09:19 | INFO | train_inner | epoch 148:    158 / 1983 loss=3.134, nll_loss=0.994, word_ins=2.819, length=3.146, ppl=8.78, wps=209372, ups=3.41, wpb=61350.5, bsz=1974.8, num_updates=291600, lr=0.000185185, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:09:48 | INFO | train_inner | epoch 148:    258 / 1983 loss=3.097, nll_loss=0.962, word_ins=2.791, length=3.068, ppl=8.56, wps=211563, ups=3.42, wpb=61853, bsz=2078.3, num_updates=291700, lr=0.000185153, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:10:17 | INFO | train_inner | epoch 148:    358 / 1983 loss=3.129, nll_loss=0.983, word_ins=2.809, length=3.203, ppl=8.75, wps=211488, ups=3.43, wpb=61601.3, bsz=1994.6, num_updates=291800, lr=0.000185122, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:10:47 | INFO | train_inner | epoch 148:    458 / 1983 loss=3.123, nll_loss=0.981, word_ins=2.807, length=3.161, ppl=8.71, wps=210241, ups=3.42, wpb=61395.1, bsz=1981.9, num_updates=291900, lr=0.00018509, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:11:16 | INFO | train_inner | epoch 148:    558 / 1983 loss=3.121, nll_loss=0.974, word_ins=2.801, length=3.199, ppl=8.7, wps=210577, ups=3.43, wpb=61339, bsz=1995.8, num_updates=292000, lr=0.000185058, gnorm=0.831, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:11:45 | INFO | train_inner | epoch 148:    658 / 1983 loss=3.126, nll_loss=0.98, word_ins=2.806, length=3.203, ppl=8.73, wps=211905, ups=3.45, wpb=61502.4, bsz=1924.9, num_updates=292100, lr=0.000185027, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:12:14 | INFO | train_inner | epoch 148:    758 / 1983 loss=3.097, nll_loss=0.96, word_ins=2.788, length=3.092, ppl=8.56, wps=212582, ups=3.42, wpb=62113.6, bsz=2064.9, num_updates=292200, lr=0.000184995, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:12:43 | INFO | train_inner | epoch 148:    858 / 1983 loss=3.117, nll_loss=0.977, word_ins=2.804, length=3.134, ppl=8.68, wps=211809, ups=3.43, wpb=61678.7, bsz=2008, num_updates=292300, lr=0.000184963, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:13:12 | INFO | train_inner | epoch 148:    958 / 1983 loss=3.104, nll_loss=0.965, word_ins=2.792, length=3.12, ppl=8.6, wps=211386, ups=3.42, wpb=61888, bsz=2065.6, num_updates=292400, lr=0.000184932, gnorm=0.836, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:13:42 | INFO | train_inner | epoch 148:   1058 / 1983 loss=3.103, nll_loss=0.964, word_ins=2.792, length=3.112, ppl=8.59, wps=212278, ups=3.43, wpb=61876.5, bsz=2029.3, num_updates=292500, lr=0.0001849, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:14:11 | INFO | train_inner | epoch 148:   1158 / 1983 loss=3.13, nll_loss=0.987, word_ins=2.813, length=3.177, ppl=8.76, wps=213117, ups=3.44, wpb=61969.7, bsz=1957.6, num_updates=292600, lr=0.000184868, gnorm=0.871, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:14:40 | INFO | train_inner | epoch 148:   1258 / 1983 loss=3.108, nll_loss=0.966, word_ins=2.793, length=3.148, ppl=8.62, wps=209849, ups=3.42, wpb=61440.2, bsz=2071.3, num_updates=292700, lr=0.000184837, gnorm=0.824, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:15:09 | INFO | train_inner | epoch 148:   1358 / 1983 loss=3.133, nll_loss=0.989, word_ins=2.814, length=3.185, ppl=8.77, wps=212532, ups=3.44, wpb=61821.3, bsz=1908.6, num_updates=292800, lr=0.000184805, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:15:38 | INFO | train_inner | epoch 148:   1458 / 1983 loss=3.121, nll_loss=0.978, word_ins=2.805, length=3.159, ppl=8.7, wps=210569, ups=3.42, wpb=61486.8, bsz=2016.1, num_updates=292900, lr=0.000184774, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:16:07 | INFO | train_inner | epoch 148:   1558 / 1983 loss=3.146, nll_loss=0.999, word_ins=2.824, length=3.216, ppl=8.85, wps=210008, ups=3.44, wpb=60965.7, bsz=1959.4, num_updates=293000, lr=0.000184742, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:16:36 | INFO | train_inner | epoch 148:   1658 / 1983 loss=3.138, nll_loss=0.995, word_ins=2.82, length=3.184, ppl=8.8, wps=209043, ups=3.42, wpb=61097, bsz=2038.4, num_updates=293100, lr=0.000184711, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:17:06 | INFO | train_inner | epoch 148:   1758 / 1983 loss=3.122, nll_loss=0.981, word_ins=2.807, length=3.149, ppl=8.71, wps=212303, ups=3.42, wpb=62163.9, bsz=2062, num_updates=293200, lr=0.000184679, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:17:35 | INFO | train_inner | epoch 148:   1858 / 1983 loss=3.146, nll_loss=1.007, word_ins=2.83, length=3.161, ppl=8.85, wps=211917, ups=3.41, wpb=62083.2, bsz=1942.5, num_updates=293300, lr=0.000184648, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:18:04 | INFO | train_inner | epoch 148:   1958 / 1983 loss=3.133, nll_loss=0.988, word_ins=2.813, length=3.194, ppl=8.77, wps=212223, ups=3.43, wpb=61876, bsz=1977.5, num_updates=293400, lr=0.000184616, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 19:18:24 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 3.21 | nll_loss 0.982 | word_ins 2.86 | length 3.507 | ppl 9.26 | wps 118154 | wpb 41551 | bsz 1500 | num_updates 293425 | best_loss 3.168
2023-03-02 19:18:24 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 19:18:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint148.pt (epoch 148 @ 293425 updates, score 3.21) (writing took 5.728999871993437 seconds)
2023-03-02 19:18:29 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2023-03-02 19:18:29 | INFO | train | epoch 148 | loss 3.123 | nll_loss 0.981 | word_ins 2.807 | length 3.158 | ppl 8.71 | wps 201404 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 293425 | lr 0.000184608 | gnorm 0.85 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 19:18:29 | INFO | fairseq.trainer | begin training epoch 149
2023-03-02 19:19:00 | INFO | train_inner | epoch 149:     75 / 1983 loss=3.138, nll_loss=0.989, word_ins=2.815, length=3.226, ppl=8.8, wps=108619, ups=1.78, wpb=61008.9, bsz=1921.7, num_updates=293500, lr=0.000184585, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:19:29 | INFO | train_inner | epoch 149:    175 / 1983 loss=3.121, nll_loss=0.979, word_ins=2.806, length=3.145, ppl=8.7, wps=211311, ups=3.44, wpb=61468.6, bsz=1991.6, num_updates=293600, lr=0.000184553, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:19:59 | INFO | train_inner | epoch 149:    275 / 1983 loss=3.123, nll_loss=0.98, word_ins=2.807, length=3.159, ppl=8.71, wps=210435, ups=3.43, wpb=61304.3, bsz=1974.8, num_updates=293700, lr=0.000184522, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:20:28 | INFO | train_inner | epoch 149:    375 / 1983 loss=3.122, nll_loss=0.979, word_ins=2.805, length=3.164, ppl=8.7, wps=211126, ups=3.43, wpb=61590.2, bsz=2021, num_updates=293800, lr=0.000184491, gnorm=0.844, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:20:57 | INFO | train_inner | epoch 149:    475 / 1983 loss=3.104, nll_loss=0.962, word_ins=2.79, length=3.137, ppl=8.6, wps=210264, ups=3.42, wpb=61439.6, bsz=2054.3, num_updates=293900, lr=0.000184459, gnorm=0.857, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:21:26 | INFO | train_inner | epoch 149:    575 / 1983 loss=3.102, nll_loss=0.963, word_ins=2.791, length=3.107, ppl=8.59, wps=210220, ups=3.41, wpb=61700, bsz=2031.9, num_updates=294000, lr=0.000184428, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:21:56 | INFO | train_inner | epoch 149:    675 / 1983 loss=3.135, nll_loss=0.989, word_ins=2.815, length=3.194, ppl=8.78, wps=210738, ups=3.43, wpb=61434.3, bsz=1945.9, num_updates=294100, lr=0.000184396, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:22:25 | INFO | train_inner | epoch 149:    775 / 1983 loss=3.113, nll_loss=0.971, word_ins=2.798, length=3.151, ppl=8.65, wps=211496, ups=3.42, wpb=61824.7, bsz=2032.2, num_updates=294200, lr=0.000184365, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:22:54 | INFO | train_inner | epoch 149:    875 / 1983 loss=3.15, nll_loss=1.001, word_ins=2.826, length=3.246, ppl=8.88, wps=211244, ups=3.44, wpb=61420.8, bsz=1861.4, num_updates=294300, lr=0.000184334, gnorm=0.905, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:23:23 | INFO | train_inner | epoch 149:    975 / 1983 loss=3.135, nll_loss=0.993, word_ins=2.818, length=3.174, ppl=8.79, wps=211530, ups=3.42, wpb=61879.9, bsz=1981.4, num_updates=294400, lr=0.000184302, gnorm=0.885, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:23:52 | INFO | train_inner | epoch 149:   1075 / 1983 loss=3.136, nll_loss=0.993, word_ins=2.818, length=3.179, ppl=8.79, wps=212165, ups=3.41, wpb=62225, bsz=1986.8, num_updates=294500, lr=0.000184271, gnorm=0.863, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:24:22 | INFO | train_inner | epoch 149:   1175 / 1983 loss=3.124, nll_loss=0.978, word_ins=2.805, length=3.197, ppl=8.72, wps=209001, ups=3.43, wpb=60985, bsz=1971.1, num_updates=294600, lr=0.00018424, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:24:51 | INFO | train_inner | epoch 149:   1275 / 1983 loss=3.111, nll_loss=0.969, word_ins=2.796, length=3.146, ppl=8.64, wps=211476, ups=3.43, wpb=61653.9, bsz=2002.2, num_updates=294700, lr=0.000184209, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:25:20 | INFO | train_inner | epoch 149:   1375 / 1983 loss=3.117, nll_loss=0.976, word_ins=2.803, length=3.142, ppl=8.68, wps=212422, ups=3.42, wpb=62059.9, bsz=1970.9, num_updates=294800, lr=0.000184177, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:25:49 | INFO | train_inner | epoch 149:   1475 / 1983 loss=3.135, nll_loss=0.994, word_ins=2.819, length=3.165, ppl=8.79, wps=212220, ups=3.42, wpb=61990.2, bsz=1947.3, num_updates=294900, lr=0.000184146, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:26:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 19:26:19 | INFO | train_inner | epoch 149:   1576 / 1983 loss=3.127, nll_loss=0.989, word_ins=2.815, length=3.124, ppl=8.74, wps=209112, ups=3.38, wpb=61804.2, bsz=1968.2, num_updates=295000, lr=0.000184115, gnorm=0.847, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:26:48 | INFO | train_inner | epoch 149:   1676 / 1983 loss=3.132, nll_loss=0.985, word_ins=2.811, length=3.21, ppl=8.77, wps=209492, ups=3.41, wpb=61348.8, bsz=2052.6, num_updates=295100, lr=0.000184084, gnorm=0.851, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:27:17 | INFO | train_inner | epoch 149:   1776 / 1983 loss=3.105, nll_loss=0.964, word_ins=2.791, length=3.142, ppl=8.61, wps=210606, ups=3.43, wpb=61422.6, bsz=2081.7, num_updates=295200, lr=0.000184053, gnorm=0.827, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:27:46 | INFO | train_inner | epoch 149:   1876 / 1983 loss=3.122, nll_loss=0.979, word_ins=2.805, length=3.171, ppl=8.71, wps=211781, ups=3.43, wpb=61726, bsz=2025.6, num_updates=295300, lr=0.000184021, gnorm=0.833, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:28:16 | INFO | train_inner | epoch 149:   1976 / 1983 loss=3.102, nll_loss=0.967, word_ins=2.794, length=3.085, ppl=8.59, wps=213070, ups=3.42, wpb=62219.1, bsz=2077, num_updates=295400, lr=0.00018399, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 19:28:31 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 3.157 | nll_loss 0.953 | word_ins 2.836 | length 3.206 | ppl 8.92 | wps 80986.9 | wpb 41551 | bsz 1500 | num_updates 295407 | best_loss 3.157
2023-03-02 19:28:31 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 19:28:40 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint149.pt (epoch 149 @ 295407 updates, score 3.157) (writing took 8.922386746038683 seconds)
2023-03-02 19:28:40 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2023-03-02 19:28:40 | INFO | train | epoch 149 | loss 3.122 | nll_loss 0.98 | word_ins 2.806 | length 3.161 | ppl 8.71 | wps 200050 | ups 3.25 | wpb 61627.5 | bsz 1997.6 | num_updates 295407 | lr 0.000183988 | gnorm 0.853 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 19:28:40 | INFO | fairseq.trainer | begin training epoch 150
2023-03-02 19:29:16 | INFO | train_inner | epoch 150:     93 / 1983 loss=3.107, nll_loss=0.966, word_ins=2.794, length=3.131, ppl=8.62, wps=100591, ups=1.65, wpb=61127.3, bsz=1998.4, num_updates=295500, lr=0.000183959, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:29:46 | INFO | train_inner | epoch 150:    193 / 1983 loss=3.112, nll_loss=0.966, word_ins=2.794, length=3.175, ppl=8.64, wps=210482, ups=3.43, wpb=61443, bsz=2028.3, num_updates=295600, lr=0.000183928, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:30:15 | INFO | train_inner | epoch 150:    293 / 1983 loss=3.109, nll_loss=0.972, word_ins=2.799, length=3.098, ppl=8.63, wps=210364, ups=3.41, wpb=61755.1, bsz=2049.9, num_updates=295700, lr=0.000183897, gnorm=0.842, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:30:44 | INFO | train_inner | epoch 150:    393 / 1983 loss=3.116, nll_loss=0.976, word_ins=2.803, length=3.129, ppl=8.67, wps=209926, ups=3.4, wpb=61681, bsz=2040.2, num_updates=295800, lr=0.000183866, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:31:14 | INFO | train_inner | epoch 150:    493 / 1983 loss=3.116, nll_loss=0.977, word_ins=2.804, length=3.13, ppl=8.67, wps=211980, ups=3.42, wpb=61976.2, bsz=1970.7, num_updates=295900, lr=0.000183835, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:31:43 | INFO | train_inner | epoch 150:    593 / 1983 loss=3.12, nll_loss=0.982, word_ins=2.808, length=3.118, ppl=8.69, wps=210850, ups=3.42, wpb=61724, bsz=2005.2, num_updates=296000, lr=0.000183804, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:32:12 | INFO | train_inner | epoch 150:    693 / 1983 loss=3.117, nll_loss=0.974, word_ins=2.801, length=3.161, ppl=8.68, wps=211328, ups=3.43, wpb=61633.2, bsz=1979.4, num_updates=296100, lr=0.000183773, gnorm=0.853, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:32:41 | INFO | train_inner | epoch 150:    793 / 1983 loss=3.116, nll_loss=0.975, word_ins=2.802, length=3.143, ppl=8.67, wps=212802, ups=3.45, wpb=61623.6, bsz=1971.6, num_updates=296200, lr=0.000183742, gnorm=0.825, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:33:10 | INFO | train_inner | epoch 150:    893 / 1983 loss=3.12, nll_loss=0.981, word_ins=2.806, length=3.14, ppl=8.7, wps=209744, ups=3.43, wpb=61203.4, bsz=2040.6, num_updates=296300, lr=0.000183711, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:33:39 | INFO | train_inner | epoch 150:    993 / 1983 loss=3.138, nll_loss=0.995, word_ins=2.82, length=3.184, ppl=8.8, wps=211109, ups=3.43, wpb=61565.4, bsz=1961.5, num_updates=296400, lr=0.00018368, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:34:09 | INFO | train_inner | epoch 150:   1093 / 1983 loss=3.151, nll_loss=1.004, word_ins=2.829, length=3.22, ppl=8.88, wps=209252, ups=3.41, wpb=61316, bsz=1951.2, num_updates=296500, lr=0.000183649, gnorm=0.889, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:34:38 | INFO | train_inner | epoch 150:   1193 / 1983 loss=3.111, nll_loss=0.971, word_ins=2.798, length=3.127, ppl=8.64, wps=211989, ups=3.43, wpb=61784.2, bsz=2096.1, num_updates=296600, lr=0.000183618, gnorm=0.845, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:35:07 | INFO | train_inner | epoch 150:   1293 / 1983 loss=3.124, nll_loss=0.981, word_ins=2.807, length=3.17, ppl=8.72, wps=211956, ups=3.43, wpb=61726.5, bsz=1992.7, num_updates=296700, lr=0.000183587, gnorm=0.866, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:35:36 | INFO | train_inner | epoch 150:   1393 / 1983 loss=3.133, nll_loss=0.99, word_ins=2.816, length=3.172, ppl=8.77, wps=212258, ups=3.42, wpb=61983.9, bsz=1953.1, num_updates=296800, lr=0.000183556, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:36:05 | INFO | train_inner | epoch 150:   1493 / 1983 loss=3.125, nll_loss=0.982, word_ins=2.808, length=3.165, ppl=8.72, wps=210422, ups=3.43, wpb=61413.2, bsz=2011.1, num_updates=296900, lr=0.000183525, gnorm=0.865, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:36:34 | INFO | train_inner | epoch 150:   1593 / 1983 loss=3.109, nll_loss=0.968, word_ins=2.795, length=3.145, ppl=8.63, wps=210778, ups=3.44, wpb=61330.6, bsz=2061.9, num_updates=297000, lr=0.000183494, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:37:03 | INFO | train_inner | epoch 150:   1693 / 1983 loss=3.136, nll_loss=0.988, word_ins=2.814, length=3.22, ppl=8.79, wps=212459, ups=3.43, wpb=61884.1, bsz=1940.6, num_updates=297100, lr=0.000183463, gnorm=0.89, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:37:32 | INFO | train_inner | epoch 150:   1793 / 1983 loss=3.143, nll_loss=0.995, word_ins=2.819, length=3.242, ppl=8.84, wps=213033, ups=3.45, wpb=61719.2, bsz=1883.1, num_updates=297200, lr=0.000183432, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:38:02 | INFO | train_inner | epoch 150:   1893 / 1983 loss=3.133, nll_loss=0.99, word_ins=2.815, length=3.18, ppl=8.77, wps=212098, ups=3.43, wpb=61842.9, bsz=1990.4, num_updates=297300, lr=0.000183401, gnorm=0.855, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 19:38:40 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 3.178 | nll_loss 0.972 | word_ins 2.853 | length 3.254 | ppl 9.05 | wps 118807 | wpb 41551 | bsz 1500 | num_updates 297390 | best_loss 3.157
2023-03-02 19:38:40 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 19:38:45 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint150.pt (epoch 150 @ 297390 updates, score 3.178) (writing took 5.539647149038501 seconds)
2023-03-02 19:38:46 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2023-03-02 19:38:46 | INFO | train | epoch 150 | loss 3.123 | nll_loss 0.981 | word_ins 2.807 | length 3.159 | ppl 8.71 | wps 201799 | ups 3.27 | wpb 61628.5 | bsz 1997.6 | num_updates 297390 | lr 0.000183374 | gnorm 0.853 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 19:38:46 | INFO | fairseq.trainer | begin training epoch 151
2023-03-02 19:38:59 | INFO | train_inner | epoch 151:     10 / 1983 loss=3.111, nll_loss=0.973, word_ins=2.8, length=3.109, ppl=8.64, wps=107522, ups=1.75, wpb=61578.8, bsz=2045.4, num_updates=297400, lr=0.000183371, gnorm=0.843, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:39:28 | INFO | train_inner | epoch 151:    110 / 1983 loss=3.111, nll_loss=0.973, word_ins=2.801, length=3.103, ppl=8.64, wps=211352, ups=3.4, wpb=62093.7, bsz=2042.2, num_updates=297500, lr=0.00018334, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:39:57 | INFO | train_inner | epoch 151:    210 / 1983 loss=3.112, nll_loss=0.969, word_ins=2.797, length=3.159, ppl=8.65, wps=211697, ups=3.44, wpb=61620, bsz=1996.3, num_updates=297600, lr=0.000183309, gnorm=0.84, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:40:27 | INFO | train_inner | epoch 151:    310 / 1983 loss=3.116, nll_loss=0.976, word_ins=2.803, length=3.138, ppl=8.67, wps=211290, ups=3.42, wpb=61834.3, bsz=2013.6, num_updates=297700, lr=0.000183278, gnorm=0.856, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:40:56 | INFO | train_inner | epoch 151:    410 / 1983 loss=3.106, nll_loss=0.967, word_ins=2.795, length=3.112, ppl=8.61, wps=211357, ups=3.42, wpb=61752.7, bsz=1989.7, num_updates=297800, lr=0.000183247, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:41:25 | INFO | train_inner | epoch 151:    510 / 1983 loss=3.125, nll_loss=0.981, word_ins=2.808, length=3.167, ppl=8.72, wps=210772, ups=3.43, wpb=61512.6, bsz=2017.7, num_updates=297900, lr=0.000183217, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:41:54 | INFO | train_inner | epoch 151:    610 / 1983 loss=3.136, nll_loss=0.994, word_ins=2.819, length=3.174, ppl=8.79, wps=212671, ups=3.44, wpb=61745.9, bsz=1961.7, num_updates=298000, lr=0.000183186, gnorm=0.868, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:42:23 | INFO | train_inner | epoch 151:    710 / 1983 loss=3.172, nll_loss=1.025, word_ins=2.847, length=3.248, ppl=9.01, wps=208814, ups=3.43, wpb=60845.7, bsz=1916.2, num_updates=298100, lr=0.000183155, gnorm=0.869, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:42:52 | INFO | train_inner | epoch 151:    810 / 1983 loss=3.115, nll_loss=0.972, word_ins=2.799, length=3.162, ppl=8.66, wps=211598, ups=3.44, wpb=61598.9, bsz=2014.9, num_updates=298200, lr=0.000183124, gnorm=0.87, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:43:21 | INFO | train_inner | epoch 151:    910 / 1983 loss=3.11, nll_loss=0.968, word_ins=2.795, length=3.149, ppl=8.64, wps=212785, ups=3.44, wpb=61874.1, bsz=2044.4, num_updates=298300, lr=0.000183094, gnorm=0.838, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:43:51 | INFO | train_inner | epoch 151:   1010 / 1983 loss=3.103, nll_loss=0.963, word_ins=2.79, length=3.121, ppl=8.59, wps=212622, ups=3.43, wpb=62057.1, bsz=2043.8, num_updates=298400, lr=0.000183063, gnorm=0.837, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:44:20 | INFO | train_inner | epoch 151:   1110 / 1983 loss=3.119, nll_loss=0.98, word_ins=2.806, length=3.132, ppl=8.69, wps=211154, ups=3.42, wpb=61660.9, bsz=2018, num_updates=298500, lr=0.000183032, gnorm=0.854, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:44:49 | INFO | train_inner | epoch 151:   1210 / 1983 loss=3.119, nll_loss=0.979, word_ins=2.805, length=3.134, ppl=8.69, wps=212145, ups=3.43, wpb=61905.8, bsz=1985.1, num_updates=298600, lr=0.000183002, gnorm=0.846, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:45:18 | INFO | train_inner | epoch 151:   1310 / 1983 loss=3.128, nll_loss=0.985, word_ins=2.811, length=3.166, ppl=8.74, wps=210536, ups=3.42, wpb=61593.6, bsz=1979.1, num_updates=298700, lr=0.000182971, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:45:47 | INFO | train_inner | epoch 151:   1410 / 1983 loss=3.139, nll_loss=0.992, word_ins=2.817, length=3.215, ppl=8.81, wps=209942, ups=3.44, wpb=61008.9, bsz=1962.9, num_updates=298800, lr=0.00018294, gnorm=0.852, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:46:16 | INFO | train_inner | epoch 151:   1510 / 1983 loss=3.117, nll_loss=0.974, word_ins=2.8, length=3.169, ppl=8.68, wps=212469, ups=3.44, wpb=61732.6, bsz=2050, num_updates=298900, lr=0.00018291, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:46:46 | INFO | train_inner | epoch 151:   1610 / 1983 loss=3.119, nll_loss=0.976, word_ins=2.803, length=3.164, ppl=8.69, wps=210050, ups=3.43, wpb=61160.3, bsz=2009, num_updates=299000, lr=0.000182879, gnorm=0.848, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:47:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16384.0
2023-03-02 19:47:15 | INFO | train_inner | epoch 151:   1711 / 1983 loss=3.124, nll_loss=0.981, word_ins=2.807, length=3.175, ppl=8.72, wps=208970, ups=3.4, wpb=61411.7, bsz=1985.5, num_updates=299100, lr=0.000182849, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:47:44 | INFO | train_inner | epoch 151:   1811 / 1983 loss=3.137, nll_loss=0.994, word_ins=2.819, length=3.188, ppl=8.8, wps=211719, ups=3.43, wpb=61790.3, bsz=1918.6, num_updates=299200, lr=0.000182818, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:48:13 | INFO | train_inner | epoch 151:   1911 / 1983 loss=3.11, nll_loss=0.97, word_ins=2.797, length=3.132, ppl=8.63, wps=211876, ups=3.41, wpb=62062.3, bsz=2026.3, num_updates=299300, lr=0.000182788, gnorm=0.861, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 19:48:46 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 3.182 | nll_loss 0.976 | word_ins 2.857 | length 3.242 | ppl 9.07 | wps 136570 | wpb 41551 | bsz 1500 | num_updates 299372 | best_loss 3.157
2023-03-02 19:48:46 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 19:48:52 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint151.pt (epoch 151 @ 299372 updates, score 3.182) (writing took 5.689454487990588 seconds)
2023-03-02 19:48:52 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2023-03-02 19:48:52 | INFO | train | epoch 151 | loss 3.122 | nll_loss 0.98 | word_ins 2.806 | length 3.161 | ppl 8.71 | wps 201504 | ups 3.27 | wpb 61628.8 | bsz 1997.9 | num_updates 299372 | lr 0.000182766 | gnorm 0.855 | loss_scale 16384 | train_wall 576 | wall 0
2023-03-02 19:48:52 | INFO | fairseq.trainer | begin training epoch 152
2023-03-02 19:49:09 | INFO | train_inner | epoch 152:     28 / 1983 loss=3.118, nll_loss=0.972, word_ins=2.799, length=3.186, ppl=8.68, wps=109976, ups=1.8, wpb=61170.8, bsz=1960.7, num_updates=299400, lr=0.000182757, gnorm=0.859, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:49:38 | INFO | train_inner | epoch 152:    128 / 1983 loss=3.084, nll_loss=0.95, word_ins=2.779, length=3.054, ppl=8.48, wps=210661, ups=3.41, wpb=61809.7, bsz=2066.6, num_updates=299500, lr=0.000182727, gnorm=0.834, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:50:08 | INFO | train_inner | epoch 152:    228 / 1983 loss=3.099, nll_loss=0.958, word_ins=2.786, length=3.126, ppl=8.57, wps=212022, ups=3.42, wpb=61979.3, bsz=2038.2, num_updates=299600, lr=0.000182696, gnorm=0.841, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:50:37 | INFO | train_inner | epoch 152:    328 / 1983 loss=3.104, nll_loss=0.965, word_ins=2.793, length=3.118, ppl=8.6, wps=213452, ups=3.43, wpb=62308.2, bsz=2002.5, num_updates=299700, lr=0.000182666, gnorm=0.849, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:51:06 | INFO | train_inner | epoch 152:    428 / 1983 loss=3.112, nll_loss=0.968, word_ins=2.795, length=3.166, ppl=8.64, wps=212142, ups=3.44, wpb=61610.6, bsz=2012.7, num_updates=299800, lr=0.000182635, gnorm=0.858, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:51:35 | INFO | train_inner | epoch 152:    528 / 1983 loss=3.13, nll_loss=0.988, word_ins=2.814, length=3.156, ppl=8.75, wps=211784, ups=3.42, wpb=61934.3, bsz=1953.9, num_updates=299900, lr=0.000182605, gnorm=0.835, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:52:04 | INFO | train_inner | epoch 152:    628 / 1983 loss=3.138, nll_loss=0.991, word_ins=2.816, length=3.222, ppl=8.8, wps=211450, ups=3.44, wpb=61408.2, bsz=1913.3, num_updates=300000, lr=0.000182574, gnorm=0.86, loss_scale=16384, train_wall=29, wall=0
2023-03-02 19:52:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-03-02 19:52:18 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 3.199 | nll_loss 0.986 | word_ins 2.871 | length 3.286 | ppl 9.18 | wps 105042 | wpb 41551 | bsz 1500 | num_updates 300000 | best_loss 3.157
2023-03-02 19:52:18 | INFO | fairseq_cli.train | begin save checkpoint
2023-03-02 19:52:21 | INFO | fairseq.checkpoint_utils | saved checkpoint /mnt/petrelfs/jiangshuyang/checkpoints/WMTende_distill_CMLMC_L5D3_300k_abc_decoder_causalself/checkpoint_last.pt (epoch 152 @ 300000 updates, score 3.199) (writing took 3.1385237158974633 seconds)
2023-03-02 19:52:21 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2023-03-02 19:52:21 | INFO | train | epoch 152 | loss 3.11 | nll_loss 0.969 | word_ins 2.797 | length 3.137 | ppl 8.64 | wps 185596 | ups 3 | wpb 61832.8 | bsz 1998.4 | num_updates 300000 | lr 0.000182574 | gnorm 0.846 | loss_scale 16384 | train_wall 183 | wall 0
2023-03-02 19:52:21 | INFO | fairseq_cli.train | done training in 79650.1 seconds
